/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
/******/ (() => { // webpackBootstrap
/******/ 	var __webpack_modules__ = ({

/***/ "./node_modules/@msgpack/msgpack/dist.es5+esm/CachedKeyDecoder.mjs":
/*!*************************************************************************!*\
  !*** ./node_modules/@msgpack/msgpack/dist.es5+esm/CachedKeyDecoder.mjs ***!
  \*************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   CachedKeyDecoder: () => (/* binding */ CachedKeyDecoder)\n/* harmony export */ });\n/* harmony import */ var _utils_utf8_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./utils/utf8.mjs */ \"./node_modules/@msgpack/msgpack/dist.es5+esm/utils/utf8.mjs\");\n\nvar DEFAULT_MAX_KEY_LENGTH = 16;\nvar DEFAULT_MAX_LENGTH_PER_KEY = 16;\nvar CachedKeyDecoder = /** @class */ (function () {\n    function CachedKeyDecoder(maxKeyLength, maxLengthPerKey) {\n        if (maxKeyLength === void 0) { maxKeyLength = DEFAULT_MAX_KEY_LENGTH; }\n        if (maxLengthPerKey === void 0) { maxLengthPerKey = DEFAULT_MAX_LENGTH_PER_KEY; }\n        this.maxKeyLength = maxKeyLength;\n        this.maxLengthPerKey = maxLengthPerKey;\n        this.hit = 0;\n        this.miss = 0;\n        // avoid `new Array(N)`, which makes a sparse array,\n        // because a sparse array is typically slower than a non-sparse array.\n        this.caches = [];\n        for (var i = 0; i < this.maxKeyLength; i++) {\n            this.caches.push([]);\n        }\n    }\n    CachedKeyDecoder.prototype.canBeCached = function (byteLength) {\n        return byteLength > 0 && byteLength <= this.maxKeyLength;\n    };\n    CachedKeyDecoder.prototype.find = function (bytes, inputOffset, byteLength) {\n        var records = this.caches[byteLength - 1];\n        FIND_CHUNK: for (var _i = 0, records_1 = records; _i < records_1.length; _i++) {\n            var record = records_1[_i];\n            var recordBytes = record.bytes;\n            for (var j = 0; j < byteLength; j++) {\n                if (recordBytes[j] !== bytes[inputOffset + j]) {\n                    continue FIND_CHUNK;\n                }\n            }\n            return record.str;\n        }\n        return null;\n    };\n    CachedKeyDecoder.prototype.store = function (bytes, value) {\n        var records = this.caches[bytes.length - 1];\n        var record = { bytes: bytes, str: value };\n        if (records.length >= this.maxLengthPerKey) {\n            // `records` are full!\n            // Set `record` to an arbitrary position.\n            records[(Math.random() * records.length) | 0] = record;\n        }\n        else {\n            records.push(record);\n        }\n    };\n    CachedKeyDecoder.prototype.decode = function (bytes, inputOffset, byteLength) {\n        var cachedValue = this.find(bytes, inputOffset, byteLength);\n        if (cachedValue != null) {\n            this.hit++;\n            return cachedValue;\n        }\n        this.miss++;\n        var str = (0,_utils_utf8_mjs__WEBPACK_IMPORTED_MODULE_0__.utf8DecodeJs)(bytes, inputOffset, byteLength);\n        // Ensure to copy a slice of bytes because the byte may be NodeJS Buffer and Buffer#slice() returns a reference to its internal ArrayBuffer.\n        var slicedCopyOfBytes = Uint8Array.prototype.slice.call(bytes, inputOffset, inputOffset + byteLength);\n        this.store(slicedCopyOfBytes, str);\n        return str;\n    };\n    return CachedKeyDecoder;\n}());\n\n//# sourceMappingURL=CachedKeyDecoder.mjs.map\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/@msgpack/msgpack/dist.es5+esm/CachedKeyDecoder.mjs?\n}");

/***/ }),

/***/ "./node_modules/@msgpack/msgpack/dist.es5+esm/DecodeError.mjs":
/*!********************************************************************!*\
  !*** ./node_modules/@msgpack/msgpack/dist.es5+esm/DecodeError.mjs ***!
  \********************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   DecodeError: () => (/* binding */ DecodeError)\n/* harmony export */ });\nvar __extends = (undefined && undefined.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        if (typeof b !== \"function\" && b !== null)\n            throw new TypeError(\"Class extends value \" + String(b) + \" is not a constructor or null\");\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar DecodeError = /** @class */ (function (_super) {\n    __extends(DecodeError, _super);\n    function DecodeError(message) {\n        var _this = _super.call(this, message) || this;\n        // fix the prototype chain in a cross-platform way\n        var proto = Object.create(DecodeError.prototype);\n        Object.setPrototypeOf(_this, proto);\n        Object.defineProperty(_this, \"name\", {\n            configurable: true,\n            enumerable: false,\n            value: DecodeError.name,\n        });\n        return _this;\n    }\n    return DecodeError;\n}(Error));\n\n//# sourceMappingURL=DecodeError.mjs.map\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/@msgpack/msgpack/dist.es5+esm/DecodeError.mjs?\n}");

/***/ }),

/***/ "./node_modules/@msgpack/msgpack/dist.es5+esm/Decoder.mjs":
/*!****************************************************************!*\
  !*** ./node_modules/@msgpack/msgpack/dist.es5+esm/Decoder.mjs ***!
  \****************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   DataViewIndexOutOfBoundsError: () => (/* binding */ DataViewIndexOutOfBoundsError),\n/* harmony export */   Decoder: () => (/* binding */ Decoder)\n/* harmony export */ });\n/* harmony import */ var _utils_prettyByte_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./utils/prettyByte.mjs */ \"./node_modules/@msgpack/msgpack/dist.es5+esm/utils/prettyByte.mjs\");\n/* harmony import */ var _ExtensionCodec_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ExtensionCodec.mjs */ \"./node_modules/@msgpack/msgpack/dist.es5+esm/ExtensionCodec.mjs\");\n/* harmony import */ var _utils_int_mjs__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./utils/int.mjs */ \"./node_modules/@msgpack/msgpack/dist.es5+esm/utils/int.mjs\");\n/* harmony import */ var _utils_utf8_mjs__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./utils/utf8.mjs */ \"./node_modules/@msgpack/msgpack/dist.es5+esm/utils/utf8.mjs\");\n/* harmony import */ var _utils_typedArrays_mjs__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./utils/typedArrays.mjs */ \"./node_modules/@msgpack/msgpack/dist.es5+esm/utils/typedArrays.mjs\");\n/* harmony import */ var _CachedKeyDecoder_mjs__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./CachedKeyDecoder.mjs */ \"./node_modules/@msgpack/msgpack/dist.es5+esm/CachedKeyDecoder.mjs\");\n/* harmony import */ var _DecodeError_mjs__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./DecodeError.mjs */ \"./node_modules/@msgpack/msgpack/dist.es5+esm/DecodeError.mjs\");\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (undefined && undefined.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nvar __asyncValues = (undefined && undefined.__asyncValues) || function (o) {\n    if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\n    var m = o[Symbol.asyncIterator], i;\n    return m ? m.call(o) : (o = typeof __values === \"function\" ? __values(o) : o[Symbol.iterator](), i = {}, verb(\"next\"), verb(\"throw\"), verb(\"return\"), i[Symbol.asyncIterator] = function () { return this; }, i);\n    function verb(n) { i[n] = o[n] && function (v) { return new Promise(function (resolve, reject) { v = o[n](v), settle(resolve, reject, v.done, v.value); }); }; }\n    function settle(resolve, reject, d, v) { Promise.resolve(v).then(function(v) { resolve({ value: v, done: d }); }, reject); }\n};\nvar __await = (undefined && undefined.__await) || function (v) { return this instanceof __await ? (this.v = v, this) : new __await(v); }\nvar __asyncGenerator = (undefined && undefined.__asyncGenerator) || function (thisArg, _arguments, generator) {\n    if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\n    var g = generator.apply(thisArg, _arguments || []), i, q = [];\n    return i = {}, verb(\"next\"), verb(\"throw\"), verb(\"return\"), i[Symbol.asyncIterator] = function () { return this; }, i;\n    function verb(n) { if (g[n]) i[n] = function (v) { return new Promise(function (a, b) { q.push([n, v, a, b]) > 1 || resume(n, v); }); }; }\n    function resume(n, v) { try { step(g[n](v)); } catch (e) { settle(q[0][3], e); } }\n    function step(r) { r.value instanceof __await ? Promise.resolve(r.value.v).then(fulfill, reject) : settle(q[0][2], r); }\n    function fulfill(value) { resume(\"next\", value); }\n    function reject(value) { resume(\"throw\", value); }\n    function settle(f, v) { if (f(v), q.shift(), q.length) resume(q[0][0], q[0][1]); }\n};\n\n\n\n\n\n\n\nvar isValidMapKeyType = function (key) {\n    var keyType = typeof key;\n    return keyType === \"string\" || keyType === \"number\";\n};\nvar HEAD_BYTE_REQUIRED = -1;\nvar EMPTY_VIEW = new DataView(new ArrayBuffer(0));\nvar EMPTY_BYTES = new Uint8Array(EMPTY_VIEW.buffer);\n// IE11: Hack to support IE11.\n// IE11: Drop this hack and just use RangeError when IE11 is obsolete.\nvar DataViewIndexOutOfBoundsError = (function () {\n    try {\n        // IE11: The spec says it should throw RangeError,\n        // IE11: but in IE11 it throws TypeError.\n        EMPTY_VIEW.getInt8(0);\n    }\n    catch (e) {\n        return e.constructor;\n    }\n    throw new Error(\"never reached\");\n})();\nvar MORE_DATA = new DataViewIndexOutOfBoundsError(\"Insufficient data\");\nvar sharedCachedKeyDecoder = new _CachedKeyDecoder_mjs__WEBPACK_IMPORTED_MODULE_5__.CachedKeyDecoder();\nvar Decoder = /** @class */ (function () {\n    function Decoder(extensionCodec, context, maxStrLength, maxBinLength, maxArrayLength, maxMapLength, maxExtLength, keyDecoder) {\n        if (extensionCodec === void 0) { extensionCodec = _ExtensionCodec_mjs__WEBPACK_IMPORTED_MODULE_1__.ExtensionCodec.defaultCodec; }\n        if (context === void 0) { context = undefined; }\n        if (maxStrLength === void 0) { maxStrLength = _utils_int_mjs__WEBPACK_IMPORTED_MODULE_2__.UINT32_MAX; }\n        if (maxBinLength === void 0) { maxBinLength = _utils_int_mjs__WEBPACK_IMPORTED_MODULE_2__.UINT32_MAX; }\n        if (maxArrayLength === void 0) { maxArrayLength = _utils_int_mjs__WEBPACK_IMPORTED_MODULE_2__.UINT32_MAX; }\n        if (maxMapLength === void 0) { maxMapLength = _utils_int_mjs__WEBPACK_IMPORTED_MODULE_2__.UINT32_MAX; }\n        if (maxExtLength === void 0) { maxExtLength = _utils_int_mjs__WEBPACK_IMPORTED_MODULE_2__.UINT32_MAX; }\n        if (keyDecoder === void 0) { keyDecoder = sharedCachedKeyDecoder; }\n        this.extensionCodec = extensionCodec;\n        this.context = context;\n        this.maxStrLength = maxStrLength;\n        this.maxBinLength = maxBinLength;\n        this.maxArrayLength = maxArrayLength;\n        this.maxMapLength = maxMapLength;\n        this.maxExtLength = maxExtLength;\n        this.keyDecoder = keyDecoder;\n        this.totalPos = 0;\n        this.pos = 0;\n        this.view = EMPTY_VIEW;\n        this.bytes = EMPTY_BYTES;\n        this.headByte = HEAD_BYTE_REQUIRED;\n        this.stack = [];\n    }\n    Decoder.prototype.reinitializeState = function () {\n        this.totalPos = 0;\n        this.headByte = HEAD_BYTE_REQUIRED;\n        this.stack.length = 0;\n        // view, bytes, and pos will be re-initialized in setBuffer()\n    };\n    Decoder.prototype.setBuffer = function (buffer) {\n        this.bytes = (0,_utils_typedArrays_mjs__WEBPACK_IMPORTED_MODULE_4__.ensureUint8Array)(buffer);\n        this.view = (0,_utils_typedArrays_mjs__WEBPACK_IMPORTED_MODULE_4__.createDataView)(this.bytes);\n        this.pos = 0;\n    };\n    Decoder.prototype.appendBuffer = function (buffer) {\n        if (this.headByte === HEAD_BYTE_REQUIRED && !this.hasRemaining(1)) {\n            this.setBuffer(buffer);\n        }\n        else {\n            var remainingData = this.bytes.subarray(this.pos);\n            var newData = (0,_utils_typedArrays_mjs__WEBPACK_IMPORTED_MODULE_4__.ensureUint8Array)(buffer);\n            // concat remainingData + newData\n            var newBuffer = new Uint8Array(remainingData.length + newData.length);\n            newBuffer.set(remainingData);\n            newBuffer.set(newData, remainingData.length);\n            this.setBuffer(newBuffer);\n        }\n    };\n    Decoder.prototype.hasRemaining = function (size) {\n        return this.view.byteLength - this.pos >= size;\n    };\n    Decoder.prototype.createExtraByteError = function (posToShow) {\n        var _a = this, view = _a.view, pos = _a.pos;\n        return new RangeError(\"Extra \".concat(view.byteLength - pos, \" of \").concat(view.byteLength, \" byte(s) found at buffer[\").concat(posToShow, \"]\"));\n    };\n    /**\n     * @throws {@link DecodeError}\n     * @throws {@link RangeError}\n     */\n    Decoder.prototype.decode = function (buffer) {\n        this.reinitializeState();\n        this.setBuffer(buffer);\n        var object = this.doDecodeSync();\n        if (this.hasRemaining(1)) {\n            throw this.createExtraByteError(this.pos);\n        }\n        return object;\n    };\n    Decoder.prototype.decodeMulti = function (buffer) {\n        return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0:\n                    this.reinitializeState();\n                    this.setBuffer(buffer);\n                    _a.label = 1;\n                case 1:\n                    if (!this.hasRemaining(1)) return [3 /*break*/, 3];\n                    return [4 /*yield*/, this.doDecodeSync()];\n                case 2:\n                    _a.sent();\n                    return [3 /*break*/, 1];\n                case 3: return [2 /*return*/];\n            }\n        });\n    };\n    Decoder.prototype.decodeAsync = function (stream) {\n        var stream_1, stream_1_1;\n        var e_1, _a;\n        return __awaiter(this, void 0, void 0, function () {\n            var decoded, object, buffer, e_1_1, _b, headByte, pos, totalPos;\n            return __generator(this, function (_c) {\n                switch (_c.label) {\n                    case 0:\n                        decoded = false;\n                        _c.label = 1;\n                    case 1:\n                        _c.trys.push([1, 6, 7, 12]);\n                        stream_1 = __asyncValues(stream);\n                        _c.label = 2;\n                    case 2: return [4 /*yield*/, stream_1.next()];\n                    case 3:\n                        if (!(stream_1_1 = _c.sent(), !stream_1_1.done)) return [3 /*break*/, 5];\n                        buffer = stream_1_1.value;\n                        if (decoded) {\n                            throw this.createExtraByteError(this.totalPos);\n                        }\n                        this.appendBuffer(buffer);\n                        try {\n                            object = this.doDecodeSync();\n                            decoded = true;\n                        }\n                        catch (e) {\n                            if (!(e instanceof DataViewIndexOutOfBoundsError)) {\n                                throw e; // rethrow\n                            }\n                            // fallthrough\n                        }\n                        this.totalPos += this.pos;\n                        _c.label = 4;\n                    case 4: return [3 /*break*/, 2];\n                    case 5: return [3 /*break*/, 12];\n                    case 6:\n                        e_1_1 = _c.sent();\n                        e_1 = { error: e_1_1 };\n                        return [3 /*break*/, 12];\n                    case 7:\n                        _c.trys.push([7, , 10, 11]);\n                        if (!(stream_1_1 && !stream_1_1.done && (_a = stream_1.return))) return [3 /*break*/, 9];\n                        return [4 /*yield*/, _a.call(stream_1)];\n                    case 8:\n                        _c.sent();\n                        _c.label = 9;\n                    case 9: return [3 /*break*/, 11];\n                    case 10:\n                        if (e_1) throw e_1.error;\n                        return [7 /*endfinally*/];\n                    case 11: return [7 /*endfinally*/];\n                    case 12:\n                        if (decoded) {\n                            if (this.hasRemaining(1)) {\n                                throw this.createExtraByteError(this.totalPos);\n                            }\n                            return [2 /*return*/, object];\n                        }\n                        _b = this, headByte = _b.headByte, pos = _b.pos, totalPos = _b.totalPos;\n                        throw new RangeError(\"Insufficient data in parsing \".concat((0,_utils_prettyByte_mjs__WEBPACK_IMPORTED_MODULE_0__.prettyByte)(headByte), \" at \").concat(totalPos, \" (\").concat(pos, \" in the current buffer)\"));\n                }\n            });\n        });\n    };\n    Decoder.prototype.decodeArrayStream = function (stream) {\n        return this.decodeMultiAsync(stream, true);\n    };\n    Decoder.prototype.decodeStream = function (stream) {\n        return this.decodeMultiAsync(stream, false);\n    };\n    Decoder.prototype.decodeMultiAsync = function (stream, isArray) {\n        return __asyncGenerator(this, arguments, function decodeMultiAsync_1() {\n            var isArrayHeaderRequired, arrayItemsLeft, stream_2, stream_2_1, buffer, e_2, e_3_1;\n            var e_3, _a;\n            return __generator(this, function (_b) {\n                switch (_b.label) {\n                    case 0:\n                        isArrayHeaderRequired = isArray;\n                        arrayItemsLeft = -1;\n                        _b.label = 1;\n                    case 1:\n                        _b.trys.push([1, 13, 14, 19]);\n                        stream_2 = __asyncValues(stream);\n                        _b.label = 2;\n                    case 2: return [4 /*yield*/, __await(stream_2.next())];\n                    case 3:\n                        if (!(stream_2_1 = _b.sent(), !stream_2_1.done)) return [3 /*break*/, 12];\n                        buffer = stream_2_1.value;\n                        if (isArray && arrayItemsLeft === 0) {\n                            throw this.createExtraByteError(this.totalPos);\n                        }\n                        this.appendBuffer(buffer);\n                        if (isArrayHeaderRequired) {\n                            arrayItemsLeft = this.readArraySize();\n                            isArrayHeaderRequired = false;\n                            this.complete();\n                        }\n                        _b.label = 4;\n                    case 4:\n                        _b.trys.push([4, 9, , 10]);\n                        _b.label = 5;\n                    case 5:\n                        if (false) // removed by dead control flow\n{}\n                        return [4 /*yield*/, __await(this.doDecodeSync())];\n                    case 6: return [4 /*yield*/, _b.sent()];\n                    case 7:\n                        _b.sent();\n                        if (--arrayItemsLeft === 0) {\n                            return [3 /*break*/, 8];\n                        }\n                        return [3 /*break*/, 5];\n                    case 8: return [3 /*break*/, 10];\n                    case 9:\n                        e_2 = _b.sent();\n                        if (!(e_2 instanceof DataViewIndexOutOfBoundsError)) {\n                            throw e_2; // rethrow\n                        }\n                        return [3 /*break*/, 10];\n                    case 10:\n                        this.totalPos += this.pos;\n                        _b.label = 11;\n                    case 11: return [3 /*break*/, 2];\n                    case 12: return [3 /*break*/, 19];\n                    case 13:\n                        e_3_1 = _b.sent();\n                        e_3 = { error: e_3_1 };\n                        return [3 /*break*/, 19];\n                    case 14:\n                        _b.trys.push([14, , 17, 18]);\n                        if (!(stream_2_1 && !stream_2_1.done && (_a = stream_2.return))) return [3 /*break*/, 16];\n                        return [4 /*yield*/, __await(_a.call(stream_2))];\n                    case 15:\n                        _b.sent();\n                        _b.label = 16;\n                    case 16: return [3 /*break*/, 18];\n                    case 17:\n                        if (e_3) throw e_3.error;\n                        return [7 /*endfinally*/];\n                    case 18: return [7 /*endfinally*/];\n                    case 19: return [2 /*return*/];\n                }\n            });\n        });\n    };\n    Decoder.prototype.doDecodeSync = function () {\n        DECODE: while (true) {\n            var headByte = this.readHeadByte();\n            var object = void 0;\n            if (headByte >= 0xe0) {\n                // negative fixint (111x xxxx) 0xe0 - 0xff\n                object = headByte - 0x100;\n            }\n            else if (headByte < 0xc0) {\n                if (headByte < 0x80) {\n                    // positive fixint (0xxx xxxx) 0x00 - 0x7f\n                    object = headByte;\n                }\n                else if (headByte < 0x90) {\n                    // fixmap (1000 xxxx) 0x80 - 0x8f\n                    var size = headByte - 0x80;\n                    if (size !== 0) {\n                        this.pushMapState(size);\n                        this.complete();\n                        continue DECODE;\n                    }\n                    else {\n                        object = {};\n                    }\n                }\n                else if (headByte < 0xa0) {\n                    // fixarray (1001 xxxx) 0x90 - 0x9f\n                    var size = headByte - 0x90;\n                    if (size !== 0) {\n                        this.pushArrayState(size);\n                        this.complete();\n                        continue DECODE;\n                    }\n                    else {\n                        object = [];\n                    }\n                }\n                else {\n                    // fixstr (101x xxxx) 0xa0 - 0xbf\n                    var byteLength = headByte - 0xa0;\n                    object = this.decodeUtf8String(byteLength, 0);\n                }\n            }\n            else if (headByte === 0xc0) {\n                // nil\n                object = null;\n            }\n            else if (headByte === 0xc2) {\n                // false\n                object = false;\n            }\n            else if (headByte === 0xc3) {\n                // true\n                object = true;\n            }\n            else if (headByte === 0xca) {\n                // float 32\n                object = this.readF32();\n            }\n            else if (headByte === 0xcb) {\n                // float 64\n                object = this.readF64();\n            }\n            else if (headByte === 0xcc) {\n                // uint 8\n                object = this.readU8();\n            }\n            else if (headByte === 0xcd) {\n                // uint 16\n                object = this.readU16();\n            }\n            else if (headByte === 0xce) {\n                // uint 32\n                object = this.readU32();\n            }\n            else if (headByte === 0xcf) {\n                // uint 64\n                object = this.readU64();\n            }\n            else if (headByte === 0xd0) {\n                // int 8\n                object = this.readI8();\n            }\n            else if (headByte === 0xd1) {\n                // int 16\n                object = this.readI16();\n            }\n            else if (headByte === 0xd2) {\n                // int 32\n                object = this.readI32();\n            }\n            else if (headByte === 0xd3) {\n                // int 64\n                object = this.readI64();\n            }\n            else if (headByte === 0xd9) {\n                // str 8\n                var byteLength = this.lookU8();\n                object = this.decodeUtf8String(byteLength, 1);\n            }\n            else if (headByte === 0xda) {\n                // str 16\n                var byteLength = this.lookU16();\n                object = this.decodeUtf8String(byteLength, 2);\n            }\n            else if (headByte === 0xdb) {\n                // str 32\n                var byteLength = this.lookU32();\n                object = this.decodeUtf8String(byteLength, 4);\n            }\n            else if (headByte === 0xdc) {\n                // array 16\n                var size = this.readU16();\n                if (size !== 0) {\n                    this.pushArrayState(size);\n                    this.complete();\n                    continue DECODE;\n                }\n                else {\n                    object = [];\n                }\n            }\n            else if (headByte === 0xdd) {\n                // array 32\n                var size = this.readU32();\n                if (size !== 0) {\n                    this.pushArrayState(size);\n                    this.complete();\n                    continue DECODE;\n                }\n                else {\n                    object = [];\n                }\n            }\n            else if (headByte === 0xde) {\n                // map 16\n                var size = this.readU16();\n                if (size !== 0) {\n                    this.pushMapState(size);\n                    this.complete();\n                    continue DECODE;\n                }\n                else {\n                    object = {};\n                }\n            }\n            else if (headByte === 0xdf) {\n                // map 32\n                var size = this.readU32();\n                if (size !== 0) {\n                    this.pushMapState(size);\n                    this.complete();\n                    continue DECODE;\n                }\n                else {\n                    object = {};\n                }\n            }\n            else if (headByte === 0xc4) {\n                // bin 8\n                var size = this.lookU8();\n                object = this.decodeBinary(size, 1);\n            }\n            else if (headByte === 0xc5) {\n                // bin 16\n                var size = this.lookU16();\n                object = this.decodeBinary(size, 2);\n            }\n            else if (headByte === 0xc6) {\n                // bin 32\n                var size = this.lookU32();\n                object = this.decodeBinary(size, 4);\n            }\n            else if (headByte === 0xd4) {\n                // fixext 1\n                object = this.decodeExtension(1, 0);\n            }\n            else if (headByte === 0xd5) {\n                // fixext 2\n                object = this.decodeExtension(2, 0);\n            }\n            else if (headByte === 0xd6) {\n                // fixext 4\n                object = this.decodeExtension(4, 0);\n            }\n            else if (headByte === 0xd7) {\n                // fixext 8\n                object = this.decodeExtension(8, 0);\n            }\n            else if (headByte === 0xd8) {\n                // fixext 16\n                object = this.decodeExtension(16, 0);\n            }\n            else if (headByte === 0xc7) {\n                // ext 8\n                var size = this.lookU8();\n                object = this.decodeExtension(size, 1);\n            }\n            else if (headByte === 0xc8) {\n                // ext 16\n                var size = this.lookU16();\n                object = this.decodeExtension(size, 2);\n            }\n            else if (headByte === 0xc9) {\n                // ext 32\n                var size = this.lookU32();\n                object = this.decodeExtension(size, 4);\n            }\n            else {\n                throw new _DecodeError_mjs__WEBPACK_IMPORTED_MODULE_6__.DecodeError(\"Unrecognized type byte: \".concat((0,_utils_prettyByte_mjs__WEBPACK_IMPORTED_MODULE_0__.prettyByte)(headByte)));\n            }\n            this.complete();\n            var stack = this.stack;\n            while (stack.length > 0) {\n                // arrays and maps\n                var state = stack[stack.length - 1];\n                if (state.type === 0 /* State.ARRAY */) {\n                    state.array[state.position] = object;\n                    state.position++;\n                    if (state.position === state.size) {\n                        stack.pop();\n                        object = state.array;\n                    }\n                    else {\n                        continue DECODE;\n                    }\n                }\n                else if (state.type === 1 /* State.MAP_KEY */) {\n                    if (!isValidMapKeyType(object)) {\n                        throw new _DecodeError_mjs__WEBPACK_IMPORTED_MODULE_6__.DecodeError(\"The type of key must be string or number but \" + typeof object);\n                    }\n                    if (object === \"__proto__\") {\n                        throw new _DecodeError_mjs__WEBPACK_IMPORTED_MODULE_6__.DecodeError(\"The key __proto__ is not allowed\");\n                    }\n                    state.key = object;\n                    state.type = 2 /* State.MAP_VALUE */;\n                    continue DECODE;\n                }\n                else {\n                    // it must be `state.type === State.MAP_VALUE` here\n                    state.map[state.key] = object;\n                    state.readCount++;\n                    if (state.readCount === state.size) {\n                        stack.pop();\n                        object = state.map;\n                    }\n                    else {\n                        state.key = null;\n                        state.type = 1 /* State.MAP_KEY */;\n                        continue DECODE;\n                    }\n                }\n            }\n            return object;\n        }\n    };\n    Decoder.prototype.readHeadByte = function () {\n        if (this.headByte === HEAD_BYTE_REQUIRED) {\n            this.headByte = this.readU8();\n            // console.log(\"headByte\", prettyByte(this.headByte));\n        }\n        return this.headByte;\n    };\n    Decoder.prototype.complete = function () {\n        this.headByte = HEAD_BYTE_REQUIRED;\n    };\n    Decoder.prototype.readArraySize = function () {\n        var headByte = this.readHeadByte();\n        switch (headByte) {\n            case 0xdc:\n                return this.readU16();\n            case 0xdd:\n                return this.readU32();\n            default: {\n                if (headByte < 0xa0) {\n                    return headByte - 0x90;\n                }\n                else {\n                    throw new _DecodeError_mjs__WEBPACK_IMPORTED_MODULE_6__.DecodeError(\"Unrecognized array type byte: \".concat((0,_utils_prettyByte_mjs__WEBPACK_IMPORTED_MODULE_0__.prettyByte)(headByte)));\n                }\n            }\n        }\n    };\n    Decoder.prototype.pushMapState = function (size) {\n        if (size > this.maxMapLength) {\n            throw new _DecodeError_mjs__WEBPACK_IMPORTED_MODULE_6__.DecodeError(\"Max length exceeded: map length (\".concat(size, \") > maxMapLengthLength (\").concat(this.maxMapLength, \")\"));\n        }\n        this.stack.push({\n            type: 1 /* State.MAP_KEY */,\n            size: size,\n            key: null,\n            readCount: 0,\n            map: {},\n        });\n    };\n    Decoder.prototype.pushArrayState = function (size) {\n        if (size > this.maxArrayLength) {\n            throw new _DecodeError_mjs__WEBPACK_IMPORTED_MODULE_6__.DecodeError(\"Max length exceeded: array length (\".concat(size, \") > maxArrayLength (\").concat(this.maxArrayLength, \")\"));\n        }\n        this.stack.push({\n            type: 0 /* State.ARRAY */,\n            size: size,\n            array: new Array(size),\n            position: 0,\n        });\n    };\n    Decoder.prototype.decodeUtf8String = function (byteLength, headerOffset) {\n        var _a;\n        if (byteLength > this.maxStrLength) {\n            throw new _DecodeError_mjs__WEBPACK_IMPORTED_MODULE_6__.DecodeError(\"Max length exceeded: UTF-8 byte length (\".concat(byteLength, \") > maxStrLength (\").concat(this.maxStrLength, \")\"));\n        }\n        if (this.bytes.byteLength < this.pos + headerOffset + byteLength) {\n            throw MORE_DATA;\n        }\n        var offset = this.pos + headerOffset;\n        var object;\n        if (this.stateIsMapKey() && ((_a = this.keyDecoder) === null || _a === void 0 ? void 0 : _a.canBeCached(byteLength))) {\n            object = this.keyDecoder.decode(this.bytes, offset, byteLength);\n        }\n        else if (byteLength > _utils_utf8_mjs__WEBPACK_IMPORTED_MODULE_3__.TEXT_DECODER_THRESHOLD) {\n            object = (0,_utils_utf8_mjs__WEBPACK_IMPORTED_MODULE_3__.utf8DecodeTD)(this.bytes, offset, byteLength);\n        }\n        else {\n            object = (0,_utils_utf8_mjs__WEBPACK_IMPORTED_MODULE_3__.utf8DecodeJs)(this.bytes, offset, byteLength);\n        }\n        this.pos += headerOffset + byteLength;\n        return object;\n    };\n    Decoder.prototype.stateIsMapKey = function () {\n        if (this.stack.length > 0) {\n            var state = this.stack[this.stack.length - 1];\n            return state.type === 1 /* State.MAP_KEY */;\n        }\n        return false;\n    };\n    Decoder.prototype.decodeBinary = function (byteLength, headOffset) {\n        if (byteLength > this.maxBinLength) {\n            throw new _DecodeError_mjs__WEBPACK_IMPORTED_MODULE_6__.DecodeError(\"Max length exceeded: bin length (\".concat(byteLength, \") > maxBinLength (\").concat(this.maxBinLength, \")\"));\n        }\n        if (!this.hasRemaining(byteLength + headOffset)) {\n            throw MORE_DATA;\n        }\n        var offset = this.pos + headOffset;\n        var object = this.bytes.subarray(offset, offset + byteLength);\n        this.pos += headOffset + byteLength;\n        return object;\n    };\n    Decoder.prototype.decodeExtension = function (size, headOffset) {\n        if (size > this.maxExtLength) {\n            throw new _DecodeError_mjs__WEBPACK_IMPORTED_MODULE_6__.DecodeError(\"Max length exceeded: ext length (\".concat(size, \") > maxExtLength (\").concat(this.maxExtLength, \")\"));\n        }\n        var extType = this.view.getInt8(this.pos + headOffset);\n        var data = this.decodeBinary(size, headOffset + 1 /* extType */);\n        return this.extensionCodec.decode(data, extType, this.context);\n    };\n    Decoder.prototype.lookU8 = function () {\n        return this.view.getUint8(this.pos);\n    };\n    Decoder.prototype.lookU16 = function () {\n        return this.view.getUint16(this.pos);\n    };\n    Decoder.prototype.lookU32 = function () {\n        return this.view.getUint32(this.pos);\n    };\n    Decoder.prototype.readU8 = function () {\n        var value = this.view.getUint8(this.pos);\n        this.pos++;\n        return value;\n    };\n    Decoder.prototype.readI8 = function () {\n        var value = this.view.getInt8(this.pos);\n        this.pos++;\n        return value;\n    };\n    Decoder.prototype.readU16 = function () {\n        var value = this.view.getUint16(this.pos);\n        this.pos += 2;\n        return value;\n    };\n    Decoder.prototype.readI16 = function () {\n        var value = this.view.getInt16(this.pos);\n        this.pos += 2;\n        return value;\n    };\n    Decoder.prototype.readU32 = function () {\n        var value = this.view.getUint32(this.pos);\n        this.pos += 4;\n        return value;\n    };\n    Decoder.prototype.readI32 = function () {\n        var value = this.view.getInt32(this.pos);\n        this.pos += 4;\n        return value;\n    };\n    Decoder.prototype.readU64 = function () {\n        var value = (0,_utils_int_mjs__WEBPACK_IMPORTED_MODULE_2__.getUint64)(this.view, this.pos);\n        this.pos += 8;\n        return value;\n    };\n    Decoder.prototype.readI64 = function () {\n        var value = (0,_utils_int_mjs__WEBPACK_IMPORTED_MODULE_2__.getInt64)(this.view, this.pos);\n        this.pos += 8;\n        return value;\n    };\n    Decoder.prototype.readF32 = function () {\n        var value = this.view.getFloat32(this.pos);\n        this.pos += 4;\n        return value;\n    };\n    Decoder.prototype.readF64 = function () {\n        var value = this.view.getFloat64(this.pos);\n        this.pos += 8;\n        return value;\n    };\n    return Decoder;\n}());\n\n//# sourceMappingURL=Decoder.mjs.map\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/@msgpack/msgpack/dist.es5+esm/Decoder.mjs?\n}");

/***/ }),

/***/ "./node_modules/@msgpack/msgpack/dist.es5+esm/Encoder.mjs":
/*!****************************************************************!*\
  !*** ./node_modules/@msgpack/msgpack/dist.es5+esm/Encoder.mjs ***!
  \****************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   DEFAULT_INITIAL_BUFFER_SIZE: () => (/* binding */ DEFAULT_INITIAL_BUFFER_SIZE),\n/* harmony export */   DEFAULT_MAX_DEPTH: () => (/* binding */ DEFAULT_MAX_DEPTH),\n/* harmony export */   Encoder: () => (/* binding */ Encoder)\n/* harmony export */ });\n/* harmony import */ var _utils_utf8_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./utils/utf8.mjs */ \"./node_modules/@msgpack/msgpack/dist.es5+esm/utils/utf8.mjs\");\n/* harmony import */ var _ExtensionCodec_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ExtensionCodec.mjs */ \"./node_modules/@msgpack/msgpack/dist.es5+esm/ExtensionCodec.mjs\");\n/* harmony import */ var _utils_int_mjs__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./utils/int.mjs */ \"./node_modules/@msgpack/msgpack/dist.es5+esm/utils/int.mjs\");\n/* harmony import */ var _utils_typedArrays_mjs__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./utils/typedArrays.mjs */ \"./node_modules/@msgpack/msgpack/dist.es5+esm/utils/typedArrays.mjs\");\n\n\n\n\nvar DEFAULT_MAX_DEPTH = 100;\nvar DEFAULT_INITIAL_BUFFER_SIZE = 2048;\nvar Encoder = /** @class */ (function () {\n    function Encoder(extensionCodec, context, maxDepth, initialBufferSize, sortKeys, forceFloat32, ignoreUndefined, forceIntegerToFloat) {\n        if (extensionCodec === void 0) { extensionCodec = _ExtensionCodec_mjs__WEBPACK_IMPORTED_MODULE_1__.ExtensionCodec.defaultCodec; }\n        if (context === void 0) { context = undefined; }\n        if (maxDepth === void 0) { maxDepth = DEFAULT_MAX_DEPTH; }\n        if (initialBufferSize === void 0) { initialBufferSize = DEFAULT_INITIAL_BUFFER_SIZE; }\n        if (sortKeys === void 0) { sortKeys = false; }\n        if (forceFloat32 === void 0) { forceFloat32 = false; }\n        if (ignoreUndefined === void 0) { ignoreUndefined = false; }\n        if (forceIntegerToFloat === void 0) { forceIntegerToFloat = false; }\n        this.extensionCodec = extensionCodec;\n        this.context = context;\n        this.maxDepth = maxDepth;\n        this.initialBufferSize = initialBufferSize;\n        this.sortKeys = sortKeys;\n        this.forceFloat32 = forceFloat32;\n        this.ignoreUndefined = ignoreUndefined;\n        this.forceIntegerToFloat = forceIntegerToFloat;\n        this.pos = 0;\n        this.view = new DataView(new ArrayBuffer(this.initialBufferSize));\n        this.bytes = new Uint8Array(this.view.buffer);\n    }\n    Encoder.prototype.reinitializeState = function () {\n        this.pos = 0;\n    };\n    /**\n     * This is almost equivalent to {@link Encoder#encode}, but it returns an reference of the encoder's internal buffer and thus much faster than {@link Encoder#encode}.\n     *\n     * @returns Encodes the object and returns a shared reference the encoder's internal buffer.\n     */\n    Encoder.prototype.encodeSharedRef = function (object) {\n        this.reinitializeState();\n        this.doEncode(object, 1);\n        return this.bytes.subarray(0, this.pos);\n    };\n    /**\n     * @returns Encodes the object and returns a copy of the encoder's internal buffer.\n     */\n    Encoder.prototype.encode = function (object) {\n        this.reinitializeState();\n        this.doEncode(object, 1);\n        return this.bytes.slice(0, this.pos);\n    };\n    Encoder.prototype.doEncode = function (object, depth) {\n        if (depth > this.maxDepth) {\n            throw new Error(\"Too deep objects in depth \".concat(depth));\n        }\n        if (object == null) {\n            this.encodeNil();\n        }\n        else if (typeof object === \"boolean\") {\n            this.encodeBoolean(object);\n        }\n        else if (typeof object === \"number\") {\n            this.encodeNumber(object);\n        }\n        else if (typeof object === \"string\") {\n            this.encodeString(object);\n        }\n        else {\n            this.encodeObject(object, depth);\n        }\n    };\n    Encoder.prototype.ensureBufferSizeToWrite = function (sizeToWrite) {\n        var requiredSize = this.pos + sizeToWrite;\n        if (this.view.byteLength < requiredSize) {\n            this.resizeBuffer(requiredSize * 2);\n        }\n    };\n    Encoder.prototype.resizeBuffer = function (newSize) {\n        var newBuffer = new ArrayBuffer(newSize);\n        var newBytes = new Uint8Array(newBuffer);\n        var newView = new DataView(newBuffer);\n        newBytes.set(this.bytes);\n        this.view = newView;\n        this.bytes = newBytes;\n    };\n    Encoder.prototype.encodeNil = function () {\n        this.writeU8(0xc0);\n    };\n    Encoder.prototype.encodeBoolean = function (object) {\n        if (object === false) {\n            this.writeU8(0xc2);\n        }\n        else {\n            this.writeU8(0xc3);\n        }\n    };\n    Encoder.prototype.encodeNumber = function (object) {\n        if (Number.isSafeInteger(object) && !this.forceIntegerToFloat) {\n            if (object >= 0) {\n                if (object < 0x80) {\n                    // positive fixint\n                    this.writeU8(object);\n                }\n                else if (object < 0x100) {\n                    // uint 8\n                    this.writeU8(0xcc);\n                    this.writeU8(object);\n                }\n                else if (object < 0x10000) {\n                    // uint 16\n                    this.writeU8(0xcd);\n                    this.writeU16(object);\n                }\n                else if (object < 0x100000000) {\n                    // uint 32\n                    this.writeU8(0xce);\n                    this.writeU32(object);\n                }\n                else {\n                    // uint 64\n                    this.writeU8(0xcf);\n                    this.writeU64(object);\n                }\n            }\n            else {\n                if (object >= -0x20) {\n                    // negative fixint\n                    this.writeU8(0xe0 | (object + 0x20));\n                }\n                else if (object >= -0x80) {\n                    // int 8\n                    this.writeU8(0xd0);\n                    this.writeI8(object);\n                }\n                else if (object >= -0x8000) {\n                    // int 16\n                    this.writeU8(0xd1);\n                    this.writeI16(object);\n                }\n                else if (object >= -0x80000000) {\n                    // int 32\n                    this.writeU8(0xd2);\n                    this.writeI32(object);\n                }\n                else {\n                    // int 64\n                    this.writeU8(0xd3);\n                    this.writeI64(object);\n                }\n            }\n        }\n        else {\n            // non-integer numbers\n            if (this.forceFloat32) {\n                // float 32\n                this.writeU8(0xca);\n                this.writeF32(object);\n            }\n            else {\n                // float 64\n                this.writeU8(0xcb);\n                this.writeF64(object);\n            }\n        }\n    };\n    Encoder.prototype.writeStringHeader = function (byteLength) {\n        if (byteLength < 32) {\n            // fixstr\n            this.writeU8(0xa0 + byteLength);\n        }\n        else if (byteLength < 0x100) {\n            // str 8\n            this.writeU8(0xd9);\n            this.writeU8(byteLength);\n        }\n        else if (byteLength < 0x10000) {\n            // str 16\n            this.writeU8(0xda);\n            this.writeU16(byteLength);\n        }\n        else if (byteLength < 0x100000000) {\n            // str 32\n            this.writeU8(0xdb);\n            this.writeU32(byteLength);\n        }\n        else {\n            throw new Error(\"Too long string: \".concat(byteLength, \" bytes in UTF-8\"));\n        }\n    };\n    Encoder.prototype.encodeString = function (object) {\n        var maxHeaderSize = 1 + 4;\n        var strLength = object.length;\n        if (strLength > _utils_utf8_mjs__WEBPACK_IMPORTED_MODULE_0__.TEXT_ENCODER_THRESHOLD) {\n            var byteLength = (0,_utils_utf8_mjs__WEBPACK_IMPORTED_MODULE_0__.utf8Count)(object);\n            this.ensureBufferSizeToWrite(maxHeaderSize + byteLength);\n            this.writeStringHeader(byteLength);\n            (0,_utils_utf8_mjs__WEBPACK_IMPORTED_MODULE_0__.utf8EncodeTE)(object, this.bytes, this.pos);\n            this.pos += byteLength;\n        }\n        else {\n            var byteLength = (0,_utils_utf8_mjs__WEBPACK_IMPORTED_MODULE_0__.utf8Count)(object);\n            this.ensureBufferSizeToWrite(maxHeaderSize + byteLength);\n            this.writeStringHeader(byteLength);\n            (0,_utils_utf8_mjs__WEBPACK_IMPORTED_MODULE_0__.utf8EncodeJs)(object, this.bytes, this.pos);\n            this.pos += byteLength;\n        }\n    };\n    Encoder.prototype.encodeObject = function (object, depth) {\n        // try to encode objects with custom codec first of non-primitives\n        var ext = this.extensionCodec.tryToEncode(object, this.context);\n        if (ext != null) {\n            this.encodeExtension(ext);\n        }\n        else if (Array.isArray(object)) {\n            this.encodeArray(object, depth);\n        }\n        else if (ArrayBuffer.isView(object)) {\n            this.encodeBinary(object);\n        }\n        else if (typeof object === \"object\") {\n            this.encodeMap(object, depth);\n        }\n        else {\n            // symbol, function and other special object come here unless extensionCodec handles them.\n            throw new Error(\"Unrecognized object: \".concat(Object.prototype.toString.apply(object)));\n        }\n    };\n    Encoder.prototype.encodeBinary = function (object) {\n        var size = object.byteLength;\n        if (size < 0x100) {\n            // bin 8\n            this.writeU8(0xc4);\n            this.writeU8(size);\n        }\n        else if (size < 0x10000) {\n            // bin 16\n            this.writeU8(0xc5);\n            this.writeU16(size);\n        }\n        else if (size < 0x100000000) {\n            // bin 32\n            this.writeU8(0xc6);\n            this.writeU32(size);\n        }\n        else {\n            throw new Error(\"Too large binary: \".concat(size));\n        }\n        var bytes = (0,_utils_typedArrays_mjs__WEBPACK_IMPORTED_MODULE_3__.ensureUint8Array)(object);\n        this.writeU8a(bytes);\n    };\n    Encoder.prototype.encodeArray = function (object, depth) {\n        var size = object.length;\n        if (size < 16) {\n            // fixarray\n            this.writeU8(0x90 + size);\n        }\n        else if (size < 0x10000) {\n            // array 16\n            this.writeU8(0xdc);\n            this.writeU16(size);\n        }\n        else if (size < 0x100000000) {\n            // array 32\n            this.writeU8(0xdd);\n            this.writeU32(size);\n        }\n        else {\n            throw new Error(\"Too large array: \".concat(size));\n        }\n        for (var _i = 0, object_1 = object; _i < object_1.length; _i++) {\n            var item = object_1[_i];\n            this.doEncode(item, depth + 1);\n        }\n    };\n    Encoder.prototype.countWithoutUndefined = function (object, keys) {\n        var count = 0;\n        for (var _i = 0, keys_1 = keys; _i < keys_1.length; _i++) {\n            var key = keys_1[_i];\n            if (object[key] !== undefined) {\n                count++;\n            }\n        }\n        return count;\n    };\n    Encoder.prototype.encodeMap = function (object, depth) {\n        var keys = Object.keys(object);\n        if (this.sortKeys) {\n            keys.sort();\n        }\n        var size = this.ignoreUndefined ? this.countWithoutUndefined(object, keys) : keys.length;\n        if (size < 16) {\n            // fixmap\n            this.writeU8(0x80 + size);\n        }\n        else if (size < 0x10000) {\n            // map 16\n            this.writeU8(0xde);\n            this.writeU16(size);\n        }\n        else if (size < 0x100000000) {\n            // map 32\n            this.writeU8(0xdf);\n            this.writeU32(size);\n        }\n        else {\n            throw new Error(\"Too large map object: \".concat(size));\n        }\n        for (var _i = 0, keys_2 = keys; _i < keys_2.length; _i++) {\n            var key = keys_2[_i];\n            var value = object[key];\n            if (!(this.ignoreUndefined && value === undefined)) {\n                this.encodeString(key);\n                this.doEncode(value, depth + 1);\n            }\n        }\n    };\n    Encoder.prototype.encodeExtension = function (ext) {\n        var size = ext.data.length;\n        if (size === 1) {\n            // fixext 1\n            this.writeU8(0xd4);\n        }\n        else if (size === 2) {\n            // fixext 2\n            this.writeU8(0xd5);\n        }\n        else if (size === 4) {\n            // fixext 4\n            this.writeU8(0xd6);\n        }\n        else if (size === 8) {\n            // fixext 8\n            this.writeU8(0xd7);\n        }\n        else if (size === 16) {\n            // fixext 16\n            this.writeU8(0xd8);\n        }\n        else if (size < 0x100) {\n            // ext 8\n            this.writeU8(0xc7);\n            this.writeU8(size);\n        }\n        else if (size < 0x10000) {\n            // ext 16\n            this.writeU8(0xc8);\n            this.writeU16(size);\n        }\n        else if (size < 0x100000000) {\n            // ext 32\n            this.writeU8(0xc9);\n            this.writeU32(size);\n        }\n        else {\n            throw new Error(\"Too large extension object: \".concat(size));\n        }\n        this.writeI8(ext.type);\n        this.writeU8a(ext.data);\n    };\n    Encoder.prototype.writeU8 = function (value) {\n        this.ensureBufferSizeToWrite(1);\n        this.view.setUint8(this.pos, value);\n        this.pos++;\n    };\n    Encoder.prototype.writeU8a = function (values) {\n        var size = values.length;\n        this.ensureBufferSizeToWrite(size);\n        this.bytes.set(values, this.pos);\n        this.pos += size;\n    };\n    Encoder.prototype.writeI8 = function (value) {\n        this.ensureBufferSizeToWrite(1);\n        this.view.setInt8(this.pos, value);\n        this.pos++;\n    };\n    Encoder.prototype.writeU16 = function (value) {\n        this.ensureBufferSizeToWrite(2);\n        this.view.setUint16(this.pos, value);\n        this.pos += 2;\n    };\n    Encoder.prototype.writeI16 = function (value) {\n        this.ensureBufferSizeToWrite(2);\n        this.view.setInt16(this.pos, value);\n        this.pos += 2;\n    };\n    Encoder.prototype.writeU32 = function (value) {\n        this.ensureBufferSizeToWrite(4);\n        this.view.setUint32(this.pos, value);\n        this.pos += 4;\n    };\n    Encoder.prototype.writeI32 = function (value) {\n        this.ensureBufferSizeToWrite(4);\n        this.view.setInt32(this.pos, value);\n        this.pos += 4;\n    };\n    Encoder.prototype.writeF32 = function (value) {\n        this.ensureBufferSizeToWrite(4);\n        this.view.setFloat32(this.pos, value);\n        this.pos += 4;\n    };\n    Encoder.prototype.writeF64 = function (value) {\n        this.ensureBufferSizeToWrite(8);\n        this.view.setFloat64(this.pos, value);\n        this.pos += 8;\n    };\n    Encoder.prototype.writeU64 = function (value) {\n        this.ensureBufferSizeToWrite(8);\n        (0,_utils_int_mjs__WEBPACK_IMPORTED_MODULE_2__.setUint64)(this.view, this.pos, value);\n        this.pos += 8;\n    };\n    Encoder.prototype.writeI64 = function (value) {\n        this.ensureBufferSizeToWrite(8);\n        (0,_utils_int_mjs__WEBPACK_IMPORTED_MODULE_2__.setInt64)(this.view, this.pos, value);\n        this.pos += 8;\n    };\n    return Encoder;\n}());\n\n//# sourceMappingURL=Encoder.mjs.map\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/@msgpack/msgpack/dist.es5+esm/Encoder.mjs?\n}");

/***/ }),

/***/ "./node_modules/@msgpack/msgpack/dist.es5+esm/ExtData.mjs":
/*!****************************************************************!*\
  !*** ./node_modules/@msgpack/msgpack/dist.es5+esm/ExtData.mjs ***!
  \****************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   ExtData: () => (/* binding */ ExtData)\n/* harmony export */ });\n/**\n * ExtData is used to handle Extension Types that are not registered to ExtensionCodec.\n */\nvar ExtData = /** @class */ (function () {\n    function ExtData(type, data) {\n        this.type = type;\n        this.data = data;\n    }\n    return ExtData;\n}());\n\n//# sourceMappingURL=ExtData.mjs.map\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/@msgpack/msgpack/dist.es5+esm/ExtData.mjs?\n}");

/***/ }),

/***/ "./node_modules/@msgpack/msgpack/dist.es5+esm/ExtensionCodec.mjs":
/*!***********************************************************************!*\
  !*** ./node_modules/@msgpack/msgpack/dist.es5+esm/ExtensionCodec.mjs ***!
  \***********************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   ExtensionCodec: () => (/* binding */ ExtensionCodec)\n/* harmony export */ });\n/* harmony import */ var _ExtData_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ExtData.mjs */ \"./node_modules/@msgpack/msgpack/dist.es5+esm/ExtData.mjs\");\n/* harmony import */ var _timestamp_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./timestamp.mjs */ \"./node_modules/@msgpack/msgpack/dist.es5+esm/timestamp.mjs\");\n// ExtensionCodec to handle MessagePack extensions\n\n\nvar ExtensionCodec = /** @class */ (function () {\n    function ExtensionCodec() {\n        // built-in extensions\n        this.builtInEncoders = [];\n        this.builtInDecoders = [];\n        // custom extensions\n        this.encoders = [];\n        this.decoders = [];\n        this.register(_timestamp_mjs__WEBPACK_IMPORTED_MODULE_1__.timestampExtension);\n    }\n    ExtensionCodec.prototype.register = function (_a) {\n        var type = _a.type, encode = _a.encode, decode = _a.decode;\n        if (type >= 0) {\n            // custom extensions\n            this.encoders[type] = encode;\n            this.decoders[type] = decode;\n        }\n        else {\n            // built-in extensions\n            var index = 1 + type;\n            this.builtInEncoders[index] = encode;\n            this.builtInDecoders[index] = decode;\n        }\n    };\n    ExtensionCodec.prototype.tryToEncode = function (object, context) {\n        // built-in extensions\n        for (var i = 0; i < this.builtInEncoders.length; i++) {\n            var encodeExt = this.builtInEncoders[i];\n            if (encodeExt != null) {\n                var data = encodeExt(object, context);\n                if (data != null) {\n                    var type = -1 - i;\n                    return new _ExtData_mjs__WEBPACK_IMPORTED_MODULE_0__.ExtData(type, data);\n                }\n            }\n        }\n        // custom extensions\n        for (var i = 0; i < this.encoders.length; i++) {\n            var encodeExt = this.encoders[i];\n            if (encodeExt != null) {\n                var data = encodeExt(object, context);\n                if (data != null) {\n                    var type = i;\n                    return new _ExtData_mjs__WEBPACK_IMPORTED_MODULE_0__.ExtData(type, data);\n                }\n            }\n        }\n        if (object instanceof _ExtData_mjs__WEBPACK_IMPORTED_MODULE_0__.ExtData) {\n            // to keep ExtData as is\n            return object;\n        }\n        return null;\n    };\n    ExtensionCodec.prototype.decode = function (data, type, context) {\n        var decodeExt = type < 0 ? this.builtInDecoders[-1 - type] : this.decoders[type];\n        if (decodeExt) {\n            return decodeExt(data, type, context);\n        }\n        else {\n            // decode() does not fail, returns ExtData instead.\n            return new _ExtData_mjs__WEBPACK_IMPORTED_MODULE_0__.ExtData(type, data);\n        }\n    };\n    ExtensionCodec.defaultCodec = new ExtensionCodec();\n    return ExtensionCodec;\n}());\n\n//# sourceMappingURL=ExtensionCodec.mjs.map\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/@msgpack/msgpack/dist.es5+esm/ExtensionCodec.mjs?\n}");

/***/ }),

/***/ "./node_modules/@msgpack/msgpack/dist.es5+esm/decode.mjs":
/*!***************************************************************!*\
  !*** ./node_modules/@msgpack/msgpack/dist.es5+esm/decode.mjs ***!
  \***************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   decode: () => (/* binding */ decode),\n/* harmony export */   decodeMulti: () => (/* binding */ decodeMulti),\n/* harmony export */   defaultDecodeOptions: () => (/* binding */ defaultDecodeOptions)\n/* harmony export */ });\n/* harmony import */ var _Decoder_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Decoder.mjs */ \"./node_modules/@msgpack/msgpack/dist.es5+esm/Decoder.mjs\");\n\nvar defaultDecodeOptions = {};\n/**\n * It decodes a single MessagePack object in a buffer.\n *\n * This is a synchronous decoding function.\n * See other variants for asynchronous decoding: {@link decodeAsync()}, {@link decodeStream()}, or {@link decodeArrayStream()}.\n *\n * @throws {@link RangeError} if the buffer is incomplete, including the case where the buffer is empty.\n * @throws {@link DecodeError} if the buffer contains invalid data.\n */\nfunction decode(buffer, options) {\n    if (options === void 0) { options = defaultDecodeOptions; }\n    var decoder = new _Decoder_mjs__WEBPACK_IMPORTED_MODULE_0__.Decoder(options.extensionCodec, options.context, options.maxStrLength, options.maxBinLength, options.maxArrayLength, options.maxMapLength, options.maxExtLength);\n    return decoder.decode(buffer);\n}\n/**\n * It decodes multiple MessagePack objects in a buffer.\n * This is corresponding to {@link decodeMultiStream()}.\n *\n * @throws {@link RangeError} if the buffer is incomplete, including the case where the buffer is empty.\n * @throws {@link DecodeError} if the buffer contains invalid data.\n */\nfunction decodeMulti(buffer, options) {\n    if (options === void 0) { options = defaultDecodeOptions; }\n    var decoder = new _Decoder_mjs__WEBPACK_IMPORTED_MODULE_0__.Decoder(options.extensionCodec, options.context, options.maxStrLength, options.maxBinLength, options.maxArrayLength, options.maxMapLength, options.maxExtLength);\n    return decoder.decodeMulti(buffer);\n}\n//# sourceMappingURL=decode.mjs.map\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/@msgpack/msgpack/dist.es5+esm/decode.mjs?\n}");

/***/ }),

/***/ "./node_modules/@msgpack/msgpack/dist.es5+esm/decodeAsync.mjs":
/*!********************************************************************!*\
  !*** ./node_modules/@msgpack/msgpack/dist.es5+esm/decodeAsync.mjs ***!
  \********************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   decodeArrayStream: () => (/* binding */ decodeArrayStream),\n/* harmony export */   decodeAsync: () => (/* binding */ decodeAsync),\n/* harmony export */   decodeMultiStream: () => (/* binding */ decodeMultiStream),\n/* harmony export */   decodeStream: () => (/* binding */ decodeStream)\n/* harmony export */ });\n/* harmony import */ var _Decoder_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Decoder.mjs */ \"./node_modules/@msgpack/msgpack/dist.es5+esm/Decoder.mjs\");\n/* harmony import */ var _utils_stream_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./utils/stream.mjs */ \"./node_modules/@msgpack/msgpack/dist.es5+esm/utils/stream.mjs\");\n/* harmony import */ var _decode_mjs__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./decode.mjs */ \"./node_modules/@msgpack/msgpack/dist.es5+esm/decode.mjs\");\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (undefined && undefined.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\n\n\n\n/**\n * @throws {@link RangeError} if the buffer is incomplete, including the case where the buffer is empty.\n * @throws {@link DecodeError} if the buffer contains invalid data.\n */\nfunction decodeAsync(streamLike, options) {\n    if (options === void 0) { options = _decode_mjs__WEBPACK_IMPORTED_MODULE_2__.defaultDecodeOptions; }\n    return __awaiter(this, void 0, void 0, function () {\n        var stream, decoder;\n        return __generator(this, function (_a) {\n            stream = (0,_utils_stream_mjs__WEBPACK_IMPORTED_MODULE_1__.ensureAsyncIterable)(streamLike);\n            decoder = new _Decoder_mjs__WEBPACK_IMPORTED_MODULE_0__.Decoder(options.extensionCodec, options.context, options.maxStrLength, options.maxBinLength, options.maxArrayLength, options.maxMapLength, options.maxExtLength);\n            return [2 /*return*/, decoder.decodeAsync(stream)];\n        });\n    });\n}\n/**\n * @throws {@link RangeError} if the buffer is incomplete, including the case where the buffer is empty.\n * @throws {@link DecodeError} if the buffer contains invalid data.\n */\nfunction decodeArrayStream(streamLike, options) {\n    if (options === void 0) { options = _decode_mjs__WEBPACK_IMPORTED_MODULE_2__.defaultDecodeOptions; }\n    var stream = (0,_utils_stream_mjs__WEBPACK_IMPORTED_MODULE_1__.ensureAsyncIterable)(streamLike);\n    var decoder = new _Decoder_mjs__WEBPACK_IMPORTED_MODULE_0__.Decoder(options.extensionCodec, options.context, options.maxStrLength, options.maxBinLength, options.maxArrayLength, options.maxMapLength, options.maxExtLength);\n    return decoder.decodeArrayStream(stream);\n}\n/**\n * @throws {@link RangeError} if the buffer is incomplete, including the case where the buffer is empty.\n * @throws {@link DecodeError} if the buffer contains invalid data.\n */\nfunction decodeMultiStream(streamLike, options) {\n    if (options === void 0) { options = _decode_mjs__WEBPACK_IMPORTED_MODULE_2__.defaultDecodeOptions; }\n    var stream = (0,_utils_stream_mjs__WEBPACK_IMPORTED_MODULE_1__.ensureAsyncIterable)(streamLike);\n    var decoder = new _Decoder_mjs__WEBPACK_IMPORTED_MODULE_0__.Decoder(options.extensionCodec, options.context, options.maxStrLength, options.maxBinLength, options.maxArrayLength, options.maxMapLength, options.maxExtLength);\n    return decoder.decodeStream(stream);\n}\n/**\n * @deprecated Use {@link decodeMultiStream()} instead.\n */\nfunction decodeStream(streamLike, options) {\n    if (options === void 0) { options = _decode_mjs__WEBPACK_IMPORTED_MODULE_2__.defaultDecodeOptions; }\n    return decodeMultiStream(streamLike, options);\n}\n//# sourceMappingURL=decodeAsync.mjs.map\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/@msgpack/msgpack/dist.es5+esm/decodeAsync.mjs?\n}");

/***/ }),

/***/ "./node_modules/@msgpack/msgpack/dist.es5+esm/timestamp.mjs":
/*!******************************************************************!*\
  !*** ./node_modules/@msgpack/msgpack/dist.es5+esm/timestamp.mjs ***!
  \******************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   EXT_TIMESTAMP: () => (/* binding */ EXT_TIMESTAMP),\n/* harmony export */   decodeTimestampExtension: () => (/* binding */ decodeTimestampExtension),\n/* harmony export */   decodeTimestampToTimeSpec: () => (/* binding */ decodeTimestampToTimeSpec),\n/* harmony export */   encodeDateToTimeSpec: () => (/* binding */ encodeDateToTimeSpec),\n/* harmony export */   encodeTimeSpecToTimestamp: () => (/* binding */ encodeTimeSpecToTimestamp),\n/* harmony export */   encodeTimestampExtension: () => (/* binding */ encodeTimestampExtension),\n/* harmony export */   timestampExtension: () => (/* binding */ timestampExtension)\n/* harmony export */ });\n/* harmony import */ var _DecodeError_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./DecodeError.mjs */ \"./node_modules/@msgpack/msgpack/dist.es5+esm/DecodeError.mjs\");\n/* harmony import */ var _utils_int_mjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./utils/int.mjs */ \"./node_modules/@msgpack/msgpack/dist.es5+esm/utils/int.mjs\");\n// https://github.com/msgpack/msgpack/blob/master/spec.md#timestamp-extension-type\n\n\nvar EXT_TIMESTAMP = -1;\nvar TIMESTAMP32_MAX_SEC = 0x100000000 - 1; // 32-bit unsigned int\nvar TIMESTAMP64_MAX_SEC = 0x400000000 - 1; // 34-bit unsigned int\nfunction encodeTimeSpecToTimestamp(_a) {\n    var sec = _a.sec, nsec = _a.nsec;\n    if (sec >= 0 && nsec >= 0 && sec <= TIMESTAMP64_MAX_SEC) {\n        // Here sec >= 0 && nsec >= 0\n        if (nsec === 0 && sec <= TIMESTAMP32_MAX_SEC) {\n            // timestamp 32 = { sec32 (unsigned) }\n            var rv = new Uint8Array(4);\n            var view = new DataView(rv.buffer);\n            view.setUint32(0, sec);\n            return rv;\n        }\n        else {\n            // timestamp 64 = { nsec30 (unsigned), sec34 (unsigned) }\n            var secHigh = sec / 0x100000000;\n            var secLow = sec & 0xffffffff;\n            var rv = new Uint8Array(8);\n            var view = new DataView(rv.buffer);\n            // nsec30 | secHigh2\n            view.setUint32(0, (nsec << 2) | (secHigh & 0x3));\n            // secLow32\n            view.setUint32(4, secLow);\n            return rv;\n        }\n    }\n    else {\n        // timestamp 96 = { nsec32 (unsigned), sec64 (signed) }\n        var rv = new Uint8Array(12);\n        var view = new DataView(rv.buffer);\n        view.setUint32(0, nsec);\n        (0,_utils_int_mjs__WEBPACK_IMPORTED_MODULE_1__.setInt64)(view, 4, sec);\n        return rv;\n    }\n}\nfunction encodeDateToTimeSpec(date) {\n    var msec = date.getTime();\n    var sec = Math.floor(msec / 1e3);\n    var nsec = (msec - sec * 1e3) * 1e6;\n    // Normalizes { sec, nsec } to ensure nsec is unsigned.\n    var nsecInSec = Math.floor(nsec / 1e9);\n    return {\n        sec: sec + nsecInSec,\n        nsec: nsec - nsecInSec * 1e9,\n    };\n}\nfunction encodeTimestampExtension(object) {\n    if (object instanceof Date) {\n        var timeSpec = encodeDateToTimeSpec(object);\n        return encodeTimeSpecToTimestamp(timeSpec);\n    }\n    else {\n        return null;\n    }\n}\nfunction decodeTimestampToTimeSpec(data) {\n    var view = new DataView(data.buffer, data.byteOffset, data.byteLength);\n    // data may be 32, 64, or 96 bits\n    switch (data.byteLength) {\n        case 4: {\n            // timestamp 32 = { sec32 }\n            var sec = view.getUint32(0);\n            var nsec = 0;\n            return { sec: sec, nsec: nsec };\n        }\n        case 8: {\n            // timestamp 64 = { nsec30, sec34 }\n            var nsec30AndSecHigh2 = view.getUint32(0);\n            var secLow32 = view.getUint32(4);\n            var sec = (nsec30AndSecHigh2 & 0x3) * 0x100000000 + secLow32;\n            var nsec = nsec30AndSecHigh2 >>> 2;\n            return { sec: sec, nsec: nsec };\n        }\n        case 12: {\n            // timestamp 96 = { nsec32 (unsigned), sec64 (signed) }\n            var sec = (0,_utils_int_mjs__WEBPACK_IMPORTED_MODULE_1__.getInt64)(view, 4);\n            var nsec = view.getUint32(0);\n            return { sec: sec, nsec: nsec };\n        }\n        default:\n            throw new _DecodeError_mjs__WEBPACK_IMPORTED_MODULE_0__.DecodeError(\"Unrecognized data size for timestamp (expected 4, 8, or 12): \".concat(data.length));\n    }\n}\nfunction decodeTimestampExtension(data) {\n    var timeSpec = decodeTimestampToTimeSpec(data);\n    return new Date(timeSpec.sec * 1e3 + timeSpec.nsec / 1e6);\n}\nvar timestampExtension = {\n    type: EXT_TIMESTAMP,\n    encode: encodeTimestampExtension,\n    decode: decodeTimestampExtension,\n};\n//# sourceMappingURL=timestamp.mjs.map\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/@msgpack/msgpack/dist.es5+esm/timestamp.mjs?\n}");

/***/ }),

/***/ "./node_modules/@msgpack/msgpack/dist.es5+esm/utils/int.mjs":
/*!******************************************************************!*\
  !*** ./node_modules/@msgpack/msgpack/dist.es5+esm/utils/int.mjs ***!
  \******************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   UINT32_MAX: () => (/* binding */ UINT32_MAX),\n/* harmony export */   getInt64: () => (/* binding */ getInt64),\n/* harmony export */   getUint64: () => (/* binding */ getUint64),\n/* harmony export */   setInt64: () => (/* binding */ setInt64),\n/* harmony export */   setUint64: () => (/* binding */ setUint64)\n/* harmony export */ });\n// Integer Utility\nvar UINT32_MAX = 4294967295;\n// DataView extension to handle int64 / uint64,\n// where the actual range is 53-bits integer (a.k.a. safe integer)\nfunction setUint64(view, offset, value) {\n    var high = value / 4294967296;\n    var low = value; // high bits are truncated by DataView\n    view.setUint32(offset, high);\n    view.setUint32(offset + 4, low);\n}\nfunction setInt64(view, offset, value) {\n    var high = Math.floor(value / 4294967296);\n    var low = value; // high bits are truncated by DataView\n    view.setUint32(offset, high);\n    view.setUint32(offset + 4, low);\n}\nfunction getInt64(view, offset) {\n    var high = view.getInt32(offset);\n    var low = view.getUint32(offset + 4);\n    return high * 4294967296 + low;\n}\nfunction getUint64(view, offset) {\n    var high = view.getUint32(offset);\n    var low = view.getUint32(offset + 4);\n    return high * 4294967296 + low;\n}\n//# sourceMappingURL=int.mjs.map\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/@msgpack/msgpack/dist.es5+esm/utils/int.mjs?\n}");

/***/ }),

/***/ "./node_modules/@msgpack/msgpack/dist.es5+esm/utils/prettyByte.mjs":
/*!*************************************************************************!*\
  !*** ./node_modules/@msgpack/msgpack/dist.es5+esm/utils/prettyByte.mjs ***!
  \*************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   prettyByte: () => (/* binding */ prettyByte)\n/* harmony export */ });\nfunction prettyByte(byte) {\n    return \"\".concat(byte < 0 ? \"-\" : \"\", \"0x\").concat(Math.abs(byte).toString(16).padStart(2, \"0\"));\n}\n//# sourceMappingURL=prettyByte.mjs.map\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/@msgpack/msgpack/dist.es5+esm/utils/prettyByte.mjs?\n}");

/***/ }),

/***/ "./node_modules/@msgpack/msgpack/dist.es5+esm/utils/stream.mjs":
/*!*********************************************************************!*\
  !*** ./node_modules/@msgpack/msgpack/dist.es5+esm/utils/stream.mjs ***!
  \*********************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   asyncIterableFromStream: () => (/* binding */ asyncIterableFromStream),\n/* harmony export */   ensureAsyncIterable: () => (/* binding */ ensureAsyncIterable),\n/* harmony export */   isAsyncIterable: () => (/* binding */ isAsyncIterable)\n/* harmony export */ });\n// utility for whatwg streams\nvar __generator = (undefined && undefined.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nvar __await = (undefined && undefined.__await) || function (v) { return this instanceof __await ? (this.v = v, this) : new __await(v); }\nvar __asyncGenerator = (undefined && undefined.__asyncGenerator) || function (thisArg, _arguments, generator) {\n    if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\n    var g = generator.apply(thisArg, _arguments || []), i, q = [];\n    return i = {}, verb(\"next\"), verb(\"throw\"), verb(\"return\"), i[Symbol.asyncIterator] = function () { return this; }, i;\n    function verb(n) { if (g[n]) i[n] = function (v) { return new Promise(function (a, b) { q.push([n, v, a, b]) > 1 || resume(n, v); }); }; }\n    function resume(n, v) { try { step(g[n](v)); } catch (e) { settle(q[0][3], e); } }\n    function step(r) { r.value instanceof __await ? Promise.resolve(r.value.v).then(fulfill, reject) : settle(q[0][2], r); }\n    function fulfill(value) { resume(\"next\", value); }\n    function reject(value) { resume(\"throw\", value); }\n    function settle(f, v) { if (f(v), q.shift(), q.length) resume(q[0][0], q[0][1]); }\n};\nfunction isAsyncIterable(object) {\n    return object[Symbol.asyncIterator] != null;\n}\nfunction assertNonNull(value) {\n    if (value == null) {\n        throw new Error(\"Assertion Failure: value must not be null nor undefined\");\n    }\n}\nfunction asyncIterableFromStream(stream) {\n    return __asyncGenerator(this, arguments, function asyncIterableFromStream_1() {\n        var reader, _a, done, value;\n        return __generator(this, function (_b) {\n            switch (_b.label) {\n                case 0:\n                    reader = stream.getReader();\n                    _b.label = 1;\n                case 1:\n                    _b.trys.push([1, , 9, 10]);\n                    _b.label = 2;\n                case 2:\n                    if (false) // removed by dead control flow\n{}\n                    return [4 /*yield*/, __await(reader.read())];\n                case 3:\n                    _a = _b.sent(), done = _a.done, value = _a.value;\n                    if (!done) return [3 /*break*/, 5];\n                    return [4 /*yield*/, __await(void 0)];\n                case 4: return [2 /*return*/, _b.sent()];\n                case 5:\n                    assertNonNull(value);\n                    return [4 /*yield*/, __await(value)];\n                case 6: return [4 /*yield*/, _b.sent()];\n                case 7:\n                    _b.sent();\n                    return [3 /*break*/, 2];\n                case 8: return [3 /*break*/, 10];\n                case 9:\n                    reader.releaseLock();\n                    return [7 /*endfinally*/];\n                case 10: return [2 /*return*/];\n            }\n        });\n    });\n}\nfunction ensureAsyncIterable(streamLike) {\n    if (isAsyncIterable(streamLike)) {\n        return streamLike;\n    }\n    else {\n        return asyncIterableFromStream(streamLike);\n    }\n}\n//# sourceMappingURL=stream.mjs.map\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/@msgpack/msgpack/dist.es5+esm/utils/stream.mjs?\n}");

/***/ }),

/***/ "./node_modules/@msgpack/msgpack/dist.es5+esm/utils/typedArrays.mjs":
/*!**************************************************************************!*\
  !*** ./node_modules/@msgpack/msgpack/dist.es5+esm/utils/typedArrays.mjs ***!
  \**************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   createDataView: () => (/* binding */ createDataView),\n/* harmony export */   ensureUint8Array: () => (/* binding */ ensureUint8Array)\n/* harmony export */ });\nfunction ensureUint8Array(buffer) {\n    if (buffer instanceof Uint8Array) {\n        return buffer;\n    }\n    else if (ArrayBuffer.isView(buffer)) {\n        return new Uint8Array(buffer.buffer, buffer.byteOffset, buffer.byteLength);\n    }\n    else if (buffer instanceof ArrayBuffer) {\n        return new Uint8Array(buffer);\n    }\n    else {\n        // ArrayLike<number>\n        return Uint8Array.from(buffer);\n    }\n}\nfunction createDataView(buffer) {\n    if (buffer instanceof ArrayBuffer) {\n        return new DataView(buffer);\n    }\n    var bufferView = ensureUint8Array(buffer);\n    return new DataView(bufferView.buffer, bufferView.byteOffset, bufferView.byteLength);\n}\n//# sourceMappingURL=typedArrays.mjs.map\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/@msgpack/msgpack/dist.es5+esm/utils/typedArrays.mjs?\n}");

/***/ }),

/***/ "./node_modules/@msgpack/msgpack/dist.es5+esm/utils/utf8.mjs":
/*!*******************************************************************!*\
  !*** ./node_modules/@msgpack/msgpack/dist.es5+esm/utils/utf8.mjs ***!
  \*******************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   TEXT_DECODER_THRESHOLD: () => (/* binding */ TEXT_DECODER_THRESHOLD),\n/* harmony export */   TEXT_ENCODER_THRESHOLD: () => (/* binding */ TEXT_ENCODER_THRESHOLD),\n/* harmony export */   utf8Count: () => (/* binding */ utf8Count),\n/* harmony export */   utf8DecodeJs: () => (/* binding */ utf8DecodeJs),\n/* harmony export */   utf8DecodeTD: () => (/* binding */ utf8DecodeTD),\n/* harmony export */   utf8EncodeJs: () => (/* binding */ utf8EncodeJs),\n/* harmony export */   utf8EncodeTE: () => (/* binding */ utf8EncodeTE)\n/* harmony export */ });\n/* harmony import */ var _int_mjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./int.mjs */ \"./node_modules/@msgpack/msgpack/dist.es5+esm/utils/int.mjs\");\nvar _a, _b, _c;\n/* eslint-disable @typescript-eslint/no-unnecessary-condition */\n\nvar TEXT_ENCODING_AVAILABLE = (typeof process === \"undefined\" || ((_a = process === null || process === void 0 ? void 0 : process.env) === null || _a === void 0 ? void 0 : _a[\"TEXT_ENCODING\"]) !== \"never\") &&\n    typeof TextEncoder !== \"undefined\" &&\n    typeof TextDecoder !== \"undefined\";\nfunction utf8Count(str) {\n    var strLength = str.length;\n    var byteLength = 0;\n    var pos = 0;\n    while (pos < strLength) {\n        var value = str.charCodeAt(pos++);\n        if ((value & 0xffffff80) === 0) {\n            // 1-byte\n            byteLength++;\n            continue;\n        }\n        else if ((value & 0xfffff800) === 0) {\n            // 2-bytes\n            byteLength += 2;\n        }\n        else {\n            // handle surrogate pair\n            if (value >= 0xd800 && value <= 0xdbff) {\n                // high surrogate\n                if (pos < strLength) {\n                    var extra = str.charCodeAt(pos);\n                    if ((extra & 0xfc00) === 0xdc00) {\n                        ++pos;\n                        value = ((value & 0x3ff) << 10) + (extra & 0x3ff) + 0x10000;\n                    }\n                }\n            }\n            if ((value & 0xffff0000) === 0) {\n                // 3-byte\n                byteLength += 3;\n            }\n            else {\n                // 4-byte\n                byteLength += 4;\n            }\n        }\n    }\n    return byteLength;\n}\nfunction utf8EncodeJs(str, output, outputOffset) {\n    var strLength = str.length;\n    var offset = outputOffset;\n    var pos = 0;\n    while (pos < strLength) {\n        var value = str.charCodeAt(pos++);\n        if ((value & 0xffffff80) === 0) {\n            // 1-byte\n            output[offset++] = value;\n            continue;\n        }\n        else if ((value & 0xfffff800) === 0) {\n            // 2-bytes\n            output[offset++] = ((value >> 6) & 0x1f) | 0xc0;\n        }\n        else {\n            // handle surrogate pair\n            if (value >= 0xd800 && value <= 0xdbff) {\n                // high surrogate\n                if (pos < strLength) {\n                    var extra = str.charCodeAt(pos);\n                    if ((extra & 0xfc00) === 0xdc00) {\n                        ++pos;\n                        value = ((value & 0x3ff) << 10) + (extra & 0x3ff) + 0x10000;\n                    }\n                }\n            }\n            if ((value & 0xffff0000) === 0) {\n                // 3-byte\n                output[offset++] = ((value >> 12) & 0x0f) | 0xe0;\n                output[offset++] = ((value >> 6) & 0x3f) | 0x80;\n            }\n            else {\n                // 4-byte\n                output[offset++] = ((value >> 18) & 0x07) | 0xf0;\n                output[offset++] = ((value >> 12) & 0x3f) | 0x80;\n                output[offset++] = ((value >> 6) & 0x3f) | 0x80;\n            }\n        }\n        output[offset++] = (value & 0x3f) | 0x80;\n    }\n}\nvar sharedTextEncoder = TEXT_ENCODING_AVAILABLE ? new TextEncoder() : undefined;\nvar TEXT_ENCODER_THRESHOLD = !TEXT_ENCODING_AVAILABLE\n    ? _int_mjs__WEBPACK_IMPORTED_MODULE_0__.UINT32_MAX\n    : typeof process !== \"undefined\" && ((_b = process === null || process === void 0 ? void 0 : process.env) === null || _b === void 0 ? void 0 : _b[\"TEXT_ENCODING\"]) !== \"force\"\n        ? 200\n        : 0;\nfunction utf8EncodeTEencode(str, output, outputOffset) {\n    output.set(sharedTextEncoder.encode(str), outputOffset);\n}\nfunction utf8EncodeTEencodeInto(str, output, outputOffset) {\n    sharedTextEncoder.encodeInto(str, output.subarray(outputOffset));\n}\nvar utf8EncodeTE = (sharedTextEncoder === null || sharedTextEncoder === void 0 ? void 0 : sharedTextEncoder.encodeInto) ? utf8EncodeTEencodeInto : utf8EncodeTEencode;\nvar CHUNK_SIZE = 4096;\nfunction utf8DecodeJs(bytes, inputOffset, byteLength) {\n    var offset = inputOffset;\n    var end = offset + byteLength;\n    var units = [];\n    var result = \"\";\n    while (offset < end) {\n        var byte1 = bytes[offset++];\n        if ((byte1 & 0x80) === 0) {\n            // 1 byte\n            units.push(byte1);\n        }\n        else if ((byte1 & 0xe0) === 0xc0) {\n            // 2 bytes\n            var byte2 = bytes[offset++] & 0x3f;\n            units.push(((byte1 & 0x1f) << 6) | byte2);\n        }\n        else if ((byte1 & 0xf0) === 0xe0) {\n            // 3 bytes\n            var byte2 = bytes[offset++] & 0x3f;\n            var byte3 = bytes[offset++] & 0x3f;\n            units.push(((byte1 & 0x1f) << 12) | (byte2 << 6) | byte3);\n        }\n        else if ((byte1 & 0xf8) === 0xf0) {\n            // 4 bytes\n            var byte2 = bytes[offset++] & 0x3f;\n            var byte3 = bytes[offset++] & 0x3f;\n            var byte4 = bytes[offset++] & 0x3f;\n            var unit = ((byte1 & 0x07) << 0x12) | (byte2 << 0x0c) | (byte3 << 0x06) | byte4;\n            if (unit > 0xffff) {\n                unit -= 0x10000;\n                units.push(((unit >>> 10) & 0x3ff) | 0xd800);\n                unit = 0xdc00 | (unit & 0x3ff);\n            }\n            units.push(unit);\n        }\n        else {\n            units.push(byte1);\n        }\n        if (units.length >= CHUNK_SIZE) {\n            result += String.fromCharCode.apply(String, units);\n            units.length = 0;\n        }\n    }\n    if (units.length > 0) {\n        result += String.fromCharCode.apply(String, units);\n    }\n    return result;\n}\nvar sharedTextDecoder = TEXT_ENCODING_AVAILABLE ? new TextDecoder() : null;\nvar TEXT_DECODER_THRESHOLD = !TEXT_ENCODING_AVAILABLE\n    ? _int_mjs__WEBPACK_IMPORTED_MODULE_0__.UINT32_MAX\n    : typeof process !== \"undefined\" && ((_c = process === null || process === void 0 ? void 0 : process.env) === null || _c === void 0 ? void 0 : _c[\"TEXT_DECODER\"]) !== \"force\"\n        ? 200\n        : 0;\nfunction utf8DecodeTD(bytes, inputOffset, byteLength) {\n    var stringBytes = bytes.subarray(inputOffset, inputOffset + byteLength);\n    return sharedTextDecoder.decode(stringBytes);\n}\n//# sourceMappingURL=utf8.mjs.map\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/@msgpack/msgpack/dist.es5+esm/utils/utf8.mjs?\n}");

/***/ }),

/***/ "./node_modules/@tweenjs/tween.js/dist/tween.esm.js":
/*!**********************************************************!*\
  !*** ./node_modules/@tweenjs/tween.js/dist/tween.esm.js ***!
  \**********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Easing: () => (/* binding */ Easing),\n/* harmony export */   Group: () => (/* binding */ Group),\n/* harmony export */   Interpolation: () => (/* binding */ Interpolation),\n/* harmony export */   Sequence: () => (/* binding */ Sequence),\n/* harmony export */   Tween: () => (/* binding */ Tween),\n/* harmony export */   VERSION: () => (/* binding */ VERSION),\n/* harmony export */   add: () => (/* binding */ add),\n/* harmony export */   \"default\": () => (/* binding */ exports),\n/* harmony export */   getAll: () => (/* binding */ getAll),\n/* harmony export */   nextId: () => (/* binding */ nextId),\n/* harmony export */   now: () => (/* binding */ now),\n/* harmony export */   remove: () => (/* binding */ remove),\n/* harmony export */   removeAll: () => (/* binding */ removeAll),\n/* harmony export */   update: () => (/* binding */ update)\n/* harmony export */ });\n/**\n * The Ease class provides a collection of easing functions for use with tween.js.\n */\nvar Easing = Object.freeze({\n    Linear: Object.freeze({\n        None: function (amount) {\n            return amount;\n        },\n        In: function (amount) {\n            return amount;\n        },\n        Out: function (amount) {\n            return amount;\n        },\n        InOut: function (amount) {\n            return amount;\n        },\n    }),\n    Quadratic: Object.freeze({\n        In: function (amount) {\n            return amount * amount;\n        },\n        Out: function (amount) {\n            return amount * (2 - amount);\n        },\n        InOut: function (amount) {\n            if ((amount *= 2) < 1) {\n                return 0.5 * amount * amount;\n            }\n            return -0.5 * (--amount * (amount - 2) - 1);\n        },\n    }),\n    Cubic: Object.freeze({\n        In: function (amount) {\n            return amount * amount * amount;\n        },\n        Out: function (amount) {\n            return --amount * amount * amount + 1;\n        },\n        InOut: function (amount) {\n            if ((amount *= 2) < 1) {\n                return 0.5 * amount * amount * amount;\n            }\n            return 0.5 * ((amount -= 2) * amount * amount + 2);\n        },\n    }),\n    Quartic: Object.freeze({\n        In: function (amount) {\n            return amount * amount * amount * amount;\n        },\n        Out: function (amount) {\n            return 1 - --amount * amount * amount * amount;\n        },\n        InOut: function (amount) {\n            if ((amount *= 2) < 1) {\n                return 0.5 * amount * amount * amount * amount;\n            }\n            return -0.5 * ((amount -= 2) * amount * amount * amount - 2);\n        },\n    }),\n    Quintic: Object.freeze({\n        In: function (amount) {\n            return amount * amount * amount * amount * amount;\n        },\n        Out: function (amount) {\n            return --amount * amount * amount * amount * amount + 1;\n        },\n        InOut: function (amount) {\n            if ((amount *= 2) < 1) {\n                return 0.5 * amount * amount * amount * amount * amount;\n            }\n            return 0.5 * ((amount -= 2) * amount * amount * amount * amount + 2);\n        },\n    }),\n    Sinusoidal: Object.freeze({\n        In: function (amount) {\n            return 1 - Math.sin(((1.0 - amount) * Math.PI) / 2);\n        },\n        Out: function (amount) {\n            return Math.sin((amount * Math.PI) / 2);\n        },\n        InOut: function (amount) {\n            return 0.5 * (1 - Math.sin(Math.PI * (0.5 - amount)));\n        },\n    }),\n    Exponential: Object.freeze({\n        In: function (amount) {\n            return amount === 0 ? 0 : Math.pow(1024, amount - 1);\n        },\n        Out: function (amount) {\n            return amount === 1 ? 1 : 1 - Math.pow(2, -10 * amount);\n        },\n        InOut: function (amount) {\n            if (amount === 0) {\n                return 0;\n            }\n            if (amount === 1) {\n                return 1;\n            }\n            if ((amount *= 2) < 1) {\n                return 0.5 * Math.pow(1024, amount - 1);\n            }\n            return 0.5 * (-Math.pow(2, -10 * (amount - 1)) + 2);\n        },\n    }),\n    Circular: Object.freeze({\n        In: function (amount) {\n            return 1 - Math.sqrt(1 - amount * amount);\n        },\n        Out: function (amount) {\n            return Math.sqrt(1 - --amount * amount);\n        },\n        InOut: function (amount) {\n            if ((amount *= 2) < 1) {\n                return -0.5 * (Math.sqrt(1 - amount * amount) - 1);\n            }\n            return 0.5 * (Math.sqrt(1 - (amount -= 2) * amount) + 1);\n        },\n    }),\n    Elastic: Object.freeze({\n        In: function (amount) {\n            if (amount === 0) {\n                return 0;\n            }\n            if (amount === 1) {\n                return 1;\n            }\n            return -Math.pow(2, 10 * (amount - 1)) * Math.sin((amount - 1.1) * 5 * Math.PI);\n        },\n        Out: function (amount) {\n            if (amount === 0) {\n                return 0;\n            }\n            if (amount === 1) {\n                return 1;\n            }\n            return Math.pow(2, -10 * amount) * Math.sin((amount - 0.1) * 5 * Math.PI) + 1;\n        },\n        InOut: function (amount) {\n            if (amount === 0) {\n                return 0;\n            }\n            if (amount === 1) {\n                return 1;\n            }\n            amount *= 2;\n            if (amount < 1) {\n                return -0.5 * Math.pow(2, 10 * (amount - 1)) * Math.sin((amount - 1.1) * 5 * Math.PI);\n            }\n            return 0.5 * Math.pow(2, -10 * (amount - 1)) * Math.sin((amount - 1.1) * 5 * Math.PI) + 1;\n        },\n    }),\n    Back: Object.freeze({\n        In: function (amount) {\n            var s = 1.70158;\n            return amount === 1 ? 1 : amount * amount * ((s + 1) * amount - s);\n        },\n        Out: function (amount) {\n            var s = 1.70158;\n            return amount === 0 ? 0 : --amount * amount * ((s + 1) * amount + s) + 1;\n        },\n        InOut: function (amount) {\n            var s = 1.70158 * 1.525;\n            if ((amount *= 2) < 1) {\n                return 0.5 * (amount * amount * ((s + 1) * amount - s));\n            }\n            return 0.5 * ((amount -= 2) * amount * ((s + 1) * amount + s) + 2);\n        },\n    }),\n    Bounce: Object.freeze({\n        In: function (amount) {\n            return 1 - Easing.Bounce.Out(1 - amount);\n        },\n        Out: function (amount) {\n            if (amount < 1 / 2.75) {\n                return 7.5625 * amount * amount;\n            }\n            else if (amount < 2 / 2.75) {\n                return 7.5625 * (amount -= 1.5 / 2.75) * amount + 0.75;\n            }\n            else if (amount < 2.5 / 2.75) {\n                return 7.5625 * (amount -= 2.25 / 2.75) * amount + 0.9375;\n            }\n            else {\n                return 7.5625 * (amount -= 2.625 / 2.75) * amount + 0.984375;\n            }\n        },\n        InOut: function (amount) {\n            if (amount < 0.5) {\n                return Easing.Bounce.In(amount * 2) * 0.5;\n            }\n            return Easing.Bounce.Out(amount * 2 - 1) * 0.5 + 0.5;\n        },\n    }),\n    generatePow: function (power) {\n        if (power === void 0) { power = 4; }\n        power = power < Number.EPSILON ? Number.EPSILON : power;\n        power = power > 10000 ? 10000 : power;\n        return {\n            In: function (amount) {\n                return Math.pow(amount, power);\n            },\n            Out: function (amount) {\n                return 1 - Math.pow((1 - amount), power);\n            },\n            InOut: function (amount) {\n                if (amount < 0.5) {\n                    return Math.pow((amount * 2), power) / 2;\n                }\n                return (1 - Math.pow((2 - amount * 2), power)) / 2 + 0.5;\n            },\n        };\n    },\n});\n\nvar now = function () { return performance.now(); };\n\n/**\n * Controlling groups of tweens\n *\n * Using the TWEEN singleton to manage your tweens can cause issues in large apps with many components.\n * In these cases, you may want to create your own smaller groups of tween\n */\nvar Group = /** @class */ (function () {\n    function Group() {\n        this._tweens = {};\n        this._tweensAddedDuringUpdate = {};\n    }\n    Group.prototype.getAll = function () {\n        var _this = this;\n        return Object.keys(this._tweens).map(function (tweenId) {\n            return _this._tweens[tweenId];\n        });\n    };\n    Group.prototype.removeAll = function () {\n        this._tweens = {};\n    };\n    Group.prototype.add = function (tween) {\n        this._tweens[tween.getId()] = tween;\n        this._tweensAddedDuringUpdate[tween.getId()] = tween;\n    };\n    Group.prototype.remove = function (tween) {\n        delete this._tweens[tween.getId()];\n        delete this._tweensAddedDuringUpdate[tween.getId()];\n    };\n    Group.prototype.update = function (time, preserve) {\n        if (time === void 0) { time = now(); }\n        if (preserve === void 0) { preserve = false; }\n        var tweenIds = Object.keys(this._tweens);\n        if (tweenIds.length === 0) {\n            return false;\n        }\n        // Tweens are updated in \"batches\". If you add a new tween during an\n        // update, then the new tween will be updated in the next batch.\n        // If you remove a tween during an update, it may or may not be updated.\n        // However, if the removed tween was added during the current batch,\n        // then it will not be updated.\n        while (tweenIds.length > 0) {\n            this._tweensAddedDuringUpdate = {};\n            for (var i = 0; i < tweenIds.length; i++) {\n                var tween = this._tweens[tweenIds[i]];\n                var autoStart = !preserve;\n                if (tween && tween.update(time, autoStart) === false && !preserve) {\n                    delete this._tweens[tweenIds[i]];\n                }\n            }\n            tweenIds = Object.keys(this._tweensAddedDuringUpdate);\n        }\n        return true;\n    };\n    return Group;\n}());\n\n/**\n *\n */\nvar Interpolation = {\n    Linear: function (v, k) {\n        var m = v.length - 1;\n        var f = m * k;\n        var i = Math.floor(f);\n        var fn = Interpolation.Utils.Linear;\n        if (k < 0) {\n            return fn(v[0], v[1], f);\n        }\n        if (k > 1) {\n            return fn(v[m], v[m - 1], m - f);\n        }\n        return fn(v[i], v[i + 1 > m ? m : i + 1], f - i);\n    },\n    Bezier: function (v, k) {\n        var b = 0;\n        var n = v.length - 1;\n        var pw = Math.pow;\n        var bn = Interpolation.Utils.Bernstein;\n        for (var i = 0; i <= n; i++) {\n            b += pw(1 - k, n - i) * pw(k, i) * v[i] * bn(n, i);\n        }\n        return b;\n    },\n    CatmullRom: function (v, k) {\n        var m = v.length - 1;\n        var f = m * k;\n        var i = Math.floor(f);\n        var fn = Interpolation.Utils.CatmullRom;\n        if (v[0] === v[m]) {\n            if (k < 0) {\n                i = Math.floor((f = m * (1 + k)));\n            }\n            return fn(v[(i - 1 + m) % m], v[i], v[(i + 1) % m], v[(i + 2) % m], f - i);\n        }\n        else {\n            if (k < 0) {\n                return v[0] - (fn(v[0], v[0], v[1], v[1], -f) - v[0]);\n            }\n            if (k > 1) {\n                return v[m] - (fn(v[m], v[m], v[m - 1], v[m - 1], f - m) - v[m]);\n            }\n            return fn(v[i ? i - 1 : 0], v[i], v[m < i + 1 ? m : i + 1], v[m < i + 2 ? m : i + 2], f - i);\n        }\n    },\n    Utils: {\n        Linear: function (p0, p1, t) {\n            return (p1 - p0) * t + p0;\n        },\n        Bernstein: function (n, i) {\n            var fc = Interpolation.Utils.Factorial;\n            return fc(n) / fc(i) / fc(n - i);\n        },\n        Factorial: (function () {\n            var a = [1];\n            return function (n) {\n                var s = 1;\n                if (a[n]) {\n                    return a[n];\n                }\n                for (var i = n; i > 1; i--) {\n                    s *= i;\n                }\n                a[n] = s;\n                return s;\n            };\n        })(),\n        CatmullRom: function (p0, p1, p2, p3, t) {\n            var v0 = (p2 - p0) * 0.5;\n            var v1 = (p3 - p1) * 0.5;\n            var t2 = t * t;\n            var t3 = t * t2;\n            return (2 * p1 - 2 * p2 + v0 + v1) * t3 + (-3 * p1 + 3 * p2 - 2 * v0 - v1) * t2 + v0 * t + p1;\n        },\n    },\n};\n\n/**\n * Utils\n */\nvar Sequence = /** @class */ (function () {\n    function Sequence() {\n    }\n    Sequence.nextId = function () {\n        return Sequence._nextId++;\n    };\n    Sequence._nextId = 0;\n    return Sequence;\n}());\n\nvar mainGroup = new Group();\n\n/**\n * Tween.js - Licensed under the MIT license\n * https://github.com/tweenjs/tween.js\n * ----------------------------------------------\n *\n * See https://github.com/tweenjs/tween.js/graphs/contributors for the full list of contributors.\n * Thank you all, you're awesome!\n */\nvar Tween = /** @class */ (function () {\n    function Tween(_object, _group) {\n        if (_group === void 0) { _group = mainGroup; }\n        this._object = _object;\n        this._group = _group;\n        this._isPaused = false;\n        this._pauseStart = 0;\n        this._valuesStart = {};\n        this._valuesEnd = {};\n        this._valuesStartRepeat = {};\n        this._duration = 1000;\n        this._isDynamic = false;\n        this._initialRepeat = 0;\n        this._repeat = 0;\n        this._yoyo = false;\n        this._isPlaying = false;\n        this._reversed = false;\n        this._delayTime = 0;\n        this._startTime = 0;\n        this._easingFunction = Easing.Linear.None;\n        this._interpolationFunction = Interpolation.Linear;\n        // eslint-disable-next-line\n        this._chainedTweens = [];\n        this._onStartCallbackFired = false;\n        this._onEveryStartCallbackFired = false;\n        this._id = Sequence.nextId();\n        this._isChainStopped = false;\n        this._propertiesAreSetUp = false;\n        this._goToEnd = false;\n    }\n    Tween.prototype.getId = function () {\n        return this._id;\n    };\n    Tween.prototype.isPlaying = function () {\n        return this._isPlaying;\n    };\n    Tween.prototype.isPaused = function () {\n        return this._isPaused;\n    };\n    Tween.prototype.getDuration = function () {\n        return this._duration;\n    };\n    Tween.prototype.to = function (target, duration) {\n        if (duration === void 0) { duration = 1000; }\n        if (this._isPlaying)\n            throw new Error('Can not call Tween.to() while Tween is already started or paused. Stop the Tween first.');\n        this._valuesEnd = target;\n        this._propertiesAreSetUp = false;\n        this._duration = duration < 0 ? 0 : duration;\n        return this;\n    };\n    Tween.prototype.duration = function (duration) {\n        if (duration === void 0) { duration = 1000; }\n        this._duration = duration < 0 ? 0 : duration;\n        return this;\n    };\n    Tween.prototype.dynamic = function (dynamic) {\n        if (dynamic === void 0) { dynamic = false; }\n        this._isDynamic = dynamic;\n        return this;\n    };\n    Tween.prototype.start = function (time, overrideStartingValues) {\n        if (time === void 0) { time = now(); }\n        if (overrideStartingValues === void 0) { overrideStartingValues = false; }\n        if (this._isPlaying) {\n            return this;\n        }\n        // eslint-disable-next-line\n        this._group && this._group.add(this);\n        this._repeat = this._initialRepeat;\n        if (this._reversed) {\n            // If we were reversed (f.e. using the yoyo feature) then we need to\n            // flip the tween direction back to forward.\n            this._reversed = false;\n            for (var property in this._valuesStartRepeat) {\n                this._swapEndStartRepeatValues(property);\n                this._valuesStart[property] = this._valuesStartRepeat[property];\n            }\n        }\n        this._isPlaying = true;\n        this._isPaused = false;\n        this._onStartCallbackFired = false;\n        this._onEveryStartCallbackFired = false;\n        this._isChainStopped = false;\n        this._startTime = time;\n        this._startTime += this._delayTime;\n        if (!this._propertiesAreSetUp || overrideStartingValues) {\n            this._propertiesAreSetUp = true;\n            // If dynamic is not enabled, clone the end values instead of using the passed-in end values.\n            if (!this._isDynamic) {\n                var tmp = {};\n                for (var prop in this._valuesEnd)\n                    tmp[prop] = this._valuesEnd[prop];\n                this._valuesEnd = tmp;\n            }\n            this._setupProperties(this._object, this._valuesStart, this._valuesEnd, this._valuesStartRepeat, overrideStartingValues);\n        }\n        return this;\n    };\n    Tween.prototype.startFromCurrentValues = function (time) {\n        return this.start(time, true);\n    };\n    Tween.prototype._setupProperties = function (_object, _valuesStart, _valuesEnd, _valuesStartRepeat, overrideStartingValues) {\n        for (var property in _valuesEnd) {\n            var startValue = _object[property];\n            var startValueIsArray = Array.isArray(startValue);\n            var propType = startValueIsArray ? 'array' : typeof startValue;\n            var isInterpolationList = !startValueIsArray && Array.isArray(_valuesEnd[property]);\n            // If `to()` specifies a property that doesn't exist in the source object,\n            // we should not set that property in the object\n            if (propType === 'undefined' || propType === 'function') {\n                continue;\n            }\n            // Check if an Array was provided as property value\n            if (isInterpolationList) {\n                var endValues = _valuesEnd[property];\n                if (endValues.length === 0) {\n                    continue;\n                }\n                // Handle an array of relative values.\n                // Creates a local copy of the Array with the start value at the front\n                var temp = [startValue];\n                for (var i = 0, l = endValues.length; i < l; i += 1) {\n                    var value = this._handleRelativeValue(startValue, endValues[i]);\n                    if (isNaN(value)) {\n                        isInterpolationList = false;\n                        console.warn('Found invalid interpolation list. Skipping.');\n                        break;\n                    }\n                    temp.push(value);\n                }\n                if (isInterpolationList) {\n                    // if (_valuesStart[property] === undefined) { // handle end values only the first time. NOT NEEDED? setupProperties is now guarded by _propertiesAreSetUp.\n                    _valuesEnd[property] = temp;\n                    // }\n                }\n            }\n            // handle the deepness of the values\n            if ((propType === 'object' || startValueIsArray) && startValue && !isInterpolationList) {\n                _valuesStart[property] = startValueIsArray ? [] : {};\n                var nestedObject = startValue;\n                for (var prop in nestedObject) {\n                    _valuesStart[property][prop] = nestedObject[prop];\n                }\n                // TODO? repeat nested values? And yoyo? And array values?\n                _valuesStartRepeat[property] = startValueIsArray ? [] : {};\n                var endValues = _valuesEnd[property];\n                // If dynamic is not enabled, clone the end values instead of using the passed-in end values.\n                if (!this._isDynamic) {\n                    var tmp = {};\n                    for (var prop in endValues)\n                        tmp[prop] = endValues[prop];\n                    _valuesEnd[property] = endValues = tmp;\n                }\n                this._setupProperties(nestedObject, _valuesStart[property], endValues, _valuesStartRepeat[property], overrideStartingValues);\n            }\n            else {\n                // Save the starting value, but only once unless override is requested.\n                if (typeof _valuesStart[property] === 'undefined' || overrideStartingValues) {\n                    _valuesStart[property] = startValue;\n                }\n                if (!startValueIsArray) {\n                    // eslint-disable-next-line\n                    // @ts-ignore FIXME?\n                    _valuesStart[property] *= 1.0; // Ensures we're using numbers, not strings\n                }\n                if (isInterpolationList) {\n                    // eslint-disable-next-line\n                    // @ts-ignore FIXME?\n                    _valuesStartRepeat[property] = _valuesEnd[property].slice().reverse();\n                }\n                else {\n                    _valuesStartRepeat[property] = _valuesStart[property] || 0;\n                }\n            }\n        }\n    };\n    Tween.prototype.stop = function () {\n        if (!this._isChainStopped) {\n            this._isChainStopped = true;\n            this.stopChainedTweens();\n        }\n        if (!this._isPlaying) {\n            return this;\n        }\n        // eslint-disable-next-line\n        this._group && this._group.remove(this);\n        this._isPlaying = false;\n        this._isPaused = false;\n        if (this._onStopCallback) {\n            this._onStopCallback(this._object);\n        }\n        return this;\n    };\n    Tween.prototype.end = function () {\n        this._goToEnd = true;\n        this.update(Infinity);\n        return this;\n    };\n    Tween.prototype.pause = function (time) {\n        if (time === void 0) { time = now(); }\n        if (this._isPaused || !this._isPlaying) {\n            return this;\n        }\n        this._isPaused = true;\n        this._pauseStart = time;\n        // eslint-disable-next-line\n        this._group && this._group.remove(this);\n        return this;\n    };\n    Tween.prototype.resume = function (time) {\n        if (time === void 0) { time = now(); }\n        if (!this._isPaused || !this._isPlaying) {\n            return this;\n        }\n        this._isPaused = false;\n        this._startTime += time - this._pauseStart;\n        this._pauseStart = 0;\n        // eslint-disable-next-line\n        this._group && this._group.add(this);\n        return this;\n    };\n    Tween.prototype.stopChainedTweens = function () {\n        for (var i = 0, numChainedTweens = this._chainedTweens.length; i < numChainedTweens; i++) {\n            this._chainedTweens[i].stop();\n        }\n        return this;\n    };\n    Tween.prototype.group = function (group) {\n        if (group === void 0) { group = mainGroup; }\n        this._group = group;\n        return this;\n    };\n    Tween.prototype.delay = function (amount) {\n        if (amount === void 0) { amount = 0; }\n        this._delayTime = amount;\n        return this;\n    };\n    Tween.prototype.repeat = function (times) {\n        if (times === void 0) { times = 0; }\n        this._initialRepeat = times;\n        this._repeat = times;\n        return this;\n    };\n    Tween.prototype.repeatDelay = function (amount) {\n        this._repeatDelayTime = amount;\n        return this;\n    };\n    Tween.prototype.yoyo = function (yoyo) {\n        if (yoyo === void 0) { yoyo = false; }\n        this._yoyo = yoyo;\n        return this;\n    };\n    Tween.prototype.easing = function (easingFunction) {\n        if (easingFunction === void 0) { easingFunction = Easing.Linear.None; }\n        this._easingFunction = easingFunction;\n        return this;\n    };\n    Tween.prototype.interpolation = function (interpolationFunction) {\n        if (interpolationFunction === void 0) { interpolationFunction = Interpolation.Linear; }\n        this._interpolationFunction = interpolationFunction;\n        return this;\n    };\n    // eslint-disable-next-line\n    Tween.prototype.chain = function () {\n        var tweens = [];\n        for (var _i = 0; _i < arguments.length; _i++) {\n            tweens[_i] = arguments[_i];\n        }\n        this._chainedTweens = tweens;\n        return this;\n    };\n    Tween.prototype.onStart = function (callback) {\n        this._onStartCallback = callback;\n        return this;\n    };\n    Tween.prototype.onEveryStart = function (callback) {\n        this._onEveryStartCallback = callback;\n        return this;\n    };\n    Tween.prototype.onUpdate = function (callback) {\n        this._onUpdateCallback = callback;\n        return this;\n    };\n    Tween.prototype.onRepeat = function (callback) {\n        this._onRepeatCallback = callback;\n        return this;\n    };\n    Tween.prototype.onComplete = function (callback) {\n        this._onCompleteCallback = callback;\n        return this;\n    };\n    Tween.prototype.onStop = function (callback) {\n        this._onStopCallback = callback;\n        return this;\n    };\n    /**\n     * @returns true if the tween is still playing after the update, false\n     * otherwise (calling update on a paused tween still returns true because\n     * it is still playing, just paused).\n     */\n    Tween.prototype.update = function (time, autoStart) {\n        var _a;\n        if (time === void 0) { time = now(); }\n        if (autoStart === void 0) { autoStart = true; }\n        if (this._isPaused)\n            return true;\n        var endTime = this._startTime + this._duration;\n        if (!this._goToEnd && !this._isPlaying) {\n            if (time > endTime)\n                return false;\n            if (autoStart)\n                this.start(time, true);\n        }\n        this._goToEnd = false;\n        if (time < this._startTime) {\n            return true;\n        }\n        if (this._onStartCallbackFired === false) {\n            if (this._onStartCallback) {\n                this._onStartCallback(this._object);\n            }\n            this._onStartCallbackFired = true;\n        }\n        if (this._onEveryStartCallbackFired === false) {\n            if (this._onEveryStartCallback) {\n                this._onEveryStartCallback(this._object);\n            }\n            this._onEveryStartCallbackFired = true;\n        }\n        var elapsedTime = time - this._startTime;\n        var durationAndDelay = this._duration + ((_a = this._repeatDelayTime) !== null && _a !== void 0 ? _a : this._delayTime);\n        var totalTime = this._duration + this._repeat * durationAndDelay;\n        var elapsed = this._calculateElapsedPortion(elapsedTime, durationAndDelay, totalTime);\n        var value = this._easingFunction(elapsed);\n        var status = this._calculateCompletionStatus(elapsedTime, durationAndDelay);\n        if (status === 'repeat') {\n            // the current update is happening after the instant the tween repeated\n            this._processRepetition(elapsedTime, durationAndDelay);\n        }\n        this._updateProperties(this._object, this._valuesStart, this._valuesEnd, value);\n        if (status === 'about-to-repeat') {\n            // the current update is happening at the exact instant the tween is going to repeat\n            // the values should match the end of the tween, not the beginning,\n            // that's why _processRepetition happens after _updateProperties\n            this._processRepetition(elapsedTime, durationAndDelay);\n        }\n        if (this._onUpdateCallback) {\n            this._onUpdateCallback(this._object, elapsed);\n        }\n        if (status === 'repeat' || status === 'about-to-repeat') {\n            if (this._onRepeatCallback) {\n                this._onRepeatCallback(this._object);\n            }\n            this._onEveryStartCallbackFired = false;\n        }\n        else if (status === 'completed') {\n            this._isPlaying = false;\n            if (this._onCompleteCallback) {\n                this._onCompleteCallback(this._object);\n            }\n            for (var i = 0, numChainedTweens = this._chainedTweens.length; i < numChainedTweens; i++) {\n                // Make the chained tweens start exactly at the time they should,\n                // even if the `update()` method was called way past the duration of the tween\n                this._chainedTweens[i].start(this._startTime + this._duration, false);\n            }\n        }\n        return status !== 'completed';\n    };\n    Tween.prototype._calculateElapsedPortion = function (elapsedTime, durationAndDelay, totalTime) {\n        if (this._duration === 0 || elapsedTime > totalTime) {\n            return 1;\n        }\n        var timeIntoCurrentRepeat = elapsedTime % durationAndDelay;\n        var portion = Math.min(timeIntoCurrentRepeat / this._duration, 1);\n        if (portion === 0 && elapsedTime !== 0 && elapsedTime % this._duration === 0) {\n            return 1;\n        }\n        return portion;\n    };\n    Tween.prototype._calculateCompletionStatus = function (elapsedTime, durationAndDelay) {\n        if (this._duration !== 0 && elapsedTime < this._duration) {\n            return 'playing';\n        }\n        if (this._repeat <= 0) {\n            return 'completed';\n        }\n        if (elapsedTime === this._duration) {\n            return 'about-to-repeat';\n        }\n        return 'repeat';\n    };\n    Tween.prototype._processRepetition = function (elapsedTime, durationAndDelay) {\n        var completeCount = Math.min(Math.trunc((elapsedTime - this._duration) / durationAndDelay) + 1, this._repeat);\n        if (isFinite(this._repeat)) {\n            this._repeat -= completeCount;\n        }\n        // Reassign starting values, restart by making startTime = now\n        for (var property in this._valuesStartRepeat) {\n            var valueEnd = this._valuesEnd[property];\n            if (!this._yoyo && typeof valueEnd === 'string') {\n                this._valuesStartRepeat[property] = this._valuesStartRepeat[property] + parseFloat(valueEnd);\n            }\n            if (this._yoyo) {\n                this._swapEndStartRepeatValues(property);\n            }\n            this._valuesStart[property] = this._valuesStartRepeat[property];\n        }\n        if (this._yoyo) {\n            this._reversed = !this._reversed;\n        }\n        this._startTime += durationAndDelay * completeCount;\n    };\n    Tween.prototype._updateProperties = function (_object, _valuesStart, _valuesEnd, value) {\n        for (var property in _valuesEnd) {\n            // Don't update properties that do not exist in the source object\n            if (_valuesStart[property] === undefined) {\n                continue;\n            }\n            var start = _valuesStart[property] || 0;\n            var end = _valuesEnd[property];\n            var startIsArray = Array.isArray(_object[property]);\n            var endIsArray = Array.isArray(end);\n            var isInterpolationList = !startIsArray && endIsArray;\n            if (isInterpolationList) {\n                _object[property] = this._interpolationFunction(end, value);\n            }\n            else if (typeof end === 'object' && end) {\n                // eslint-disable-next-line\n                // @ts-ignore FIXME?\n                this._updateProperties(_object[property], start, end, value);\n            }\n            else {\n                // Parses relative end values with start as base (e.g.: +10, -3)\n                end = this._handleRelativeValue(start, end);\n                // Protect against non numeric properties.\n                if (typeof end === 'number') {\n                    // eslint-disable-next-line\n                    // @ts-ignore FIXME?\n                    _object[property] = start + (end - start) * value;\n                }\n            }\n        }\n    };\n    Tween.prototype._handleRelativeValue = function (start, end) {\n        if (typeof end !== 'string') {\n            return end;\n        }\n        if (end.charAt(0) === '+' || end.charAt(0) === '-') {\n            return start + parseFloat(end);\n        }\n        return parseFloat(end);\n    };\n    Tween.prototype._swapEndStartRepeatValues = function (property) {\n        var tmp = this._valuesStartRepeat[property];\n        var endValue = this._valuesEnd[property];\n        if (typeof endValue === 'string') {\n            this._valuesStartRepeat[property] = this._valuesStartRepeat[property] + parseFloat(endValue);\n        }\n        else {\n            this._valuesStartRepeat[property] = this._valuesEnd[property];\n        }\n        this._valuesEnd[property] = tmp;\n    };\n    return Tween;\n}());\n\nvar VERSION = '23.1.2';\n\n/**\n * Tween.js - Licensed under the MIT license\n * https://github.com/tweenjs/tween.js\n * ----------------------------------------------\n *\n * See https://github.com/tweenjs/tween.js/graphs/contributors for the full list of contributors.\n * Thank you all, you're awesome!\n */\nvar nextId = Sequence.nextId;\n/**\n * Controlling groups of tweens\n *\n * Using the TWEEN singleton to manage your tweens can cause issues in large apps with many components.\n * In these cases, you may want to create your own smaller groups of tweens.\n */\nvar TWEEN = mainGroup;\n// This is the best way to export things in a way that's compatible with both ES\n// Modules and CommonJS, without build hacks, and so as not to break the\n// existing API.\n// https://github.com/rollup/rollup/issues/1961#issuecomment-423037881\nvar getAll = TWEEN.getAll.bind(TWEEN);\nvar removeAll = TWEEN.removeAll.bind(TWEEN);\nvar add = TWEEN.add.bind(TWEEN);\nvar remove = TWEEN.remove.bind(TWEEN);\nvar update = TWEEN.update.bind(TWEEN);\nvar exports = {\n    Easing: Easing,\n    Group: Group,\n    Interpolation: Interpolation,\n    now: now,\n    Sequence: Sequence,\n    nextId: nextId,\n    Tween: Tween,\n    VERSION: VERSION,\n    getAll: getAll,\n    removeAll: removeAll,\n    add: add,\n    remove: remove,\n    update: update,\n};\n\n\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/@tweenjs/tween.js/dist/tween.esm.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/adapters/adapters.js":
/*!*****************************************************!*\
  !*** ./node_modules/axios/lib/adapters/adapters.js ***!
  \*****************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils.js */ \"./node_modules/axios/lib/utils.js\");\n/* harmony import */ var _http_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./http.js */ \"./node_modules/axios/lib/helpers/null.js\");\n/* harmony import */ var _xhr_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./xhr.js */ \"./node_modules/axios/lib/adapters/xhr.js\");\n/* harmony import */ var _fetch_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./fetch.js */ \"./node_modules/axios/lib/adapters/fetch.js\");\n/* harmony import */ var _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/AxiosError.js */ \"./node_modules/axios/lib/core/AxiosError.js\");\n\n\n\n\n\n\n/**\n * Known adapters mapping.\n * Provides environment-specific adapters for Axios:\n * - `http` for Node.js\n * - `xhr` for browsers\n * - `fetch` for fetch API-based requests\n * \n * @type {Object<string, Function|Object>}\n */\nconst knownAdapters = {\n  http: _http_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"],\n  xhr: _xhr_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"],\n  fetch: {\n    get: _fetch_js__WEBPACK_IMPORTED_MODULE_3__.getFetch,\n  }\n};\n\n// Assign adapter names for easier debugging and identification\n_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].forEach(knownAdapters, (fn, value) => {\n  if (fn) {\n    try {\n      Object.defineProperty(fn, 'name', { value });\n    } catch (e) {\n      // eslint-disable-next-line no-empty\n    }\n    Object.defineProperty(fn, 'adapterName', { value });\n  }\n});\n\n/**\n * Render a rejection reason string for unknown or unsupported adapters\n * \n * @param {string} reason\n * @returns {string}\n */\nconst renderReason = (reason) => `- ${reason}`;\n\n/**\n * Check if the adapter is resolved (function, null, or false)\n * \n * @param {Function|null|false} adapter\n * @returns {boolean}\n */\nconst isResolvedHandle = (adapter) => _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isFunction(adapter) || adapter === null || adapter === false;\n\n/**\n * Get the first suitable adapter from the provided list.\n * Tries each adapter in order until a supported one is found.\n * Throws an AxiosError if no adapter is suitable.\n * \n * @param {Array<string|Function>|string|Function} adapters - Adapter(s) by name or function.\n * @param {Object} config - Axios request configuration\n * @throws {AxiosError} If no suitable adapter is available\n * @returns {Function} The resolved adapter function\n */\nfunction getAdapter(adapters, config) {\n  adapters = _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isArray(adapters) ? adapters : [adapters];\n\n  const { length } = adapters;\n  let nameOrAdapter;\n  let adapter;\n\n  const rejectedReasons = {};\n\n  for (let i = 0; i < length; i++) {\n    nameOrAdapter = adapters[i];\n    let id;\n\n    adapter = nameOrAdapter;\n\n    if (!isResolvedHandle(nameOrAdapter)) {\n      adapter = knownAdapters[(id = String(nameOrAdapter)).toLowerCase()];\n\n      if (adapter === undefined) {\n        throw new _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"](`Unknown adapter '${id}'`);\n      }\n    }\n\n    if (adapter && (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isFunction(adapter) || (adapter = adapter.get(config)))) {\n      break;\n    }\n\n    rejectedReasons[id || '#' + i] = adapter;\n  }\n\n  if (!adapter) {\n    const reasons = Object.entries(rejectedReasons)\n      .map(([id, state]) => `adapter ${id} ` +\n        (state === false ? 'is not supported by the environment' : 'is not available in the build')\n      );\n\n    let s = length ?\n      (reasons.length > 1 ? 'since :\\n' + reasons.map(renderReason).join('\\n') : ' ' + renderReason(reasons[0])) :\n      'as no adapter specified';\n\n    throw new _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"](\n      `There is no suitable adapter to dispatch the request ` + s,\n      'ERR_NOT_SUPPORT'\n    );\n  }\n\n  return adapter;\n}\n\n/**\n * Exports Axios adapters and utility to resolve an adapter\n */\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ({\n  /**\n   * Resolve an adapter from a list of adapter names or functions.\n   * @type {Function}\n   */\n  getAdapter,\n\n  /**\n   * Exposes all known adapters\n   * @type {Object<string, Function|Object>}\n   */\n  adapters: knownAdapters\n});\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/adapters/adapters.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/adapters/fetch.js":
/*!**************************************************!*\
  !*** ./node_modules/axios/lib/adapters/fetch.js ***!
  \**************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__),\n/* harmony export */   getFetch: () => (/* binding */ getFetch)\n/* harmony export */ });\n/* harmony import */ var _platform_index_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../platform/index.js */ \"./node_modules/axios/lib/platform/index.js\");\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils.js */ \"./node_modules/axios/lib/utils.js\");\n/* harmony import */ var _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/AxiosError.js */ \"./node_modules/axios/lib/core/AxiosError.js\");\n/* harmony import */ var _helpers_composeSignals_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../helpers/composeSignals.js */ \"./node_modules/axios/lib/helpers/composeSignals.js\");\n/* harmony import */ var _helpers_trackStream_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../helpers/trackStream.js */ \"./node_modules/axios/lib/helpers/trackStream.js\");\n/* harmony import */ var _core_AxiosHeaders_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../core/AxiosHeaders.js */ \"./node_modules/axios/lib/core/AxiosHeaders.js\");\n/* harmony import */ var _helpers_progressEventReducer_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../helpers/progressEventReducer.js */ \"./node_modules/axios/lib/helpers/progressEventReducer.js\");\n/* harmony import */ var _helpers_resolveConfig_js__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../helpers/resolveConfig.js */ \"./node_modules/axios/lib/helpers/resolveConfig.js\");\n/* harmony import */ var _core_settle_js__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../core/settle.js */ \"./node_modules/axios/lib/core/settle.js\");\n\n\n\n\n\n\n\n\n\n\nconst DEFAULT_CHUNK_SIZE = 64 * 1024;\n\nconst {isFunction} = _utils_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"];\n\nconst globalFetchAPI = (({Request, Response}) => ({\n  Request, Response\n}))(_utils_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].global);\n\nconst {\n  ReadableStream, TextEncoder\n} = _utils_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].global;\n\n\nconst test = (fn, ...args) => {\n  try {\n    return !!fn(...args);\n  } catch (e) {\n    return false\n  }\n}\n\nconst factory = (env) => {\n  env = _utils_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].merge.call({\n    skipUndefined: true\n  }, globalFetchAPI, env);\n\n  const {fetch: envFetch, Request, Response} = env;\n  const isFetchSupported = envFetch ? isFunction(envFetch) : typeof fetch === 'function';\n  const isRequestSupported = isFunction(Request);\n  const isResponseSupported = isFunction(Response);\n\n  if (!isFetchSupported) {\n    return false;\n  }\n\n  const isReadableStreamSupported = isFetchSupported && isFunction(ReadableStream);\n\n  const encodeText = isFetchSupported && (typeof TextEncoder === 'function' ?\n      ((encoder) => (str) => encoder.encode(str))(new TextEncoder()) :\n      async (str) => new Uint8Array(await new Request(str).arrayBuffer())\n  );\n\n  const supportsRequestStream = isRequestSupported && isReadableStreamSupported && test(() => {\n    let duplexAccessed = false;\n\n    const hasContentType = new Request(_platform_index_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].origin, {\n      body: new ReadableStream(),\n      method: 'POST',\n      get duplex() {\n        duplexAccessed = true;\n        return 'half';\n      },\n    }).headers.has('Content-Type');\n\n    return duplexAccessed && !hasContentType;\n  });\n\n  const supportsResponseStream = isResponseSupported && isReadableStreamSupported &&\n    test(() => _utils_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].isReadableStream(new Response('').body));\n\n  const resolvers = {\n    stream: supportsResponseStream && ((res) => res.body)\n  };\n\n  isFetchSupported && ((() => {\n    ['text', 'arrayBuffer', 'blob', 'formData', 'stream'].forEach(type => {\n      !resolvers[type] && (resolvers[type] = (res, config) => {\n        let method = res && res[type];\n\n        if (method) {\n          return method.call(res);\n        }\n\n        throw new _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"](`Response type '${type}' is not supported`, _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"].ERR_NOT_SUPPORT, config);\n      })\n    });\n  })());\n\n  const getBodyLength = async (body) => {\n    if (body == null) {\n      return 0;\n    }\n\n    if (_utils_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].isBlob(body)) {\n      return body.size;\n    }\n\n    if (_utils_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].isSpecCompliantForm(body)) {\n      const _request = new Request(_platform_index_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].origin, {\n        method: 'POST',\n        body,\n      });\n      return (await _request.arrayBuffer()).byteLength;\n    }\n\n    if (_utils_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].isArrayBufferView(body) || _utils_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].isArrayBuffer(body)) {\n      return body.byteLength;\n    }\n\n    if (_utils_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].isURLSearchParams(body)) {\n      body = body + '';\n    }\n\n    if (_utils_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].isString(body)) {\n      return (await encodeText(body)).byteLength;\n    }\n  }\n\n  const resolveBodyLength = async (headers, body) => {\n    const length = _utils_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].toFiniteNumber(headers.getContentLength());\n\n    return length == null ? getBodyLength(body) : length;\n  }\n\n  return async (config) => {\n    let {\n      url,\n      method,\n      data,\n      signal,\n      cancelToken,\n      timeout,\n      onDownloadProgress,\n      onUploadProgress,\n      responseType,\n      headers,\n      withCredentials = 'same-origin',\n      fetchOptions\n    } = (0,_helpers_resolveConfig_js__WEBPACK_IMPORTED_MODULE_7__[\"default\"])(config);\n\n    let _fetch = envFetch || fetch;\n\n    responseType = responseType ? (responseType + '').toLowerCase() : 'text';\n\n    let composedSignal = (0,_helpers_composeSignals_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"])([signal, cancelToken && cancelToken.toAbortSignal()], timeout);\n\n    let request = null;\n\n    const unsubscribe = composedSignal && composedSignal.unsubscribe && (() => {\n      composedSignal.unsubscribe();\n    });\n\n    let requestContentLength;\n\n    try {\n      if (\n        onUploadProgress && supportsRequestStream && method !== 'get' && method !== 'head' &&\n        (requestContentLength = await resolveBodyLength(headers, data)) !== 0\n      ) {\n        let _request = new Request(url, {\n          method: 'POST',\n          body: data,\n          duplex: \"half\"\n        });\n\n        let contentTypeHeader;\n\n        if (_utils_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].isFormData(data) && (contentTypeHeader = _request.headers.get('content-type'))) {\n          headers.setContentType(contentTypeHeader)\n        }\n\n        if (_request.body) {\n          const [onProgress, flush] = (0,_helpers_progressEventReducer_js__WEBPACK_IMPORTED_MODULE_6__.progressEventDecorator)(\n            requestContentLength,\n            (0,_helpers_progressEventReducer_js__WEBPACK_IMPORTED_MODULE_6__.progressEventReducer)((0,_helpers_progressEventReducer_js__WEBPACK_IMPORTED_MODULE_6__.asyncDecorator)(onUploadProgress))\n          );\n\n          data = (0,_helpers_trackStream_js__WEBPACK_IMPORTED_MODULE_4__.trackStream)(_request.body, DEFAULT_CHUNK_SIZE, onProgress, flush);\n        }\n      }\n\n      if (!_utils_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].isString(withCredentials)) {\n        withCredentials = withCredentials ? 'include' : 'omit';\n      }\n\n      // Cloudflare Workers throws when credentials are defined\n      // see https://github.com/cloudflare/workerd/issues/902\n      const isCredentialsSupported = isRequestSupported && \"credentials\" in Request.prototype;\n\n      const resolvedOptions = {\n        ...fetchOptions,\n        signal: composedSignal,\n        method: method.toUpperCase(),\n        headers: headers.normalize().toJSON(),\n        body: data,\n        duplex: \"half\",\n        credentials: isCredentialsSupported ? withCredentials : undefined\n      };\n\n      request = isRequestSupported && new Request(url, resolvedOptions);\n\n      let response = await (isRequestSupported ? _fetch(request, fetchOptions) : _fetch(url, resolvedOptions));\n\n      const isStreamResponse = supportsResponseStream && (responseType === 'stream' || responseType === 'response');\n\n      if (supportsResponseStream && (onDownloadProgress || (isStreamResponse && unsubscribe))) {\n        const options = {};\n\n        ['status', 'statusText', 'headers'].forEach(prop => {\n          options[prop] = response[prop];\n        });\n\n        const responseContentLength = _utils_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].toFiniteNumber(response.headers.get('content-length'));\n\n        const [onProgress, flush] = onDownloadProgress && (0,_helpers_progressEventReducer_js__WEBPACK_IMPORTED_MODULE_6__.progressEventDecorator)(\n          responseContentLength,\n          (0,_helpers_progressEventReducer_js__WEBPACK_IMPORTED_MODULE_6__.progressEventReducer)((0,_helpers_progressEventReducer_js__WEBPACK_IMPORTED_MODULE_6__.asyncDecorator)(onDownloadProgress), true)\n        ) || [];\n\n        response = new Response(\n          (0,_helpers_trackStream_js__WEBPACK_IMPORTED_MODULE_4__.trackStream)(response.body, DEFAULT_CHUNK_SIZE, onProgress, () => {\n            flush && flush();\n            unsubscribe && unsubscribe();\n          }),\n          options\n        );\n      }\n\n      responseType = responseType || 'text';\n\n      let responseData = await resolvers[_utils_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].findKey(resolvers, responseType) || 'text'](response, config);\n\n      !isStreamResponse && unsubscribe && unsubscribe();\n\n      return await new Promise((resolve, reject) => {\n        (0,_core_settle_js__WEBPACK_IMPORTED_MODULE_8__[\"default\"])(resolve, reject, {\n          data: responseData,\n          headers: _core_AxiosHeaders_js__WEBPACK_IMPORTED_MODULE_5__[\"default\"].from(response.headers),\n          status: response.status,\n          statusText: response.statusText,\n          config,\n          request\n        })\n      })\n    } catch (err) {\n      unsubscribe && unsubscribe();\n\n      if (err && err.name === 'TypeError' && /Load failed|fetch/i.test(err.message)) {\n        throw Object.assign(\n          new _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"]('Network Error', _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"].ERR_NETWORK, config, request),\n          {\n            cause: err.cause || err\n          }\n        )\n      }\n\n      throw _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"].from(err, err && err.code, config, request);\n    }\n  }\n}\n\nconst seedCache = new Map();\n\nconst getFetch = (config) => {\n  let env = (config && config.env) || {};\n  const {fetch, Request, Response} = env;\n  const seeds = [\n    Request, Response, fetch\n  ];\n\n  let len = seeds.length, i = len,\n    seed, target, map = seedCache;\n\n  while (i--) {\n    seed = seeds[i];\n    target = map.get(seed);\n\n    target === undefined && map.set(seed, target = (i ? new Map() : factory(env)))\n\n    map = target;\n  }\n\n  return target;\n};\n\nconst adapter = getFetch();\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (adapter);\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/adapters/fetch.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/adapters/xhr.js":
/*!************************************************!*\
  !*** ./node_modules/axios/lib/adapters/xhr.js ***!
  \************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./../utils.js */ \"./node_modules/axios/lib/utils.js\");\n/* harmony import */ var _core_settle_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./../core/settle.js */ \"./node_modules/axios/lib/core/settle.js\");\n/* harmony import */ var _defaults_transitional_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../defaults/transitional.js */ \"./node_modules/axios/lib/defaults/transitional.js\");\n/* harmony import */ var _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/AxiosError.js */ \"./node_modules/axios/lib/core/AxiosError.js\");\n/* harmony import */ var _cancel_CanceledError_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../cancel/CanceledError.js */ \"./node_modules/axios/lib/cancel/CanceledError.js\");\n/* harmony import */ var _helpers_parseProtocol_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../helpers/parseProtocol.js */ \"./node_modules/axios/lib/helpers/parseProtocol.js\");\n/* harmony import */ var _platform_index_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../platform/index.js */ \"./node_modules/axios/lib/platform/index.js\");\n/* harmony import */ var _core_AxiosHeaders_js__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../core/AxiosHeaders.js */ \"./node_modules/axios/lib/core/AxiosHeaders.js\");\n/* harmony import */ var _helpers_progressEventReducer_js__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../helpers/progressEventReducer.js */ \"./node_modules/axios/lib/helpers/progressEventReducer.js\");\n/* harmony import */ var _helpers_resolveConfig_js__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../helpers/resolveConfig.js */ \"./node_modules/axios/lib/helpers/resolveConfig.js\");\n\n\n\n\n\n\n\n\n\n\n\nconst isXHRAdapterSupported = typeof XMLHttpRequest !== 'undefined';\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (isXHRAdapterSupported && function (config) {\n  return new Promise(function dispatchXhrRequest(resolve, reject) {\n    const _config = (0,_helpers_resolveConfig_js__WEBPACK_IMPORTED_MODULE_9__[\"default\"])(config);\n    let requestData = _config.data;\n    const requestHeaders = _core_AxiosHeaders_js__WEBPACK_IMPORTED_MODULE_7__[\"default\"].from(_config.headers).normalize();\n    let {responseType, onUploadProgress, onDownloadProgress} = _config;\n    let onCanceled;\n    let uploadThrottled, downloadThrottled;\n    let flushUpload, flushDownload;\n\n    function done() {\n      flushUpload && flushUpload(); // flush events\n      flushDownload && flushDownload(); // flush events\n\n      _config.cancelToken && _config.cancelToken.unsubscribe(onCanceled);\n\n      _config.signal && _config.signal.removeEventListener('abort', onCanceled);\n    }\n\n    let request = new XMLHttpRequest();\n\n    request.open(_config.method.toUpperCase(), _config.url, true);\n\n    // Set the request timeout in MS\n    request.timeout = _config.timeout;\n\n    function onloadend() {\n      if (!request) {\n        return;\n      }\n      // Prepare the response\n      const responseHeaders = _core_AxiosHeaders_js__WEBPACK_IMPORTED_MODULE_7__[\"default\"].from(\n        'getAllResponseHeaders' in request && request.getAllResponseHeaders()\n      );\n      const responseData = !responseType || responseType === 'text' || responseType === 'json' ?\n        request.responseText : request.response;\n      const response = {\n        data: responseData,\n        status: request.status,\n        statusText: request.statusText,\n        headers: responseHeaders,\n        config,\n        request\n      };\n\n      (0,_core_settle_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(function _resolve(value) {\n        resolve(value);\n        done();\n      }, function _reject(err) {\n        reject(err);\n        done();\n      }, response);\n\n      // Clean up request\n      request = null;\n    }\n\n    if ('onloadend' in request) {\n      // Use onloadend if available\n      request.onloadend = onloadend;\n    } else {\n      // Listen for ready state to emulate onloadend\n      request.onreadystatechange = function handleLoad() {\n        if (!request || request.readyState !== 4) {\n          return;\n        }\n\n        // The request errored out and we didn't get a response, this will be\n        // handled by onerror instead\n        // With one exception: request that using file: protocol, most browsers\n        // will return status as 0 even though it's a successful request\n        if (request.status === 0 && !(request.responseURL && request.responseURL.indexOf('file:') === 0)) {\n          return;\n        }\n        // readystate handler is calling before onerror or ontimeout handlers,\n        // so we should call onloadend on the next 'tick'\n        setTimeout(onloadend);\n      };\n    }\n\n    // Handle browser request cancellation (as opposed to a manual cancellation)\n    request.onabort = function handleAbort() {\n      if (!request) {\n        return;\n      }\n\n      reject(new _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"]('Request aborted', _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"].ECONNABORTED, config, request));\n\n      // Clean up request\n      request = null;\n    };\n\n    // Handle low level network errors\n  request.onerror = function handleError(event) {\n       // Browsers deliver a ProgressEvent in XHR onerror\n       // (message may be empty; when present, surface it)\n       // See https://developer.mozilla.org/docs/Web/API/XMLHttpRequest/error_event\n       const msg = event && event.message ? event.message : 'Network Error';\n       const err = new _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"](msg, _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"].ERR_NETWORK, config, request);\n       // attach the underlying event for consumers who want details\n       err.event = event || null;\n       reject(err);\n       request = null;\n    };\n    \n    // Handle timeout\n    request.ontimeout = function handleTimeout() {\n      let timeoutErrorMessage = _config.timeout ? 'timeout of ' + _config.timeout + 'ms exceeded' : 'timeout exceeded';\n      const transitional = _config.transitional || _defaults_transitional_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"];\n      if (_config.timeoutErrorMessage) {\n        timeoutErrorMessage = _config.timeoutErrorMessage;\n      }\n      reject(new _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"](\n        timeoutErrorMessage,\n        transitional.clarifyTimeoutError ? _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"].ETIMEDOUT : _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"].ECONNABORTED,\n        config,\n        request));\n\n      // Clean up request\n      request = null;\n    };\n\n    // Remove Content-Type if data is undefined\n    requestData === undefined && requestHeaders.setContentType(null);\n\n    // Add headers to the request\n    if ('setRequestHeader' in request) {\n      _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].forEach(requestHeaders.toJSON(), function setRequestHeader(val, key) {\n        request.setRequestHeader(key, val);\n      });\n    }\n\n    // Add withCredentials to request if needed\n    if (!_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isUndefined(_config.withCredentials)) {\n      request.withCredentials = !!_config.withCredentials;\n    }\n\n    // Add responseType to request if needed\n    if (responseType && responseType !== 'json') {\n      request.responseType = _config.responseType;\n    }\n\n    // Handle progress if needed\n    if (onDownloadProgress) {\n      ([downloadThrottled, flushDownload] = (0,_helpers_progressEventReducer_js__WEBPACK_IMPORTED_MODULE_8__.progressEventReducer)(onDownloadProgress, true));\n      request.addEventListener('progress', downloadThrottled);\n    }\n\n    // Not all browsers support upload events\n    if (onUploadProgress && request.upload) {\n      ([uploadThrottled, flushUpload] = (0,_helpers_progressEventReducer_js__WEBPACK_IMPORTED_MODULE_8__.progressEventReducer)(onUploadProgress));\n\n      request.upload.addEventListener('progress', uploadThrottled);\n\n      request.upload.addEventListener('loadend', flushUpload);\n    }\n\n    if (_config.cancelToken || _config.signal) {\n      // Handle cancellation\n      // eslint-disable-next-line func-names\n      onCanceled = cancel => {\n        if (!request) {\n          return;\n        }\n        reject(!cancel || cancel.type ? new _cancel_CanceledError_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"](null, config, request) : cancel);\n        request.abort();\n        request = null;\n      };\n\n      _config.cancelToken && _config.cancelToken.subscribe(onCanceled);\n      if (_config.signal) {\n        _config.signal.aborted ? onCanceled() : _config.signal.addEventListener('abort', onCanceled);\n      }\n    }\n\n    const protocol = (0,_helpers_parseProtocol_js__WEBPACK_IMPORTED_MODULE_5__[\"default\"])(_config.url);\n\n    if (protocol && _platform_index_js__WEBPACK_IMPORTED_MODULE_6__[\"default\"].protocols.indexOf(protocol) === -1) {\n      reject(new _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"]('Unsupported protocol ' + protocol + ':', _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"].ERR_BAD_REQUEST, config));\n      return;\n    }\n\n\n    // Send the request\n    request.send(requestData || null);\n  });\n});\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/adapters/xhr.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/axios.js":
/*!*****************************************!*\
  !*** ./node_modules/axios/lib/axios.js ***!
  \*****************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./utils.js */ \"./node_modules/axios/lib/utils.js\");\n/* harmony import */ var _helpers_bind_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./helpers/bind.js */ \"./node_modules/axios/lib/helpers/bind.js\");\n/* harmony import */ var _core_Axios_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./core/Axios.js */ \"./node_modules/axios/lib/core/Axios.js\");\n/* harmony import */ var _core_mergeConfig_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./core/mergeConfig.js */ \"./node_modules/axios/lib/core/mergeConfig.js\");\n/* harmony import */ var _defaults_index_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./defaults/index.js */ \"./node_modules/axios/lib/defaults/index.js\");\n/* harmony import */ var _helpers_formDataToJSON_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./helpers/formDataToJSON.js */ \"./node_modules/axios/lib/helpers/formDataToJSON.js\");\n/* harmony import */ var _cancel_CanceledError_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./cancel/CanceledError.js */ \"./node_modules/axios/lib/cancel/CanceledError.js\");\n/* harmony import */ var _cancel_CancelToken_js__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./cancel/CancelToken.js */ \"./node_modules/axios/lib/cancel/CancelToken.js\");\n/* harmony import */ var _cancel_isCancel_js__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./cancel/isCancel.js */ \"./node_modules/axios/lib/cancel/isCancel.js\");\n/* harmony import */ var _env_data_js__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./env/data.js */ \"./node_modules/axios/lib/env/data.js\");\n/* harmony import */ var _helpers_toFormData_js__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./helpers/toFormData.js */ \"./node_modules/axios/lib/helpers/toFormData.js\");\n/* harmony import */ var _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./core/AxiosError.js */ \"./node_modules/axios/lib/core/AxiosError.js\");\n/* harmony import */ var _helpers_spread_js__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./helpers/spread.js */ \"./node_modules/axios/lib/helpers/spread.js\");\n/* harmony import */ var _helpers_isAxiosError_js__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./helpers/isAxiosError.js */ \"./node_modules/axios/lib/helpers/isAxiosError.js\");\n/* harmony import */ var _core_AxiosHeaders_js__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./core/AxiosHeaders.js */ \"./node_modules/axios/lib/core/AxiosHeaders.js\");\n/* harmony import */ var _adapters_adapters_js__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./adapters/adapters.js */ \"./node_modules/axios/lib/adapters/adapters.js\");\n/* harmony import */ var _helpers_HttpStatusCode_js__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./helpers/HttpStatusCode.js */ \"./node_modules/axios/lib/helpers/HttpStatusCode.js\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n/**\n * Create an instance of Axios\n *\n * @param {Object} defaultConfig The default config for the instance\n *\n * @returns {Axios} A new instance of Axios\n */\nfunction createInstance(defaultConfig) {\n  const context = new _core_Axios_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"](defaultConfig);\n  const instance = (0,_helpers_bind_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(_core_Axios_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"].prototype.request, context);\n\n  // Copy axios.prototype to instance\n  _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].extend(instance, _core_Axios_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"].prototype, context, {allOwnKeys: true});\n\n  // Copy context to instance\n  _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].extend(instance, context, null, {allOwnKeys: true});\n\n  // Factory for creating new instances\n  instance.create = function create(instanceConfig) {\n    return createInstance((0,_core_mergeConfig_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"])(defaultConfig, instanceConfig));\n  };\n\n  return instance;\n}\n\n// Create the default instance to be exported\nconst axios = createInstance(_defaults_index_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"]);\n\n// Expose Axios class to allow class inheritance\naxios.Axios = _core_Axios_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"];\n\n// Expose Cancel & CancelToken\naxios.CanceledError = _cancel_CanceledError_js__WEBPACK_IMPORTED_MODULE_6__[\"default\"];\naxios.CancelToken = _cancel_CancelToken_js__WEBPACK_IMPORTED_MODULE_7__[\"default\"];\naxios.isCancel = _cancel_isCancel_js__WEBPACK_IMPORTED_MODULE_8__[\"default\"];\naxios.VERSION = _env_data_js__WEBPACK_IMPORTED_MODULE_9__.VERSION;\naxios.toFormData = _helpers_toFormData_js__WEBPACK_IMPORTED_MODULE_10__[\"default\"];\n\n// Expose AxiosError class\naxios.AxiosError = _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_11__[\"default\"];\n\n// alias for CanceledError for backward compatibility\naxios.Cancel = axios.CanceledError;\n\n// Expose all/spread\naxios.all = function all(promises) {\n  return Promise.all(promises);\n};\n\naxios.spread = _helpers_spread_js__WEBPACK_IMPORTED_MODULE_12__[\"default\"];\n\n// Expose isAxiosError\naxios.isAxiosError = _helpers_isAxiosError_js__WEBPACK_IMPORTED_MODULE_13__[\"default\"];\n\n// Expose mergeConfig\naxios.mergeConfig = _core_mergeConfig_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"];\n\naxios.AxiosHeaders = _core_AxiosHeaders_js__WEBPACK_IMPORTED_MODULE_14__[\"default\"];\n\naxios.formToJSON = thing => (0,_helpers_formDataToJSON_js__WEBPACK_IMPORTED_MODULE_5__[\"default\"])(_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isHTMLForm(thing) ? new FormData(thing) : thing);\n\naxios.getAdapter = _adapters_adapters_js__WEBPACK_IMPORTED_MODULE_15__[\"default\"].getAdapter;\n\naxios.HttpStatusCode = _helpers_HttpStatusCode_js__WEBPACK_IMPORTED_MODULE_16__[\"default\"];\n\naxios.default = axios;\n\n// this module should only have a default export\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (axios);\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/axios.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/cancel/CancelToken.js":
/*!******************************************************!*\
  !*** ./node_modules/axios/lib/cancel/CancelToken.js ***!
  \******************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _CanceledError_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./CanceledError.js */ \"./node_modules/axios/lib/cancel/CanceledError.js\");\n\n\n\n\n/**\n * A `CancelToken` is an object that can be used to request cancellation of an operation.\n *\n * @param {Function} executor The executor function.\n *\n * @returns {CancelToken}\n */\nclass CancelToken {\n  constructor(executor) {\n    if (typeof executor !== 'function') {\n      throw new TypeError('executor must be a function.');\n    }\n\n    let resolvePromise;\n\n    this.promise = new Promise(function promiseExecutor(resolve) {\n      resolvePromise = resolve;\n    });\n\n    const token = this;\n\n    // eslint-disable-next-line func-names\n    this.promise.then(cancel => {\n      if (!token._listeners) return;\n\n      let i = token._listeners.length;\n\n      while (i-- > 0) {\n        token._listeners[i](cancel);\n      }\n      token._listeners = null;\n    });\n\n    // eslint-disable-next-line func-names\n    this.promise.then = onfulfilled => {\n      let _resolve;\n      // eslint-disable-next-line func-names\n      const promise = new Promise(resolve => {\n        token.subscribe(resolve);\n        _resolve = resolve;\n      }).then(onfulfilled);\n\n      promise.cancel = function reject() {\n        token.unsubscribe(_resolve);\n      };\n\n      return promise;\n    };\n\n    executor(function cancel(message, config, request) {\n      if (token.reason) {\n        // Cancellation has already been requested\n        return;\n      }\n\n      token.reason = new _CanceledError_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"](message, config, request);\n      resolvePromise(token.reason);\n    });\n  }\n\n  /**\n   * Throws a `CanceledError` if cancellation has been requested.\n   */\n  throwIfRequested() {\n    if (this.reason) {\n      throw this.reason;\n    }\n  }\n\n  /**\n   * Subscribe to the cancel signal\n   */\n\n  subscribe(listener) {\n    if (this.reason) {\n      listener(this.reason);\n      return;\n    }\n\n    if (this._listeners) {\n      this._listeners.push(listener);\n    } else {\n      this._listeners = [listener];\n    }\n  }\n\n  /**\n   * Unsubscribe from the cancel signal\n   */\n\n  unsubscribe(listener) {\n    if (!this._listeners) {\n      return;\n    }\n    const index = this._listeners.indexOf(listener);\n    if (index !== -1) {\n      this._listeners.splice(index, 1);\n    }\n  }\n\n  toAbortSignal() {\n    const controller = new AbortController();\n\n    const abort = (err) => {\n      controller.abort(err);\n    };\n\n    this.subscribe(abort);\n\n    controller.signal.unsubscribe = () => this.unsubscribe(abort);\n\n    return controller.signal;\n  }\n\n  /**\n   * Returns an object that contains a new `CancelToken` and a function that, when called,\n   * cancels the `CancelToken`.\n   */\n  static source() {\n    let cancel;\n    const token = new CancelToken(function executor(c) {\n      cancel = c;\n    });\n    return {\n      token,\n      cancel\n    };\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (CancelToken);\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/cancel/CancelToken.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/cancel/CanceledError.js":
/*!********************************************************!*\
  !*** ./node_modules/axios/lib/cancel/CanceledError.js ***!
  \********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/AxiosError.js */ \"./node_modules/axios/lib/core/AxiosError.js\");\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils.js */ \"./node_modules/axios/lib/utils.js\");\n\n\n\n\n\n/**\n * A `CanceledError` is an object that is thrown when an operation is canceled.\n *\n * @param {string=} message The message.\n * @param {Object=} config The config.\n * @param {Object=} request The request.\n *\n * @returns {CanceledError} The created error.\n */\nfunction CanceledError(message, config, request) {\n  // eslint-disable-next-line no-eq-null,eqeqeq\n  _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].call(this, message == null ? 'canceled' : message, _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].ERR_CANCELED, config, request);\n  this.name = 'CanceledError';\n}\n\n_utils_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].inherits(CanceledError, _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"], {\n  __CANCEL__: true\n});\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (CanceledError);\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/cancel/CanceledError.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/cancel/isCancel.js":
/*!***************************************************!*\
  !*** ./node_modules/axios/lib/cancel/isCancel.js ***!
  \***************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ isCancel)\n/* harmony export */ });\n\n\nfunction isCancel(value) {\n  return !!(value && value.__CANCEL__);\n}\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/cancel/isCancel.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/core/Axios.js":
/*!**********************************************!*\
  !*** ./node_modules/axios/lib/core/Axios.js ***!
  \**********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./../utils.js */ \"./node_modules/axios/lib/utils.js\");\n/* harmony import */ var _helpers_buildURL_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/buildURL.js */ \"./node_modules/axios/lib/helpers/buildURL.js\");\n/* harmony import */ var _InterceptorManager_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./InterceptorManager.js */ \"./node_modules/axios/lib/core/InterceptorManager.js\");\n/* harmony import */ var _dispatchRequest_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./dispatchRequest.js */ \"./node_modules/axios/lib/core/dispatchRequest.js\");\n/* harmony import */ var _mergeConfig_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./mergeConfig.js */ \"./node_modules/axios/lib/core/mergeConfig.js\");\n/* harmony import */ var _buildFullPath_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./buildFullPath.js */ \"./node_modules/axios/lib/core/buildFullPath.js\");\n/* harmony import */ var _helpers_validator_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../helpers/validator.js */ \"./node_modules/axios/lib/helpers/validator.js\");\n/* harmony import */ var _AxiosHeaders_js__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./AxiosHeaders.js */ \"./node_modules/axios/lib/core/AxiosHeaders.js\");\n\n\n\n\n\n\n\n\n\n\n\nconst validators = _helpers_validator_js__WEBPACK_IMPORTED_MODULE_6__[\"default\"].validators;\n\n/**\n * Create a new instance of Axios\n *\n * @param {Object} instanceConfig The default config for the instance\n *\n * @return {Axios} A new instance of Axios\n */\nclass Axios {\n  constructor(instanceConfig) {\n    this.defaults = instanceConfig || {};\n    this.interceptors = {\n      request: new _InterceptorManager_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"](),\n      response: new _InterceptorManager_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"]()\n    };\n  }\n\n  /**\n   * Dispatch a request\n   *\n   * @param {String|Object} configOrUrl The config specific for this request (merged with this.defaults)\n   * @param {?Object} config\n   *\n   * @returns {Promise} The Promise to be fulfilled\n   */\n  async request(configOrUrl, config) {\n    try {\n      return await this._request(configOrUrl, config);\n    } catch (err) {\n      if (err instanceof Error) {\n        let dummy = {};\n\n        Error.captureStackTrace ? Error.captureStackTrace(dummy) : (dummy = new Error());\n\n        // slice off the Error: ... line\n        const stack = dummy.stack ? dummy.stack.replace(/^.+\\n/, '') : '';\n        try {\n          if (!err.stack) {\n            err.stack = stack;\n            // match without the 2 top stack lines\n          } else if (stack && !String(err.stack).endsWith(stack.replace(/^.+\\n.+\\n/, ''))) {\n            err.stack += '\\n' + stack\n          }\n        } catch (e) {\n          // ignore the case where \"stack\" is an un-writable property\n        }\n      }\n\n      throw err;\n    }\n  }\n\n  _request(configOrUrl, config) {\n    /*eslint no-param-reassign:0*/\n    // Allow for axios('example/url'[, config]) a la fetch API\n    if (typeof configOrUrl === 'string') {\n      config = config || {};\n      config.url = configOrUrl;\n    } else {\n      config = configOrUrl || {};\n    }\n\n    config = (0,_mergeConfig_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"])(this.defaults, config);\n\n    const {transitional, paramsSerializer, headers} = config;\n\n    if (transitional !== undefined) {\n      _helpers_validator_js__WEBPACK_IMPORTED_MODULE_6__[\"default\"].assertOptions(transitional, {\n        silentJSONParsing: validators.transitional(validators.boolean),\n        forcedJSONParsing: validators.transitional(validators.boolean),\n        clarifyTimeoutError: validators.transitional(validators.boolean)\n      }, false);\n    }\n\n    if (paramsSerializer != null) {\n      if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isFunction(paramsSerializer)) {\n        config.paramsSerializer = {\n          serialize: paramsSerializer\n        }\n      } else {\n        _helpers_validator_js__WEBPACK_IMPORTED_MODULE_6__[\"default\"].assertOptions(paramsSerializer, {\n          encode: validators.function,\n          serialize: validators.function\n        }, true);\n      }\n    }\n\n    // Set config.allowAbsoluteUrls\n    if (config.allowAbsoluteUrls !== undefined) {\n      // do nothing\n    } else if (this.defaults.allowAbsoluteUrls !== undefined) {\n      config.allowAbsoluteUrls = this.defaults.allowAbsoluteUrls;\n    } else {\n      config.allowAbsoluteUrls = true;\n    }\n\n    _helpers_validator_js__WEBPACK_IMPORTED_MODULE_6__[\"default\"].assertOptions(config, {\n      baseUrl: validators.spelling('baseURL'),\n      withXsrfToken: validators.spelling('withXSRFToken')\n    }, true);\n\n    // Set config.method\n    config.method = (config.method || this.defaults.method || 'get').toLowerCase();\n\n    // Flatten headers\n    let contextHeaders = headers && _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].merge(\n      headers.common,\n      headers[config.method]\n    );\n\n    headers && _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].forEach(\n      ['delete', 'get', 'head', 'post', 'put', 'patch', 'common'],\n      (method) => {\n        delete headers[method];\n      }\n    );\n\n    config.headers = _AxiosHeaders_js__WEBPACK_IMPORTED_MODULE_7__[\"default\"].concat(contextHeaders, headers);\n\n    // filter out skipped interceptors\n    const requestInterceptorChain = [];\n    let synchronousRequestInterceptors = true;\n    this.interceptors.request.forEach(function unshiftRequestInterceptors(interceptor) {\n      if (typeof interceptor.runWhen === 'function' && interceptor.runWhen(config) === false) {\n        return;\n      }\n\n      synchronousRequestInterceptors = synchronousRequestInterceptors && interceptor.synchronous;\n\n      requestInterceptorChain.unshift(interceptor.fulfilled, interceptor.rejected);\n    });\n\n    const responseInterceptorChain = [];\n    this.interceptors.response.forEach(function pushResponseInterceptors(interceptor) {\n      responseInterceptorChain.push(interceptor.fulfilled, interceptor.rejected);\n    });\n\n    let promise;\n    let i = 0;\n    let len;\n\n    if (!synchronousRequestInterceptors) {\n      const chain = [_dispatchRequest_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"].bind(this), undefined];\n      chain.unshift(...requestInterceptorChain);\n      chain.push(...responseInterceptorChain);\n      len = chain.length;\n\n      promise = Promise.resolve(config);\n\n      while (i < len) {\n        promise = promise.then(chain[i++], chain[i++]);\n      }\n\n      return promise;\n    }\n\n    len = requestInterceptorChain.length;\n\n    let newConfig = config;\n\n    while (i < len) {\n      const onFulfilled = requestInterceptorChain[i++];\n      const onRejected = requestInterceptorChain[i++];\n      try {\n        newConfig = onFulfilled(newConfig);\n      } catch (error) {\n        onRejected.call(this, error);\n        break;\n      }\n    }\n\n    try {\n      promise = _dispatchRequest_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"].call(this, newConfig);\n    } catch (error) {\n      return Promise.reject(error);\n    }\n\n    i = 0;\n    len = responseInterceptorChain.length;\n\n    while (i < len) {\n      promise = promise.then(responseInterceptorChain[i++], responseInterceptorChain[i++]);\n    }\n\n    return promise;\n  }\n\n  getUri(config) {\n    config = (0,_mergeConfig_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"])(this.defaults, config);\n    const fullPath = (0,_buildFullPath_js__WEBPACK_IMPORTED_MODULE_5__[\"default\"])(config.baseURL, config.url, config.allowAbsoluteUrls);\n    return (0,_helpers_buildURL_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(fullPath, config.params, config.paramsSerializer);\n  }\n}\n\n// Provide aliases for supported request methods\n_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].forEach(['delete', 'get', 'head', 'options'], function forEachMethodNoData(method) {\n  /*eslint func-names:0*/\n  Axios.prototype[method] = function(url, config) {\n    return this.request((0,_mergeConfig_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"])(config || {}, {\n      method,\n      url,\n      data: (config || {}).data\n    }));\n  };\n});\n\n_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].forEach(['post', 'put', 'patch'], function forEachMethodWithData(method) {\n  /*eslint func-names:0*/\n\n  function generateHTTPMethod(isForm) {\n    return function httpMethod(url, data, config) {\n      return this.request((0,_mergeConfig_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"])(config || {}, {\n        method,\n        headers: isForm ? {\n          'Content-Type': 'multipart/form-data'\n        } : {},\n        url,\n        data\n      }));\n    };\n  }\n\n  Axios.prototype[method] = generateHTTPMethod();\n\n  Axios.prototype[method + 'Form'] = generateHTTPMethod(true);\n});\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Axios);\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/core/Axios.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/core/AxiosError.js":
/*!***************************************************!*\
  !*** ./node_modules/axios/lib/core/AxiosError.js ***!
  \***************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils.js */ \"./node_modules/axios/lib/utils.js\");\n\n\n\n\n/**\n * Create an Error with the specified message, config, error code, request and response.\n *\n * @param {string} message The error message.\n * @param {string} [code] The error code (for example, 'ECONNABORTED').\n * @param {Object} [config] The config.\n * @param {Object} [request] The request.\n * @param {Object} [response] The response.\n *\n * @returns {Error} The created error.\n */\nfunction AxiosError(message, code, config, request, response) {\n  Error.call(this);\n\n  if (Error.captureStackTrace) {\n    Error.captureStackTrace(this, this.constructor);\n  } else {\n    this.stack = (new Error()).stack;\n  }\n\n  this.message = message;\n  this.name = 'AxiosError';\n  code && (this.code = code);\n  config && (this.config = config);\n  request && (this.request = request);\n  if (response) {\n    this.response = response;\n    this.status = response.status ? response.status : null;\n  }\n}\n\n_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].inherits(AxiosError, Error, {\n  toJSON: function toJSON() {\n    return {\n      // Standard\n      message: this.message,\n      name: this.name,\n      // Microsoft\n      description: this.description,\n      number: this.number,\n      // Mozilla\n      fileName: this.fileName,\n      lineNumber: this.lineNumber,\n      columnNumber: this.columnNumber,\n      stack: this.stack,\n      // Axios\n      config: _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].toJSONObject(this.config),\n      code: this.code,\n      status: this.status\n    };\n  }\n});\n\nconst prototype = AxiosError.prototype;\nconst descriptors = {};\n\n[\n  'ERR_BAD_OPTION_VALUE',\n  'ERR_BAD_OPTION',\n  'ECONNABORTED',\n  'ETIMEDOUT',\n  'ERR_NETWORK',\n  'ERR_FR_TOO_MANY_REDIRECTS',\n  'ERR_DEPRECATED',\n  'ERR_BAD_RESPONSE',\n  'ERR_BAD_REQUEST',\n  'ERR_CANCELED',\n  'ERR_NOT_SUPPORT',\n  'ERR_INVALID_URL'\n// eslint-disable-next-line func-names\n].forEach(code => {\n  descriptors[code] = {value: code};\n});\n\nObject.defineProperties(AxiosError, descriptors);\nObject.defineProperty(prototype, 'isAxiosError', {value: true});\n\n// eslint-disable-next-line func-names\nAxiosError.from = (error, code, config, request, response, customProps) => {\n  const axiosError = Object.create(prototype);\n\n  _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].toFlatObject(error, axiosError, function filter(obj) {\n    return obj !== Error.prototype;\n  }, prop => {\n    return prop !== 'isAxiosError';\n  });\n\n  const msg = error && error.message ? error.message : 'Error';\n\n  // Prefer explicit code; otherwise copy the low-level error's code (e.g. ECONNREFUSED)\n  const errCode = code == null && error ? error.code : code;\n  AxiosError.call(axiosError, msg, errCode, config, request, response);\n\n  // Chain the original error on the standard field; non-enumerable to avoid JSON noise\n  if (error && axiosError.cause == null) {\n    Object.defineProperty(axiosError, 'cause', { value: error, configurable: true });\n  }\n\n  axiosError.name = (error && error.name) || 'Error';\n\n  customProps && Object.assign(axiosError, customProps);\n\n  return axiosError;\n};\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (AxiosError);\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/core/AxiosError.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/core/AxiosHeaders.js":
/*!*****************************************************!*\
  !*** ./node_modules/axios/lib/core/AxiosHeaders.js ***!
  \*****************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils.js */ \"./node_modules/axios/lib/utils.js\");\n/* harmony import */ var _helpers_parseHeaders_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/parseHeaders.js */ \"./node_modules/axios/lib/helpers/parseHeaders.js\");\n\n\n\n\n\nconst $internals = Symbol('internals');\n\nfunction normalizeHeader(header) {\n  return header && String(header).trim().toLowerCase();\n}\n\nfunction normalizeValue(value) {\n  if (value === false || value == null) {\n    return value;\n  }\n\n  return _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isArray(value) ? value.map(normalizeValue) : String(value);\n}\n\nfunction parseTokens(str) {\n  const tokens = Object.create(null);\n  const tokensRE = /([^\\s,;=]+)\\s*(?:=\\s*([^,;]+))?/g;\n  let match;\n\n  while ((match = tokensRE.exec(str))) {\n    tokens[match[1]] = match[2];\n  }\n\n  return tokens;\n}\n\nconst isValidHeaderName = (str) => /^[-_a-zA-Z0-9^`|~,!#$%&'*+.]+$/.test(str.trim());\n\nfunction matchHeaderValue(context, value, header, filter, isHeaderNameFilter) {\n  if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isFunction(filter)) {\n    return filter.call(this, value, header);\n  }\n\n  if (isHeaderNameFilter) {\n    value = header;\n  }\n\n  if (!_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isString(value)) return;\n\n  if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isString(filter)) {\n    return value.indexOf(filter) !== -1;\n  }\n\n  if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isRegExp(filter)) {\n    return filter.test(value);\n  }\n}\n\nfunction formatHeader(header) {\n  return header.trim()\n    .toLowerCase().replace(/([a-z\\d])(\\w*)/g, (w, char, str) => {\n      return char.toUpperCase() + str;\n    });\n}\n\nfunction buildAccessors(obj, header) {\n  const accessorName = _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].toCamelCase(' ' + header);\n\n  ['get', 'set', 'has'].forEach(methodName => {\n    Object.defineProperty(obj, methodName + accessorName, {\n      value: function(arg1, arg2, arg3) {\n        return this[methodName].call(this, header, arg1, arg2, arg3);\n      },\n      configurable: true\n    });\n  });\n}\n\nclass AxiosHeaders {\n  constructor(headers) {\n    headers && this.set(headers);\n  }\n\n  set(header, valueOrRewrite, rewrite) {\n    const self = this;\n\n    function setHeader(_value, _header, _rewrite) {\n      const lHeader = normalizeHeader(_header);\n\n      if (!lHeader) {\n        throw new Error('header name must be a non-empty string');\n      }\n\n      const key = _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].findKey(self, lHeader);\n\n      if(!key || self[key] === undefined || _rewrite === true || (_rewrite === undefined && self[key] !== false)) {\n        self[key || _header] = normalizeValue(_value);\n      }\n    }\n\n    const setHeaders = (headers, _rewrite) =>\n      _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].forEach(headers, (_value, _header) => setHeader(_value, _header, _rewrite));\n\n    if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isPlainObject(header) || header instanceof this.constructor) {\n      setHeaders(header, valueOrRewrite)\n    } else if(_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isString(header) && (header = header.trim()) && !isValidHeaderName(header)) {\n      setHeaders((0,_helpers_parseHeaders_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(header), valueOrRewrite);\n    } else if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isObject(header) && _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isIterable(header)) {\n      let obj = {}, dest, key;\n      for (const entry of header) {\n        if (!_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isArray(entry)) {\n          throw TypeError('Object iterator must return a key-value pair');\n        }\n\n        obj[key = entry[0]] = (dest = obj[key]) ?\n          (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isArray(dest) ? [...dest, entry[1]] : [dest, entry[1]]) : entry[1];\n      }\n\n      setHeaders(obj, valueOrRewrite)\n    } else {\n      header != null && setHeader(valueOrRewrite, header, rewrite);\n    }\n\n    return this;\n  }\n\n  get(header, parser) {\n    header = normalizeHeader(header);\n\n    if (header) {\n      const key = _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].findKey(this, header);\n\n      if (key) {\n        const value = this[key];\n\n        if (!parser) {\n          return value;\n        }\n\n        if (parser === true) {\n          return parseTokens(value);\n        }\n\n        if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isFunction(parser)) {\n          return parser.call(this, value, key);\n        }\n\n        if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isRegExp(parser)) {\n          return parser.exec(value);\n        }\n\n        throw new TypeError('parser must be boolean|regexp|function');\n      }\n    }\n  }\n\n  has(header, matcher) {\n    header = normalizeHeader(header);\n\n    if (header) {\n      const key = _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].findKey(this, header);\n\n      return !!(key && this[key] !== undefined && (!matcher || matchHeaderValue(this, this[key], key, matcher)));\n    }\n\n    return false;\n  }\n\n  delete(header, matcher) {\n    const self = this;\n    let deleted = false;\n\n    function deleteHeader(_header) {\n      _header = normalizeHeader(_header);\n\n      if (_header) {\n        const key = _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].findKey(self, _header);\n\n        if (key && (!matcher || matchHeaderValue(self, self[key], key, matcher))) {\n          delete self[key];\n\n          deleted = true;\n        }\n      }\n    }\n\n    if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isArray(header)) {\n      header.forEach(deleteHeader);\n    } else {\n      deleteHeader(header);\n    }\n\n    return deleted;\n  }\n\n  clear(matcher) {\n    const keys = Object.keys(this);\n    let i = keys.length;\n    let deleted = false;\n\n    while (i--) {\n      const key = keys[i];\n      if(!matcher || matchHeaderValue(this, this[key], key, matcher, true)) {\n        delete this[key];\n        deleted = true;\n      }\n    }\n\n    return deleted;\n  }\n\n  normalize(format) {\n    const self = this;\n    const headers = {};\n\n    _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].forEach(this, (value, header) => {\n      const key = _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].findKey(headers, header);\n\n      if (key) {\n        self[key] = normalizeValue(value);\n        delete self[header];\n        return;\n      }\n\n      const normalized = format ? formatHeader(header) : String(header).trim();\n\n      if (normalized !== header) {\n        delete self[header];\n      }\n\n      self[normalized] = normalizeValue(value);\n\n      headers[normalized] = true;\n    });\n\n    return this;\n  }\n\n  concat(...targets) {\n    return this.constructor.concat(this, ...targets);\n  }\n\n  toJSON(asStrings) {\n    const obj = Object.create(null);\n\n    _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].forEach(this, (value, header) => {\n      value != null && value !== false && (obj[header] = asStrings && _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isArray(value) ? value.join(', ') : value);\n    });\n\n    return obj;\n  }\n\n  [Symbol.iterator]() {\n    return Object.entries(this.toJSON())[Symbol.iterator]();\n  }\n\n  toString() {\n    return Object.entries(this.toJSON()).map(([header, value]) => header + ': ' + value).join('\\n');\n  }\n\n  getSetCookie() {\n    return this.get(\"set-cookie\") || [];\n  }\n\n  get [Symbol.toStringTag]() {\n    return 'AxiosHeaders';\n  }\n\n  static from(thing) {\n    return thing instanceof this ? thing : new this(thing);\n  }\n\n  static concat(first, ...targets) {\n    const computed = new this(first);\n\n    targets.forEach((target) => computed.set(target));\n\n    return computed;\n  }\n\n  static accessor(header) {\n    const internals = this[$internals] = (this[$internals] = {\n      accessors: {}\n    });\n\n    const accessors = internals.accessors;\n    const prototype = this.prototype;\n\n    function defineAccessor(_header) {\n      const lHeader = normalizeHeader(_header);\n\n      if (!accessors[lHeader]) {\n        buildAccessors(prototype, _header);\n        accessors[lHeader] = true;\n      }\n    }\n\n    _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isArray(header) ? header.forEach(defineAccessor) : defineAccessor(header);\n\n    return this;\n  }\n}\n\nAxiosHeaders.accessor(['Content-Type', 'Content-Length', 'Accept', 'Accept-Encoding', 'User-Agent', 'Authorization']);\n\n// reserved names hotfix\n_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].reduceDescriptors(AxiosHeaders.prototype, ({value}, key) => {\n  let mapped = key[0].toUpperCase() + key.slice(1); // map `set` => `Set`\n  return {\n    get: () => value,\n    set(headerValue) {\n      this[mapped] = headerValue;\n    }\n  }\n});\n\n_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].freezeMethods(AxiosHeaders);\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (AxiosHeaders);\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/core/AxiosHeaders.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/core/InterceptorManager.js":
/*!***********************************************************!*\
  !*** ./node_modules/axios/lib/core/InterceptorManager.js ***!
  \***********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./../utils.js */ \"./node_modules/axios/lib/utils.js\");\n\n\n\n\nclass InterceptorManager {\n  constructor() {\n    this.handlers = [];\n  }\n\n  /**\n   * Add a new interceptor to the stack\n   *\n   * @param {Function} fulfilled The function to handle `then` for a `Promise`\n   * @param {Function} rejected The function to handle `reject` for a `Promise`\n   *\n   * @return {Number} An ID used to remove interceptor later\n   */\n  use(fulfilled, rejected, options) {\n    this.handlers.push({\n      fulfilled,\n      rejected,\n      synchronous: options ? options.synchronous : false,\n      runWhen: options ? options.runWhen : null\n    });\n    return this.handlers.length - 1;\n  }\n\n  /**\n   * Remove an interceptor from the stack\n   *\n   * @param {Number} id The ID that was returned by `use`\n   *\n   * @returns {void}\n   */\n  eject(id) {\n    if (this.handlers[id]) {\n      this.handlers[id] = null;\n    }\n  }\n\n  /**\n   * Clear all interceptors from the stack\n   *\n   * @returns {void}\n   */\n  clear() {\n    if (this.handlers) {\n      this.handlers = [];\n    }\n  }\n\n  /**\n   * Iterate over all the registered interceptors\n   *\n   * This method is particularly useful for skipping over any\n   * interceptors that may have become `null` calling `eject`.\n   *\n   * @param {Function} fn The function to call for each interceptor\n   *\n   * @returns {void}\n   */\n  forEach(fn) {\n    _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].forEach(this.handlers, function forEachHandler(h) {\n      if (h !== null) {\n        fn(h);\n      }\n    });\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (InterceptorManager);\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/core/InterceptorManager.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/core/buildFullPath.js":
/*!******************************************************!*\
  !*** ./node_modules/axios/lib/core/buildFullPath.js ***!
  \******************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ buildFullPath)\n/* harmony export */ });\n/* harmony import */ var _helpers_isAbsoluteURL_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/isAbsoluteURL.js */ \"./node_modules/axios/lib/helpers/isAbsoluteURL.js\");\n/* harmony import */ var _helpers_combineURLs_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/combineURLs.js */ \"./node_modules/axios/lib/helpers/combineURLs.js\");\n\n\n\n\n\n/**\n * Creates a new URL by combining the baseURL with the requestedURL,\n * only when the requestedURL is not already an absolute URL.\n * If the requestURL is absolute, this function returns the requestedURL untouched.\n *\n * @param {string} baseURL The base URL\n * @param {string} requestedURL Absolute or relative URL to combine\n *\n * @returns {string} The combined full path\n */\nfunction buildFullPath(baseURL, requestedURL, allowAbsoluteUrls) {\n  let isRelativeUrl = !(0,_helpers_isAbsoluteURL_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(requestedURL);\n  if (baseURL && (isRelativeUrl || allowAbsoluteUrls == false)) {\n    return (0,_helpers_combineURLs_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(baseURL, requestedURL);\n  }\n  return requestedURL;\n}\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/core/buildFullPath.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/core/dispatchRequest.js":
/*!********************************************************!*\
  !*** ./node_modules/axios/lib/core/dispatchRequest.js ***!
  \********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ dispatchRequest)\n/* harmony export */ });\n/* harmony import */ var _transformData_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./transformData.js */ \"./node_modules/axios/lib/core/transformData.js\");\n/* harmony import */ var _cancel_isCancel_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../cancel/isCancel.js */ \"./node_modules/axios/lib/cancel/isCancel.js\");\n/* harmony import */ var _defaults_index_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../defaults/index.js */ \"./node_modules/axios/lib/defaults/index.js\");\n/* harmony import */ var _cancel_CanceledError_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../cancel/CanceledError.js */ \"./node_modules/axios/lib/cancel/CanceledError.js\");\n/* harmony import */ var _core_AxiosHeaders_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/AxiosHeaders.js */ \"./node_modules/axios/lib/core/AxiosHeaders.js\");\n/* harmony import */ var _adapters_adapters_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../adapters/adapters.js */ \"./node_modules/axios/lib/adapters/adapters.js\");\n\n\n\n\n\n\n\n\n\n/**\n * Throws a `CanceledError` if cancellation has been requested.\n *\n * @param {Object} config The config that is to be used for the request\n *\n * @returns {void}\n */\nfunction throwIfCancellationRequested(config) {\n  if (config.cancelToken) {\n    config.cancelToken.throwIfRequested();\n  }\n\n  if (config.signal && config.signal.aborted) {\n    throw new _cancel_CanceledError_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"](null, config);\n  }\n}\n\n/**\n * Dispatch a request to the server using the configured adapter.\n *\n * @param {object} config The config that is to be used for the request\n *\n * @returns {Promise} The Promise to be fulfilled\n */\nfunction dispatchRequest(config) {\n  throwIfCancellationRequested(config);\n\n  config.headers = _core_AxiosHeaders_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"].from(config.headers);\n\n  // Transform request data\n  config.data = _transformData_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].call(\n    config,\n    config.transformRequest\n  );\n\n  if (['post', 'put', 'patch'].indexOf(config.method) !== -1) {\n    config.headers.setContentType('application/x-www-form-urlencoded', false);\n  }\n\n  const adapter = _adapters_adapters_js__WEBPACK_IMPORTED_MODULE_5__[\"default\"].getAdapter(config.adapter || _defaults_index_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"].adapter, config);\n\n  return adapter(config).then(function onAdapterResolution(response) {\n    throwIfCancellationRequested(config);\n\n    // Transform response data\n    response.data = _transformData_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].call(\n      config,\n      config.transformResponse,\n      response\n    );\n\n    response.headers = _core_AxiosHeaders_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"].from(response.headers);\n\n    return response;\n  }, function onAdapterRejection(reason) {\n    if (!(0,_cancel_isCancel_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(reason)) {\n      throwIfCancellationRequested(config);\n\n      // Transform response data\n      if (reason && reason.response) {\n        reason.response.data = _transformData_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].call(\n          config,\n          config.transformResponse,\n          reason.response\n        );\n        reason.response.headers = _core_AxiosHeaders_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"].from(reason.response.headers);\n      }\n    }\n\n    return Promise.reject(reason);\n  });\n}\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/core/dispatchRequest.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/core/mergeConfig.js":
/*!****************************************************!*\
  !*** ./node_modules/axios/lib/core/mergeConfig.js ***!
  \****************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ mergeConfig)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils.js */ \"./node_modules/axios/lib/utils.js\");\n/* harmony import */ var _AxiosHeaders_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./AxiosHeaders.js */ \"./node_modules/axios/lib/core/AxiosHeaders.js\");\n\n\n\n\n\nconst headersToObject = (thing) => thing instanceof _AxiosHeaders_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"] ? { ...thing } : thing;\n\n/**\n * Config-specific merge-function which creates a new config-object\n * by merging two configuration objects together.\n *\n * @param {Object} config1\n * @param {Object} config2\n *\n * @returns {Object} New object resulting from merging config2 to config1\n */\nfunction mergeConfig(config1, config2) {\n  // eslint-disable-next-line no-param-reassign\n  config2 = config2 || {};\n  const config = {};\n\n  function getMergedValue(target, source, prop, caseless) {\n    if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isPlainObject(target) && _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isPlainObject(source)) {\n      return _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].merge.call({caseless}, target, source);\n    } else if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isPlainObject(source)) {\n      return _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].merge({}, source);\n    } else if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isArray(source)) {\n      return source.slice();\n    }\n    return source;\n  }\n\n  // eslint-disable-next-line consistent-return\n  function mergeDeepProperties(a, b, prop, caseless) {\n    if (!_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isUndefined(b)) {\n      return getMergedValue(a, b, prop, caseless);\n    } else if (!_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isUndefined(a)) {\n      return getMergedValue(undefined, a, prop, caseless);\n    }\n  }\n\n  // eslint-disable-next-line consistent-return\n  function valueFromConfig2(a, b) {\n    if (!_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isUndefined(b)) {\n      return getMergedValue(undefined, b);\n    }\n  }\n\n  // eslint-disable-next-line consistent-return\n  function defaultToConfig2(a, b) {\n    if (!_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isUndefined(b)) {\n      return getMergedValue(undefined, b);\n    } else if (!_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isUndefined(a)) {\n      return getMergedValue(undefined, a);\n    }\n  }\n\n  // eslint-disable-next-line consistent-return\n  function mergeDirectKeys(a, b, prop) {\n    if (prop in config2) {\n      return getMergedValue(a, b);\n    } else if (prop in config1) {\n      return getMergedValue(undefined, a);\n    }\n  }\n\n  const mergeMap = {\n    url: valueFromConfig2,\n    method: valueFromConfig2,\n    data: valueFromConfig2,\n    baseURL: defaultToConfig2,\n    transformRequest: defaultToConfig2,\n    transformResponse: defaultToConfig2,\n    paramsSerializer: defaultToConfig2,\n    timeout: defaultToConfig2,\n    timeoutMessage: defaultToConfig2,\n    withCredentials: defaultToConfig2,\n    withXSRFToken: defaultToConfig2,\n    adapter: defaultToConfig2,\n    responseType: defaultToConfig2,\n    xsrfCookieName: defaultToConfig2,\n    xsrfHeaderName: defaultToConfig2,\n    onUploadProgress: defaultToConfig2,\n    onDownloadProgress: defaultToConfig2,\n    decompress: defaultToConfig2,\n    maxContentLength: defaultToConfig2,\n    maxBodyLength: defaultToConfig2,\n    beforeRedirect: defaultToConfig2,\n    transport: defaultToConfig2,\n    httpAgent: defaultToConfig2,\n    httpsAgent: defaultToConfig2,\n    cancelToken: defaultToConfig2,\n    socketPath: defaultToConfig2,\n    responseEncoding: defaultToConfig2,\n    validateStatus: mergeDirectKeys,\n    headers: (a, b, prop) => mergeDeepProperties(headersToObject(a), headersToObject(b), prop, true)\n  };\n\n  _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].forEach(Object.keys({...config1, ...config2}), function computeConfigValue(prop) {\n    const merge = mergeMap[prop] || mergeDeepProperties;\n    const configValue = merge(config1[prop], config2[prop], prop);\n    (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isUndefined(configValue) && merge !== mergeDirectKeys) || (config[prop] = configValue);\n  });\n\n  return config;\n}\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/core/mergeConfig.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/core/settle.js":
/*!***********************************************!*\
  !*** ./node_modules/axios/lib/core/settle.js ***!
  \***********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ settle)\n/* harmony export */ });\n/* harmony import */ var _AxiosError_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./AxiosError.js */ \"./node_modules/axios/lib/core/AxiosError.js\");\n\n\n\n\n/**\n * Resolve or reject a Promise based on response status.\n *\n * @param {Function} resolve A function that resolves the promise.\n * @param {Function} reject A function that rejects the promise.\n * @param {object} response The response.\n *\n * @returns {object} The response.\n */\nfunction settle(resolve, reject, response) {\n  const validateStatus = response.config.validateStatus;\n  if (!response.status || !validateStatus || validateStatus(response.status)) {\n    resolve(response);\n  } else {\n    reject(new _AxiosError_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"](\n      'Request failed with status code ' + response.status,\n      [_AxiosError_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].ERR_BAD_REQUEST, _AxiosError_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].ERR_BAD_RESPONSE][Math.floor(response.status / 100) - 4],\n      response.config,\n      response.request,\n      response\n    ));\n  }\n}\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/core/settle.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/core/transformData.js":
/*!******************************************************!*\
  !*** ./node_modules/axios/lib/core/transformData.js ***!
  \******************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ transformData)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./../utils.js */ \"./node_modules/axios/lib/utils.js\");\n/* harmony import */ var _defaults_index_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../defaults/index.js */ \"./node_modules/axios/lib/defaults/index.js\");\n/* harmony import */ var _core_AxiosHeaders_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/AxiosHeaders.js */ \"./node_modules/axios/lib/core/AxiosHeaders.js\");\n\n\n\n\n\n\n/**\n * Transform the data for a request or a response\n *\n * @param {Array|Function} fns A single function or Array of functions\n * @param {?Object} response The response object\n *\n * @returns {*} The resulting transformed data\n */\nfunction transformData(fns, response) {\n  const config = this || _defaults_index_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"];\n  const context = response || config;\n  const headers = _core_AxiosHeaders_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"].from(context.headers);\n  let data = context.data;\n\n  _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].forEach(fns, function transform(fn) {\n    data = fn.call(config, data, headers.normalize(), response ? response.status : undefined);\n  });\n\n  headers.normalize();\n\n  return data;\n}\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/core/transformData.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/defaults/index.js":
/*!**************************************************!*\
  !*** ./node_modules/axios/lib/defaults/index.js ***!
  \**************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils.js */ \"./node_modules/axios/lib/utils.js\");\n/* harmony import */ var _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/AxiosError.js */ \"./node_modules/axios/lib/core/AxiosError.js\");\n/* harmony import */ var _transitional_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./transitional.js */ \"./node_modules/axios/lib/defaults/transitional.js\");\n/* harmony import */ var _helpers_toFormData_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../helpers/toFormData.js */ \"./node_modules/axios/lib/helpers/toFormData.js\");\n/* harmony import */ var _helpers_toURLEncodedForm_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../helpers/toURLEncodedForm.js */ \"./node_modules/axios/lib/helpers/toURLEncodedForm.js\");\n/* harmony import */ var _platform_index_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../platform/index.js */ \"./node_modules/axios/lib/platform/index.js\");\n/* harmony import */ var _helpers_formDataToJSON_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../helpers/formDataToJSON.js */ \"./node_modules/axios/lib/helpers/formDataToJSON.js\");\n\n\n\n\n\n\n\n\n\n\n/**\n * It takes a string, tries to parse it, and if it fails, it returns the stringified version\n * of the input\n *\n * @param {any} rawValue - The value to be stringified.\n * @param {Function} parser - A function that parses a string into a JavaScript object.\n * @param {Function} encoder - A function that takes a value and returns a string.\n *\n * @returns {string} A stringified version of the rawValue.\n */\nfunction stringifySafely(rawValue, parser, encoder) {\n  if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isString(rawValue)) {\n    try {\n      (parser || JSON.parse)(rawValue);\n      return _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].trim(rawValue);\n    } catch (e) {\n      if (e.name !== 'SyntaxError') {\n        throw e;\n      }\n    }\n  }\n\n  return (encoder || JSON.stringify)(rawValue);\n}\n\nconst defaults = {\n\n  transitional: _transitional_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"],\n\n  adapter: ['xhr', 'http', 'fetch'],\n\n  transformRequest: [function transformRequest(data, headers) {\n    const contentType = headers.getContentType() || '';\n    const hasJSONContentType = contentType.indexOf('application/json') > -1;\n    const isObjectPayload = _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isObject(data);\n\n    if (isObjectPayload && _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isHTMLForm(data)) {\n      data = new FormData(data);\n    }\n\n    const isFormData = _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isFormData(data);\n\n    if (isFormData) {\n      return hasJSONContentType ? JSON.stringify((0,_helpers_formDataToJSON_js__WEBPACK_IMPORTED_MODULE_6__[\"default\"])(data)) : data;\n    }\n\n    if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isArrayBuffer(data) ||\n      _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isBuffer(data) ||\n      _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isStream(data) ||\n      _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isFile(data) ||\n      _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isBlob(data) ||\n      _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isReadableStream(data)\n    ) {\n      return data;\n    }\n    if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isArrayBufferView(data)) {\n      return data.buffer;\n    }\n    if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isURLSearchParams(data)) {\n      headers.setContentType('application/x-www-form-urlencoded;charset=utf-8', false);\n      return data.toString();\n    }\n\n    let isFileList;\n\n    if (isObjectPayload) {\n      if (contentType.indexOf('application/x-www-form-urlencoded') > -1) {\n        return (0,_helpers_toURLEncodedForm_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"])(data, this.formSerializer).toString();\n      }\n\n      if ((isFileList = _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isFileList(data)) || contentType.indexOf('multipart/form-data') > -1) {\n        const _FormData = this.env && this.env.FormData;\n\n        return (0,_helpers_toFormData_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"])(\n          isFileList ? {'files[]': data} : data,\n          _FormData && new _FormData(),\n          this.formSerializer\n        );\n      }\n    }\n\n    if (isObjectPayload || hasJSONContentType ) {\n      headers.setContentType('application/json', false);\n      return stringifySafely(data);\n    }\n\n    return data;\n  }],\n\n  transformResponse: [function transformResponse(data) {\n    const transitional = this.transitional || defaults.transitional;\n    const forcedJSONParsing = transitional && transitional.forcedJSONParsing;\n    const JSONRequested = this.responseType === 'json';\n\n    if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isResponse(data) || _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isReadableStream(data)) {\n      return data;\n    }\n\n    if (data && _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isString(data) && ((forcedJSONParsing && !this.responseType) || JSONRequested)) {\n      const silentJSONParsing = transitional && transitional.silentJSONParsing;\n      const strictJSONParsing = !silentJSONParsing && JSONRequested;\n\n      try {\n        return JSON.parse(data, this.parseReviver);\n      } catch (e) {\n        if (strictJSONParsing) {\n          if (e.name === 'SyntaxError') {\n            throw _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].from(e, _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].ERR_BAD_RESPONSE, this, null, this.response);\n          }\n          throw e;\n        }\n      }\n    }\n\n    return data;\n  }],\n\n  /**\n   * A timeout in milliseconds to abort a request. If set to 0 (default) a\n   * timeout is not created.\n   */\n  timeout: 0,\n\n  xsrfCookieName: 'XSRF-TOKEN',\n  xsrfHeaderName: 'X-XSRF-TOKEN',\n\n  maxContentLength: -1,\n  maxBodyLength: -1,\n\n  env: {\n    FormData: _platform_index_js__WEBPACK_IMPORTED_MODULE_5__[\"default\"].classes.FormData,\n    Blob: _platform_index_js__WEBPACK_IMPORTED_MODULE_5__[\"default\"].classes.Blob\n  },\n\n  validateStatus: function validateStatus(status) {\n    return status >= 200 && status < 300;\n  },\n\n  headers: {\n    common: {\n      'Accept': 'application/json, text/plain, */*',\n      'Content-Type': undefined\n    }\n  }\n};\n\n_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].forEach(['delete', 'get', 'head', 'post', 'put', 'patch'], (method) => {\n  defaults.headers[method] = {};\n});\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (defaults);\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/defaults/index.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/defaults/transitional.js":
/*!*********************************************************!*\
  !*** ./node_modules/axios/lib/defaults/transitional.js ***!
  \*********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ({\n  silentJSONParsing: true,\n  forcedJSONParsing: true,\n  clarifyTimeoutError: false\n});\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/defaults/transitional.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/env/data.js":
/*!********************************************!*\
  !*** ./node_modules/axios/lib/env/data.js ***!
  \********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   VERSION: () => (/* binding */ VERSION)\n/* harmony export */ });\nconst VERSION = \"1.13.2\";\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/env/data.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/AxiosURLSearchParams.js":
/*!****************************************************************!*\
  !*** ./node_modules/axios/lib/helpers/AxiosURLSearchParams.js ***!
  \****************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _toFormData_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./toFormData.js */ \"./node_modules/axios/lib/helpers/toFormData.js\");\n\n\n\n\n/**\n * It encodes a string by replacing all characters that are not in the unreserved set with\n * their percent-encoded equivalents\n *\n * @param {string} str - The string to encode.\n *\n * @returns {string} The encoded string.\n */\nfunction encode(str) {\n  const charMap = {\n    '!': '%21',\n    \"'\": '%27',\n    '(': '%28',\n    ')': '%29',\n    '~': '%7E',\n    '%20': '+',\n    '%00': '\\x00'\n  };\n  return encodeURIComponent(str).replace(/[!'()~]|%20|%00/g, function replacer(match) {\n    return charMap[match];\n  });\n}\n\n/**\n * It takes a params object and converts it to a FormData object\n *\n * @param {Object<string, any>} params - The parameters to be converted to a FormData object.\n * @param {Object<string, any>} options - The options object passed to the Axios constructor.\n *\n * @returns {void}\n */\nfunction AxiosURLSearchParams(params, options) {\n  this._pairs = [];\n\n  params && (0,_toFormData_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(params, this, options);\n}\n\nconst prototype = AxiosURLSearchParams.prototype;\n\nprototype.append = function append(name, value) {\n  this._pairs.push([name, value]);\n};\n\nprototype.toString = function toString(encoder) {\n  const _encode = encoder ? function(value) {\n    return encoder.call(this, value, encode);\n  } : encode;\n\n  return this._pairs.map(function each(pair) {\n    return _encode(pair[0]) + '=' + _encode(pair[1]);\n  }, '').join('&');\n};\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (AxiosURLSearchParams);\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/helpers/AxiosURLSearchParams.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/HttpStatusCode.js":
/*!**********************************************************!*\
  !*** ./node_modules/axios/lib/helpers/HttpStatusCode.js ***!
  \**********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nconst HttpStatusCode = {\n  Continue: 100,\n  SwitchingProtocols: 101,\n  Processing: 102,\n  EarlyHints: 103,\n  Ok: 200,\n  Created: 201,\n  Accepted: 202,\n  NonAuthoritativeInformation: 203,\n  NoContent: 204,\n  ResetContent: 205,\n  PartialContent: 206,\n  MultiStatus: 207,\n  AlreadyReported: 208,\n  ImUsed: 226,\n  MultipleChoices: 300,\n  MovedPermanently: 301,\n  Found: 302,\n  SeeOther: 303,\n  NotModified: 304,\n  UseProxy: 305,\n  Unused: 306,\n  TemporaryRedirect: 307,\n  PermanentRedirect: 308,\n  BadRequest: 400,\n  Unauthorized: 401,\n  PaymentRequired: 402,\n  Forbidden: 403,\n  NotFound: 404,\n  MethodNotAllowed: 405,\n  NotAcceptable: 406,\n  ProxyAuthenticationRequired: 407,\n  RequestTimeout: 408,\n  Conflict: 409,\n  Gone: 410,\n  LengthRequired: 411,\n  PreconditionFailed: 412,\n  PayloadTooLarge: 413,\n  UriTooLong: 414,\n  UnsupportedMediaType: 415,\n  RangeNotSatisfiable: 416,\n  ExpectationFailed: 417,\n  ImATeapot: 418,\n  MisdirectedRequest: 421,\n  UnprocessableEntity: 422,\n  Locked: 423,\n  FailedDependency: 424,\n  TooEarly: 425,\n  UpgradeRequired: 426,\n  PreconditionRequired: 428,\n  TooManyRequests: 429,\n  RequestHeaderFieldsTooLarge: 431,\n  UnavailableForLegalReasons: 451,\n  InternalServerError: 500,\n  NotImplemented: 501,\n  BadGateway: 502,\n  ServiceUnavailable: 503,\n  GatewayTimeout: 504,\n  HttpVersionNotSupported: 505,\n  VariantAlsoNegotiates: 506,\n  InsufficientStorage: 507,\n  LoopDetected: 508,\n  NotExtended: 510,\n  NetworkAuthenticationRequired: 511,\n  WebServerIsDown: 521,\n  ConnectionTimedOut: 522,\n  OriginIsUnreachable: 523,\n  TimeoutOccurred: 524,\n  SslHandshakeFailed: 525,\n  InvalidSslCertificate: 526,\n};\n\nObject.entries(HttpStatusCode).forEach(([key, value]) => {\n  HttpStatusCode[value] = key;\n});\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (HttpStatusCode);\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/helpers/HttpStatusCode.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/bind.js":
/*!************************************************!*\
  !*** ./node_modules/axios/lib/helpers/bind.js ***!
  \************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ bind)\n/* harmony export */ });\n\n\n/**\n * Create a bound version of a function with a specified `this` context\n *\n * @param {Function} fn - The function to bind\n * @param {*} thisArg - The value to be passed as the `this` parameter\n * @returns {Function} A new function that will call the original function with the specified `this` context\n */\nfunction bind(fn, thisArg) {\n  return function wrap() {\n    return fn.apply(thisArg, arguments);\n  };\n}\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/helpers/bind.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/buildURL.js":
/*!****************************************************!*\
  !*** ./node_modules/axios/lib/helpers/buildURL.js ***!
  \****************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ buildURL)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils.js */ \"./node_modules/axios/lib/utils.js\");\n/* harmony import */ var _helpers_AxiosURLSearchParams_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/AxiosURLSearchParams.js */ \"./node_modules/axios/lib/helpers/AxiosURLSearchParams.js\");\n\n\n\n\n\n/**\n * It replaces all instances of the characters `:`, `$`, `,`, `+`, `[`, and `]` with their\n * URI encoded counterparts\n *\n * @param {string} val The value to be encoded.\n *\n * @returns {string} The encoded value.\n */\nfunction encode(val) {\n  return encodeURIComponent(val).\n    replace(/%3A/gi, ':').\n    replace(/%24/g, '$').\n    replace(/%2C/gi, ',').\n    replace(/%20/g, '+');\n}\n\n/**\n * Build a URL by appending params to the end\n *\n * @param {string} url The base of the url (e.g., http://www.google.com)\n * @param {object} [params] The params to be appended\n * @param {?(object|Function)} options\n *\n * @returns {string} The formatted url\n */\nfunction buildURL(url, params, options) {\n  /*eslint no-param-reassign:0*/\n  if (!params) {\n    return url;\n  }\n  \n  const _encode = options && options.encode || encode;\n\n  if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isFunction(options)) {\n    options = {\n      serialize: options\n    };\n  } \n\n  const serializeFn = options && options.serialize;\n\n  let serializedParams;\n\n  if (serializeFn) {\n    serializedParams = serializeFn(params, options);\n  } else {\n    serializedParams = _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isURLSearchParams(params) ?\n      params.toString() :\n      new _helpers_AxiosURLSearchParams_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"](params, options).toString(_encode);\n  }\n\n  if (serializedParams) {\n    const hashmarkIndex = url.indexOf(\"#\");\n\n    if (hashmarkIndex !== -1) {\n      url = url.slice(0, hashmarkIndex);\n    }\n    url += (url.indexOf('?') === -1 ? '?' : '&') + serializedParams;\n  }\n\n  return url;\n}\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/helpers/buildURL.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/combineURLs.js":
/*!*******************************************************!*\
  !*** ./node_modules/axios/lib/helpers/combineURLs.js ***!
  \*******************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ combineURLs)\n/* harmony export */ });\n\n\n/**\n * Creates a new URL by combining the specified URLs\n *\n * @param {string} baseURL The base URL\n * @param {string} relativeURL The relative URL\n *\n * @returns {string} The combined URL\n */\nfunction combineURLs(baseURL, relativeURL) {\n  return relativeURL\n    ? baseURL.replace(/\\/?\\/$/, '') + '/' + relativeURL.replace(/^\\/+/, '')\n    : baseURL;\n}\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/helpers/combineURLs.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/composeSignals.js":
/*!**********************************************************!*\
  !*** ./node_modules/axios/lib/helpers/composeSignals.js ***!
  \**********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _cancel_CanceledError_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../cancel/CanceledError.js */ \"./node_modules/axios/lib/cancel/CanceledError.js\");\n/* harmony import */ var _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/AxiosError.js */ \"./node_modules/axios/lib/core/AxiosError.js\");\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils.js */ \"./node_modules/axios/lib/utils.js\");\n\n\n\n\nconst composeSignals = (signals, timeout) => {\n  const {length} = (signals = signals ? signals.filter(Boolean) : []);\n\n  if (timeout || length) {\n    let controller = new AbortController();\n\n    let aborted;\n\n    const onabort = function (reason) {\n      if (!aborted) {\n        aborted = true;\n        unsubscribe();\n        const err = reason instanceof Error ? reason : this.reason;\n        controller.abort(err instanceof _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"] ? err : new _cancel_CanceledError_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"](err instanceof Error ? err.message : err));\n      }\n    }\n\n    let timer = timeout && setTimeout(() => {\n      timer = null;\n      onabort(new _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"](`timeout ${timeout} of ms exceeded`, _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].ETIMEDOUT))\n    }, timeout)\n\n    const unsubscribe = () => {\n      if (signals) {\n        timer && clearTimeout(timer);\n        timer = null;\n        signals.forEach(signal => {\n          signal.unsubscribe ? signal.unsubscribe(onabort) : signal.removeEventListener('abort', onabort);\n        });\n        signals = null;\n      }\n    }\n\n    signals.forEach((signal) => signal.addEventListener('abort', onabort));\n\n    const {signal} = controller;\n\n    signal.unsubscribe = () => _utils_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"].asap(unsubscribe);\n\n    return signal;\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (composeSignals);\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/helpers/composeSignals.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/cookies.js":
/*!***************************************************!*\
  !*** ./node_modules/axios/lib/helpers/cookies.js ***!
  \***************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./../utils.js */ \"./node_modules/axios/lib/utils.js\");\n/* harmony import */ var _platform_index_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../platform/index.js */ \"./node_modules/axios/lib/platform/index.js\");\n\n\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (_platform_index_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].hasStandardBrowserEnv ?\n\n  // Standard browser envs support document.cookie\n  {\n    write(name, value, expires, path, domain, secure, sameSite) {\n      if (typeof document === 'undefined') return;\n\n      const cookie = [`${name}=${encodeURIComponent(value)}`];\n\n      if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isNumber(expires)) {\n        cookie.push(`expires=${new Date(expires).toUTCString()}`);\n      }\n      if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isString(path)) {\n        cookie.push(`path=${path}`);\n      }\n      if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isString(domain)) {\n        cookie.push(`domain=${domain}`);\n      }\n      if (secure === true) {\n        cookie.push('secure');\n      }\n      if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isString(sameSite)) {\n        cookie.push(`SameSite=${sameSite}`);\n      }\n\n      document.cookie = cookie.join('; ');\n    },\n\n    read(name) {\n      if (typeof document === 'undefined') return null;\n      const match = document.cookie.match(new RegExp('(?:^|; )' + name + '=([^;]*)'));\n      return match ? decodeURIComponent(match[1]) : null;\n    },\n\n    remove(name) {\n      this.write(name, '', Date.now() - 86400000, '/');\n    }\n  }\n\n  :\n\n  // Non-standard browser env (web workers, react-native) lack needed support.\n  {\n    write() {},\n    read() {\n      return null;\n    },\n    remove() {}\n  });\n\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/helpers/cookies.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/formDataToJSON.js":
/*!**********************************************************!*\
  !*** ./node_modules/axios/lib/helpers/formDataToJSON.js ***!
  \**********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils.js */ \"./node_modules/axios/lib/utils.js\");\n\n\n\n\n/**\n * It takes a string like `foo[x][y][z]` and returns an array like `['foo', 'x', 'y', 'z']\n *\n * @param {string} name - The name of the property to get.\n *\n * @returns An array of strings.\n */\nfunction parsePropPath(name) {\n  // foo[x][y][z]\n  // foo.x.y.z\n  // foo-x-y-z\n  // foo x y z\n  return _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].matchAll(/\\w+|\\[(\\w*)]/g, name).map(match => {\n    return match[0] === '[]' ? '' : match[1] || match[0];\n  });\n}\n\n/**\n * Convert an array to an object.\n *\n * @param {Array<any>} arr - The array to convert to an object.\n *\n * @returns An object with the same keys and values as the array.\n */\nfunction arrayToObject(arr) {\n  const obj = {};\n  const keys = Object.keys(arr);\n  let i;\n  const len = keys.length;\n  let key;\n  for (i = 0; i < len; i++) {\n    key = keys[i];\n    obj[key] = arr[key];\n  }\n  return obj;\n}\n\n/**\n * It takes a FormData object and returns a JavaScript object\n *\n * @param {string} formData The FormData object to convert to JSON.\n *\n * @returns {Object<string, any> | null} The converted object.\n */\nfunction formDataToJSON(formData) {\n  function buildPath(path, value, target, index) {\n    let name = path[index++];\n\n    if (name === '__proto__') return true;\n\n    const isNumericKey = Number.isFinite(+name);\n    const isLast = index >= path.length;\n    name = !name && _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isArray(target) ? target.length : name;\n\n    if (isLast) {\n      if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].hasOwnProp(target, name)) {\n        target[name] = [target[name], value];\n      } else {\n        target[name] = value;\n      }\n\n      return !isNumericKey;\n    }\n\n    if (!target[name] || !_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isObject(target[name])) {\n      target[name] = [];\n    }\n\n    const result = buildPath(path, value, target[name], index);\n\n    if (result && _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isArray(target[name])) {\n      target[name] = arrayToObject(target[name]);\n    }\n\n    return !isNumericKey;\n  }\n\n  if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isFormData(formData) && _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isFunction(formData.entries)) {\n    const obj = {};\n\n    _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].forEachEntry(formData, (name, value) => {\n      buildPath(parsePropPath(name), value, obj, 0);\n    });\n\n    return obj;\n  }\n\n  return null;\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (formDataToJSON);\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/helpers/formDataToJSON.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/isAbsoluteURL.js":
/*!*********************************************************!*\
  !*** ./node_modules/axios/lib/helpers/isAbsoluteURL.js ***!
  \*********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ isAbsoluteURL)\n/* harmony export */ });\n\n\n/**\n * Determines whether the specified URL is absolute\n *\n * @param {string} url The URL to test\n *\n * @returns {boolean} True if the specified URL is absolute, otherwise false\n */\nfunction isAbsoluteURL(url) {\n  // A URL is considered absolute if it begins with \"<scheme>://\" or \"//\" (protocol-relative URL).\n  // RFC 3986 defines scheme name as a sequence of characters beginning with a letter and followed\n  // by any combination of letters, digits, plus, period, or hyphen.\n  return /^([a-z][a-z\\d+\\-.]*:)?\\/\\//i.test(url);\n}\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/helpers/isAbsoluteURL.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/isAxiosError.js":
/*!********************************************************!*\
  !*** ./node_modules/axios/lib/helpers/isAxiosError.js ***!
  \********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ isAxiosError)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./../utils.js */ \"./node_modules/axios/lib/utils.js\");\n\n\n\n\n/**\n * Determines whether the payload is an error thrown by Axios\n *\n * @param {*} payload The value to test\n *\n * @returns {boolean} True if the payload is an error thrown by Axios, otherwise false\n */\nfunction isAxiosError(payload) {\n  return _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isObject(payload) && (payload.isAxiosError === true);\n}\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/helpers/isAxiosError.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/isURLSameOrigin.js":
/*!***********************************************************!*\
  !*** ./node_modules/axios/lib/helpers/isURLSameOrigin.js ***!
  \***********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _platform_index_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../platform/index.js */ \"./node_modules/axios/lib/platform/index.js\");\n\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (_platform_index_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].hasStandardBrowserEnv ? ((origin, isMSIE) => (url) => {\n  url = new URL(url, _platform_index_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].origin);\n\n  return (\n    origin.protocol === url.protocol &&\n    origin.host === url.host &&\n    (isMSIE || origin.port === url.port)\n  );\n})(\n  new URL(_platform_index_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].origin),\n  _platform_index_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].navigator && /(msie|trident)/i.test(_platform_index_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].navigator.userAgent)\n) : () => true);\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/helpers/isURLSameOrigin.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/null.js":
/*!************************************************!*\
  !*** ./node_modules/axios/lib/helpers/null.js ***!
  \************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n// eslint-disable-next-line strict\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (null);\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/helpers/null.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/parseHeaders.js":
/*!********************************************************!*\
  !*** ./node_modules/axios/lib/helpers/parseHeaders.js ***!
  \********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./../utils.js */ \"./node_modules/axios/lib/utils.js\");\n\n\n\n\n// RawAxiosHeaders whose duplicates are ignored by node\n// c.f. https://nodejs.org/api/http.html#http_message_headers\nconst ignoreDuplicateOf = _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].toObjectSet([\n  'age', 'authorization', 'content-length', 'content-type', 'etag',\n  'expires', 'from', 'host', 'if-modified-since', 'if-unmodified-since',\n  'last-modified', 'location', 'max-forwards', 'proxy-authorization',\n  'referer', 'retry-after', 'user-agent'\n]);\n\n/**\n * Parse headers into an object\n *\n * ```\n * Date: Wed, 27 Aug 2014 08:58:49 GMT\n * Content-Type: application/json\n * Connection: keep-alive\n * Transfer-Encoding: chunked\n * ```\n *\n * @param {String} rawHeaders Headers needing to be parsed\n *\n * @returns {Object} Headers parsed into an object\n */\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (rawHeaders => {\n  const parsed = {};\n  let key;\n  let val;\n  let i;\n\n  rawHeaders && rawHeaders.split('\\n').forEach(function parser(line) {\n    i = line.indexOf(':');\n    key = line.substring(0, i).trim().toLowerCase();\n    val = line.substring(i + 1).trim();\n\n    if (!key || (parsed[key] && ignoreDuplicateOf[key])) {\n      return;\n    }\n\n    if (key === 'set-cookie') {\n      if (parsed[key]) {\n        parsed[key].push(val);\n      } else {\n        parsed[key] = [val];\n      }\n    } else {\n      parsed[key] = parsed[key] ? parsed[key] + ', ' + val : val;\n    }\n  });\n\n  return parsed;\n});\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/helpers/parseHeaders.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/parseProtocol.js":
/*!*********************************************************!*\
  !*** ./node_modules/axios/lib/helpers/parseProtocol.js ***!
  \*********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ parseProtocol)\n/* harmony export */ });\n\n\nfunction parseProtocol(url) {\n  const match = /^([-+\\w]{1,25})(:?\\/\\/|:)/.exec(url);\n  return match && match[1] || '';\n}\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/helpers/parseProtocol.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/progressEventReducer.js":
/*!****************************************************************!*\
  !*** ./node_modules/axios/lib/helpers/progressEventReducer.js ***!
  \****************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   asyncDecorator: () => (/* binding */ asyncDecorator),\n/* harmony export */   progressEventDecorator: () => (/* binding */ progressEventDecorator),\n/* harmony export */   progressEventReducer: () => (/* binding */ progressEventReducer)\n/* harmony export */ });\n/* harmony import */ var _speedometer_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./speedometer.js */ \"./node_modules/axios/lib/helpers/speedometer.js\");\n/* harmony import */ var _throttle_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./throttle.js */ \"./node_modules/axios/lib/helpers/throttle.js\");\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils.js */ \"./node_modules/axios/lib/utils.js\");\n\n\n\n\nconst progressEventReducer = (listener, isDownloadStream, freq = 3) => {\n  let bytesNotified = 0;\n  const _speedometer = (0,_speedometer_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(50, 250);\n\n  return (0,_throttle_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(e => {\n    const loaded = e.loaded;\n    const total = e.lengthComputable ? e.total : undefined;\n    const progressBytes = loaded - bytesNotified;\n    const rate = _speedometer(progressBytes);\n    const inRange = loaded <= total;\n\n    bytesNotified = loaded;\n\n    const data = {\n      loaded,\n      total,\n      progress: total ? (loaded / total) : undefined,\n      bytes: progressBytes,\n      rate: rate ? rate : undefined,\n      estimated: rate && total && inRange ? (total - loaded) / rate : undefined,\n      event: e,\n      lengthComputable: total != null,\n      [isDownloadStream ? 'download' : 'upload']: true\n    };\n\n    listener(data);\n  }, freq);\n}\n\nconst progressEventDecorator = (total, throttled) => {\n  const lengthComputable = total != null;\n\n  return [(loaded) => throttled[0]({\n    lengthComputable,\n    total,\n    loaded\n  }), throttled[1]];\n}\n\nconst asyncDecorator = (fn) => (...args) => _utils_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"].asap(() => fn(...args));\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/helpers/progressEventReducer.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/resolveConfig.js":
/*!*********************************************************!*\
  !*** ./node_modules/axios/lib/helpers/resolveConfig.js ***!
  \*********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _platform_index_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../platform/index.js */ \"./node_modules/axios/lib/platform/index.js\");\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils.js */ \"./node_modules/axios/lib/utils.js\");\n/* harmony import */ var _isURLSameOrigin_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./isURLSameOrigin.js */ \"./node_modules/axios/lib/helpers/isURLSameOrigin.js\");\n/* harmony import */ var _cookies_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./cookies.js */ \"./node_modules/axios/lib/helpers/cookies.js\");\n/* harmony import */ var _core_buildFullPath_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/buildFullPath.js */ \"./node_modules/axios/lib/core/buildFullPath.js\");\n/* harmony import */ var _core_mergeConfig_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../core/mergeConfig.js */ \"./node_modules/axios/lib/core/mergeConfig.js\");\n/* harmony import */ var _core_AxiosHeaders_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../core/AxiosHeaders.js */ \"./node_modules/axios/lib/core/AxiosHeaders.js\");\n/* harmony import */ var _buildURL_js__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./buildURL.js */ \"./node_modules/axios/lib/helpers/buildURL.js\");\n\n\n\n\n\n\n\n\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ((config) => {\n  const newConfig = (0,_core_mergeConfig_js__WEBPACK_IMPORTED_MODULE_5__[\"default\"])({}, config);\n\n  let { data, withXSRFToken, xsrfHeaderName, xsrfCookieName, headers, auth } = newConfig;\n\n  newConfig.headers = headers = _core_AxiosHeaders_js__WEBPACK_IMPORTED_MODULE_6__[\"default\"].from(headers);\n\n  newConfig.url = (0,_buildURL_js__WEBPACK_IMPORTED_MODULE_7__[\"default\"])((0,_core_buildFullPath_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"])(newConfig.baseURL, newConfig.url, newConfig.allowAbsoluteUrls), config.params, config.paramsSerializer);\n\n  // HTTP basic authentication\n  if (auth) {\n    headers.set('Authorization', 'Basic ' +\n      btoa((auth.username || '') + ':' + (auth.password ? unescape(encodeURIComponent(auth.password)) : ''))\n    );\n  }\n\n  if (_utils_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].isFormData(data)) {\n    if (_platform_index_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].hasStandardBrowserEnv || _platform_index_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].hasStandardBrowserWebWorkerEnv) {\n      headers.setContentType(undefined); // browser handles it\n    } else if (_utils_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].isFunction(data.getHeaders)) {\n      // Node.js FormData (like form-data package)\n      const formHeaders = data.getHeaders();\n      // Only set safe headers to avoid overwriting security headers\n      const allowedHeaders = ['content-type', 'content-length'];\n      Object.entries(formHeaders).forEach(([key, val]) => {\n        if (allowedHeaders.includes(key.toLowerCase())) {\n          headers.set(key, val);\n        }\n      });\n    }\n  }  \n\n  // Add xsrf header\n  // This is only done if running in a standard browser environment.\n  // Specifically not if we're in a web worker, or react-native.\n\n  if (_platform_index_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].hasStandardBrowserEnv) {\n    withXSRFToken && _utils_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].isFunction(withXSRFToken) && (withXSRFToken = withXSRFToken(newConfig));\n\n    if (withXSRFToken || (withXSRFToken !== false && (0,_isURLSameOrigin_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(newConfig.url))) {\n      // Add xsrf header\n      const xsrfValue = xsrfHeaderName && xsrfCookieName && _cookies_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"].read(xsrfCookieName);\n\n      if (xsrfValue) {\n        headers.set(xsrfHeaderName, xsrfValue);\n      }\n    }\n  }\n\n  return newConfig;\n});\n\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/helpers/resolveConfig.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/speedometer.js":
/*!*******************************************************!*\
  !*** ./node_modules/axios/lib/helpers/speedometer.js ***!
  \*******************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n\n\n/**\n * Calculate data maxRate\n * @param {Number} [samplesCount= 10]\n * @param {Number} [min= 1000]\n * @returns {Function}\n */\nfunction speedometer(samplesCount, min) {\n  samplesCount = samplesCount || 10;\n  const bytes = new Array(samplesCount);\n  const timestamps = new Array(samplesCount);\n  let head = 0;\n  let tail = 0;\n  let firstSampleTS;\n\n  min = min !== undefined ? min : 1000;\n\n  return function push(chunkLength) {\n    const now = Date.now();\n\n    const startedAt = timestamps[tail];\n\n    if (!firstSampleTS) {\n      firstSampleTS = now;\n    }\n\n    bytes[head] = chunkLength;\n    timestamps[head] = now;\n\n    let i = tail;\n    let bytesCount = 0;\n\n    while (i !== head) {\n      bytesCount += bytes[i++];\n      i = i % samplesCount;\n    }\n\n    head = (head + 1) % samplesCount;\n\n    if (head === tail) {\n      tail = (tail + 1) % samplesCount;\n    }\n\n    if (now - firstSampleTS < min) {\n      return;\n    }\n\n    const passed = startedAt && now - startedAt;\n\n    return passed ? Math.round(bytesCount * 1000 / passed) : undefined;\n  };\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (speedometer);\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/helpers/speedometer.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/spread.js":
/*!**************************************************!*\
  !*** ./node_modules/axios/lib/helpers/spread.js ***!
  \**************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ spread)\n/* harmony export */ });\n\n\n/**\n * Syntactic sugar for invoking a function and expanding an array for arguments.\n *\n * Common use case would be to use `Function.prototype.apply`.\n *\n *  ```js\n *  function f(x, y, z) {}\n *  var args = [1, 2, 3];\n *  f.apply(null, args);\n *  ```\n *\n * With `spread` this example can be re-written.\n *\n *  ```js\n *  spread(function(x, y, z) {})([1, 2, 3]);\n *  ```\n *\n * @param {Function} callback\n *\n * @returns {Function}\n */\nfunction spread(callback) {\n  return function wrap(arr) {\n    return callback.apply(null, arr);\n  };\n}\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/helpers/spread.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/throttle.js":
/*!****************************************************!*\
  !*** ./node_modules/axios/lib/helpers/throttle.js ***!
  \****************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/**\n * Throttle decorator\n * @param {Function} fn\n * @param {Number} freq\n * @return {Function}\n */\nfunction throttle(fn, freq) {\n  let timestamp = 0;\n  let threshold = 1000 / freq;\n  let lastArgs;\n  let timer;\n\n  const invoke = (args, now = Date.now()) => {\n    timestamp = now;\n    lastArgs = null;\n    if (timer) {\n      clearTimeout(timer);\n      timer = null;\n    }\n    fn(...args);\n  }\n\n  const throttled = (...args) => {\n    const now = Date.now();\n    const passed = now - timestamp;\n    if ( passed >= threshold) {\n      invoke(args, now);\n    } else {\n      lastArgs = args;\n      if (!timer) {\n        timer = setTimeout(() => {\n          timer = null;\n          invoke(lastArgs)\n        }, threshold - passed);\n      }\n    }\n  }\n\n  const flush = () => lastArgs && invoke(lastArgs);\n\n  return [throttled, flush];\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (throttle);\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/helpers/throttle.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/toFormData.js":
/*!******************************************************!*\
  !*** ./node_modules/axios/lib/helpers/toFormData.js ***!
  \******************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils.js */ \"./node_modules/axios/lib/utils.js\");\n/* harmony import */ var _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/AxiosError.js */ \"./node_modules/axios/lib/core/AxiosError.js\");\n/* harmony import */ var _platform_node_classes_FormData_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../platform/node/classes/FormData.js */ \"./node_modules/axios/lib/helpers/null.js\");\n\n\n\n\n// temporary hotfix to avoid circular references until AxiosURLSearchParams is refactored\n\n\n/**\n * Determines if the given thing is a array or js object.\n *\n * @param {string} thing - The object or array to be visited.\n *\n * @returns {boolean}\n */\nfunction isVisitable(thing) {\n  return _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isPlainObject(thing) || _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isArray(thing);\n}\n\n/**\n * It removes the brackets from the end of a string\n *\n * @param {string} key - The key of the parameter.\n *\n * @returns {string} the key without the brackets.\n */\nfunction removeBrackets(key) {\n  return _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].endsWith(key, '[]') ? key.slice(0, -2) : key;\n}\n\n/**\n * It takes a path, a key, and a boolean, and returns a string\n *\n * @param {string} path - The path to the current key.\n * @param {string} key - The key of the current object being iterated over.\n * @param {string} dots - If true, the key will be rendered with dots instead of brackets.\n *\n * @returns {string} The path to the current key.\n */\nfunction renderKey(path, key, dots) {\n  if (!path) return key;\n  return path.concat(key).map(function each(token, i) {\n    // eslint-disable-next-line no-param-reassign\n    token = removeBrackets(token);\n    return !dots && i ? '[' + token + ']' : token;\n  }).join(dots ? '.' : '');\n}\n\n/**\n * If the array is an array and none of its elements are visitable, then it's a flat array.\n *\n * @param {Array<any>} arr - The array to check\n *\n * @returns {boolean}\n */\nfunction isFlatArray(arr) {\n  return _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isArray(arr) && !arr.some(isVisitable);\n}\n\nconst predicates = _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].toFlatObject(_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"], {}, null, function filter(prop) {\n  return /^is[A-Z]/.test(prop);\n});\n\n/**\n * Convert a data object to FormData\n *\n * @param {Object} obj\n * @param {?Object} [formData]\n * @param {?Object} [options]\n * @param {Function} [options.visitor]\n * @param {Boolean} [options.metaTokens = true]\n * @param {Boolean} [options.dots = false]\n * @param {?Boolean} [options.indexes = false]\n *\n * @returns {Object}\n **/\n\n/**\n * It converts an object into a FormData object\n *\n * @param {Object<any, any>} obj - The object to convert to form data.\n * @param {string} formData - The FormData object to append to.\n * @param {Object<string, any>} options\n *\n * @returns\n */\nfunction toFormData(obj, formData, options) {\n  if (!_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isObject(obj)) {\n    throw new TypeError('target must be an object');\n  }\n\n  // eslint-disable-next-line no-param-reassign\n  formData = formData || new (_platform_node_classes_FormData_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"] || FormData)();\n\n  // eslint-disable-next-line no-param-reassign\n  options = _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].toFlatObject(options, {\n    metaTokens: true,\n    dots: false,\n    indexes: false\n  }, false, function defined(option, source) {\n    // eslint-disable-next-line no-eq-null,eqeqeq\n    return !_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isUndefined(source[option]);\n  });\n\n  const metaTokens = options.metaTokens;\n  // eslint-disable-next-line no-use-before-define\n  const visitor = options.visitor || defaultVisitor;\n  const dots = options.dots;\n  const indexes = options.indexes;\n  const _Blob = options.Blob || typeof Blob !== 'undefined' && Blob;\n  const useBlob = _Blob && _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isSpecCompliantForm(formData);\n\n  if (!_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isFunction(visitor)) {\n    throw new TypeError('visitor must be a function');\n  }\n\n  function convertValue(value) {\n    if (value === null) return '';\n\n    if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isDate(value)) {\n      return value.toISOString();\n    }\n\n    if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isBoolean(value)) {\n      return value.toString();\n    }\n\n    if (!useBlob && _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isBlob(value)) {\n      throw new _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"]('Blob is not supported. Use a Buffer instead.');\n    }\n\n    if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isArrayBuffer(value) || _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isTypedArray(value)) {\n      return useBlob && typeof Blob === 'function' ? new Blob([value]) : Buffer.from(value);\n    }\n\n    return value;\n  }\n\n  /**\n   * Default visitor.\n   *\n   * @param {*} value\n   * @param {String|Number} key\n   * @param {Array<String|Number>} path\n   * @this {FormData}\n   *\n   * @returns {boolean} return true to visit the each prop of the value recursively\n   */\n  function defaultVisitor(value, key, path) {\n    let arr = value;\n\n    if (value && !path && typeof value === 'object') {\n      if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].endsWith(key, '{}')) {\n        // eslint-disable-next-line no-param-reassign\n        key = metaTokens ? key : key.slice(0, -2);\n        // eslint-disable-next-line no-param-reassign\n        value = JSON.stringify(value);\n      } else if (\n        (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isArray(value) && isFlatArray(value)) ||\n        ((_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isFileList(value) || _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].endsWith(key, '[]')) && (arr = _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].toArray(value))\n        )) {\n        // eslint-disable-next-line no-param-reassign\n        key = removeBrackets(key);\n\n        arr.forEach(function each(el, index) {\n          !(_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isUndefined(el) || el === null) && formData.append(\n            // eslint-disable-next-line no-nested-ternary\n            indexes === true ? renderKey([key], index, dots) : (indexes === null ? key : key + '[]'),\n            convertValue(el)\n          );\n        });\n        return false;\n      }\n    }\n\n    if (isVisitable(value)) {\n      return true;\n    }\n\n    formData.append(renderKey(path, key, dots), convertValue(value));\n\n    return false;\n  }\n\n  const stack = [];\n\n  const exposedHelpers = Object.assign(predicates, {\n    defaultVisitor,\n    convertValue,\n    isVisitable\n  });\n\n  function build(value, path) {\n    if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isUndefined(value)) return;\n\n    if (stack.indexOf(value) !== -1) {\n      throw Error('Circular reference detected in ' + path.join('.'));\n    }\n\n    stack.push(value);\n\n    _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].forEach(value, function each(el, key) {\n      const result = !(_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isUndefined(el) || el === null) && visitor.call(\n        formData, el, _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isString(key) ? key.trim() : key, path, exposedHelpers\n      );\n\n      if (result === true) {\n        build(el, path ? path.concat(key) : [key]);\n      }\n    });\n\n    stack.pop();\n  }\n\n  if (!_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isObject(obj)) {\n    throw new TypeError('data must be an object');\n  }\n\n  build(obj);\n\n  return formData;\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (toFormData);\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/helpers/toFormData.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/toURLEncodedForm.js":
/*!************************************************************!*\
  !*** ./node_modules/axios/lib/helpers/toURLEncodedForm.js ***!
  \************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ toURLEncodedForm)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils.js */ \"./node_modules/axios/lib/utils.js\");\n/* harmony import */ var _toFormData_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./toFormData.js */ \"./node_modules/axios/lib/helpers/toFormData.js\");\n/* harmony import */ var _platform_index_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../platform/index.js */ \"./node_modules/axios/lib/platform/index.js\");\n\n\n\n\n\n\nfunction toURLEncodedForm(data, options) {\n  return (0,_toFormData_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(data, new _platform_index_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"].classes.URLSearchParams(), {\n    visitor: function(value, key, path, helpers) {\n      if (_platform_index_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"].isNode && _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isBuffer(value)) {\n        this.append(key, value.toString('base64'));\n        return false;\n      }\n\n      return helpers.defaultVisitor.apply(this, arguments);\n    },\n    ...options\n  });\n}\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/helpers/toURLEncodedForm.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/trackStream.js":
/*!*******************************************************!*\
  !*** ./node_modules/axios/lib/helpers/trackStream.js ***!
  \*******************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   readBytes: () => (/* binding */ readBytes),\n/* harmony export */   streamChunk: () => (/* binding */ streamChunk),\n/* harmony export */   trackStream: () => (/* binding */ trackStream)\n/* harmony export */ });\n\nconst streamChunk = function* (chunk, chunkSize) {\n  let len = chunk.byteLength;\n\n  if (!chunkSize || len < chunkSize) {\n    yield chunk;\n    return;\n  }\n\n  let pos = 0;\n  let end;\n\n  while (pos < len) {\n    end = pos + chunkSize;\n    yield chunk.slice(pos, end);\n    pos = end;\n  }\n}\n\nconst readBytes = async function* (iterable, chunkSize) {\n  for await (const chunk of readStream(iterable)) {\n    yield* streamChunk(chunk, chunkSize);\n  }\n}\n\nconst readStream = async function* (stream) {\n  if (stream[Symbol.asyncIterator]) {\n    yield* stream;\n    return;\n  }\n\n  const reader = stream.getReader();\n  try {\n    for (;;) {\n      const {done, value} = await reader.read();\n      if (done) {\n        break;\n      }\n      yield value;\n    }\n  } finally {\n    await reader.cancel();\n  }\n}\n\nconst trackStream = (stream, chunkSize, onProgress, onFinish) => {\n  const iterator = readBytes(stream, chunkSize);\n\n  let bytes = 0;\n  let done;\n  let _onFinish = (e) => {\n    if (!done) {\n      done = true;\n      onFinish && onFinish(e);\n    }\n  }\n\n  return new ReadableStream({\n    async pull(controller) {\n      try {\n        const {done, value} = await iterator.next();\n\n        if (done) {\n         _onFinish();\n          controller.close();\n          return;\n        }\n\n        let len = value.byteLength;\n        if (onProgress) {\n          let loadedBytes = bytes += len;\n          onProgress(loadedBytes);\n        }\n        controller.enqueue(new Uint8Array(value));\n      } catch (err) {\n        _onFinish(err);\n        throw err;\n      }\n    },\n    cancel(reason) {\n      _onFinish(reason);\n      return iterator.return();\n    }\n  }, {\n    highWaterMark: 2\n  })\n}\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/helpers/trackStream.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/validator.js":
/*!*****************************************************!*\
  !*** ./node_modules/axios/lib/helpers/validator.js ***!
  \*****************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _env_data_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../env/data.js */ \"./node_modules/axios/lib/env/data.js\");\n/* harmony import */ var _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/AxiosError.js */ \"./node_modules/axios/lib/core/AxiosError.js\");\n\n\n\n\n\nconst validators = {};\n\n// eslint-disable-next-line func-names\n['object', 'boolean', 'number', 'function', 'string', 'symbol'].forEach((type, i) => {\n  validators[type] = function validator(thing) {\n    return typeof thing === type || 'a' + (i < 1 ? 'n ' : ' ') + type;\n  };\n});\n\nconst deprecatedWarnings = {};\n\n/**\n * Transitional option validator\n *\n * @param {function|boolean?} validator - set to false if the transitional option has been removed\n * @param {string?} version - deprecated version / removed since version\n * @param {string?} message - some message with additional info\n *\n * @returns {function}\n */\nvalidators.transitional = function transitional(validator, version, message) {\n  function formatMessage(opt, desc) {\n    return '[Axios v' + _env_data_js__WEBPACK_IMPORTED_MODULE_0__.VERSION + '] Transitional option \\'' + opt + '\\'' + desc + (message ? '. ' + message : '');\n  }\n\n  // eslint-disable-next-line func-names\n  return (value, opt, opts) => {\n    if (validator === false) {\n      throw new _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"](\n        formatMessage(opt, ' has been removed' + (version ? ' in ' + version : '')),\n        _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].ERR_DEPRECATED\n      );\n    }\n\n    if (version && !deprecatedWarnings[opt]) {\n      deprecatedWarnings[opt] = true;\n      // eslint-disable-next-line no-console\n      console.warn(\n        formatMessage(\n          opt,\n          ' has been deprecated since v' + version + ' and will be removed in the near future'\n        )\n      );\n    }\n\n    return validator ? validator(value, opt, opts) : true;\n  };\n};\n\nvalidators.spelling = function spelling(correctSpelling) {\n  return (value, opt) => {\n    // eslint-disable-next-line no-console\n    console.warn(`${opt} is likely a misspelling of ${correctSpelling}`);\n    return true;\n  }\n};\n\n/**\n * Assert object's properties type\n *\n * @param {object} options\n * @param {object} schema\n * @param {boolean?} allowUnknown\n *\n * @returns {object}\n */\n\nfunction assertOptions(options, schema, allowUnknown) {\n  if (typeof options !== 'object') {\n    throw new _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"]('options must be an object', _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].ERR_BAD_OPTION_VALUE);\n  }\n  const keys = Object.keys(options);\n  let i = keys.length;\n  while (i-- > 0) {\n    const opt = keys[i];\n    const validator = schema[opt];\n    if (validator) {\n      const value = options[opt];\n      const result = value === undefined || validator(value, opt, options);\n      if (result !== true) {\n        throw new _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"]('option ' + opt + ' must be ' + result, _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].ERR_BAD_OPTION_VALUE);\n      }\n      continue;\n    }\n    if (allowUnknown !== true) {\n      throw new _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"]('Unknown option ' + opt, _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].ERR_BAD_OPTION);\n    }\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ({\n  assertOptions,\n  validators\n});\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/helpers/validator.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/platform/browser/classes/Blob.js":
/*!*****************************************************************!*\
  !*** ./node_modules/axios/lib/platform/browser/classes/Blob.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (typeof Blob !== 'undefined' ? Blob : null);\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/platform/browser/classes/Blob.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/platform/browser/classes/FormData.js":
/*!*********************************************************************!*\
  !*** ./node_modules/axios/lib/platform/browser/classes/FormData.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (typeof FormData !== 'undefined' ? FormData : null);\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/platform/browser/classes/FormData.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/platform/browser/classes/URLSearchParams.js":
/*!****************************************************************************!*\
  !*** ./node_modules/axios/lib/platform/browser/classes/URLSearchParams.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _helpers_AxiosURLSearchParams_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../../helpers/AxiosURLSearchParams.js */ \"./node_modules/axios/lib/helpers/AxiosURLSearchParams.js\");\n\n\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (typeof URLSearchParams !== 'undefined' ? URLSearchParams : _helpers_AxiosURLSearchParams_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"]);\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/platform/browser/classes/URLSearchParams.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/platform/browser/index.js":
/*!**********************************************************!*\
  !*** ./node_modules/axios/lib/platform/browser/index.js ***!
  \**********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _classes_URLSearchParams_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./classes/URLSearchParams.js */ \"./node_modules/axios/lib/platform/browser/classes/URLSearchParams.js\");\n/* harmony import */ var _classes_FormData_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./classes/FormData.js */ \"./node_modules/axios/lib/platform/browser/classes/FormData.js\");\n/* harmony import */ var _classes_Blob_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./classes/Blob.js */ \"./node_modules/axios/lib/platform/browser/classes/Blob.js\");\n\n\n\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ({\n  isBrowser: true,\n  classes: {\n    URLSearchParams: _classes_URLSearchParams_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"],\n    FormData: _classes_FormData_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"],\n    Blob: _classes_Blob_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"]\n  },\n  protocols: ['http', 'https', 'file', 'blob', 'url', 'data']\n});\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/platform/browser/index.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/platform/common/utils.js":
/*!*********************************************************!*\
  !*** ./node_modules/axios/lib/platform/common/utils.js ***!
  \*********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   hasBrowserEnv: () => (/* binding */ hasBrowserEnv),\n/* harmony export */   hasStandardBrowserEnv: () => (/* binding */ hasStandardBrowserEnv),\n/* harmony export */   hasStandardBrowserWebWorkerEnv: () => (/* binding */ hasStandardBrowserWebWorkerEnv),\n/* harmony export */   navigator: () => (/* binding */ _navigator),\n/* harmony export */   origin: () => (/* binding */ origin)\n/* harmony export */ });\nconst hasBrowserEnv = typeof window !== 'undefined' && typeof document !== 'undefined';\n\nconst _navigator = typeof navigator === 'object' && navigator || undefined;\n\n/**\n * Determine if we're running in a standard browser environment\n *\n * This allows axios to run in a web worker, and react-native.\n * Both environments support XMLHttpRequest, but not fully standard globals.\n *\n * web workers:\n *  typeof window -> undefined\n *  typeof document -> undefined\n *\n * react-native:\n *  navigator.product -> 'ReactNative'\n * nativescript\n *  navigator.product -> 'NativeScript' or 'NS'\n *\n * @returns {boolean}\n */\nconst hasStandardBrowserEnv = hasBrowserEnv &&\n  (!_navigator || ['ReactNative', 'NativeScript', 'NS'].indexOf(_navigator.product) < 0);\n\n/**\n * Determine if we're running in a standard browser webWorker environment\n *\n * Although the `isStandardBrowserEnv` method indicates that\n * `allows axios to run in a web worker`, the WebWorker will still be\n * filtered out due to its judgment standard\n * `typeof window !== 'undefined' && typeof document !== 'undefined'`.\n * This leads to a problem when axios post `FormData` in webWorker\n */\nconst hasStandardBrowserWebWorkerEnv = (() => {\n  return (\n    typeof WorkerGlobalScope !== 'undefined' &&\n    // eslint-disable-next-line no-undef\n    self instanceof WorkerGlobalScope &&\n    typeof self.importScripts === 'function'\n  );\n})();\n\nconst origin = hasBrowserEnv && window.location.href || 'http://localhost';\n\n\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/platform/common/utils.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/platform/index.js":
/*!**************************************************!*\
  !*** ./node_modules/axios/lib/platform/index.js ***!
  \**************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _node_index_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./node/index.js */ \"./node_modules/axios/lib/platform/browser/index.js\");\n/* harmony import */ var _common_utils_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./common/utils.js */ \"./node_modules/axios/lib/platform/common/utils.js\");\n\n\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ({\n  ..._common_utils_js__WEBPACK_IMPORTED_MODULE_1__,\n  ..._node_index_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"]\n});\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/platform/index.js?\n}");

/***/ }),

/***/ "./node_modules/axios/lib/utils.js":
/*!*****************************************!*\
  !*** ./node_modules/axios/lib/utils.js ***!
  \*****************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _helpers_bind_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./helpers/bind.js */ \"./node_modules/axios/lib/helpers/bind.js\");\n\n\n\n\n// utils is a library of generic helper functions non-specific to axios\n\nconst {toString} = Object.prototype;\nconst {getPrototypeOf} = Object;\nconst {iterator, toStringTag} = Symbol;\n\nconst kindOf = (cache => thing => {\n    const str = toString.call(thing);\n    return cache[str] || (cache[str] = str.slice(8, -1).toLowerCase());\n})(Object.create(null));\n\nconst kindOfTest = (type) => {\n  type = type.toLowerCase();\n  return (thing) => kindOf(thing) === type\n}\n\nconst typeOfTest = type => thing => typeof thing === type;\n\n/**\n * Determine if a value is an Array\n *\n * @param {Object} val The value to test\n *\n * @returns {boolean} True if value is an Array, otherwise false\n */\nconst {isArray} = Array;\n\n/**\n * Determine if a value is undefined\n *\n * @param {*} val The value to test\n *\n * @returns {boolean} True if the value is undefined, otherwise false\n */\nconst isUndefined = typeOfTest('undefined');\n\n/**\n * Determine if a value is a Buffer\n *\n * @param {*} val The value to test\n *\n * @returns {boolean} True if value is a Buffer, otherwise false\n */\nfunction isBuffer(val) {\n  return val !== null && !isUndefined(val) && val.constructor !== null && !isUndefined(val.constructor)\n    && isFunction(val.constructor.isBuffer) && val.constructor.isBuffer(val);\n}\n\n/**\n * Determine if a value is an ArrayBuffer\n *\n * @param {*} val The value to test\n *\n * @returns {boolean} True if value is an ArrayBuffer, otherwise false\n */\nconst isArrayBuffer = kindOfTest('ArrayBuffer');\n\n\n/**\n * Determine if a value is a view on an ArrayBuffer\n *\n * @param {*} val The value to test\n *\n * @returns {boolean} True if value is a view on an ArrayBuffer, otherwise false\n */\nfunction isArrayBufferView(val) {\n  let result;\n  if ((typeof ArrayBuffer !== 'undefined') && (ArrayBuffer.isView)) {\n    result = ArrayBuffer.isView(val);\n  } else {\n    result = (val) && (val.buffer) && (isArrayBuffer(val.buffer));\n  }\n  return result;\n}\n\n/**\n * Determine if a value is a String\n *\n * @param {*} val The value to test\n *\n * @returns {boolean} True if value is a String, otherwise false\n */\nconst isString = typeOfTest('string');\n\n/**\n * Determine if a value is a Function\n *\n * @param {*} val The value to test\n * @returns {boolean} True if value is a Function, otherwise false\n */\nconst isFunction = typeOfTest('function');\n\n/**\n * Determine if a value is a Number\n *\n * @param {*} val The value to test\n *\n * @returns {boolean} True if value is a Number, otherwise false\n */\nconst isNumber = typeOfTest('number');\n\n/**\n * Determine if a value is an Object\n *\n * @param {*} thing The value to test\n *\n * @returns {boolean} True if value is an Object, otherwise false\n */\nconst isObject = (thing) => thing !== null && typeof thing === 'object';\n\n/**\n * Determine if a value is a Boolean\n *\n * @param {*} thing The value to test\n * @returns {boolean} True if value is a Boolean, otherwise false\n */\nconst isBoolean = thing => thing === true || thing === false;\n\n/**\n * Determine if a value is a plain Object\n *\n * @param {*} val The value to test\n *\n * @returns {boolean} True if value is a plain Object, otherwise false\n */\nconst isPlainObject = (val) => {\n  if (kindOf(val) !== 'object') {\n    return false;\n  }\n\n  const prototype = getPrototypeOf(val);\n  return (prototype === null || prototype === Object.prototype || Object.getPrototypeOf(prototype) === null) && !(toStringTag in val) && !(iterator in val);\n}\n\n/**\n * Determine if a value is an empty object (safely handles Buffers)\n *\n * @param {*} val The value to test\n *\n * @returns {boolean} True if value is an empty object, otherwise false\n */\nconst isEmptyObject = (val) => {\n  // Early return for non-objects or Buffers to prevent RangeError\n  if (!isObject(val) || isBuffer(val)) {\n    return false;\n  }\n\n  try {\n    return Object.keys(val).length === 0 && Object.getPrototypeOf(val) === Object.prototype;\n  } catch (e) {\n    // Fallback for any other objects that might cause RangeError with Object.keys()\n    return false;\n  }\n}\n\n/**\n * Determine if a value is a Date\n *\n * @param {*} val The value to test\n *\n * @returns {boolean} True if value is a Date, otherwise false\n */\nconst isDate = kindOfTest('Date');\n\n/**\n * Determine if a value is a File\n *\n * @param {*} val The value to test\n *\n * @returns {boolean} True if value is a File, otherwise false\n */\nconst isFile = kindOfTest('File');\n\n/**\n * Determine if a value is a Blob\n *\n * @param {*} val The value to test\n *\n * @returns {boolean} True if value is a Blob, otherwise false\n */\nconst isBlob = kindOfTest('Blob');\n\n/**\n * Determine if a value is a FileList\n *\n * @param {*} val The value to test\n *\n * @returns {boolean} True if value is a File, otherwise false\n */\nconst isFileList = kindOfTest('FileList');\n\n/**\n * Determine if a value is a Stream\n *\n * @param {*} val The value to test\n *\n * @returns {boolean} True if value is a Stream, otherwise false\n */\nconst isStream = (val) => isObject(val) && isFunction(val.pipe);\n\n/**\n * Determine if a value is a FormData\n *\n * @param {*} thing The value to test\n *\n * @returns {boolean} True if value is an FormData, otherwise false\n */\nconst isFormData = (thing) => {\n  let kind;\n  return thing && (\n    (typeof FormData === 'function' && thing instanceof FormData) || (\n      isFunction(thing.append) && (\n        (kind = kindOf(thing)) === 'formdata' ||\n        // detect form-data instance\n        (kind === 'object' && isFunction(thing.toString) && thing.toString() === '[object FormData]')\n      )\n    )\n  )\n}\n\n/**\n * Determine if a value is a URLSearchParams object\n *\n * @param {*} val The value to test\n *\n * @returns {boolean} True if value is a URLSearchParams object, otherwise false\n */\nconst isURLSearchParams = kindOfTest('URLSearchParams');\n\nconst [isReadableStream, isRequest, isResponse, isHeaders] = ['ReadableStream', 'Request', 'Response', 'Headers'].map(kindOfTest);\n\n/**\n * Trim excess whitespace off the beginning and end of a string\n *\n * @param {String} str The String to trim\n *\n * @returns {String} The String freed of excess whitespace\n */\nconst trim = (str) => str.trim ?\n  str.trim() : str.replace(/^[\\s\\uFEFF\\xA0]+|[\\s\\uFEFF\\xA0]+$/g, '');\n\n/**\n * Iterate over an Array or an Object invoking a function for each item.\n *\n * If `obj` is an Array callback will be called passing\n * the value, index, and complete array for each item.\n *\n * If 'obj' is an Object callback will be called passing\n * the value, key, and complete object for each property.\n *\n * @param {Object|Array} obj The object to iterate\n * @param {Function} fn The callback to invoke for each item\n *\n * @param {Boolean} [allOwnKeys = false]\n * @returns {any}\n */\nfunction forEach(obj, fn, {allOwnKeys = false} = {}) {\n  // Don't bother if no value provided\n  if (obj === null || typeof obj === 'undefined') {\n    return;\n  }\n\n  let i;\n  let l;\n\n  // Force an array if not already something iterable\n  if (typeof obj !== 'object') {\n    /*eslint no-param-reassign:0*/\n    obj = [obj];\n  }\n\n  if (isArray(obj)) {\n    // Iterate over array values\n    for (i = 0, l = obj.length; i < l; i++) {\n      fn.call(null, obj[i], i, obj);\n    }\n  } else {\n    // Buffer check\n    if (isBuffer(obj)) {\n      return;\n    }\n\n    // Iterate over object keys\n    const keys = allOwnKeys ? Object.getOwnPropertyNames(obj) : Object.keys(obj);\n    const len = keys.length;\n    let key;\n\n    for (i = 0; i < len; i++) {\n      key = keys[i];\n      fn.call(null, obj[key], key, obj);\n    }\n  }\n}\n\nfunction findKey(obj, key) {\n  if (isBuffer(obj)){\n    return null;\n  }\n\n  key = key.toLowerCase();\n  const keys = Object.keys(obj);\n  let i = keys.length;\n  let _key;\n  while (i-- > 0) {\n    _key = keys[i];\n    if (key === _key.toLowerCase()) {\n      return _key;\n    }\n  }\n  return null;\n}\n\nconst _global = (() => {\n  /*eslint no-undef:0*/\n  if (typeof globalThis !== \"undefined\") return globalThis;\n  return typeof self !== \"undefined\" ? self : (typeof window !== 'undefined' ? window : global)\n})();\n\nconst isContextDefined = (context) => !isUndefined(context) && context !== _global;\n\n/**\n * Accepts varargs expecting each argument to be an object, then\n * immutably merges the properties of each object and returns result.\n *\n * When multiple objects contain the same key the later object in\n * the arguments list will take precedence.\n *\n * Example:\n *\n * ```js\n * var result = merge({foo: 123}, {foo: 456});\n * console.log(result.foo); // outputs 456\n * ```\n *\n * @param {Object} obj1 Object to merge\n *\n * @returns {Object} Result of all merge properties\n */\nfunction merge(/* obj1, obj2, obj3, ... */) {\n  const {caseless, skipUndefined} = isContextDefined(this) && this || {};\n  const result = {};\n  const assignValue = (val, key) => {\n    const targetKey = caseless && findKey(result, key) || key;\n    if (isPlainObject(result[targetKey]) && isPlainObject(val)) {\n      result[targetKey] = merge(result[targetKey], val);\n    } else if (isPlainObject(val)) {\n      result[targetKey] = merge({}, val);\n    } else if (isArray(val)) {\n      result[targetKey] = val.slice();\n    } else if (!skipUndefined || !isUndefined(val)) {\n      result[targetKey] = val;\n    }\n  }\n\n  for (let i = 0, l = arguments.length; i < l; i++) {\n    arguments[i] && forEach(arguments[i], assignValue);\n  }\n  return result;\n}\n\n/**\n * Extends object a by mutably adding to it the properties of object b.\n *\n * @param {Object} a The object to be extended\n * @param {Object} b The object to copy properties from\n * @param {Object} thisArg The object to bind function to\n *\n * @param {Boolean} [allOwnKeys]\n * @returns {Object} The resulting value of object a\n */\nconst extend = (a, b, thisArg, {allOwnKeys}= {}) => {\n  forEach(b, (val, key) => {\n    if (thisArg && isFunction(val)) {\n      a[key] = (0,_helpers_bind_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(val, thisArg);\n    } else {\n      a[key] = val;\n    }\n  }, {allOwnKeys});\n  return a;\n}\n\n/**\n * Remove byte order marker. This catches EF BB BF (the UTF-8 BOM)\n *\n * @param {string} content with BOM\n *\n * @returns {string} content value without BOM\n */\nconst stripBOM = (content) => {\n  if (content.charCodeAt(0) === 0xFEFF) {\n    content = content.slice(1);\n  }\n  return content;\n}\n\n/**\n * Inherit the prototype methods from one constructor into another\n * @param {function} constructor\n * @param {function} superConstructor\n * @param {object} [props]\n * @param {object} [descriptors]\n *\n * @returns {void}\n */\nconst inherits = (constructor, superConstructor, props, descriptors) => {\n  constructor.prototype = Object.create(superConstructor.prototype, descriptors);\n  constructor.prototype.constructor = constructor;\n  Object.defineProperty(constructor, 'super', {\n    value: superConstructor.prototype\n  });\n  props && Object.assign(constructor.prototype, props);\n}\n\n/**\n * Resolve object with deep prototype chain to a flat object\n * @param {Object} sourceObj source object\n * @param {Object} [destObj]\n * @param {Function|Boolean} [filter]\n * @param {Function} [propFilter]\n *\n * @returns {Object}\n */\nconst toFlatObject = (sourceObj, destObj, filter, propFilter) => {\n  let props;\n  let i;\n  let prop;\n  const merged = {};\n\n  destObj = destObj || {};\n  // eslint-disable-next-line no-eq-null,eqeqeq\n  if (sourceObj == null) return destObj;\n\n  do {\n    props = Object.getOwnPropertyNames(sourceObj);\n    i = props.length;\n    while (i-- > 0) {\n      prop = props[i];\n      if ((!propFilter || propFilter(prop, sourceObj, destObj)) && !merged[prop]) {\n        destObj[prop] = sourceObj[prop];\n        merged[prop] = true;\n      }\n    }\n    sourceObj = filter !== false && getPrototypeOf(sourceObj);\n  } while (sourceObj && (!filter || filter(sourceObj, destObj)) && sourceObj !== Object.prototype);\n\n  return destObj;\n}\n\n/**\n * Determines whether a string ends with the characters of a specified string\n *\n * @param {String} str\n * @param {String} searchString\n * @param {Number} [position= 0]\n *\n * @returns {boolean}\n */\nconst endsWith = (str, searchString, position) => {\n  str = String(str);\n  if (position === undefined || position > str.length) {\n    position = str.length;\n  }\n  position -= searchString.length;\n  const lastIndex = str.indexOf(searchString, position);\n  return lastIndex !== -1 && lastIndex === position;\n}\n\n\n/**\n * Returns new array from array like object or null if failed\n *\n * @param {*} [thing]\n *\n * @returns {?Array}\n */\nconst toArray = (thing) => {\n  if (!thing) return null;\n  if (isArray(thing)) return thing;\n  let i = thing.length;\n  if (!isNumber(i)) return null;\n  const arr = new Array(i);\n  while (i-- > 0) {\n    arr[i] = thing[i];\n  }\n  return arr;\n}\n\n/**\n * Checking if the Uint8Array exists and if it does, it returns a function that checks if the\n * thing passed in is an instance of Uint8Array\n *\n * @param {TypedArray}\n *\n * @returns {Array}\n */\n// eslint-disable-next-line func-names\nconst isTypedArray = (TypedArray => {\n  // eslint-disable-next-line func-names\n  return thing => {\n    return TypedArray && thing instanceof TypedArray;\n  };\n})(typeof Uint8Array !== 'undefined' && getPrototypeOf(Uint8Array));\n\n/**\n * For each entry in the object, call the function with the key and value.\n *\n * @param {Object<any, any>} obj - The object to iterate over.\n * @param {Function} fn - The function to call for each entry.\n *\n * @returns {void}\n */\nconst forEachEntry = (obj, fn) => {\n  const generator = obj && obj[iterator];\n\n  const _iterator = generator.call(obj);\n\n  let result;\n\n  while ((result = _iterator.next()) && !result.done) {\n    const pair = result.value;\n    fn.call(obj, pair[0], pair[1]);\n  }\n}\n\n/**\n * It takes a regular expression and a string, and returns an array of all the matches\n *\n * @param {string} regExp - The regular expression to match against.\n * @param {string} str - The string to search.\n *\n * @returns {Array<boolean>}\n */\nconst matchAll = (regExp, str) => {\n  let matches;\n  const arr = [];\n\n  while ((matches = regExp.exec(str)) !== null) {\n    arr.push(matches);\n  }\n\n  return arr;\n}\n\n/* Checking if the kindOfTest function returns true when passed an HTMLFormElement. */\nconst isHTMLForm = kindOfTest('HTMLFormElement');\n\nconst toCamelCase = str => {\n  return str.toLowerCase().replace(/[-_\\s]([a-z\\d])(\\w*)/g,\n    function replacer(m, p1, p2) {\n      return p1.toUpperCase() + p2;\n    }\n  );\n};\n\n/* Creating a function that will check if an object has a property. */\nconst hasOwnProperty = (({hasOwnProperty}) => (obj, prop) => hasOwnProperty.call(obj, prop))(Object.prototype);\n\n/**\n * Determine if a value is a RegExp object\n *\n * @param {*} val The value to test\n *\n * @returns {boolean} True if value is a RegExp object, otherwise false\n */\nconst isRegExp = kindOfTest('RegExp');\n\nconst reduceDescriptors = (obj, reducer) => {\n  const descriptors = Object.getOwnPropertyDescriptors(obj);\n  const reducedDescriptors = {};\n\n  forEach(descriptors, (descriptor, name) => {\n    let ret;\n    if ((ret = reducer(descriptor, name, obj)) !== false) {\n      reducedDescriptors[name] = ret || descriptor;\n    }\n  });\n\n  Object.defineProperties(obj, reducedDescriptors);\n}\n\n/**\n * Makes all methods read-only\n * @param {Object} obj\n */\n\nconst freezeMethods = (obj) => {\n  reduceDescriptors(obj, (descriptor, name) => {\n    // skip restricted props in strict mode\n    if (isFunction(obj) && ['arguments', 'caller', 'callee'].indexOf(name) !== -1) {\n      return false;\n    }\n\n    const value = obj[name];\n\n    if (!isFunction(value)) return;\n\n    descriptor.enumerable = false;\n\n    if ('writable' in descriptor) {\n      descriptor.writable = false;\n      return;\n    }\n\n    if (!descriptor.set) {\n      descriptor.set = () => {\n        throw Error('Can not rewrite read-only method \\'' + name + '\\'');\n      };\n    }\n  });\n}\n\nconst toObjectSet = (arrayOrString, delimiter) => {\n  const obj = {};\n\n  const define = (arr) => {\n    arr.forEach(value => {\n      obj[value] = true;\n    });\n  }\n\n  isArray(arrayOrString) ? define(arrayOrString) : define(String(arrayOrString).split(delimiter));\n\n  return obj;\n}\n\nconst noop = () => {}\n\nconst toFiniteNumber = (value, defaultValue) => {\n  return value != null && Number.isFinite(value = +value) ? value : defaultValue;\n}\n\n\n\n/**\n * If the thing is a FormData object, return true, otherwise return false.\n *\n * @param {unknown} thing - The thing to check.\n *\n * @returns {boolean}\n */\nfunction isSpecCompliantForm(thing) {\n  return !!(thing && isFunction(thing.append) && thing[toStringTag] === 'FormData' && thing[iterator]);\n}\n\nconst toJSONObject = (obj) => {\n  const stack = new Array(10);\n\n  const visit = (source, i) => {\n\n    if (isObject(source)) {\n      if (stack.indexOf(source) >= 0) {\n        return;\n      }\n\n      //Buffer check\n      if (isBuffer(source)) {\n        return source;\n      }\n\n      if(!('toJSON' in source)) {\n        stack[i] = source;\n        const target = isArray(source) ? [] : {};\n\n        forEach(source, (value, key) => {\n          const reducedValue = visit(value, i + 1);\n          !isUndefined(reducedValue) && (target[key] = reducedValue);\n        });\n\n        stack[i] = undefined;\n\n        return target;\n      }\n    }\n\n    return source;\n  }\n\n  return visit(obj, 0);\n}\n\nconst isAsyncFn = kindOfTest('AsyncFunction');\n\nconst isThenable = (thing) =>\n  thing && (isObject(thing) || isFunction(thing)) && isFunction(thing.then) && isFunction(thing.catch);\n\n// original code\n// https://github.com/DigitalBrainJS/AxiosPromise/blob/16deab13710ec09779922131f3fa5954320f83ab/lib/utils.js#L11-L34\n\nconst _setImmediate = ((setImmediateSupported, postMessageSupported) => {\n  if (setImmediateSupported) {\n    return setImmediate;\n  }\n\n  return postMessageSupported ? ((token, callbacks) => {\n    _global.addEventListener(\"message\", ({source, data}) => {\n      if (source === _global && data === token) {\n        callbacks.length && callbacks.shift()();\n      }\n    }, false);\n\n    return (cb) => {\n      callbacks.push(cb);\n      _global.postMessage(token, \"*\");\n    }\n  })(`axios@${Math.random()}`, []) : (cb) => setTimeout(cb);\n})(\n  typeof setImmediate === 'function',\n  isFunction(_global.postMessage)\n);\n\nconst asap = typeof queueMicrotask !== 'undefined' ?\n  queueMicrotask.bind(_global) : ( typeof process !== 'undefined' && process.nextTick || _setImmediate);\n\n// *********************\n\n\nconst isIterable = (thing) => thing != null && isFunction(thing[iterator]);\n\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ({\n  isArray,\n  isArrayBuffer,\n  isBuffer,\n  isFormData,\n  isArrayBufferView,\n  isString,\n  isNumber,\n  isBoolean,\n  isObject,\n  isPlainObject,\n  isEmptyObject,\n  isReadableStream,\n  isRequest,\n  isResponse,\n  isHeaders,\n  isUndefined,\n  isDate,\n  isFile,\n  isBlob,\n  isRegExp,\n  isFunction,\n  isStream,\n  isURLSearchParams,\n  isTypedArray,\n  isFileList,\n  forEach,\n  merge,\n  extend,\n  trim,\n  stripBOM,\n  inherits,\n  toFlatObject,\n  kindOf,\n  kindOfTest,\n  endsWith,\n  toArray,\n  forEachEntry,\n  matchAll,\n  isHTMLForm,\n  hasOwnProperty,\n  hasOwnProp: hasOwnProperty, // an alias to avoid ESLint no-prototype-builtins detection\n  reduceDescriptors,\n  freezeMethods,\n  toObjectSet,\n  toCamelCase,\n  noop,\n  toFiniteNumber,\n  findKey,\n  global: _global,\n  isContextDefined,\n  isSpecCompliantForm,\n  toJSONObject,\n  isAsyncFn,\n  isThenable,\n  setImmediate: _setImmediate,\n  asap,\n  isIterable\n});\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/axios/lib/utils.js?\n}");

/***/ }),

/***/ "./node_modules/bcrypt-ts/dist/browser.mjs":
/*!*************************************************!*\
  !*** ./node_modules/bcrypt-ts/dist/browser.mjs ***!
  \*************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   compare: () => (/* binding */ v),\n/* harmony export */   compareSync: () => (/* binding */ x),\n/* harmony export */   genSalt: () => (/* binding */ $),\n/* harmony export */   genSaltSync: () => (/* binding */ m),\n/* harmony export */   getRounds: () => (/* binding */ M),\n/* harmony export */   getSalt: () => (/* binding */ X),\n/* harmony export */   hash: () => (/* binding */ P),\n/* harmony export */   hashSync: () => (/* binding */ U)\n/* harmony export */ });\nconst Y=16,W=10,H=16,V=100,A=\"./ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789\".split(\"\"),I=Array.from({length:64},(n,r)=>r),f=n=>Array(n).fill(-1),E=[...f(46),0,1,...I.slice(54,64),...f(7),...I.slice(2,28),...f(6),...I.slice(28,54),...f(5)],L=[608135816,2242054355,320440878,57701188,2752067618,698298832,137296536,3964562569,1160258022,953160567,3193202383,887688300,3232508343,3380367581,1065670069,3041331479,2450970073,2306472731],b=[3509652390,2564797868,805139163,3491422135,3101798381,1780907670,3128725573,4046225305,614570311,3012652279,134345442,2240740374,1667834072,1901547113,2757295779,4103290238,227898511,1921955416,1904987480,2182433518,2069144605,3260701109,2620446009,720527379,3318853667,677414384,3393288472,3101374703,2390351024,1614419982,1822297739,2954791486,3608508353,3174124327,2024746970,1432378464,3864339955,2857741204,1464375394,1676153920,1439316330,715854006,3033291828,289532110,2706671279,2087905683,3018724369,1668267050,732546397,1947742710,3462151702,2609353502,2950085171,1814351708,2050118529,680887927,999245976,1800124847,3300911131,1713906067,1641548236,4213287313,1216130144,1575780402,4018429277,3917837745,3693486850,3949271944,596196993,3549867205,258830323,2213823033,772490370,2760122372,1774776394,2652871518,566650946,4142492826,1728879713,2882767088,1783734482,3629395816,2517608232,2874225571,1861159788,326777828,3124490320,2130389656,2716951837,967770486,1724537150,2185432712,2364442137,1164943284,2105845187,998989502,3765401048,2244026483,1075463327,1455516326,1322494562,910128902,469688178,1117454909,936433444,3490320968,3675253459,1240580251,122909385,2157517691,634681816,4142456567,3825094682,3061402683,2540495037,79693498,3249098678,1084186820,1583128258,426386531,1761308591,1047286709,322548459,995290223,1845252383,2603652396,3431023940,2942221577,3202600964,3727903485,1712269319,422464435,3234572375,1170764815,3523960633,3117677531,1434042557,442511882,3600875718,1076654713,1738483198,4213154764,2393238008,3677496056,1014306527,4251020053,793779912,2902807211,842905082,4246964064,1395751752,1040244610,2656851899,3396308128,445077038,3742853595,3577915638,679411651,2892444358,2354009459,1767581616,3150600392,3791627101,3102740896,284835224,4246832056,1258075500,768725851,2589189241,3069724005,3532540348,1274779536,3789419226,2764799539,1660621633,3471099624,4011903706,913787905,3497959166,737222580,2514213453,2928710040,3937242737,1804850592,3499020752,2949064160,2386320175,2390070455,2415321851,4061277028,2290661394,2416832540,1336762016,1754252060,3520065937,3014181293,791618072,3188594551,3933548030,2332172193,3852520463,3043980520,413987798,3465142937,3030929376,4245938359,2093235073,3534596313,375366246,2157278981,2479649556,555357303,3870105701,2008414854,3344188149,4221384143,3956125452,2067696032,3594591187,2921233993,2428461,544322398,577241275,1471733935,610547355,4027169054,1432588573,1507829418,2025931657,3646575487,545086370,48609733,2200306550,1653985193,298326376,1316178497,3007786442,2064951626,458293330,2589141269,3591329599,3164325604,727753846,2179363840,146436021,1461446943,4069977195,705550613,3059967265,3887724982,4281599278,3313849956,1404054877,2845806497,146425753,1854211946,1266315497,3048417604,3681880366,3289982499,290971e4,1235738493,2632868024,2414719590,3970600049,1771706367,1449415276,3266420449,422970021,1963543593,2690192192,3826793022,1062508698,1531092325,1804592342,2583117782,2714934279,4024971509,1294809318,4028980673,1289560198,2221992742,1669523910,35572830,157838143,1052438473,1016535060,1802137761,1753167236,1386275462,3080475397,2857371447,1040679964,2145300060,2390574316,1461121720,2956646967,4031777805,4028374788,33600511,2920084762,1018524850,629373528,3691585981,3515945977,2091462646,2486323059,586499841,988145025,935516892,3367335476,2599673255,2839830854,265290510,3972581182,2759138881,3795373465,1005194799,847297441,406762289,1314163512,1332590856,1866599683,4127851711,750260880,613907577,1450815602,3165620655,3734664991,3650291728,3012275730,3704569646,1427272223,778793252,1343938022,2676280711,2052605720,1946737175,3164576444,3914038668,3967478842,3682934266,1661551462,3294938066,4011595847,840292616,3712170807,616741398,312560963,711312465,1351876610,322626781,1910503582,271666773,2175563734,1594956187,70604529,3617834859,1007753275,1495573769,4069517037,2549218298,2663038764,504708206,2263041392,3941167025,2249088522,1514023603,1998579484,1312622330,694541497,2582060303,2151582166,1382467621,776784248,2618340202,3323268794,2497899128,2784771155,503983604,4076293799,907881277,423175695,432175456,1378068232,4145222326,3954048622,3938656102,3820766613,2793130115,2977904593,26017576,3274890735,3194772133,1700274565,1756076034,4006520079,3677328699,720338349,1533947780,354530856,688349552,3973924725,1637815568,332179504,3949051286,53804574,2852348879,3044236432,1282449977,3583942155,3416972820,4006381244,1617046695,2628476075,3002303598,1686838959,431878346,2686675385,1700445008,1080580658,1009431731,832498133,3223435511,2605976345,2271191193,2516031870,1648197032,4164389018,2548247927,300782431,375919233,238389289,3353747414,2531188641,2019080857,1475708069,455242339,2609103871,448939670,3451063019,1395535956,2413381860,1841049896,1491858159,885456874,4264095073,4001119347,1565136089,3898914787,1108368660,540939232,1173283510,2745871338,3681308437,4207628240,3343053890,4016749493,1699691293,1103962373,3625875870,2256883143,3830138730,1031889488,3479347698,1535977030,4236805024,3251091107,2132092099,1774941330,1199868427,1452454533,157007616,2904115357,342012276,595725824,1480756522,206960106,497939518,591360097,863170706,2375253569,3596610801,1814182875,2094937945,3421402208,1082520231,3463918190,2785509508,435703966,3908032597,1641649973,2842273706,3305899714,1510255612,2148256476,2655287854,3276092548,4258621189,236887753,3681803219,274041037,1734335097,3815195456,3317970021,1899903192,1026095262,4050517792,356393447,2410691914,3873677099,3682840055,3913112168,2491498743,4132185628,2489919796,1091903735,1979897079,3170134830,3567386728,3557303409,857797738,1136121015,1342202287,507115054,2535736646,337727348,3213592640,1301675037,2528481711,1895095763,1721773893,3216771564,62756741,2142006736,835421444,2531993523,1442658625,3659876326,2882144922,676362277,1392781812,170690266,3921047035,1759253602,3611846912,1745797284,664899054,1329594018,3901205900,3045908486,2062866102,2865634940,3543621612,3464012697,1080764994,553557557,3656615353,3996768171,991055499,499776247,1265440854,648242737,3940784050,980351604,3713745714,1749149687,3396870395,4211799374,3640570775,1161844396,3125318951,1431517754,545492359,4268468663,3499529547,1437099964,2702547544,3433638243,2581715763,2787789398,1060185593,1593081372,2418618748,4260947970,69676912,2159744348,86519011,2512459080,3838209314,1220612927,3339683548,133810670,1090789135,1078426020,1569222167,845107691,3583754449,4072456591,1091646820,628848692,1613405280,3757631651,526609435,236106946,48312990,2942717905,3402727701,1797494240,859738849,992217954,4005476642,2243076622,3870952857,3732016268,765654824,3490871365,2511836413,1685915746,3888969200,1414112111,2273134842,3281911079,4080962846,172450625,2569994100,980381355,4109958455,2819808352,2716589560,2568741196,3681446669,3329971472,1835478071,660984891,3704678404,4045999559,3422617507,3040415634,1762651403,1719377915,3470491036,2693910283,3642056355,3138596744,1364962596,2073328063,1983633131,926494387,3423689081,2150032023,4096667949,1749200295,3328846651,309677260,2016342300,1779581495,3079819751,111262694,1274766160,443224088,298511866,1025883608,3806446537,1145181785,168956806,3641502830,3584813610,1689216846,3666258015,3200248200,1692713982,2646376535,4042768518,1618508792,1610833997,3523052358,4130873264,2001055236,3610705100,2202168115,4028541809,2961195399,1006657119,2006996926,3186142756,1430667929,3210227297,1314452623,4074634658,4101304120,2273951170,1399257539,3367210612,3027628629,1190975929,2062231137,2333990788,2221543033,2438960610,1181637006,548689776,2362791313,3372408396,3104550113,3145860560,296247880,1970579870,3078560182,3769228297,1714227617,3291629107,3898220290,166772364,1251581989,493813264,448347421,195405023,2709975567,677966185,3703036547,1463355134,2715995803,1338867538,1343315457,2802222074,2684532164,233230375,2599980071,2000651841,3277868038,1638401717,4028070440,3237316320,6314154,819756386,300326615,590932579,1405279636,3267499572,3150704214,2428286686,3959192993,3461946742,1862657033,1266418056,963775037,2089974820,2263052895,1917689273,448879540,3550394620,3981727096,150775221,3627908307,1303187396,508620638,2975983352,2726630617,1817252668,1876281319,1457606340,908771278,3720792119,3617206836,2455994898,1729034894,1080033504,976866871,3556439503,2881648439,1522871579,1555064734,1336096578,3548522304,2579274686,3574697629,3205460757,3593280638,3338716283,3079412587,564236357,2993598910,1781952180,1464380207,3163844217,3332601554,1699332808,1393555694,1183702653,3581086237,1288719814,691649499,2847557200,2895455976,3193889540,2717570544,1781354906,1676643554,2592534050,3230253752,1126444790,2770207658,2633158820,2210423226,2615765581,2414155088,3127139286,673620729,2805611233,1269405062,4015350505,3341807571,4149409754,1057255273,2012875353,2162469141,2276492801,2601117357,993977747,3918593370,2654263191,753973209,36408145,2530585658,25011837,3520020182,2088578344,530523599,2918365339,1524020338,1518925132,3760827505,3759777254,1202760957,3985898139,3906192525,674977740,4174734889,2031300136,2019492241,3983892565,4153806404,3822280332,352677332,2297720250,60907813,90501309,3286998549,1016092578,2535922412,2839152426,457141659,509813237,4120667899,652014361,1966332200,2975202805,55981186,2327461051,676427537,3255491064,2882294119,3433927263,1307055953,942726286,933058658,2468411793,3933900994,4215176142,1361170020,2001714738,2830558078,3274259782,1222529897,1679025792,2729314320,3714953764,1770335741,151462246,3013232138,1682292957,1483529935,471910574,1539241949,458788160,3436315007,1807016891,3718408830,978976581,1043663428,3165965781,1927990952,4200891579,2372276910,3208408903,3533431907,1412390302,2931980059,4132332400,1947078029,3881505623,4168226417,2941484381,1077988104,1320477388,886195818,18198404,3786409e3,2509781533,112762804,3463356488,1866414978,891333506,18488651,661792760,1628790961,3885187036,3141171499,876946877,2693282273,1372485963,791857591,2686433993,3759982718,3167212022,3472953795,2716379847,445679433,3561995674,3504004811,3574258232,54117162,3331405415,2381918588,3769707343,4154350007,1140177722,4074052095,668550556,3214352940,367459370,261225585,2610173221,4209349473,3468074219,3265815641,314222801,3066103646,3808782860,282218597,3406013506,3773591054,379116347,1285071038,846784868,2669647154,3771962079,3550491691,2305946142,453669953,1268987020,3317592352,3279303384,3744833421,2610507566,3859509063,266596637,3847019092,517658769,3462560207,3443424879,370717030,4247526661,2224018117,4143653529,4112773975,2788324899,2477274417,1456262402,2901442914,1517677493,1846949527,2295493580,3734397586,2176403920,1280348187,1908823572,3871786941,846861322,1172426758,3287448474,3383383037,1655181056,3139813346,901632758,1897031941,2986607138,3066810236,3447102507,1393639104,373351379,950779232,625454576,3124240540,4148612726,2007998917,544563296,2244738638,2330496472,2058025392,1291430526,424198748,50039436,29584100,3605783033,2429876329,2791104160,1057563949,3255363231,3075367218,3463963227,1469046755,985887462],C=[1332899944,1700884034,1701343084,1684370003,1668446532,1869963892],S=(n,r)=>{if(r<=0||r>n.length)throw Error(`Illegal len: ${r}`);let o=0,t,e;const l=[];for(;o<r;){if(t=n[o++]&255,l.push(A[t>>2&63]),t=(t&3)<<4,o>=r){l.push(A[t&63]);break}if(e=n[o++]&255,t|=e>>4&15,l.push(A[t&63]),t=(e&15)<<2,o>=r){l.push(A[t&63]);break}e=n[o++]&255,t|=e>>6&3,l.push(A[t&63]),l.push(A[e&63])}return l.join(\"\")},O=(n,r)=>{if(r<=0)throw Error(`Illegal len: ${r}`);const o=n.length;let t=0,e=0,l,s,h,u,i,p;const g=[];for(;t<o-1&&e<r&&(p=n.charCodeAt(t++),l=p<E.length?E[p]:-1,p=n.charCodeAt(t++),s=p<E.length?E[p]:-1,!(l==-1||s==-1||(i=l<<2>>>0,i|=(s&48)>>4,g.push(String.fromCharCode(i)),++e>=r||t>=o)||(p=n.charCodeAt(t++),h=p<E.length?E[p]:-1,h==-1)||(i=(s&15)<<4>>>0,i|=(h&60)>>2,g.push(String.fromCharCode(i)),++e>=r||t>=o)));)p=n.charCodeAt(t++),u=p<E.length?E[p]:-1,i=(h&3)<<6>>>0,i|=u,g.push(String.fromCharCode(i)),++e;return g.map(c=>c.charCodeAt(0))},D=(n,r)=>{let o=null;for(typeof n==\"number\"&&(o=n,n=()=>null);o!==null||(o=n())!==null;)o<128?r(o&127):o<2048?(r(o>>6&31|192),r(o&63|128)):o<65536?(r(o>>12&15|224),r(o>>6&63|128),r(o&63|128)):(r(o>>18&7|240),r(o>>12&63|128),r(o>>6&63|128),r(o&63|128)),o=null},B=(n,r)=>{let o,t=null;for(;(o=t!==null?t:n())!==null;){if(o>=55296&&o<=57343&&(t=n())!==null&&t>=56320&&t<=57343){r((o-55296)*1024+t-56320+65536),t=null;continue}r(o)}t!==null&&r(t)},j=(n,r)=>{B(n,function(o){D(o,r)})},w=typeof process==\"object\"&&process.env.NEXT_RUNTIME===\"edge\"?setTimeout:typeof setImmediate==\"function\"?setImmediate:typeof process==\"object\"&&typeof process.nextTick==\"function\"?process.nextTick:setTimeout,k=n=>{const r=[];let o=0;return j(()=>o>=n.length?null:n.charCodeAt(o++),t=>{r.push(t)}),r},_=(n,r,o,t)=>{let e,l=n[r],s=n[r+1];return l^=o[0],e=t[l>>>24],e+=t[256|l>>16&255],e^=t[512|l>>8&255],e+=t[768|l&255],s^=e^o[1],e=t[s>>>24],e+=t[256|s>>16&255],e^=t[512|s>>8&255],e+=t[768|s&255],l^=e^o[2],e=t[l>>>24],e+=t[256|l>>16&255],e^=t[512|l>>8&255],e+=t[768|l&255],s^=e^o[3],e=t[s>>>24],e+=t[256|s>>16&255],e^=t[512|s>>8&255],e+=t[768|s&255],l^=e^o[4],e=t[l>>>24],e+=t[256|l>>16&255],e^=t[512|l>>8&255],e+=t[768|l&255],s^=e^o[5],e=t[s>>>24],e+=t[256|s>>16&255],e^=t[512|s>>8&255],e+=t[768|s&255],l^=e^o[6],e=t[l>>>24],e+=t[256|l>>16&255],e^=t[512|l>>8&255],e+=t[768|l&255],s^=e^o[7],e=t[s>>>24],e+=t[256|s>>16&255],e^=t[512|s>>8&255],e+=t[768|s&255],l^=e^o[8],e=t[l>>>24],e+=t[256|l>>16&255],e^=t[512|l>>8&255],e+=t[768|l&255],s^=e^o[9],e=t[s>>>24],e+=t[256|s>>16&255],e^=t[512|s>>8&255],e+=t[768|s&255],l^=e^o[10],e=t[l>>>24],e+=t[256|l>>16&255],e^=t[512|l>>8&255],e+=t[768|l&255],s^=e^o[11],e=t[s>>>24],e+=t[256|s>>16&255],e^=t[512|s>>8&255],e+=t[768|s&255],l^=e^o[12],e=t[l>>>24],e+=t[256|l>>16&255],e^=t[512|l>>8&255],e+=t[768|l&255],s^=e^o[13],e=t[s>>>24],e+=t[256|s>>16&255],e^=t[512|s>>8&255],e+=t[768|s&255],l^=e^o[14],e=t[l>>>24],e+=t[256|l>>16&255],e^=t[512|l>>8&255],e+=t[768|l&255],s^=e^o[15],e=t[s>>>24],e+=t[256|s>>16&255],e^=t[512|s>>8&255],e+=t[768|s&255],l^=e^o[16],n[r]=s^o[17],n[r+1]=l,n},T=(n,r)=>{let o=0;for(let t=0;t<4;++t)o=o<<8|n[r]&255,r=(r+1)%n.length;return{key:o,offp:r}},N=(n,r,o)=>{const t=r.length,e=o.length;let l=0,s=[0,0],h;for(let u=0;u<t;u++)h=T(n,l),l=h.offp,r[u]=r[u]^h.key;for(let u=0;u<t;u+=2)s=_(s,0,r,o),r[u]=s[0],r[u+1]=s[1];for(let u=0;u<e;u+=2)s=_(s,0,r,o),o[u]=s[0],o[u+1]=s[1]},F=(n,r,o,t)=>{const e=o.length,l=t.length;let s=0,h=[0,0],u;for(let i=0;i<e;i++)u=T(r,s),s=u.offp,o[i]=o[i]^u.key;s=0;for(let i=0;i<e;i+=2)u=T(n,s),s=u.offp,h[0]^=u.key,u=T(n,s),s=u.offp,h[1]^=u.key,h=_(h,0,o,t),o[i]=h[0],o[i+1]=h[1];for(let i=0;i<l;i+=2)u=T(n,s),s=u.offp,h[0]^=u.key,u=T(n,s),s=u.offp,h[1]^=u.key,h=_(h,0,o,t),t[i]=h[0],t[i+1]=h[1]},R=(n,r,o,t,e)=>{const l=C.slice(),s=l.length;if(o<4||o>31){const c=new Error(`Illegal number of rounds (4-31): ${o}`);if(t===!1)return Promise.reject(c);throw c}if(r.length!==16){const c=new Error(`Illegal salt length: ${r.length} != 16`);if(t===!1)return Promise.reject(c);throw c}o=1<<o>>>0;let h,u,i=0,p;Int32Array?(h=new Int32Array(L),u=new Int32Array(b)):(h=L.slice(),u=b.slice()),F(r,n,h,u);const g=()=>{if(e&&e(i/o),i<o){const c=Date.now();for(;i<o&&(i=i+1,N(n,h,u),N(r,h,u),!(Date.now()-c>100)););}else{for(i=0;i<64;i++)for(p=0;p<s>>1;p++)_(l,p<<1,h,u);const c=[];for(i=0;i<s;i++)c.push((l[i]>>24&255)>>>0),c.push((l[i]>>16&255)>>>0),c.push((l[i]>>8&255)>>>0),c.push((l[i]&255)>>>0);return t===!1?Promise.resolve(c):c}if(t===!1)return new Promise(c=>w(()=>{g().then(c)}))};if(t===!1)return g();{let c;for(;;)if(typeof(c=g())<\"u\")return c||[]}},G=n=>{try{let r;typeof window<\"u\"?r=window.crypto??window.msCrypto:r=globalThis.crypto;const o=new Uint32Array(n);return r==null||r.getRandomValues(o),Array.from(o)}catch{throw Error(\"WebCryptoAPI is not available\")}},m=(n=10)=>{if(typeof n!=\"number\")throw Error(\"Illegal arguments: \"+typeof n);n<4?n=4:n>31&&(n=31);const r=[];return r.push(\"$2a$\"),n<10&&r.push(\"0\"),r.push(n.toString()),r.push(\"$\"),r.push(S(G(16),16)),r.join(\"\")},$=(n=10)=>{if(typeof n!=\"number\")throw Error(\"illegal arguments: \"+typeof n);return new Promise((r,o)=>w(()=>{try{r(m(n))}catch(t){o(t)}}))};function d(n,r,o,t){if(typeof n!=\"string\"||typeof r!=\"string\"){const a=new Error(\"Invalid string / salt: Not a string\");if(o===!1)return Promise.reject(a);throw a}let e,l;if(r.charAt(0)!==\"$\"||r.charAt(1)!==\"2\"){const a=new Error(\"Invalid salt version: \"+r.substring(0,2));if(o===!1)return Promise.reject(a);throw a}if(r.charAt(2)===\"$\")e=\"\\0\",l=3;else{if(e=r.charAt(2),e!==\"a\"&&e!==\"b\"&&e!==\"y\"||r.charAt(3)!==\"$\"){const a=Error(\"Invalid salt revision: \"+r.substring(2,4));if(o===!1)return Promise.reject(a);throw a}l=4}if(r.charAt(l+2)>\"$\"){const a=new Error(\"Missing salt rounds\");if(o===!1)return Promise.reject(a);throw a}const s=parseInt(r.substring(l,l+1),10)*10,h=parseInt(r.substring(l+1,l+2),10),u=s+h,i=r.substring(l+3,l+25);n+=e>=\"a\"?\"\\0\":\"\";const p=k(n),g=O(i,16),c=a=>{const y=[];return y.push(\"$2\"),e>=\"a\"&&y.push(e),y.push(\"$\"),u<10&&y.push(\"0\"),y.push(u.toString()),y.push(\"$\"),y.push(S(g,g.length)),y.push(S(a,C.length*4-1)),y.join(\"\")};return o===!1?R(p,g,u,!1,t).then(a=>c(a)):c(R(p,g,u,!0,t))}const U=(n,r=10)=>{if(typeof r==\"number\"&&(r=m(r)),typeof n!=\"string\"||typeof r!=\"string\")throw Error(\"Illegal arguments: \"+typeof n+\", \"+typeof r);return d(n,r,!0)},P=function(n,r,o){return typeof n==\"string\"&&typeof r==\"number\"?$(r).then(t=>d(n,t,!1,o)):typeof n==\"string\"&&typeof r==\"string\"?d(n,r,!1,o):Promise.reject(new Error(`Illegal arguments: ${typeof n}, ${typeof r}`))},x=(n,r)=>{if(typeof n!=\"string\"||typeof r!=\"string\")throw Error(\"Illegal arguments: \"+typeof n+\", \"+typeof r);return r.length!==60?!1:U(n,r.substring(0,r.length-31))===r},v=(n,r,o)=>new Promise((t,e)=>{if(typeof n!=\"string\"||typeof r!=\"string\"){w(()=>e(new Error(`Illegal arguments: ${typeof n}, ${typeof r}`)));return}if(r.length!==60){w(()=>e(!1));return}P(n,r.substring(0,29),o).then(l=>t(l===r)).catch(l=>e(l))}),M=n=>{if(typeof n!=\"string\")throw new Error(`Illegal arguments: ${typeof n}`);return parseInt(n.split(\"$\")[2],10)},X=n=>{if(typeof n!=\"string\")throw new Error(`Illegal arguments: ${typeof n}`);if(n.length!==60)throw new Error(`Illegal hash length: ${n.length} != 60`);return n.substring(0,29)};\n//# sourceMappingURL=browser.mjs.map\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/bcrypt-ts/dist/browser.mjs?\n}");

/***/ }),

/***/ "./node_modules/file-saver/dist/FileSaver.min.js":
/*!*******************************************************!*\
  !*** ./node_modules/file-saver/dist/FileSaver.min.js ***!
  \*******************************************************/
/***/ (function(module, exports, __webpack_require__) {

eval("{var __WEBPACK_AMD_DEFINE_FACTORY__, __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;(function(a,b){if(true)!(__WEBPACK_AMD_DEFINE_ARRAY__ = [], __WEBPACK_AMD_DEFINE_FACTORY__ = (b),\n\t\t__WEBPACK_AMD_DEFINE_RESULT__ = (typeof __WEBPACK_AMD_DEFINE_FACTORY__ === 'function' ?\n\t\t(__WEBPACK_AMD_DEFINE_FACTORY__.apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__)) : __WEBPACK_AMD_DEFINE_FACTORY__),\n\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));else // removed by dead control flow\n{}})(this,function(){\"use strict\";function b(a,b){return\"undefined\"==typeof b?b={autoBom:!1}:\"object\"!=typeof b&&(console.warn(\"Deprecated: Expected third argument to be a object\"),b={autoBom:!b}),b.autoBom&&/^\\s*(?:text\\/\\S*|application\\/xml|\\S*\\/\\S*\\+xml)\\s*;.*charset\\s*=\\s*utf-8/i.test(a.type)?new Blob([\"\\uFEFF\",a],{type:a.type}):a}function c(a,b,c){var d=new XMLHttpRequest;d.open(\"GET\",a),d.responseType=\"blob\",d.onload=function(){g(d.response,b,c)},d.onerror=function(){console.error(\"could not download file\")},d.send()}function d(a){var b=new XMLHttpRequest;b.open(\"HEAD\",a,!1);try{b.send()}catch(a){}return 200<=b.status&&299>=b.status}function e(a){try{a.dispatchEvent(new MouseEvent(\"click\"))}catch(c){var b=document.createEvent(\"MouseEvents\");b.initMouseEvent(\"click\",!0,!0,window,0,0,0,80,20,!1,!1,!1,!1,0,null),a.dispatchEvent(b)}}var f=\"object\"==typeof window&&window.window===window?window:\"object\"==typeof self&&self.self===self?self:\"object\"==typeof __webpack_require__.g&&__webpack_require__.g.global===__webpack_require__.g?__webpack_require__.g:void 0,a=f.navigator&&/Macintosh/.test(navigator.userAgent)&&/AppleWebKit/.test(navigator.userAgent)&&!/Safari/.test(navigator.userAgent),g=f.saveAs||(\"object\"!=typeof window||window!==f?function(){}:\"download\"in HTMLAnchorElement.prototype&&!a?function(b,g,h){var i=f.URL||f.webkitURL,j=document.createElement(\"a\");g=g||b.name||\"download\",j.download=g,j.rel=\"noopener\",\"string\"==typeof b?(j.href=b,j.origin===location.origin?e(j):d(j.href)?c(b,g,h):e(j,j.target=\"_blank\")):(j.href=i.createObjectURL(b),setTimeout(function(){i.revokeObjectURL(j.href)},4E4),setTimeout(function(){e(j)},0))}:\"msSaveOrOpenBlob\"in navigator?function(f,g,h){if(g=g||f.name||\"download\",\"string\"!=typeof f)navigator.msSaveOrOpenBlob(b(f,h),g);else if(d(f))c(f,g,h);else{var i=document.createElement(\"a\");i.href=f,i.target=\"_blank\",setTimeout(function(){e(i)})}}:function(b,d,e,g){if(g=g||open(\"\",\"_blank\"),g&&(g.document.title=g.document.body.innerText=\"downloading...\"),\"string\"==typeof b)return c(b,d,e);var h=\"application/octet-stream\"===b.type,i=/constructor/i.test(f.HTMLElement)||f.safari,j=/CriOS\\/[\\d]+/.test(navigator.userAgent);if((j||h&&i||a)&&\"undefined\"!=typeof FileReader){var k=new FileReader;k.onloadend=function(){var a=k.result;a=j?a:a.replace(/^data:[^;]*;/,\"data:attachment/file;\"),g?g.location.href=a:location=a,g=null},k.readAsDataURL(b)}else{var l=f.URL||f.webkitURL,m=l.createObjectURL(b);g?g.location=m:location.href=m,g=null,setTimeout(function(){l.revokeObjectURL(m)},4E4)}});f.saveAs=g.saveAs=g, true&&(module.exports=g)});\n\n//# sourceMappingURL=FileSaver.min.js.map\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/file-saver/dist/FileSaver.min.js?\n}");

/***/ }),

/***/ "./node_modules/hls.js/dist/hls.mjs":
/*!******************************************!*\
  !*** ./node_modules/hls.js/dist/hls.mjs ***!
  \******************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   AbrController: () => (/* binding */ AbrController),\n/* harmony export */   AttrList: () => (/* binding */ AttrList),\n/* harmony export */   AudioStreamController: () => (/* binding */ AudioStreamController),\n/* harmony export */   AudioTrackController: () => (/* binding */ AudioTrackController),\n/* harmony export */   BasePlaylistController: () => (/* binding */ BasePlaylistController),\n/* harmony export */   BaseSegment: () => (/* binding */ BaseSegment),\n/* harmony export */   BaseStreamController: () => (/* binding */ BaseStreamController),\n/* harmony export */   BufferController: () => (/* binding */ BufferController),\n/* harmony export */   CMCDController: () => (/* binding */ CMCDController),\n/* harmony export */   CapLevelController: () => (/* binding */ CapLevelController),\n/* harmony export */   ChunkMetadata: () => (/* binding */ ChunkMetadata),\n/* harmony export */   ContentSteeringController: () => (/* binding */ ContentSteeringController),\n/* harmony export */   Cues: () => (/* binding */ Cues),\n/* harmony export */   DateRange: () => (/* binding */ DateRange),\n/* harmony export */   EMEController: () => (/* binding */ EMEController),\n/* harmony export */   ErrorActionFlags: () => (/* binding */ ErrorActionFlags),\n/* harmony export */   ErrorController: () => (/* binding */ ErrorController),\n/* harmony export */   ErrorDetails: () => (/* binding */ ErrorDetails),\n/* harmony export */   ErrorTypes: () => (/* binding */ ErrorTypes),\n/* harmony export */   Events: () => (/* binding */ Events),\n/* harmony export */   FPSController: () => (/* binding */ FPSController),\n/* harmony export */   FetchLoader: () => (/* binding */ FetchLoader),\n/* harmony export */   Fragment: () => (/* binding */ Fragment),\n/* harmony export */   Hls: () => (/* binding */ Hls),\n/* harmony export */   HlsSkip: () => (/* binding */ HlsSkip),\n/* harmony export */   HlsUrlParameters: () => (/* binding */ HlsUrlParameters),\n/* harmony export */   KeySystemFormats: () => (/* binding */ KeySystemFormats),\n/* harmony export */   KeySystems: () => (/* binding */ KeySystems),\n/* harmony export */   Level: () => (/* binding */ Level),\n/* harmony export */   LevelDetails: () => (/* binding */ LevelDetails),\n/* harmony export */   LevelKey: () => (/* binding */ LevelKey),\n/* harmony export */   LoadStats: () => (/* binding */ LoadStats),\n/* harmony export */   M3U8Parser: () => (/* binding */ M3U8Parser),\n/* harmony export */   MetadataSchema: () => (/* binding */ MetadataSchema),\n/* harmony export */   NetworkErrorAction: () => (/* binding */ NetworkErrorAction),\n/* harmony export */   Part: () => (/* binding */ Part),\n/* harmony export */   PlaylistLevelType: () => (/* binding */ PlaylistLevelType),\n/* harmony export */   SubtitleStreamController: () => (/* binding */ SubtitleStreamController),\n/* harmony export */   SubtitleTrackController: () => (/* binding */ SubtitleTrackController),\n/* harmony export */   TimelineController: () => (/* binding */ TimelineController),\n/* harmony export */   XhrLoader: () => (/* binding */ XhrLoader),\n/* harmony export */   \"default\": () => (/* binding */ Hls),\n/* harmony export */   fetchSupported: () => (/* binding */ fetchSupported),\n/* harmony export */   getMediaSource: () => (/* binding */ getMediaSource),\n/* harmony export */   isMSESupported: () => (/* binding */ isMSESupported),\n/* harmony export */   isSupported: () => (/* binding */ isSupported),\n/* harmony export */   requestMediaKeySystemAccess: () => (/* binding */ requestMediaKeySystemAccess)\n/* harmony export */ });\n// https://caniuse.com/mdn-javascript_builtins_number_isfinite\nconst isFiniteNumber = Number.isFinite || function (value) {\n  return typeof value === 'number' && isFinite(value);\n};\n\n// https://caniuse.com/mdn-javascript_builtins_number_issafeinteger\nconst isSafeInteger = Number.isSafeInteger || function (value) {\n  return typeof value === 'number' && Math.abs(value) <= MAX_SAFE_INTEGER;\n};\nconst MAX_SAFE_INTEGER = Number.MAX_SAFE_INTEGER || 9007199254740991;\n\nlet ErrorTypes = /*#__PURE__*/function (ErrorTypes) {\n  // Identifier for a network error (loading error / timeout ...)\n  ErrorTypes[\"NETWORK_ERROR\"] = \"networkError\";\n  // Identifier for a media Error (video/parsing/mediasource error)\n  ErrorTypes[\"MEDIA_ERROR\"] = \"mediaError\";\n  // EME (encrypted media extensions) errors\n  ErrorTypes[\"KEY_SYSTEM_ERROR\"] = \"keySystemError\";\n  // Identifier for a mux Error (demuxing/remuxing)\n  ErrorTypes[\"MUX_ERROR\"] = \"muxError\";\n  // Identifier for all other errors\n  ErrorTypes[\"OTHER_ERROR\"] = \"otherError\";\n  return ErrorTypes;\n}({});\nlet ErrorDetails = /*#__PURE__*/function (ErrorDetails) {\n  ErrorDetails[\"KEY_SYSTEM_NO_KEYS\"] = \"keySystemNoKeys\";\n  ErrorDetails[\"KEY_SYSTEM_NO_ACCESS\"] = \"keySystemNoAccess\";\n  ErrorDetails[\"KEY_SYSTEM_NO_SESSION\"] = \"keySystemNoSession\";\n  ErrorDetails[\"KEY_SYSTEM_NO_CONFIGURED_LICENSE\"] = \"keySystemNoConfiguredLicense\";\n  ErrorDetails[\"KEY_SYSTEM_LICENSE_REQUEST_FAILED\"] = \"keySystemLicenseRequestFailed\";\n  ErrorDetails[\"KEY_SYSTEM_SERVER_CERTIFICATE_REQUEST_FAILED\"] = \"keySystemServerCertificateRequestFailed\";\n  ErrorDetails[\"KEY_SYSTEM_SERVER_CERTIFICATE_UPDATE_FAILED\"] = \"keySystemServerCertificateUpdateFailed\";\n  ErrorDetails[\"KEY_SYSTEM_SESSION_UPDATE_FAILED\"] = \"keySystemSessionUpdateFailed\";\n  ErrorDetails[\"KEY_SYSTEM_STATUS_OUTPUT_RESTRICTED\"] = \"keySystemStatusOutputRestricted\";\n  ErrorDetails[\"KEY_SYSTEM_STATUS_INTERNAL_ERROR\"] = \"keySystemStatusInternalError\";\n  ErrorDetails[\"KEY_SYSTEM_DESTROY_MEDIA_KEYS_ERROR\"] = \"keySystemDestroyMediaKeysError\";\n  ErrorDetails[\"KEY_SYSTEM_DESTROY_CLOSE_SESSION_ERROR\"] = \"keySystemDestroyCloseSessionError\";\n  ErrorDetails[\"KEY_SYSTEM_DESTROY_REMOVE_SESSION_ERROR\"] = \"keySystemDestroyRemoveSessionError\";\n  // Identifier for a manifest load error - data: { url : faulty URL, response : { code: error code, text: error text }}\n  ErrorDetails[\"MANIFEST_LOAD_ERROR\"] = \"manifestLoadError\";\n  // Identifier for a manifest load timeout - data: { url : faulty URL, response : { code: error code, text: error text }}\n  ErrorDetails[\"MANIFEST_LOAD_TIMEOUT\"] = \"manifestLoadTimeOut\";\n  // Identifier for a manifest parsing error - data: { url : faulty URL, reason : error reason}\n  ErrorDetails[\"MANIFEST_PARSING_ERROR\"] = \"manifestParsingError\";\n  // Identifier for a manifest with only incompatible codecs error - data: { url : faulty URL, reason : error reason}\n  ErrorDetails[\"MANIFEST_INCOMPATIBLE_CODECS_ERROR\"] = \"manifestIncompatibleCodecsError\";\n  // Identifier for a level which contains no fragments - data: { url: faulty URL, reason: \"no fragments found in level\", level: index of the bad level }\n  ErrorDetails[\"LEVEL_EMPTY_ERROR\"] = \"levelEmptyError\";\n  // Identifier for a level load error - data: { url : faulty URL, response : { code: error code, text: error text }}\n  ErrorDetails[\"LEVEL_LOAD_ERROR\"] = \"levelLoadError\";\n  // Identifier for a level load timeout - data: { url : faulty URL, response : { code: error code, text: error text }}\n  ErrorDetails[\"LEVEL_LOAD_TIMEOUT\"] = \"levelLoadTimeOut\";\n  // Identifier for a level parse error - data: { url : faulty URL, error: Error, reason: error message }\n  ErrorDetails[\"LEVEL_PARSING_ERROR\"] = \"levelParsingError\";\n  // Identifier for a level switch error - data: { level : faulty level Id, event : error description}\n  ErrorDetails[\"LEVEL_SWITCH_ERROR\"] = \"levelSwitchError\";\n  // Identifier for an audio track load error - data: { url : faulty URL, response : { code: error code, text: error text }}\n  ErrorDetails[\"AUDIO_TRACK_LOAD_ERROR\"] = \"audioTrackLoadError\";\n  // Identifier for an audio track load timeout - data: { url : faulty URL, response : { code: error code, text: error text }}\n  ErrorDetails[\"AUDIO_TRACK_LOAD_TIMEOUT\"] = \"audioTrackLoadTimeOut\";\n  // Identifier for a subtitle track load error - data: { url : faulty URL, response : { code: error code, text: error text }}\n  ErrorDetails[\"SUBTITLE_LOAD_ERROR\"] = \"subtitleTrackLoadError\";\n  // Identifier for a subtitle track load timeout - data: { url : faulty URL, response : { code: error code, text: error text }}\n  ErrorDetails[\"SUBTITLE_TRACK_LOAD_TIMEOUT\"] = \"subtitleTrackLoadTimeOut\";\n  // Identifier for fragment load error - data: { frag : fragment object, response : { code: error code, text: error text }}\n  ErrorDetails[\"FRAG_LOAD_ERROR\"] = \"fragLoadError\";\n  // Identifier for fragment load timeout error - data: { frag : fragment object}\n  ErrorDetails[\"FRAG_LOAD_TIMEOUT\"] = \"fragLoadTimeOut\";\n  // Identifier for a fragment decryption error event - data: {id : demuxer Id,frag: fragment object, reason : parsing error description }\n  ErrorDetails[\"FRAG_DECRYPT_ERROR\"] = \"fragDecryptError\";\n  // Identifier for a fragment parsing error event - data: { id : demuxer Id, reason : parsing error description }\n  // will be renamed DEMUX_PARSING_ERROR and switched to MUX_ERROR in the next major release\n  ErrorDetails[\"FRAG_PARSING_ERROR\"] = \"fragParsingError\";\n  // Identifier for a fragment or part load skipped because of a GAP tag or attribute\n  ErrorDetails[\"FRAG_GAP\"] = \"fragGap\";\n  // Identifier for a remux alloc error event - data: { id : demuxer Id, frag : fragment object, bytes : nb of bytes on which allocation failed , reason : error text }\n  ErrorDetails[\"REMUX_ALLOC_ERROR\"] = \"remuxAllocError\";\n  // Identifier for decrypt key load error - data: { frag : fragment object, response : { code: error code, text: error text }}\n  ErrorDetails[\"KEY_LOAD_ERROR\"] = \"keyLoadError\";\n  // Identifier for decrypt key load timeout error - data: { frag : fragment object}\n  ErrorDetails[\"KEY_LOAD_TIMEOUT\"] = \"keyLoadTimeOut\";\n  // Triggered when an exception occurs while adding a sourceBuffer to MediaSource - data : { error : exception , mimeType : mimeType }\n  ErrorDetails[\"BUFFER_ADD_CODEC_ERROR\"] = \"bufferAddCodecError\";\n  // Triggered when source buffer(s) could not be created using level (manifest CODECS attribute), parsed media, or best guess codec(s) - data: { reason : error reason }\n  ErrorDetails[\"BUFFER_INCOMPATIBLE_CODECS_ERROR\"] = \"bufferIncompatibleCodecsError\";\n  // Identifier for a buffer append error - data: append error description\n  ErrorDetails[\"BUFFER_APPEND_ERROR\"] = \"bufferAppendError\";\n  // Identifier for a buffer appending error event - data: appending error description\n  ErrorDetails[\"BUFFER_APPENDING_ERROR\"] = \"bufferAppendingError\";\n  // Identifier for a buffer stalled error event\n  ErrorDetails[\"BUFFER_STALLED_ERROR\"] = \"bufferStalledError\";\n  // Identifier for a buffer full event\n  ErrorDetails[\"BUFFER_FULL_ERROR\"] = \"bufferFullError\";\n  // Identifier for a buffer seek over hole event\n  ErrorDetails[\"BUFFER_SEEK_OVER_HOLE\"] = \"bufferSeekOverHole\";\n  // Identifier for a buffer nudge on stall (playback is stuck although currentTime is in a buffered area)\n  ErrorDetails[\"BUFFER_NUDGE_ON_STALL\"] = \"bufferNudgeOnStall\";\n  // Identifier for a Interstitial Asset List load error - data: { url: faulty URL, response: { code: error code, text: error text } }\n  ErrorDetails[\"ASSET_LIST_LOAD_ERROR\"] = \"assetListLoadError\";\n  // Identifier for a Interstitial Asset List load timeout - data: { url: faulty URL, response: { code: error code, text: error text } }\n  ErrorDetails[\"ASSET_LIST_LOAD_TIMEOUT\"] = \"assetListLoadTimeout\";\n  // Identifier for a Interstitial Asset List parsing error - data: { url : faulty URL, reason : error reason, response : { code: error code, text: error text }}\n  ErrorDetails[\"ASSET_LIST_PARSING_ERROR\"] = \"assetListParsingError\";\n  // Identifier for a Interstitial Asset List parsing error - data: { url : faulty URL, reason : error reason, response : { code: error code, text: error text }}\n  ErrorDetails[\"INTERSTITIAL_ASSET_ITEM_ERROR\"] = \"interstitialAssetItemError\";\n  // Identifier for an internal exception happening inside hls.js while handling an event\n  ErrorDetails[\"INTERNAL_EXCEPTION\"] = \"internalException\";\n  // Identifier for an internal call to abort a loader\n  ErrorDetails[\"INTERNAL_ABORTED\"] = \"aborted\";\n  // Triggered when attachMedia fails\n  ErrorDetails[\"ATTACH_MEDIA_ERROR\"] = \"attachMediaError\";\n  // Uncategorized error\n  ErrorDetails[\"UNKNOWN\"] = \"unknown\";\n  return ErrorDetails;\n}({});\n\nlet Events = /*#__PURE__*/function (Events) {\n  // Fired before MediaSource is attaching to media element\n  Events[\"MEDIA_ATTACHING\"] = \"hlsMediaAttaching\";\n  // Fired when MediaSource has been successfully attached to media element\n  Events[\"MEDIA_ATTACHED\"] = \"hlsMediaAttached\";\n  // Fired before detaching MediaSource from media element\n  Events[\"MEDIA_DETACHING\"] = \"hlsMediaDetaching\";\n  // Fired when MediaSource has been detached from media element\n  Events[\"MEDIA_DETACHED\"] = \"hlsMediaDetached\";\n  // Fired when HTMLMediaElement dispatches \"ended\" event, or stalls at end of VOD program\n  Events[\"MEDIA_ENDED\"] = \"hlsMediaEnded\";\n  // Fired after playback stall is resolved with playing, seeked, or ended event following BUFFER_STALLED_ERROR\n  Events[\"STALL_RESOLVED\"] = \"hlsStallResolved\";\n  // Fired when the buffer is going to be reset\n  Events[\"BUFFER_RESET\"] = \"hlsBufferReset\";\n  // Fired when we know about the codecs that we need buffers for to push into - data: {tracks : { container, codec, levelCodec, initSegment, metadata }}\n  Events[\"BUFFER_CODECS\"] = \"hlsBufferCodecs\";\n  // fired when sourcebuffers have been created - data: { tracks : tracks }\n  Events[\"BUFFER_CREATED\"] = \"hlsBufferCreated\";\n  // fired when we append a segment to the buffer - data: { segment: segment object }\n  Events[\"BUFFER_APPENDING\"] = \"hlsBufferAppending\";\n  // fired when we are done with appending a media segment to the buffer - data : { parent : segment parent that triggered BUFFER_APPENDING, pending : nb of segments waiting for appending for this segment parent}\n  Events[\"BUFFER_APPENDED\"] = \"hlsBufferAppended\";\n  // fired when the stream is finished and we want to notify the media buffer that there will be no more data - data: { }\n  Events[\"BUFFER_EOS\"] = \"hlsBufferEos\";\n  // fired when all buffers are full to the end of the program, after calling MediaSource.endOfStream() (unless restricted)\n  Events[\"BUFFERED_TO_END\"] = \"hlsBufferedToEnd\";\n  // fired when the media buffer should be flushed - data { startOffset, endOffset }\n  Events[\"BUFFER_FLUSHING\"] = \"hlsBufferFlushing\";\n  // fired when the media buffer has been flushed - data: { }\n  Events[\"BUFFER_FLUSHED\"] = \"hlsBufferFlushed\";\n  // fired to signal that a manifest loading starts - data: { url : manifestURL}\n  Events[\"MANIFEST_LOADING\"] = \"hlsManifestLoading\";\n  // fired after manifest has been loaded - data: { levels : [available quality levels], audioTracks : [ available audio tracks ], url : manifestURL, stats : LoaderStats }\n  Events[\"MANIFEST_LOADED\"] = \"hlsManifestLoaded\";\n  // fired after manifest has been parsed - data: { levels : [available quality levels], firstLevel : index of first quality level appearing in Manifest}\n  Events[\"MANIFEST_PARSED\"] = \"hlsManifestParsed\";\n  // fired when a level switch is requested - data: { level : id of new level }\n  Events[\"LEVEL_SWITCHING\"] = \"hlsLevelSwitching\";\n  // fired when a level switch is effective - data: { level : id of new level }\n  Events[\"LEVEL_SWITCHED\"] = \"hlsLevelSwitched\";\n  // fired when a level playlist loading starts - data: { url : level URL, level : id of level being loaded}\n  Events[\"LEVEL_LOADING\"] = \"hlsLevelLoading\";\n  // fired when a level playlist loading finishes - data: { details : levelDetails object, level : id of loaded level, stats : LoaderStats }\n  Events[\"LEVEL_LOADED\"] = \"hlsLevelLoaded\";\n  // fired when a level's details have been updated based on previous details, after it has been loaded - data: { details : levelDetails object, level : id of updated level }\n  Events[\"LEVEL_UPDATED\"] = \"hlsLevelUpdated\";\n  // fired when a level's PTS information has been updated after parsing a fragment - data: { details : levelDetails object, level : id of updated level, drift: PTS drift observed when parsing last fragment }\n  Events[\"LEVEL_PTS_UPDATED\"] = \"hlsLevelPtsUpdated\";\n  // fired to notify that levels have changed after removing a level - data: { levels : [available quality levels] }\n  Events[\"LEVELS_UPDATED\"] = \"hlsLevelsUpdated\";\n  // fired to notify that audio track lists has been updated - data: { audioTracks : audioTracks }\n  Events[\"AUDIO_TRACKS_UPDATED\"] = \"hlsAudioTracksUpdated\";\n  // fired when an audio track switching is requested - data: { id : audio track id }\n  Events[\"AUDIO_TRACK_SWITCHING\"] = \"hlsAudioTrackSwitching\";\n  // fired when an audio track switch actually occurs - data: { id : audio track id }\n  Events[\"AUDIO_TRACK_SWITCHED\"] = \"hlsAudioTrackSwitched\";\n  // fired when an audio track loading starts - data: { url : audio track URL, id : audio track id }\n  Events[\"AUDIO_TRACK_LOADING\"] = \"hlsAudioTrackLoading\";\n  // fired when an audio track loading finishes - data: { details : levelDetails object, id : audio track id, stats : LoaderStats }\n  Events[\"AUDIO_TRACK_LOADED\"] = \"hlsAudioTrackLoaded\";\n  // fired when an audio tracks's details have been updated based on previous details, after it has been loaded - data: { details : levelDetails object, id : track id }\n  Events[\"AUDIO_TRACK_UPDATED\"] = \"hlsAudioTrackUpdated\";\n  // fired to notify that subtitle track lists has been updated - data: { subtitleTracks : subtitleTracks }\n  Events[\"SUBTITLE_TRACKS_UPDATED\"] = \"hlsSubtitleTracksUpdated\";\n  // fired to notify that subtitle tracks were cleared as a result of stopping the media\n  Events[\"SUBTITLE_TRACKS_CLEARED\"] = \"hlsSubtitleTracksCleared\";\n  // fired when an subtitle track switch occurs - data: { id : subtitle track id }\n  Events[\"SUBTITLE_TRACK_SWITCH\"] = \"hlsSubtitleTrackSwitch\";\n  // fired when a subtitle track loading starts - data: { url : subtitle track URL, id : subtitle track id }\n  Events[\"SUBTITLE_TRACK_LOADING\"] = \"hlsSubtitleTrackLoading\";\n  // fired when a subtitle track loading finishes - data: { details : levelDetails object, id : subtitle track id, stats : LoaderStats }\n  Events[\"SUBTITLE_TRACK_LOADED\"] = \"hlsSubtitleTrackLoaded\";\n  // fired when a subtitle  racks's details have been updated based on previous details, after it has been loaded - data: { details : levelDetails object, id : track id }\n  Events[\"SUBTITLE_TRACK_UPDATED\"] = \"hlsSubtitleTrackUpdated\";\n  // fired when a subtitle fragment has been processed - data: { success : boolean, frag : the processed frag }\n  Events[\"SUBTITLE_FRAG_PROCESSED\"] = \"hlsSubtitleFragProcessed\";\n  // fired when a set of VTTCues to be managed externally has been parsed - data: { type: string, track: string, cues: [ VTTCue ] }\n  Events[\"CUES_PARSED\"] = \"hlsCuesParsed\";\n  // fired when a text track to be managed externally is found - data: { tracks: [ { label: string, kind: string, default: boolean } ] }\n  Events[\"NON_NATIVE_TEXT_TRACKS_FOUND\"] = \"hlsNonNativeTextTracksFound\";\n  // fired when the first timestamp is found - data: { id : demuxer id, initPTS: initPTS, timescale: timescale, frag : fragment object }\n  Events[\"INIT_PTS_FOUND\"] = \"hlsInitPtsFound\";\n  // fired when a fragment loading starts - data: { frag : fragment object }\n  Events[\"FRAG_LOADING\"] = \"hlsFragLoading\";\n  // fired when a fragment loading is progressing - data: { frag : fragment object, { trequest, tfirst, loaded } }\n  // FRAG_LOAD_PROGRESS = 'hlsFragLoadProgress',\n  // Identifier for fragment load aborting for emergency switch down - data: { frag : fragment object }\n  Events[\"FRAG_LOAD_EMERGENCY_ABORTED\"] = \"hlsFragLoadEmergencyAborted\";\n  // fired when a fragment loading is completed - data: { frag : fragment object, payload : fragment payload, stats : LoaderStats }\n  Events[\"FRAG_LOADED\"] = \"hlsFragLoaded\";\n  // fired when a fragment has finished decrypting - data: { id : demuxer id, frag: fragment object, payload : fragment payload, stats : { tstart, tdecrypt } }\n  Events[\"FRAG_DECRYPTED\"] = \"hlsFragDecrypted\";\n  // fired when Init Segment has been extracted from fragment - data: { id : demuxer id, frag: fragment object, moov : moov MP4 box, codecs : codecs found while parsing fragment }\n  Events[\"FRAG_PARSING_INIT_SEGMENT\"] = \"hlsFragParsingInitSegment\";\n  // fired when parsing sei text is completed - data: { id : demuxer id, frag: fragment object, samples : [ sei samples pes ] }\n  Events[\"FRAG_PARSING_USERDATA\"] = \"hlsFragParsingUserdata\";\n  // fired when parsing id3 is completed - data: { id : demuxer id, frag: fragment object, samples : [ id3 samples pes ] }\n  Events[\"FRAG_PARSING_METADATA\"] = \"hlsFragParsingMetadata\";\n  // fired when data have been extracted from fragment - data: { id : demuxer id, frag: fragment object, data1 : moof MP4 box or TS fragments, data2 : mdat MP4 box or null}\n  // FRAG_PARSING_DATA = 'hlsFragParsingData',\n  // fired when fragment parsing is completed - data: { id : demuxer id, frag: fragment object }\n  Events[\"FRAG_PARSED\"] = \"hlsFragParsed\";\n  // fired when fragment remuxed MP4 boxes have all been appended into SourceBuffer - data: { id : demuxer id, frag : fragment object, stats : LoaderStats }\n  Events[\"FRAG_BUFFERED\"] = \"hlsFragBuffered\";\n  // fired when fragment matching with current media position is changing - data : { id : demuxer id, frag : fragment object }\n  Events[\"FRAG_CHANGED\"] = \"hlsFragChanged\";\n  // Identifier for a FPS drop event - data: { currentDropped, currentDecoded, totalDroppedFrames }\n  Events[\"FPS_DROP\"] = \"hlsFpsDrop\";\n  // triggered when FPS drop triggers auto level capping - data: { level, droppedLevel }\n  Events[\"FPS_DROP_LEVEL_CAPPING\"] = \"hlsFpsDropLevelCapping\";\n  // triggered when maxAutoLevel changes - data { autoLevelCapping, levels, maxAutoLevel, minAutoLevel, maxHdcpLevel }\n  Events[\"MAX_AUTO_LEVEL_UPDATED\"] = \"hlsMaxAutoLevelUpdated\";\n  // Identifier for an error event - data: { type : error type, details : error details, fatal : if true, hls.js cannot/will not try to recover, if false, hls.js will try to recover,other error specific data }\n  Events[\"ERROR\"] = \"hlsError\";\n  // fired when hls.js instance starts destroying. Different from MEDIA_DETACHED as one could want to detach and reattach a media to the instance of hls.js to handle mid-rolls for example - data: { }\n  Events[\"DESTROYING\"] = \"hlsDestroying\";\n  // fired when a decrypt key loading starts - data: { frag : fragment object }\n  Events[\"KEY_LOADING\"] = \"hlsKeyLoading\";\n  // fired when a decrypt key loading is completed - data: { frag : fragment object, keyInfo : KeyLoaderInfo }\n  Events[\"KEY_LOADED\"] = \"hlsKeyLoaded\";\n  // deprecated; please use BACK_BUFFER_REACHED - data : { bufferEnd: number }\n  Events[\"LIVE_BACK_BUFFER_REACHED\"] = \"hlsLiveBackBufferReached\";\n  // fired when the back buffer is reached as defined by the backBufferLength config option - data : { bufferEnd: number }\n  Events[\"BACK_BUFFER_REACHED\"] = \"hlsBackBufferReached\";\n  // fired after steering manifest has been loaded - data: { steeringManifest: SteeringManifest object, url: steering manifest URL }\n  Events[\"STEERING_MANIFEST_LOADED\"] = \"hlsSteeringManifestLoaded\";\n  // fired when asset list has begun loading\n  Events[\"ASSET_LIST_LOADING\"] = \"hlsAssetListLoading\";\n  // fired when a valid asset list is loaded\n  Events[\"ASSET_LIST_LOADED\"] = \"hlsAssetListLoaded\";\n  // fired when the list of Interstitial Events and Interstitial Schedule is updated\n  Events[\"INTERSTITIALS_UPDATED\"] = \"hlsInterstitialsUpdated\";\n  // fired when the buffer reaches an Interstitial Schedule boundary (both Primary segments and Interstitial Assets)\n  Events[\"INTERSTITIALS_BUFFERED_TO_BOUNDARY\"] = \"hlsInterstitialsBufferedToBoundary\";\n  // fired when a player instance for an Interstitial Asset has been created\n  Events[\"INTERSTITIAL_ASSET_PLAYER_CREATED\"] = \"hlsInterstitialAssetPlayerCreated\";\n  // Interstitial playback started\n  Events[\"INTERSTITIAL_STARTED\"] = \"hlsInterstitialStarted\";\n  // InterstitialAsset playback started\n  Events[\"INTERSTITIAL_ASSET_STARTED\"] = \"hlsInterstitialAssetStarted\";\n  // InterstitialAsset playback ended\n  Events[\"INTERSTITIAL_ASSET_ENDED\"] = \"hlsInterstitialAssetEnded\";\n  // InterstitialAsset playback errored\n  Events[\"INTERSTITIAL_ASSET_ERROR\"] = \"hlsInterstitialAssetError\";\n  // Interstitial playback ended\n  Events[\"INTERSTITIAL_ENDED\"] = \"hlsInterstitialEnded\";\n  // Interstitial schedule resumed primary playback\n  Events[\"INTERSTITIALS_PRIMARY_RESUMED\"] = \"hlsInterstitialsPrimaryResumed\";\n  // Interstitial players dispatch this event when playout limit is reached\n  Events[\"PLAYOUT_LIMIT_REACHED\"] = \"hlsPlayoutLimitReached\";\n  // Event DateRange cue \"enter\" event dispatched\n  Events[\"EVENT_CUE_ENTER\"] = \"hlsEventCueEnter\";\n  return Events;\n}({});\n\n/**\n * Defines each Event type and payload by Event name. Used in {@link hls.js#HlsEventEmitter} to strongly type the event listener API.\n */\n\nvar PlaylistContextType = {\n  MANIFEST: \"manifest\",\n  LEVEL: \"level\",\n  AUDIO_TRACK: \"audioTrack\",\n  SUBTITLE_TRACK: \"subtitleTrack\"\n};\nvar PlaylistLevelType = {\n  MAIN: \"main\",\n  AUDIO: \"audio\",\n  SUBTITLE: \"subtitle\"\n};\n\n/*\n * compute an Exponential Weighted moving average\n * - https://en.wikipedia.org/wiki/Moving_average#Exponential_moving_average\n *  - heavily inspired from shaka-player\n */\n\nclass EWMA {\n  //  About half of the estimated value will be from the last |halfLife| samples by weight.\n  constructor(halfLife, estimate = 0, weight = 0) {\n    this.halfLife = void 0;\n    this.alpha_ = void 0;\n    this.estimate_ = void 0;\n    this.totalWeight_ = void 0;\n    this.halfLife = halfLife;\n    // Larger values of alpha expire historical data more slowly.\n    this.alpha_ = halfLife ? Math.exp(Math.log(0.5) / halfLife) : 0;\n    this.estimate_ = estimate;\n    this.totalWeight_ = weight;\n  }\n  sample(weight, value) {\n    const adjAlpha = Math.pow(this.alpha_, weight);\n    this.estimate_ = value * (1 - adjAlpha) + adjAlpha * this.estimate_;\n    this.totalWeight_ += weight;\n  }\n  getTotalWeight() {\n    return this.totalWeight_;\n  }\n  getEstimate() {\n    if (this.alpha_) {\n      const zeroFactor = 1 - Math.pow(this.alpha_, this.totalWeight_);\n      if (zeroFactor) {\n        return this.estimate_ / zeroFactor;\n      }\n    }\n    return this.estimate_;\n  }\n}\n\n/*\n * EWMA Bandwidth Estimator\n *  - heavily inspired from shaka-player\n * Tracks bandwidth samples and estimates available bandwidth.\n * Based on the minimum of two exponentially-weighted moving averages with\n * different half-lives.\n */\n\nclass EwmaBandWidthEstimator {\n  constructor(slow, fast, defaultEstimate, defaultTTFB = 100) {\n    this.defaultEstimate_ = void 0;\n    this.minWeight_ = void 0;\n    this.minDelayMs_ = void 0;\n    this.slow_ = void 0;\n    this.fast_ = void 0;\n    this.defaultTTFB_ = void 0;\n    this.ttfb_ = void 0;\n    this.defaultEstimate_ = defaultEstimate;\n    this.minWeight_ = 0.001;\n    this.minDelayMs_ = 50;\n    this.slow_ = new EWMA(slow);\n    this.fast_ = new EWMA(fast);\n    this.defaultTTFB_ = defaultTTFB;\n    this.ttfb_ = new EWMA(slow);\n  }\n  update(slow, fast) {\n    const {\n      slow_,\n      fast_,\n      ttfb_\n    } = this;\n    if (slow_.halfLife !== slow) {\n      this.slow_ = new EWMA(slow, slow_.getEstimate(), slow_.getTotalWeight());\n    }\n    if (fast_.halfLife !== fast) {\n      this.fast_ = new EWMA(fast, fast_.getEstimate(), fast_.getTotalWeight());\n    }\n    if (ttfb_.halfLife !== slow) {\n      this.ttfb_ = new EWMA(slow, ttfb_.getEstimate(), ttfb_.getTotalWeight());\n    }\n  }\n  sample(durationMs, numBytes) {\n    durationMs = Math.max(durationMs, this.minDelayMs_);\n    const numBits = 8 * numBytes;\n    // weight is duration in seconds\n    const durationS = durationMs / 1000;\n    // value is bandwidth in bits/s\n    const bandwidthInBps = numBits / durationS;\n    this.fast_.sample(durationS, bandwidthInBps);\n    this.slow_.sample(durationS, bandwidthInBps);\n  }\n  sampleTTFB(ttfb) {\n    // weight is frequency curve applied to TTFB in seconds\n    // (longer times have less weight with expected input under 1 second)\n    const seconds = ttfb / 1000;\n    const weight = Math.sqrt(2) * Math.exp(-Math.pow(seconds, 2) / 2);\n    this.ttfb_.sample(weight, Math.max(ttfb, 5));\n  }\n  canEstimate() {\n    return this.fast_.getTotalWeight() >= this.minWeight_;\n  }\n  getEstimate() {\n    if (this.canEstimate()) {\n      // console.log('slow estimate:'+ Math.round(this.slow_.getEstimate()));\n      // console.log('fast estimate:'+ Math.round(this.fast_.getEstimate()));\n      // Take the minimum of these two estimates.  This should have the effect of\n      // adapting down quickly, but up more slowly.\n      return Math.min(this.fast_.getEstimate(), this.slow_.getEstimate());\n    } else {\n      return this.defaultEstimate_;\n    }\n  }\n  getEstimateTTFB() {\n    if (this.ttfb_.getTotalWeight() >= this.minWeight_) {\n      return this.ttfb_.getEstimate();\n    } else {\n      return this.defaultTTFB_;\n    }\n  }\n  get defaultEstimate() {\n    return this.defaultEstimate_;\n  }\n  destroy() {}\n}\n\nfunction _defineProperty(e, r, t) {\n  return (r = _toPropertyKey(r)) in e ? Object.defineProperty(e, r, {\n    value: t,\n    enumerable: true,\n    configurable: true,\n    writable: true\n  }) : e[r] = t, e;\n}\nfunction _extends() {\n  return _extends = Object.assign ? Object.assign.bind() : function (n) {\n    for (var e = 1; e < arguments.length; e++) {\n      var t = arguments[e];\n      for (var r in t) ({}).hasOwnProperty.call(t, r) && (n[r] = t[r]);\n    }\n    return n;\n  }, _extends.apply(null, arguments);\n}\nfunction ownKeys(e, r) {\n  var t = Object.keys(e);\n  if (Object.getOwnPropertySymbols) {\n    var o = Object.getOwnPropertySymbols(e);\n    r && (o = o.filter(function (r) {\n      return Object.getOwnPropertyDescriptor(e, r).enumerable;\n    })), t.push.apply(t, o);\n  }\n  return t;\n}\nfunction _objectSpread2(e) {\n  for (var r = 1; r < arguments.length; r++) {\n    var t = null != arguments[r] ? arguments[r] : {};\n    r % 2 ? ownKeys(Object(t), true).forEach(function (r) {\n      _defineProperty(e, r, t[r]);\n    }) : Object.getOwnPropertyDescriptors ? Object.defineProperties(e, Object.getOwnPropertyDescriptors(t)) : ownKeys(Object(t)).forEach(function (r) {\n      Object.defineProperty(e, r, Object.getOwnPropertyDescriptor(t, r));\n    });\n  }\n  return e;\n}\nfunction _toPrimitive(t, r) {\n  if (\"object\" != typeof t || !t) return t;\n  var e = t[Symbol.toPrimitive];\n  if (void 0 !== e) {\n    var i = e.call(t, r);\n    if (\"object\" != typeof i) return i;\n    throw new TypeError(\"@@toPrimitive must return a primitive value.\");\n  }\n  return (\"string\" === r ? String : Number)(t);\n}\nfunction _toPropertyKey(t) {\n  var i = _toPrimitive(t, \"string\");\n  return \"symbol\" == typeof i ? i : i + \"\";\n}\n\nclass Logger {\n  constructor(label, logger) {\n    this.trace = void 0;\n    this.debug = void 0;\n    this.log = void 0;\n    this.warn = void 0;\n    this.info = void 0;\n    this.error = void 0;\n    const lb = `[${label}]:`;\n    this.trace = noop;\n    this.debug = logger.debug.bind(null, lb);\n    this.log = logger.log.bind(null, lb);\n    this.warn = logger.warn.bind(null, lb);\n    this.info = logger.info.bind(null, lb);\n    this.error = logger.error.bind(null, lb);\n  }\n}\nconst noop = function noop() {};\nconst fakeLogger = {\n  trace: noop,\n  debug: noop,\n  log: noop,\n  warn: noop,\n  info: noop,\n  error: noop\n};\nfunction createLogger() {\n  return _extends({}, fakeLogger);\n}\n\n// let lastCallTime;\n// function formatMsgWithTimeInfo(type, msg) {\n//   const now = Date.now();\n//   const diff = lastCallTime ? '+' + (now - lastCallTime) : '0';\n//   lastCallTime = now;\n//   msg = (new Date(now)).toISOString() + ' | [' +  type + '] > ' + msg + ' ( ' + diff + ' ms )';\n//   return msg;\n// }\n\nfunction consolePrintFn(type, id) {\n  const func = self.console[type];\n  return func ? func.bind(self.console, `${id ? '[' + id + '] ' : ''}[${type}] >`) : noop;\n}\nfunction getLoggerFn(key, debugConfig, id) {\n  return debugConfig[key] ? debugConfig[key].bind(debugConfig) : consolePrintFn(key, id);\n}\nconst exportedLogger = createLogger();\nfunction enableLogs(debugConfig, context, id) {\n  // check that console is available\n  const newLogger = createLogger();\n  if (typeof console === 'object' && debugConfig === true || typeof debugConfig === 'object') {\n    const keys = [\n    // Remove out from list here to hard-disable a log-level\n    // 'trace',\n    'debug', 'log', 'info', 'warn', 'error'];\n    keys.forEach(key => {\n      newLogger[key] = getLoggerFn(key, debugConfig, id);\n    });\n    // Some browsers don't allow to use bind on console object anyway\n    // fallback to default if needed\n    try {\n      newLogger.log(`Debug logs enabled for \"${context}\" in hls.js version ${\"1.6.15\"}`);\n    } catch (e) {\n      /* log fn threw an exception. All logger methods are no-ops. */\n      return createLogger();\n    }\n    // global exported logger uses the same functions as new logger without `id`\n    keys.forEach(key => {\n      exportedLogger[key] = getLoggerFn(key, debugConfig);\n    });\n  } else {\n    // Reset global exported logger\n    _extends(exportedLogger, newLogger);\n  }\n  return newLogger;\n}\nconst logger = exportedLogger;\n\nfunction getMediaSource(preferManagedMediaSource = true) {\n  if (typeof self === 'undefined') return undefined;\n  const mms = (preferManagedMediaSource || !self.MediaSource) && self.ManagedMediaSource;\n  return mms || self.MediaSource || self.WebKitMediaSource;\n}\nfunction isManagedMediaSource(source) {\n  return typeof self !== 'undefined' && source === self.ManagedMediaSource;\n}\nfunction isCompatibleTrackChange(currentTracks, requiredTracks) {\n  const trackNames = Object.keys(currentTracks);\n  const requiredTrackNames = Object.keys(requiredTracks);\n  const trackCount = trackNames.length;\n  const requiredTrackCount = requiredTrackNames.length;\n  return !trackCount || !requiredTrackCount || trackCount === requiredTrackCount && !trackNames.some(name => requiredTrackNames.indexOf(name) === -1);\n}\n\n// http://stackoverflow.com/questions/8936984/uint8array-to-string-in-javascript/22373197\n// http://www.onicos.com/staff/iz/amuse/javascript/expert/utf.txt\n/* utf.js - UTF-8 <=> UTF-16 convertion\n *\n * Copyright (C) 1999 Masanao Izumo <iz@onicos.co.jp>\n * Version: 1.0\n * LastModified: Dec 25 1999\n * This library is free.  You can redistribute it and/or modify it.\n */\n/**\n * Converts a UTF-8 array to a string.\n *\n * @param array - The UTF-8 array to convert\n *\n * @returns The string\n *\n * @group Utils\n *\n * @beta\n */\nfunction utf8ArrayToStr(array, exitOnNull = false) {\n  if (typeof TextDecoder !== 'undefined') {\n    const decoder = new TextDecoder('utf-8');\n    const decoded = decoder.decode(array);\n    if (exitOnNull) {\n      // grab up to the first null\n      const idx = decoded.indexOf('\\0');\n      return idx !== -1 ? decoded.substring(0, idx) : decoded;\n    }\n    // remove any null characters\n    return decoded.replace(/\\0/g, '');\n  }\n  const len = array.length;\n  let c;\n  let char2;\n  let char3;\n  let out = '';\n  let i = 0;\n  while (i < len) {\n    c = array[i++];\n    if (c === 0x00 && exitOnNull) {\n      return out;\n    } else if (c === 0x00 || c === 0x03) {\n      // If the character is 3 (END_OF_TEXT) or 0 (NULL) then skip it\n      continue;\n    }\n    switch (c >> 4) {\n      case 0:\n      case 1:\n      case 2:\n      case 3:\n      case 4:\n      case 5:\n      case 6:\n      case 7:\n        // 0xxxxxxx\n        out += String.fromCharCode(c);\n        break;\n      case 12:\n      case 13:\n        // 110x xxxx   10xx xxxx\n        char2 = array[i++];\n        out += String.fromCharCode((c & 0x1f) << 6 | char2 & 0x3f);\n        break;\n      case 14:\n        // 1110 xxxx  10xx xxxx  10xx xxxx\n        char2 = array[i++];\n        char3 = array[i++];\n        out += String.fromCharCode((c & 0x0f) << 12 | (char2 & 0x3f) << 6 | (char3 & 0x3f) << 0);\n        break;\n    }\n  }\n  return out;\n}\n\n/**\n *  hex dump helper class\n */\n\nfunction arrayToHex(array) {\n  let str = '';\n  for (let i = 0; i < array.length; i++) {\n    let h = array[i].toString(16);\n    if (h.length < 2) {\n      h = '0' + h;\n    }\n    str += h;\n  }\n  return str;\n}\nfunction hexToArrayBuffer(str) {\n  return Uint8Array.from(str.replace(/^0x/, '').replace(/([\\da-fA-F]{2}) ?/g, '0x$1 ').replace(/ +$/, '').split(' ')).buffer;\n}\n\nfunction getDefaultExportFromCjs (x) {\n\treturn x && x.__esModule && Object.prototype.hasOwnProperty.call(x, 'default') ? x['default'] : x;\n}\n\nvar urlToolkit = {exports: {}};\n\nvar hasRequiredUrlToolkit;\n\nfunction requireUrlToolkit () {\n\tif (hasRequiredUrlToolkit) return urlToolkit.exports;\n\thasRequiredUrlToolkit = 1;\n\t(function (module, exports) {\n\t\t// see https://tools.ietf.org/html/rfc1808\n\n\t\t(function (root) {\n\t\t  var URL_REGEX =\n\t\t    /^(?=((?:[a-zA-Z0-9+\\-.]+:)?))\\1(?=((?:\\/\\/[^\\/?#]*)?))\\2(?=((?:(?:[^?#\\/]*\\/)*[^;?#\\/]*)?))\\3((?:;[^?#]*)?)(\\?[^#]*)?(#[^]*)?$/;\n\t\t  var FIRST_SEGMENT_REGEX = /^(?=([^\\/?#]*))\\1([^]*)$/;\n\t\t  var SLASH_DOT_REGEX = /(?:\\/|^)\\.(?=\\/)/g;\n\t\t  var SLASH_DOT_DOT_REGEX = /(?:\\/|^)\\.\\.\\/(?!\\.\\.\\/)[^\\/]*(?=\\/)/g;\n\n\t\t  var URLToolkit = {\n\t\t    // If opts.alwaysNormalize is true then the path will always be normalized even when it starts with / or //\n\t\t    // E.g\n\t\t    // With opts.alwaysNormalize = false (default, spec compliant)\n\t\t    // http://a.com/b/cd + /e/f/../g => http://a.com/e/f/../g\n\t\t    // With opts.alwaysNormalize = true (not spec compliant)\n\t\t    // http://a.com/b/cd + /e/f/../g => http://a.com/e/g\n\t\t    buildAbsoluteURL: function (baseURL, relativeURL, opts) {\n\t\t      opts = opts || {};\n\t\t      // remove any remaining space and CRLF\n\t\t      baseURL = baseURL.trim();\n\t\t      relativeURL = relativeURL.trim();\n\t\t      if (!relativeURL) {\n\t\t        // 2a) If the embedded URL is entirely empty, it inherits the\n\t\t        // entire base URL (i.e., is set equal to the base URL)\n\t\t        // and we are done.\n\t\t        if (!opts.alwaysNormalize) {\n\t\t          return baseURL;\n\t\t        }\n\t\t        var basePartsForNormalise = URLToolkit.parseURL(baseURL);\n\t\t        if (!basePartsForNormalise) {\n\t\t          throw new Error('Error trying to parse base URL.');\n\t\t        }\n\t\t        basePartsForNormalise.path = URLToolkit.normalizePath(\n\t\t          basePartsForNormalise.path\n\t\t        );\n\t\t        return URLToolkit.buildURLFromParts(basePartsForNormalise);\n\t\t      }\n\t\t      var relativeParts = URLToolkit.parseURL(relativeURL);\n\t\t      if (!relativeParts) {\n\t\t        throw new Error('Error trying to parse relative URL.');\n\t\t      }\n\t\t      if (relativeParts.scheme) {\n\t\t        // 2b) If the embedded URL starts with a scheme name, it is\n\t\t        // interpreted as an absolute URL and we are done.\n\t\t        if (!opts.alwaysNormalize) {\n\t\t          return relativeURL;\n\t\t        }\n\t\t        relativeParts.path = URLToolkit.normalizePath(relativeParts.path);\n\t\t        return URLToolkit.buildURLFromParts(relativeParts);\n\t\t      }\n\t\t      var baseParts = URLToolkit.parseURL(baseURL);\n\t\t      if (!baseParts) {\n\t\t        throw new Error('Error trying to parse base URL.');\n\t\t      }\n\t\t      if (!baseParts.netLoc && baseParts.path && baseParts.path[0] !== '/') {\n\t\t        // If netLoc missing and path doesn't start with '/', assume everthing before the first '/' is the netLoc\n\t\t        // This causes 'example.com/a' to be handled as '//example.com/a' instead of '/example.com/a'\n\t\t        var pathParts = FIRST_SEGMENT_REGEX.exec(baseParts.path);\n\t\t        baseParts.netLoc = pathParts[1];\n\t\t        baseParts.path = pathParts[2];\n\t\t      }\n\t\t      if (baseParts.netLoc && !baseParts.path) {\n\t\t        baseParts.path = '/';\n\t\t      }\n\t\t      var builtParts = {\n\t\t        // 2c) Otherwise, the embedded URL inherits the scheme of\n\t\t        // the base URL.\n\t\t        scheme: baseParts.scheme,\n\t\t        netLoc: relativeParts.netLoc,\n\t\t        path: null,\n\t\t        params: relativeParts.params,\n\t\t        query: relativeParts.query,\n\t\t        fragment: relativeParts.fragment,\n\t\t      };\n\t\t      if (!relativeParts.netLoc) {\n\t\t        // 3) If the embedded URL's <net_loc> is non-empty, we skip to\n\t\t        // Step 7.  Otherwise, the embedded URL inherits the <net_loc>\n\t\t        // (if any) of the base URL.\n\t\t        builtParts.netLoc = baseParts.netLoc;\n\t\t        // 4) If the embedded URL path is preceded by a slash \"/\", the\n\t\t        // path is not relative and we skip to Step 7.\n\t\t        if (relativeParts.path[0] !== '/') {\n\t\t          if (!relativeParts.path) {\n\t\t            // 5) If the embedded URL path is empty (and not preceded by a\n\t\t            // slash), then the embedded URL inherits the base URL path\n\t\t            builtParts.path = baseParts.path;\n\t\t            // 5a) if the embedded URL's <params> is non-empty, we skip to\n\t\t            // step 7; otherwise, it inherits the <params> of the base\n\t\t            // URL (if any) and\n\t\t            if (!relativeParts.params) {\n\t\t              builtParts.params = baseParts.params;\n\t\t              // 5b) if the embedded URL's <query> is non-empty, we skip to\n\t\t              // step 7; otherwise, it inherits the <query> of the base\n\t\t              // URL (if any) and we skip to step 7.\n\t\t              if (!relativeParts.query) {\n\t\t                builtParts.query = baseParts.query;\n\t\t              }\n\t\t            }\n\t\t          } else {\n\t\t            // 6) The last segment of the base URL's path (anything\n\t\t            // following the rightmost slash \"/\", or the entire path if no\n\t\t            // slash is present) is removed and the embedded URL's path is\n\t\t            // appended in its place.\n\t\t            var baseURLPath = baseParts.path;\n\t\t            var newPath =\n\t\t              baseURLPath.substring(0, baseURLPath.lastIndexOf('/') + 1) +\n\t\t              relativeParts.path;\n\t\t            builtParts.path = URLToolkit.normalizePath(newPath);\n\t\t          }\n\t\t        }\n\t\t      }\n\t\t      if (builtParts.path === null) {\n\t\t        builtParts.path = opts.alwaysNormalize\n\t\t          ? URLToolkit.normalizePath(relativeParts.path)\n\t\t          : relativeParts.path;\n\t\t      }\n\t\t      return URLToolkit.buildURLFromParts(builtParts);\n\t\t    },\n\t\t    parseURL: function (url) {\n\t\t      var parts = URL_REGEX.exec(url);\n\t\t      if (!parts) {\n\t\t        return null;\n\t\t      }\n\t\t      return {\n\t\t        scheme: parts[1] || '',\n\t\t        netLoc: parts[2] || '',\n\t\t        path: parts[3] || '',\n\t\t        params: parts[4] || '',\n\t\t        query: parts[5] || '',\n\t\t        fragment: parts[6] || '',\n\t\t      };\n\t\t    },\n\t\t    normalizePath: function (path) {\n\t\t      // The following operations are\n\t\t      // then applied, in order, to the new path:\n\t\t      // 6a) All occurrences of \"./\", where \".\" is a complete path\n\t\t      // segment, are removed.\n\t\t      // 6b) If the path ends with \".\" as a complete path segment,\n\t\t      // that \".\" is removed.\n\t\t      path = path.split('').reverse().join('').replace(SLASH_DOT_REGEX, '');\n\t\t      // 6c) All occurrences of \"<segment>/../\", where <segment> is a\n\t\t      // complete path segment not equal to \"..\", are removed.\n\t\t      // Removal of these path segments is performed iteratively,\n\t\t      // removing the leftmost matching pattern on each iteration,\n\t\t      // until no matching pattern remains.\n\t\t      // 6d) If the path ends with \"<segment>/..\", where <segment> is a\n\t\t      // complete path segment not equal to \"..\", that\n\t\t      // \"<segment>/..\" is removed.\n\t\t      while (\n\t\t        path.length !== (path = path.replace(SLASH_DOT_DOT_REGEX, '')).length\n\t\t      ) {}\n\t\t      return path.split('').reverse().join('');\n\t\t    },\n\t\t    buildURLFromParts: function (parts) {\n\t\t      return (\n\t\t        parts.scheme +\n\t\t        parts.netLoc +\n\t\t        parts.path +\n\t\t        parts.params +\n\t\t        parts.query +\n\t\t        parts.fragment\n\t\t      );\n\t\t    },\n\t\t  };\n\n\t\t  module.exports = URLToolkit;\n\t\t})(); \n\t} (urlToolkit));\n\treturn urlToolkit.exports;\n}\n\nvar urlToolkitExports = requireUrlToolkit();\n\nclass LoadStats {\n  constructor() {\n    this.aborted = false;\n    this.loaded = 0;\n    this.retry = 0;\n    this.total = 0;\n    this.chunkCount = 0;\n    this.bwEstimate = 0;\n    this.loading = {\n      start: 0,\n      first: 0,\n      end: 0\n    };\n    this.parsing = {\n      start: 0,\n      end: 0\n    };\n    this.buffering = {\n      start: 0,\n      first: 0,\n      end: 0\n    };\n  }\n}\n\nvar ElementaryStreamTypes = {\n  AUDIO: \"audio\",\n  VIDEO: \"video\",\n  AUDIOVIDEO: \"audiovideo\"\n};\nclass BaseSegment {\n  constructor(base) {\n    this._byteRange = null;\n    this._url = null;\n    this._stats = null;\n    this._streams = null;\n    // baseurl is the URL to the playlist\n    this.base = void 0;\n    // relurl is the portion of the URL that comes from inside the playlist.\n    this.relurl = void 0;\n    if (typeof base === 'string') {\n      base = {\n        url: base\n      };\n    }\n    this.base = base;\n    makeEnumerable(this, 'stats');\n  }\n\n  // setByteRange converts a EXT-X-BYTERANGE attribute into a two element array\n  setByteRange(value, previous) {\n    const params = value.split('@', 2);\n    let start;\n    if (params.length === 1) {\n      start = (previous == null ? void 0 : previous.byteRangeEndOffset) || 0;\n    } else {\n      start = parseInt(params[1]);\n    }\n    this._byteRange = [start, parseInt(params[0]) + start];\n  }\n  get baseurl() {\n    return this.base.url;\n  }\n  get byteRange() {\n    if (this._byteRange === null) {\n      return [];\n    }\n    return this._byteRange;\n  }\n  get byteRangeStartOffset() {\n    return this.byteRange[0];\n  }\n  get byteRangeEndOffset() {\n    return this.byteRange[1];\n  }\n  get elementaryStreams() {\n    if (this._streams === null) {\n      this._streams = {\n        [ElementaryStreamTypes.AUDIO]: null,\n        [ElementaryStreamTypes.VIDEO]: null,\n        [ElementaryStreamTypes.AUDIOVIDEO]: null\n      };\n    }\n    return this._streams;\n  }\n  set elementaryStreams(value) {\n    this._streams = value;\n  }\n  get hasStats() {\n    return this._stats !== null;\n  }\n  get hasStreams() {\n    return this._streams !== null;\n  }\n  get stats() {\n    if (this._stats === null) {\n      this._stats = new LoadStats();\n    }\n    return this._stats;\n  }\n  set stats(value) {\n    this._stats = value;\n  }\n  get url() {\n    if (!this._url && this.baseurl && this.relurl) {\n      this._url = urlToolkitExports.buildAbsoluteURL(this.baseurl, this.relurl, {\n        alwaysNormalize: true\n      });\n    }\n    return this._url || '';\n  }\n  set url(value) {\n    this._url = value;\n  }\n  clearElementaryStreamInfo() {\n    const {\n      elementaryStreams\n    } = this;\n    elementaryStreams[ElementaryStreamTypes.AUDIO] = null;\n    elementaryStreams[ElementaryStreamTypes.VIDEO] = null;\n    elementaryStreams[ElementaryStreamTypes.AUDIOVIDEO] = null;\n  }\n}\nfunction isMediaFragment(frag) {\n  return frag.sn !== 'initSegment';\n}\n\n/**\n * Object representing parsed data from an HLS Segment. Found in {@link hls.js#LevelDetails.fragments}.\n */\nclass Fragment extends BaseSegment {\n  constructor(type, base) {\n    super(base);\n    this._decryptdata = null;\n    this._programDateTime = null;\n    this._ref = null;\n    // Approximate bit rate of the fragment expressed in bits per second (bps) as indicated by the last EXT-X-BITRATE (kbps) tag\n    this._bitrate = void 0;\n    this.rawProgramDateTime = null;\n    this.tagList = [];\n    // EXTINF has to be present for a m3u8 to be considered valid\n    this.duration = 0;\n    // sn notates the sequence number for a segment, and if set to a string can be 'initSegment'\n    this.sn = 0;\n    // levelkeys are the EXT-X-KEY tags that apply to this segment for decryption\n    // core difference from the private field _decryptdata is the lack of the initialized IV\n    // _decryptdata will set the IV for this segment based on the segment number in the fragment\n    this.levelkeys = void 0;\n    // A string representing the fragment type\n    this.type = void 0;\n    // A reference to the loader. Set while the fragment is loading, and removed afterwards. Used to abort fragment loading\n    this.loader = null;\n    // A reference to the key loader. Set while the key is loading, and removed afterwards. Used to abort key loading\n    this.keyLoader = null;\n    // The level/track index to which the fragment belongs\n    this.level = -1;\n    // The continuity counter of the fragment\n    this.cc = 0;\n    // The starting Presentation Time Stamp (PTS) of the fragment. Set after transmux complete.\n    this.startPTS = void 0;\n    // The ending Presentation Time Stamp (PTS) of the fragment. Set after transmux complete.\n    this.endPTS = void 0;\n    // The starting Decode Time Stamp (DTS) of the fragment. Set after transmux complete.\n    this.startDTS = void 0;\n    // The ending Decode Time Stamp (DTS) of the fragment. Set after transmux complete.\n    this.endDTS = void 0;\n    // The start time of the fragment, as listed in the manifest. Updated after transmux complete.\n    this.start = 0;\n    // The offset time (seconds) of the fragment from the start of the Playlist\n    this.playlistOffset = 0;\n    // Set by `updateFragPTSDTS` in level-helper\n    this.deltaPTS = void 0;\n    // The maximum starting Presentation Time Stamp (audio/video PTS) of the fragment. Set after transmux complete.\n    this.maxStartPTS = void 0;\n    // The minimum ending Presentation Time Stamp (audio/video PTS) of the fragment. Set after transmux complete.\n    this.minEndPTS = void 0;\n    // Init Segment bytes (unset for media segments)\n    this.data = void 0;\n    // A flag indicating whether the segment was downloaded in order to test bitrate, and was not buffered\n    this.bitrateTest = false;\n    // #EXTINF  segment title\n    this.title = null;\n    // The Media Initialization Section for this segment\n    this.initSegment = null;\n    // Fragment is the last fragment in the media playlist\n    this.endList = void 0;\n    // Fragment is marked by an EXT-X-GAP tag indicating that it does not contain media data and should not be loaded\n    this.gap = void 0;\n    // Deprecated\n    this.urlId = 0;\n    this.type = type;\n  }\n  get byteLength() {\n    if (this.hasStats) {\n      const total = this.stats.total;\n      if (total) {\n        return total;\n      }\n    }\n    if (this.byteRange.length) {\n      const start = this.byteRange[0];\n      const end = this.byteRange[1];\n      if (isFiniteNumber(start) && isFiniteNumber(end)) {\n        return end - start;\n      }\n    }\n    return null;\n  }\n  get bitrate() {\n    if (this.byteLength) {\n      return this.byteLength * 8 / this.duration;\n    }\n    if (this._bitrate) {\n      return this._bitrate;\n    }\n    return null;\n  }\n  set bitrate(value) {\n    this._bitrate = value;\n  }\n  get decryptdata() {\n    var _this$_decryptdata;\n    const {\n      levelkeys\n    } = this;\n    if (!levelkeys || levelkeys.NONE) {\n      return null;\n    }\n    if (levelkeys.identity) {\n      if (!this._decryptdata) {\n        this._decryptdata = levelkeys.identity.getDecryptData(this.sn);\n      }\n    } else if (!((_this$_decryptdata = this._decryptdata) != null && _this$_decryptdata.keyId)) {\n      const keyFormats = Object.keys(levelkeys);\n      if (keyFormats.length === 1) {\n        const levelKey = this._decryptdata = levelkeys[keyFormats[0]] || null;\n        if (levelKey) {\n          this._decryptdata = levelKey.getDecryptData(this.sn, levelkeys);\n        }\n      }\n    }\n    return this._decryptdata;\n  }\n  get end() {\n    return this.start + this.duration;\n  }\n  get endProgramDateTime() {\n    if (this.programDateTime === null) {\n      return null;\n    }\n    const duration = !isFiniteNumber(this.duration) ? 0 : this.duration;\n    return this.programDateTime + duration * 1000;\n  }\n  get encrypted() {\n    var _this$_decryptdata2;\n    // At the m3u8-parser level we need to add support for manifest signalled keyformats\n    // when we want the fragment to start reporting that it is encrypted.\n    // Currently, keyFormat will only be set for identity keys\n    if ((_this$_decryptdata2 = this._decryptdata) != null && _this$_decryptdata2.encrypted) {\n      return true;\n    } else if (this.levelkeys) {\n      var _this$levelkeys$keyFo;\n      const keyFormats = Object.keys(this.levelkeys);\n      const len = keyFormats.length;\n      if (len > 1 || len === 1 && (_this$levelkeys$keyFo = this.levelkeys[keyFormats[0]]) != null && _this$levelkeys$keyFo.encrypted) {\n        return true;\n      }\n    }\n    return false;\n  }\n  get programDateTime() {\n    if (this._programDateTime === null && this.rawProgramDateTime) {\n      this.programDateTime = Date.parse(this.rawProgramDateTime);\n    }\n    return this._programDateTime;\n  }\n  set programDateTime(value) {\n    if (!isFiniteNumber(value)) {\n      this._programDateTime = this.rawProgramDateTime = null;\n      return;\n    }\n    this._programDateTime = value;\n  }\n  get ref() {\n    if (!isMediaFragment(this)) {\n      return null;\n    }\n    if (!this._ref) {\n      this._ref = {\n        base: this.base,\n        start: this.start,\n        duration: this.duration,\n        sn: this.sn,\n        programDateTime: this.programDateTime\n      };\n    }\n    return this._ref;\n  }\n  addStart(value) {\n    this.setStart(this.start + value);\n  }\n  setStart(value) {\n    this.start = value;\n    if (this._ref) {\n      this._ref.start = value;\n    }\n  }\n  setDuration(value) {\n    this.duration = value;\n    if (this._ref) {\n      this._ref.duration = value;\n    }\n  }\n  setKeyFormat(keyFormat) {\n    const levelkeys = this.levelkeys;\n    if (levelkeys) {\n      var _this$_decryptdata3;\n      const key = levelkeys[keyFormat];\n      if (key && !((_this$_decryptdata3 = this._decryptdata) != null && _this$_decryptdata3.keyId)) {\n        this._decryptdata = key.getDecryptData(this.sn, levelkeys);\n      }\n    }\n  }\n  abortRequests() {\n    var _this$loader, _this$keyLoader;\n    (_this$loader = this.loader) == null || _this$loader.abort();\n    (_this$keyLoader = this.keyLoader) == null || _this$keyLoader.abort();\n  }\n  setElementaryStreamInfo(type, startPTS, endPTS, startDTS, endDTS, partial = false) {\n    const {\n      elementaryStreams\n    } = this;\n    const info = elementaryStreams[type];\n    if (!info) {\n      elementaryStreams[type] = {\n        startPTS,\n        endPTS,\n        startDTS,\n        endDTS,\n        partial\n      };\n      return;\n    }\n    info.startPTS = Math.min(info.startPTS, startPTS);\n    info.endPTS = Math.max(info.endPTS, endPTS);\n    info.startDTS = Math.min(info.startDTS, startDTS);\n    info.endDTS = Math.max(info.endDTS, endDTS);\n  }\n}\n\n/**\n * Object representing parsed data from an HLS Partial Segment. Found in {@link hls.js#LevelDetails.partList}.\n */\nclass Part extends BaseSegment {\n  constructor(partAttrs, frag, base, index, previous) {\n    super(base);\n    this.fragOffset = 0;\n    this.duration = 0;\n    this.gap = false;\n    this.independent = false;\n    this.relurl = void 0;\n    this.fragment = void 0;\n    this.index = void 0;\n    this.duration = partAttrs.decimalFloatingPoint('DURATION');\n    this.gap = partAttrs.bool('GAP');\n    this.independent = partAttrs.bool('INDEPENDENT');\n    this.relurl = partAttrs.enumeratedString('URI');\n    this.fragment = frag;\n    this.index = index;\n    const byteRange = partAttrs.enumeratedString('BYTERANGE');\n    if (byteRange) {\n      this.setByteRange(byteRange, previous);\n    }\n    if (previous) {\n      this.fragOffset = previous.fragOffset + previous.duration;\n    }\n  }\n  get start() {\n    return this.fragment.start + this.fragOffset;\n  }\n  get end() {\n    return this.start + this.duration;\n  }\n  get loaded() {\n    const {\n      elementaryStreams\n    } = this;\n    return !!(elementaryStreams.audio || elementaryStreams.video || elementaryStreams.audiovideo);\n  }\n}\nfunction getOwnPropertyDescriptorFromPrototypeChain(object, property) {\n  const prototype = Object.getPrototypeOf(object);\n  if (prototype) {\n    const propertyDescriptor = Object.getOwnPropertyDescriptor(prototype, property);\n    if (propertyDescriptor) {\n      return propertyDescriptor;\n    }\n    return getOwnPropertyDescriptorFromPrototypeChain(prototype, property);\n  }\n}\nfunction makeEnumerable(object, property) {\n  const d = getOwnPropertyDescriptorFromPrototypeChain(object, property);\n  if (d) {\n    d.enumerable = true;\n    Object.defineProperty(object, property, d);\n  }\n}\n\nconst UINT32_MAX$1 = Math.pow(2, 32) - 1;\nconst push = [].push;\n\n// We are using fixed track IDs for driving the MP4 remuxer\n// instead of following the TS PIDs.\n// There is no reason not to do this and some browsers/SourceBuffer-demuxers\n// may not like if there are TrackID \"switches\"\n// See https://github.com/video-dev/hls.js/issues/1331\n// Here we are mapping our internal track types to constant MP4 track IDs\n// With MSE currently one can only have one track of each, and we are muxing\n// whatever video/audio rendition in them.\nconst RemuxerTrackIdConfig = {\n  video: 1,\n  audio: 2,\n  id3: 3,\n  text: 4\n};\nfunction bin2str(data) {\n  return String.fromCharCode.apply(null, data);\n}\nfunction readUint16(buffer, offset) {\n  const val = buffer[offset] << 8 | buffer[offset + 1];\n  return val < 0 ? 65536 + val : val;\n}\nfunction readUint32(buffer, offset) {\n  const val = readSint32(buffer, offset);\n  return val < 0 ? 4294967296 + val : val;\n}\nfunction readUint64(buffer, offset) {\n  let result = readUint32(buffer, offset);\n  result *= Math.pow(2, 32);\n  result += readUint32(buffer, offset + 4);\n  return result;\n}\nfunction readSint32(buffer, offset) {\n  return buffer[offset] << 24 | buffer[offset + 1] << 16 | buffer[offset + 2] << 8 | buffer[offset + 3];\n}\n\n// Find \"moof\" box\nfunction hasMoofData(data) {\n  const end = data.byteLength;\n  for (let i = 0; i < end;) {\n    const size = readUint32(data, i);\n    if (size > 8 && data[i + 4] === 0x6d && data[i + 5] === 0x6f && data[i + 6] === 0x6f && data[i + 7] === 0x66) {\n      return true;\n    }\n    i = size > 1 ? i + size : end;\n  }\n  return false;\n}\n\n// Find the data for a box specified by its path\nfunction findBox(data, path) {\n  const results = [];\n  if (!path.length) {\n    // short-circuit the search for empty paths\n    return results;\n  }\n  const end = data.byteLength;\n  for (let i = 0; i < end;) {\n    const size = readUint32(data, i);\n    const type = bin2str(data.subarray(i + 4, i + 8));\n    const endbox = size > 1 ? i + size : end;\n    if (type === path[0]) {\n      if (path.length === 1) {\n        // this is the end of the path and we've found the box we were\n        // looking for\n        results.push(data.subarray(i + 8, endbox));\n      } else {\n        // recursively search for the next box along the path\n        const subresults = findBox(data.subarray(i + 8, endbox), path.slice(1));\n        if (subresults.length) {\n          push.apply(results, subresults);\n        }\n      }\n    }\n    i = endbox;\n  }\n\n  // we've finished searching all of data\n  return results;\n}\nfunction parseSegmentIndex(sidx) {\n  const references = [];\n  const version = sidx[0];\n\n  // set initial offset, we skip the reference ID (not needed)\n  let index = 8;\n  const timescale = readUint32(sidx, index);\n  index += 4;\n  let earliestPresentationTime = 0;\n  let firstOffset = 0;\n  if (version === 0) {\n    earliestPresentationTime = readUint32(sidx, index);\n    firstOffset = readUint32(sidx, index + 4);\n    index += 8;\n  } else {\n    earliestPresentationTime = readUint64(sidx, index);\n    firstOffset = readUint64(sidx, index + 8);\n    index += 16;\n  }\n\n  // skip reserved\n  index += 2;\n  let startByte = sidx.length + firstOffset;\n  const referencesCount = readUint16(sidx, index);\n  index += 2;\n  for (let i = 0; i < referencesCount; i++) {\n    let referenceIndex = index;\n    const referenceInfo = readUint32(sidx, referenceIndex);\n    referenceIndex += 4;\n    const referenceSize = referenceInfo & 0x7fffffff;\n    const referenceType = (referenceInfo & 0x80000000) >>> 31;\n    if (referenceType === 1) {\n      logger.warn('SIDX has hierarchical references (not supported)');\n      return null;\n    }\n    const subsegmentDuration = readUint32(sidx, referenceIndex);\n    referenceIndex += 4;\n    references.push({\n      referenceSize,\n      subsegmentDuration,\n      // unscaled\n      info: {\n        duration: subsegmentDuration / timescale,\n        start: startByte,\n        end: startByte + referenceSize - 1\n      }\n    });\n    startByte += referenceSize;\n\n    // Skipping 1 bit for |startsWithSap|, 3 bits for |sapType|, and 28 bits\n    // for |sapDelta|.\n    referenceIndex += 4;\n\n    // skip to next ref\n    index = referenceIndex;\n  }\n  return {\n    earliestPresentationTime,\n    timescale,\n    version,\n    referencesCount,\n    references\n  };\n}\n\n/**\n * Parses an MP4 initialization segment and extracts stream type and\n * timescale values for any declared tracks. Timescale values indicate the\n * number of clock ticks per second to assume for time-based values\n * elsewhere in the MP4.\n *\n * To determine the start time of an MP4, you need two pieces of\n * information: the timescale unit and the earliest base media decode\n * time. Multiple timescales can be specified within an MP4 but the\n * base media decode time is always expressed in the timescale from\n * the media header box for the track:\n * ```\n * moov > trak > mdia > mdhd.timescale\n * moov > trak > mdia > hdlr\n * ```\n * @param initSegment the bytes of the init segment\n * @returns a hash of track type to timescale values or null if\n * the init segment is malformed.\n */\n\nfunction parseInitSegment(initSegment) {\n  const result = [];\n  const traks = findBox(initSegment, ['moov', 'trak']);\n  for (let i = 0; i < traks.length; i++) {\n    const trak = traks[i];\n    const tkhd = findBox(trak, ['tkhd'])[0];\n    if (tkhd) {\n      let version = tkhd[0];\n      const trackId = readUint32(tkhd, version === 0 ? 12 : 20);\n      const mdhd = findBox(trak, ['mdia', 'mdhd'])[0];\n      if (mdhd) {\n        version = mdhd[0];\n        const timescale = readUint32(mdhd, version === 0 ? 12 : 20);\n        const hdlr = findBox(trak, ['mdia', 'hdlr'])[0];\n        if (hdlr) {\n          const hdlrType = bin2str(hdlr.subarray(8, 12));\n          const type = {\n            soun: ElementaryStreamTypes.AUDIO,\n            vide: ElementaryStreamTypes.VIDEO\n          }[hdlrType];\n          // Parse codec details\n          const stsdBox = findBox(trak, ['mdia', 'minf', 'stbl', 'stsd'])[0];\n          const stsd = parseStsd(stsdBox);\n          if (type) {\n            // Add 'audio', 'video', and 'audiovideo' track records that will map to SourceBuffers\n            result[trackId] = {\n              timescale,\n              type,\n              stsd\n            };\n            result[type] = _objectSpread2({\n              timescale,\n              id: trackId\n            }, stsd);\n          } else {\n            // Add 'meta' and other track records\n            result[trackId] = {\n              timescale,\n              type: hdlrType,\n              stsd\n            };\n          }\n        }\n      }\n    }\n  }\n  const trex = findBox(initSegment, ['moov', 'mvex', 'trex']);\n  trex.forEach(trex => {\n    const trackId = readUint32(trex, 4);\n    const track = result[trackId];\n    if (track) {\n      track.default = {\n        duration: readUint32(trex, 12),\n        flags: readUint32(trex, 20)\n      };\n    }\n  });\n  return result;\n}\nfunction parseStsd(stsd) {\n  const sampleEntries = stsd.subarray(8);\n  const sampleEntriesEnd = sampleEntries.subarray(8 + 78);\n  const fourCC = bin2str(sampleEntries.subarray(4, 8));\n  let codec = fourCC;\n  let supplemental;\n  const encrypted = fourCC === 'enca' || fourCC === 'encv';\n  if (encrypted) {\n    const encBox = findBox(sampleEntries, [fourCC])[0];\n    const encBoxChildren = encBox.subarray(fourCC === 'enca' ? 28 : 78);\n    const sinfs = findBox(encBoxChildren, ['sinf']);\n    sinfs.forEach(sinf => {\n      const schm = findBox(sinf, ['schm'])[0];\n      if (schm) {\n        const scheme = bin2str(schm.subarray(4, 8));\n        if (scheme === 'cbcs' || scheme === 'cenc') {\n          const frma = findBox(sinf, ['frma'])[0];\n          if (frma) {\n            // for encrypted content codec fourCC will be in frma\n            codec = bin2str(frma);\n          }\n        }\n      }\n    });\n  }\n  const codecFourCC = codec;\n  switch (codec) {\n    case 'avc1':\n    case 'avc2':\n    case 'avc3':\n    case 'avc4':\n      {\n        // extract profile + compatibility + level out of avcC box\n        const avcCBox = findBox(sampleEntriesEnd, ['avcC'])[0];\n        if (avcCBox && avcCBox.length > 3) {\n          codec += '.' + toHex(avcCBox[1]) + toHex(avcCBox[2]) + toHex(avcCBox[3]);\n          supplemental = parseSupplementalDoViCodec(codecFourCC === 'avc1' ? 'dva1' : 'dvav', sampleEntriesEnd);\n        }\n        break;\n      }\n    case 'mp4a':\n      {\n        const codecBox = findBox(sampleEntries, [fourCC])[0];\n        const esdsBox = findBox(codecBox.subarray(28), ['esds'])[0];\n        if (esdsBox && esdsBox.length > 7) {\n          let i = 4;\n          // ES Descriptor tag\n          if (esdsBox[i++] !== 0x03) {\n            break;\n          }\n          i = skipBERInteger(esdsBox, i);\n          i += 2; // skip es_id;\n          const flags = esdsBox[i++];\n          if (flags & 0x80) {\n            i += 2; // skip dependency es_id\n          }\n          if (flags & 0x40) {\n            i += esdsBox[i++]; // skip URL\n          }\n          // Decoder config descriptor\n          if (esdsBox[i++] !== 0x04) {\n            break;\n          }\n          i = skipBERInteger(esdsBox, i);\n          const objectType = esdsBox[i++];\n          if (objectType === 0x40) {\n            codec += '.' + toHex(objectType);\n          } else {\n            break;\n          }\n          i += 12;\n          // Decoder specific info\n          if (esdsBox[i++] !== 0x05) {\n            break;\n          }\n          i = skipBERInteger(esdsBox, i);\n          const firstByte = esdsBox[i++];\n          let audioObjectType = (firstByte & 0xf8) >> 3;\n          if (audioObjectType === 31) {\n            audioObjectType += 1 + ((firstByte & 0x7) << 3) + ((esdsBox[i] & 0xe0) >> 5);\n          }\n          codec += '.' + audioObjectType;\n        }\n        break;\n      }\n    case 'hvc1':\n    case 'hev1':\n      {\n        const hvcCBox = findBox(sampleEntriesEnd, ['hvcC'])[0];\n        if (hvcCBox && hvcCBox.length > 12) {\n          const profileByte = hvcCBox[1];\n          const profileSpace = ['', 'A', 'B', 'C'][profileByte >> 6];\n          const generalProfileIdc = profileByte & 0x1f;\n          const profileCompat = readUint32(hvcCBox, 2);\n          const tierFlag = (profileByte & 0x20) >> 5 ? 'H' : 'L';\n          const levelIDC = hvcCBox[12];\n          const constraintIndicator = hvcCBox.subarray(6, 12);\n          codec += '.' + profileSpace + generalProfileIdc;\n          codec += '.' + reverse32BitInt(profileCompat).toString(16).toUpperCase();\n          codec += '.' + tierFlag + levelIDC;\n          let constraintString = '';\n          for (let i = constraintIndicator.length; i--;) {\n            const byte = constraintIndicator[i];\n            if (byte || constraintString) {\n              const encodedByte = byte.toString(16).toUpperCase();\n              constraintString = '.' + encodedByte + constraintString;\n            }\n          }\n          codec += constraintString;\n        }\n        supplemental = parseSupplementalDoViCodec(codecFourCC == 'hev1' ? 'dvhe' : 'dvh1', sampleEntriesEnd);\n        break;\n      }\n    case 'dvh1':\n    case 'dvhe':\n    case 'dvav':\n    case 'dva1':\n    case 'dav1':\n      {\n        codec = parseSupplementalDoViCodec(codec, sampleEntriesEnd) || codec;\n        break;\n      }\n    case 'vp09':\n      {\n        const vpcCBox = findBox(sampleEntriesEnd, ['vpcC'])[0];\n        if (vpcCBox && vpcCBox.length > 6) {\n          const profile = vpcCBox[4];\n          const level = vpcCBox[5];\n          const bitDepth = vpcCBox[6] >> 4 & 0x0f;\n          codec += '.' + addLeadingZero(profile) + '.' + addLeadingZero(level) + '.' + addLeadingZero(bitDepth);\n        }\n        break;\n      }\n    case 'av01':\n      {\n        const av1CBox = findBox(sampleEntriesEnd, ['av1C'])[0];\n        if (av1CBox && av1CBox.length > 2) {\n          const profile = av1CBox[1] >>> 5;\n          const level = av1CBox[1] & 0x1f;\n          const tierFlag = av1CBox[2] >>> 7 ? 'H' : 'M';\n          const highBitDepth = (av1CBox[2] & 0x40) >> 6;\n          const twelveBit = (av1CBox[2] & 0x20) >> 5;\n          const bitDepth = profile === 2 && highBitDepth ? twelveBit ? 12 : 10 : highBitDepth ? 10 : 8;\n          const monochrome = (av1CBox[2] & 0x10) >> 4;\n          const chromaSubsamplingX = (av1CBox[2] & 0x08) >> 3;\n          const chromaSubsamplingY = (av1CBox[2] & 0x04) >> 2;\n          const chromaSamplePosition = av1CBox[2] & 0x03;\n          // TODO: parse color_description_present_flag\n          // default it to BT.709/limited range for now\n          // more info https://aomediacodec.github.io/av1-isobmff/#av1codecconfigurationbox-syntax\n          const colorPrimaries = 1;\n          const transferCharacteristics = 1;\n          const matrixCoefficients = 1;\n          const videoFullRangeFlag = 0;\n          codec += '.' + profile + '.' + addLeadingZero(level) + tierFlag + '.' + addLeadingZero(bitDepth) + '.' + monochrome + '.' + chromaSubsamplingX + chromaSubsamplingY + chromaSamplePosition + '.' + addLeadingZero(colorPrimaries) + '.' + addLeadingZero(transferCharacteristics) + '.' + addLeadingZero(matrixCoefficients) + '.' + videoFullRangeFlag;\n          supplemental = parseSupplementalDoViCodec('dav1', sampleEntriesEnd);\n        }\n        break;\n      }\n  }\n  return {\n    codec,\n    encrypted,\n    supplemental\n  };\n}\nfunction parseSupplementalDoViCodec(fourCC, sampleEntriesEnd) {\n  const dvvCResult = findBox(sampleEntriesEnd, ['dvvC']); // used by DoVi Profile 8 to 10\n  const dvXCBox = dvvCResult.length ? dvvCResult[0] : findBox(sampleEntriesEnd, ['dvcC'])[0]; // used by DoVi Profiles up to 7 and 20\n  if (dvXCBox) {\n    const doViProfile = dvXCBox[2] >> 1 & 0x7f;\n    const doViLevel = dvXCBox[2] << 5 & 0x20 | dvXCBox[3] >> 3 & 0x1f;\n    return fourCC + '.' + addLeadingZero(doViProfile) + '.' + addLeadingZero(doViLevel);\n  }\n}\nfunction reverse32BitInt(val) {\n  let result = 0;\n  for (let i = 0; i < 32; i++) {\n    result |= (val >> i & 1) << 32 - 1 - i;\n  }\n  return result >>> 0;\n}\nfunction skipBERInteger(bytes, i) {\n  const limit = i + 5;\n  while (bytes[i++] & 0x80 && i < limit) {\n    /* do nothing */\n  }\n  return i;\n}\nfunction toHex(x) {\n  return ('0' + x.toString(16).toUpperCase()).slice(-2);\n}\nfunction addLeadingZero(num) {\n  return (num < 10 ? '0' : '') + num;\n}\nfunction patchEncyptionData(initSegment, decryptdata) {\n  if (!initSegment || !decryptdata) {\n    return;\n  }\n  const keyId = decryptdata.keyId;\n  if (keyId && decryptdata.isCommonEncryption) {\n    applyToTencBoxes(initSegment, (tenc, isAudio) => {\n      // Look for default key id (keyID offset is always 8 within the tenc box):\n      const tencKeyId = tenc.subarray(8, 24);\n      if (!tencKeyId.some(b => b !== 0)) {\n        logger.log(`[eme] Patching keyId in 'enc${isAudio ? 'a' : 'v'}>sinf>>tenc' box: ${arrayToHex(tencKeyId)} -> ${arrayToHex(keyId)}`);\n        tenc.set(keyId, 8);\n      }\n    });\n  }\n}\nfunction parseKeyIdsFromTenc(initSegment) {\n  const keyIds = [];\n  applyToTencBoxes(initSegment, tenc => keyIds.push(tenc.subarray(8, 24)));\n  return keyIds;\n}\nfunction applyToTencBoxes(initSegment, predicate) {\n  const traks = findBox(initSegment, ['moov', 'trak']);\n  traks.forEach(trak => {\n    const stsd = findBox(trak, ['mdia', 'minf', 'stbl', 'stsd'])[0];\n    if (!stsd) return;\n    const sampleEntries = stsd.subarray(8);\n    let encBoxes = findBox(sampleEntries, ['enca']);\n    const isAudio = encBoxes.length > 0;\n    if (!isAudio) {\n      encBoxes = findBox(sampleEntries, ['encv']);\n    }\n    encBoxes.forEach(enc => {\n      const encBoxChildren = isAudio ? enc.subarray(28) : enc.subarray(78);\n      const sinfBoxes = findBox(encBoxChildren, ['sinf']);\n      sinfBoxes.forEach(sinf => {\n        const tenc = parseSinf(sinf);\n        if (tenc) {\n          predicate(tenc, isAudio);\n        }\n      });\n    });\n  });\n}\nfunction parseSinf(sinf) {\n  const schm = findBox(sinf, ['schm'])[0];\n  if (schm) {\n    const scheme = bin2str(schm.subarray(4, 8));\n    if (scheme === 'cbcs' || scheme === 'cenc') {\n      const tenc = findBox(sinf, ['schi', 'tenc'])[0];\n      if (tenc) {\n        return tenc;\n      }\n    }\n  }\n}\n\n/*\n  For Reference:\n  aligned(8) class TrackFragmentHeaderBox\n           extends FullBox(tfhd, 0, tf_flags){\n     unsigned int(32)  track_ID;\n     // all the following are optional fields\n     unsigned int(64)  base_data_offset;\n     unsigned int(32)  sample_description_index;\n     unsigned int(32)  default_sample_duration;\n     unsigned int(32)  default_sample_size;\n     unsigned int(32)  default_sample_flags\n  }\n */\n\nfunction getSampleData(data, initData, logger) {\n  const tracks = {};\n  const trafs = findBox(data, ['moof', 'traf']);\n  for (let i = 0; i < trafs.length; i++) {\n    const traf = trafs[i];\n    // There is only one tfhd & trun per traf\n    // This is true for CMAF style content, and we should perhaps check the ftyp\n    // and only look for a single trun then, but for ISOBMFF we should check\n    // for multiple track runs.\n    const tfhd = findBox(traf, ['tfhd'])[0];\n    // get the track id from the tfhd\n    const id = readUint32(tfhd, 4);\n    const track = initData[id];\n    if (!track) {\n      continue;\n    }\n    tracks[id] || (tracks[id] = {\n      start: NaN,\n      duration: 0,\n      sampleCount: 0,\n      timescale: track.timescale,\n      type: track.type\n    });\n    const trackTimes = tracks[id];\n    // get start DTS\n    const tfdt = findBox(traf, ['tfdt'])[0];\n    if (tfdt) {\n      const version = tfdt[0];\n      let baseTime = readUint32(tfdt, 4);\n      if (version === 1) {\n        // If value is too large, assume signed 64-bit. Negative track fragment decode times are invalid, but they exist in the wild.\n        // This prevents large values from being used for initPTS, which can cause playlist sync issues.\n        // https://github.com/video-dev/hls.js/issues/5303\n        if (baseTime === UINT32_MAX$1) {\n          logger.warn(`[mp4-demuxer]: Ignoring assumed invalid signed 64-bit track fragment decode time`);\n        } else {\n          baseTime *= UINT32_MAX$1 + 1;\n          baseTime += readUint32(tfdt, 8);\n        }\n      }\n      if (isFiniteNumber(baseTime) && (!isFiniteNumber(trackTimes.start) || baseTime < trackTimes.start)) {\n        trackTimes.start = baseTime;\n      }\n    }\n    const trackDefault = track.default;\n    const tfhdFlags = readUint32(tfhd, 0) | (trackDefault == null ? void 0 : trackDefault.flags);\n    let defaultSampleDuration = (trackDefault == null ? void 0 : trackDefault.duration) || 0;\n    if (tfhdFlags & 0x000008) {\n      // 0x000008 indicates the presence of the default_sample_duration field\n      if (tfhdFlags & 0x000002) {\n        // 0x000002 indicates the presence of the sample_description_index field, which precedes default_sample_duration\n        // If present, the default_sample_duration exists at byte offset 12\n        defaultSampleDuration = readUint32(tfhd, 12);\n      } else {\n        // Otherwise, the duration is at byte offset 8\n        defaultSampleDuration = readUint32(tfhd, 8);\n      }\n    }\n    const truns = findBox(traf, ['trun']);\n    let sampleDTS = trackTimes.start || 0;\n    let rawDuration = 0;\n    let sampleDuration = defaultSampleDuration;\n    for (let j = 0; j < truns.length; j++) {\n      const trun = truns[j];\n      const sampleCount = readUint32(trun, 4);\n      const sampleIndex = trackTimes.sampleCount;\n      trackTimes.sampleCount += sampleCount;\n      // Get duration from samples\n      const dataOffsetPresent = trun[3] & 0x01;\n      const firstSampleFlagsPresent = trun[3] & 0x04;\n      const sampleDurationPresent = trun[2] & 0x01;\n      const sampleSizePresent = trun[2] & 0x02;\n      const sampleFlagsPresent = trun[2] & 0x04;\n      const sampleCompositionTimeOffsetPresent = trun[2] & 0x08;\n      let offset = 8;\n      let remaining = sampleCount;\n      if (dataOffsetPresent) {\n        offset += 4;\n      }\n      if (firstSampleFlagsPresent && sampleCount) {\n        const isNonSyncSample = trun[offset + 1] & 0x01;\n        if (!isNonSyncSample && trackTimes.keyFrameIndex === undefined) {\n          trackTimes.keyFrameIndex = sampleIndex;\n        }\n        offset += 4;\n        if (sampleDurationPresent) {\n          sampleDuration = readUint32(trun, offset);\n          offset += 4;\n        } else {\n          sampleDuration = defaultSampleDuration;\n        }\n        if (sampleSizePresent) {\n          offset += 4;\n        }\n        if (sampleCompositionTimeOffsetPresent) {\n          offset += 4;\n        }\n        sampleDTS += sampleDuration;\n        rawDuration += sampleDuration;\n        remaining--;\n      }\n      while (remaining--) {\n        if (sampleDurationPresent) {\n          sampleDuration = readUint32(trun, offset);\n          offset += 4;\n        } else {\n          sampleDuration = defaultSampleDuration;\n        }\n        if (sampleSizePresent) {\n          offset += 4;\n        }\n        if (sampleFlagsPresent) {\n          const isNonSyncSample = trun[offset + 1] & 0x01;\n          if (!isNonSyncSample) {\n            if (trackTimes.keyFrameIndex === undefined) {\n              trackTimes.keyFrameIndex = trackTimes.sampleCount - (remaining + 1);\n              trackTimes.keyFrameStart = sampleDTS;\n            }\n          }\n          offset += 4;\n        }\n        if (sampleCompositionTimeOffsetPresent) {\n          offset += 4;\n        }\n        sampleDTS += sampleDuration;\n        rawDuration += sampleDuration;\n      }\n      if (!rawDuration && defaultSampleDuration) {\n        rawDuration += defaultSampleDuration * sampleCount;\n      }\n    }\n    trackTimes.duration += rawDuration;\n  }\n  if (!Object.keys(tracks).some(trackId => tracks[trackId].duration)) {\n    // If duration samples are not available in the traf use sidx subsegment_duration\n    let sidxMinStart = Infinity;\n    let sidxMaxEnd = 0;\n    const sidxs = findBox(data, ['sidx']);\n    for (let i = 0; i < sidxs.length; i++) {\n      const sidx = parseSegmentIndex(sidxs[i]);\n      if (sidx != null && sidx.references) {\n        sidxMinStart = Math.min(sidxMinStart, sidx.earliestPresentationTime / sidx.timescale);\n        const subSegmentDuration = sidx.references.reduce((dur, ref) => dur + ref.info.duration || 0, 0);\n        sidxMaxEnd = Math.max(sidxMaxEnd, subSegmentDuration + sidx.earliestPresentationTime / sidx.timescale);\n      }\n    }\n    if (sidxMaxEnd && isFiniteNumber(sidxMaxEnd)) {\n      Object.keys(tracks).forEach(trackId => {\n        if (!tracks[trackId].duration) {\n          tracks[trackId].duration = sidxMaxEnd * tracks[trackId].timescale - tracks[trackId].start;\n        }\n      });\n    }\n  }\n  return tracks;\n}\n\n// TODO: Check if the last moof+mdat pair is part of the valid range\nfunction segmentValidRange(data) {\n  const segmentedRange = {\n    valid: null,\n    remainder: null\n  };\n  const moofs = findBox(data, ['moof']);\n  if (moofs.length < 2) {\n    segmentedRange.remainder = data;\n    return segmentedRange;\n  }\n  const last = moofs[moofs.length - 1];\n  // Offset by 8 bytes; findBox offsets the start by as much\n  segmentedRange.valid = data.slice(0, last.byteOffset - 8);\n  segmentedRange.remainder = data.slice(last.byteOffset - 8);\n  return segmentedRange;\n}\nfunction appendUint8Array(data1, data2) {\n  const temp = new Uint8Array(data1.length + data2.length);\n  temp.set(data1);\n  temp.set(data2, data1.length);\n  return temp;\n}\nfunction parseSamples(timeOffset, track) {\n  const seiSamples = [];\n  const videoData = track.samples;\n  const timescale = track.timescale;\n  const trackId = track.id;\n  let isHEVCFlavor = false;\n  const moofs = findBox(videoData, ['moof']);\n  moofs.map(moof => {\n    const moofOffset = moof.byteOffset - 8;\n    const trafs = findBox(moof, ['traf']);\n    trafs.map(traf => {\n      // get the base media decode time from the tfdt\n      const baseTime = findBox(traf, ['tfdt']).map(tfdt => {\n        const version = tfdt[0];\n        let result = readUint32(tfdt, 4);\n        if (version === 1) {\n          result *= Math.pow(2, 32);\n          result += readUint32(tfdt, 8);\n        }\n        return result / timescale;\n      })[0];\n      if (baseTime !== undefined) {\n        timeOffset = baseTime;\n      }\n      return findBox(traf, ['tfhd']).map(tfhd => {\n        const id = readUint32(tfhd, 4);\n        const tfhdFlags = readUint32(tfhd, 0) & 0xffffff;\n        const baseDataOffsetPresent = (tfhdFlags & 0x000001) !== 0;\n        const sampleDescriptionIndexPresent = (tfhdFlags & 0x000002) !== 0;\n        const defaultSampleDurationPresent = (tfhdFlags & 0x000008) !== 0;\n        let defaultSampleDuration = 0;\n        const defaultSampleSizePresent = (tfhdFlags & 0x000010) !== 0;\n        let defaultSampleSize = 0;\n        const defaultSampleFlagsPresent = (tfhdFlags & 0x000020) !== 0;\n        let tfhdOffset = 8;\n        if (id === trackId) {\n          if (baseDataOffsetPresent) {\n            tfhdOffset += 8;\n          }\n          if (sampleDescriptionIndexPresent) {\n            tfhdOffset += 4;\n          }\n          if (defaultSampleDurationPresent) {\n            defaultSampleDuration = readUint32(tfhd, tfhdOffset);\n            tfhdOffset += 4;\n          }\n          if (defaultSampleSizePresent) {\n            defaultSampleSize = readUint32(tfhd, tfhdOffset);\n            tfhdOffset += 4;\n          }\n          if (defaultSampleFlagsPresent) {\n            tfhdOffset += 4;\n          }\n          if (track.type === 'video') {\n            isHEVCFlavor = isHEVC(track.codec);\n          }\n          findBox(traf, ['trun']).map(trun => {\n            const version = trun[0];\n            const flags = readUint32(trun, 0) & 0xffffff;\n            const dataOffsetPresent = (flags & 0x000001) !== 0;\n            let dataOffset = 0;\n            const firstSampleFlagsPresent = (flags & 0x000004) !== 0;\n            const sampleDurationPresent = (flags & 0x000100) !== 0;\n            let sampleDuration = 0;\n            const sampleSizePresent = (flags & 0x000200) !== 0;\n            let sampleSize = 0;\n            const sampleFlagsPresent = (flags & 0x000400) !== 0;\n            const sampleCompositionOffsetsPresent = (flags & 0x000800) !== 0;\n            let compositionOffset = 0;\n            const sampleCount = readUint32(trun, 4);\n            let trunOffset = 8; // past version, flags, and sample count\n\n            if (dataOffsetPresent) {\n              dataOffset = readUint32(trun, trunOffset);\n              trunOffset += 4;\n            }\n            if (firstSampleFlagsPresent) {\n              trunOffset += 4;\n            }\n            let sampleOffset = dataOffset + moofOffset;\n            for (let ix = 0; ix < sampleCount; ix++) {\n              if (sampleDurationPresent) {\n                sampleDuration = readUint32(trun, trunOffset);\n                trunOffset += 4;\n              } else {\n                sampleDuration = defaultSampleDuration;\n              }\n              if (sampleSizePresent) {\n                sampleSize = readUint32(trun, trunOffset);\n                trunOffset += 4;\n              } else {\n                sampleSize = defaultSampleSize;\n              }\n              if (sampleFlagsPresent) {\n                trunOffset += 4;\n              }\n              if (sampleCompositionOffsetsPresent) {\n                if (version === 0) {\n                  compositionOffset = readUint32(trun, trunOffset);\n                } else {\n                  compositionOffset = readSint32(trun, trunOffset);\n                }\n                trunOffset += 4;\n              }\n              if (track.type === ElementaryStreamTypes.VIDEO) {\n                let naluTotalSize = 0;\n                while (naluTotalSize < sampleSize) {\n                  const naluSize = readUint32(videoData, sampleOffset);\n                  sampleOffset += 4;\n                  if (isSEIMessage(isHEVCFlavor, videoData[sampleOffset])) {\n                    const data = videoData.subarray(sampleOffset, sampleOffset + naluSize);\n                    parseSEIMessageFromNALu(data, isHEVCFlavor ? 2 : 1, timeOffset + compositionOffset / timescale, seiSamples);\n                  }\n                  sampleOffset += naluSize;\n                  naluTotalSize += naluSize + 4;\n                }\n              }\n              timeOffset += sampleDuration / timescale;\n            }\n          });\n        }\n      });\n    });\n  });\n  return seiSamples;\n}\nfunction isHEVC(codec) {\n  if (!codec) {\n    return false;\n  }\n  const baseCodec = codec.substring(0, 4);\n  return baseCodec === 'hvc1' || baseCodec === 'hev1' ||\n  // Dolby Vision\n  baseCodec === 'dvh1' || baseCodec === 'dvhe';\n}\nfunction isSEIMessage(isHEVCFlavor, naluHeader) {\n  if (isHEVCFlavor) {\n    const naluType = naluHeader >> 1 & 0x3f;\n    return naluType === 39 || naluType === 40;\n  } else {\n    const naluType = naluHeader & 0x1f;\n    return naluType === 6;\n  }\n}\nfunction parseSEIMessageFromNALu(unescapedData, headerSize, pts, samples) {\n  const data = discardEPB(unescapedData);\n  let seiPtr = 0;\n  // skip nal header\n  seiPtr += headerSize;\n  let payloadType = 0;\n  let payloadSize = 0;\n  let b = 0;\n  while (seiPtr < data.length) {\n    payloadType = 0;\n    do {\n      if (seiPtr >= data.length) {\n        break;\n      }\n      b = data[seiPtr++];\n      payloadType += b;\n    } while (b === 0xff);\n\n    // Parse payload size.\n    payloadSize = 0;\n    do {\n      if (seiPtr >= data.length) {\n        break;\n      }\n      b = data[seiPtr++];\n      payloadSize += b;\n    } while (b === 0xff);\n    const leftOver = data.length - seiPtr;\n    // Create a variable to process the payload\n    let payPtr = seiPtr;\n\n    // Increment the seiPtr to the end of the payload\n    if (payloadSize < leftOver) {\n      seiPtr += payloadSize;\n    } else if (payloadSize > leftOver) {\n      // Some type of corruption has happened?\n      logger.error(`Malformed SEI payload. ${payloadSize} is too small, only ${leftOver} bytes left to parse.`);\n      // We might be able to parse some data, but let's be safe and ignore it.\n      break;\n    }\n    if (payloadType === 4) {\n      const countryCode = data[payPtr++];\n      if (countryCode === 181) {\n        const providerCode = readUint16(data, payPtr);\n        payPtr += 2;\n        if (providerCode === 49) {\n          const userStructure = readUint32(data, payPtr);\n          payPtr += 4;\n          if (userStructure === 0x47413934) {\n            const userDataType = data[payPtr++];\n\n            // Raw CEA-608 bytes wrapped in CEA-708 packet\n            if (userDataType === 3) {\n              const firstByte = data[payPtr++];\n              const totalCCs = 0x1f & firstByte;\n              const enabled = 0x40 & firstByte;\n              const totalBytes = enabled ? 2 + totalCCs * 3 : 0;\n              const byteArray = new Uint8Array(totalBytes);\n              if (enabled) {\n                byteArray[0] = firstByte;\n                for (let i = 1; i < totalBytes; i++) {\n                  byteArray[i] = data[payPtr++];\n                }\n              }\n              samples.push({\n                type: userDataType,\n                payloadType,\n                pts,\n                bytes: byteArray\n              });\n            }\n          }\n        }\n      }\n    } else if (payloadType === 5) {\n      if (payloadSize > 16) {\n        const uuidStrArray = [];\n        for (let i = 0; i < 16; i++) {\n          const _b = data[payPtr++].toString(16);\n          uuidStrArray.push(_b.length == 1 ? '0' + _b : _b);\n          if (i === 3 || i === 5 || i === 7 || i === 9) {\n            uuidStrArray.push('-');\n          }\n        }\n        const length = payloadSize - 16;\n        const userDataBytes = new Uint8Array(length);\n        for (let i = 0; i < length; i++) {\n          userDataBytes[i] = data[payPtr++];\n        }\n        samples.push({\n          payloadType,\n          pts,\n          uuid: uuidStrArray.join(''),\n          userData: utf8ArrayToStr(userDataBytes),\n          userDataBytes\n        });\n      }\n    }\n  }\n}\n\n/**\n * remove Emulation Prevention bytes from a RBSP\n */\nfunction discardEPB(data) {\n  const length = data.byteLength;\n  const EPBPositions = [];\n  let i = 1;\n\n  // Find all `Emulation Prevention Bytes`\n  while (i < length - 2) {\n    if (data[i] === 0 && data[i + 1] === 0 && data[i + 2] === 0x03) {\n      EPBPositions.push(i + 2);\n      i += 2;\n    } else {\n      i++;\n    }\n  }\n\n  // If no Emulation Prevention Bytes were found just return the original\n  // array\n  if (EPBPositions.length === 0) {\n    return data;\n  }\n\n  // Create a new array to hold the NAL unit data\n  const newLength = length - EPBPositions.length;\n  const newData = new Uint8Array(newLength);\n  let sourceIndex = 0;\n  for (i = 0; i < newLength; sourceIndex++, i++) {\n    if (sourceIndex === EPBPositions[0]) {\n      // Skip this byte\n      sourceIndex++;\n      // Remove this position index\n      EPBPositions.shift();\n    }\n    newData[i] = data[sourceIndex];\n  }\n  return newData;\n}\nfunction parseEmsg(data) {\n  const version = data[0];\n  let schemeIdUri = '';\n  let value = '';\n  let timeScale = 0;\n  let presentationTimeDelta = 0;\n  let presentationTime = 0;\n  let eventDuration = 0;\n  let id = 0;\n  let offset = 0;\n  if (version === 0) {\n    while (bin2str(data.subarray(offset, offset + 1)) !== '\\0') {\n      schemeIdUri += bin2str(data.subarray(offset, offset + 1));\n      offset += 1;\n    }\n    schemeIdUri += bin2str(data.subarray(offset, offset + 1));\n    offset += 1;\n    while (bin2str(data.subarray(offset, offset + 1)) !== '\\0') {\n      value += bin2str(data.subarray(offset, offset + 1));\n      offset += 1;\n    }\n    value += bin2str(data.subarray(offset, offset + 1));\n    offset += 1;\n    timeScale = readUint32(data, 12);\n    presentationTimeDelta = readUint32(data, 16);\n    eventDuration = readUint32(data, 20);\n    id = readUint32(data, 24);\n    offset = 28;\n  } else if (version === 1) {\n    offset += 4;\n    timeScale = readUint32(data, offset);\n    offset += 4;\n    const leftPresentationTime = readUint32(data, offset);\n    offset += 4;\n    const rightPresentationTime = readUint32(data, offset);\n    offset += 4;\n    presentationTime = 2 ** 32 * leftPresentationTime + rightPresentationTime;\n    if (!isSafeInteger(presentationTime)) {\n      presentationTime = Number.MAX_SAFE_INTEGER;\n      logger.warn('Presentation time exceeds safe integer limit and wrapped to max safe integer in parsing emsg box');\n    }\n    eventDuration = readUint32(data, offset);\n    offset += 4;\n    id = readUint32(data, offset);\n    offset += 4;\n    while (bin2str(data.subarray(offset, offset + 1)) !== '\\0') {\n      schemeIdUri += bin2str(data.subarray(offset, offset + 1));\n      offset += 1;\n    }\n    schemeIdUri += bin2str(data.subarray(offset, offset + 1));\n    offset += 1;\n    while (bin2str(data.subarray(offset, offset + 1)) !== '\\0') {\n      value += bin2str(data.subarray(offset, offset + 1));\n      offset += 1;\n    }\n    value += bin2str(data.subarray(offset, offset + 1));\n    offset += 1;\n  }\n  const payload = data.subarray(offset, data.byteLength);\n  return {\n    schemeIdUri,\n    value,\n    timeScale,\n    presentationTime,\n    presentationTimeDelta,\n    eventDuration,\n    id,\n    payload\n  };\n}\nfunction mp4Box(type, ...payload) {\n  const len = payload.length;\n  let size = 8;\n  let i = len;\n  while (i--) {\n    size += payload[i].byteLength;\n  }\n  const result = new Uint8Array(size);\n  result[0] = size >> 24 & 0xff;\n  result[1] = size >> 16 & 0xff;\n  result[2] = size >> 8 & 0xff;\n  result[3] = size & 0xff;\n  result.set(type, 4);\n  for (i = 0, size = 8; i < len; i++) {\n    result.set(payload[i], size);\n    size += payload[i].byteLength;\n  }\n  return result;\n}\nfunction mp4pssh(systemId, keyids, data) {\n  if (systemId.byteLength !== 16) {\n    throw new RangeError('Invalid system id');\n  }\n  let version;\n  let kids;\n  {\n    version = 0;\n    kids = new Uint8Array();\n  }\n  let kidCount;\n  if (version > 0) {\n    kidCount = new Uint8Array(4);\n    if (keyids.length > 0) {\n      new DataView(kidCount.buffer).setUint32(0, keyids.length, false);\n    }\n  } else {\n    kidCount = new Uint8Array();\n  }\n  const dataSize = new Uint8Array(4);\n  if (data.byteLength > 0) {\n    new DataView(dataSize.buffer).setUint32(0, data.byteLength, false);\n  }\n  return mp4Box([112, 115, 115, 104], new Uint8Array([version, 0x00, 0x00, 0x00 // Flags\n  ]), systemId,\n  // 16 bytes\n  kidCount, kids, dataSize, data);\n}\nfunction parseMultiPssh(initData) {\n  const results = [];\n  if (initData instanceof ArrayBuffer) {\n    const length = initData.byteLength;\n    let offset = 0;\n    while (offset + 32 < length) {\n      const view = new DataView(initData, offset);\n      const pssh = parsePssh(view);\n      results.push(pssh);\n      offset += pssh.size;\n    }\n  }\n  return results;\n}\nfunction parsePssh(view) {\n  const size = view.getUint32(0);\n  const offset = view.byteOffset;\n  const length = view.byteLength;\n  if (length < size) {\n    return {\n      offset,\n      size: length\n    };\n  }\n  const type = view.getUint32(4);\n  if (type !== 0x70737368) {\n    return {\n      offset,\n      size\n    };\n  }\n  const version = view.getUint32(8) >>> 24;\n  if (version !== 0 && version !== 1) {\n    return {\n      offset,\n      size\n    };\n  }\n  const buffer = view.buffer;\n  const systemId = arrayToHex(new Uint8Array(buffer, offset + 12, 16));\n  let kids = null;\n  let data = null;\n  let dataSizeOffset = 0;\n  if (version === 0) {\n    dataSizeOffset = 28;\n  } else {\n    const kidCounts = view.getUint32(28);\n    if (!kidCounts || length < 32 + kidCounts * 16) {\n      return {\n        offset,\n        size\n      };\n    }\n    kids = [];\n    for (let i = 0; i < kidCounts; i++) {\n      kids.push(new Uint8Array(buffer, offset + 32 + i * 16, 16));\n    }\n    dataSizeOffset = 32 + kidCounts * 16;\n  }\n  if (!dataSizeOffset) {\n    return {\n      offset,\n      size\n    };\n  }\n  const dataSizeOrKidCount = view.getUint32(dataSizeOffset);\n  if (size - 32 < dataSizeOrKidCount) {\n    return {\n      offset,\n      size\n    };\n  }\n  data = new Uint8Array(buffer, offset + dataSizeOffset + 4, dataSizeOrKidCount);\n  return {\n    version,\n    systemId,\n    kids,\n    data,\n    offset,\n    size\n  };\n}\n\nconst userAgentHevcSupportIsInaccurate = () => {\n  return /\\(Windows.+Firefox\\//i.test(navigator.userAgent);\n};\n\n// from http://mp4ra.org/codecs.html\n// values indicate codec selection preference (lower is higher priority)\nconst sampleEntryCodesISO = {\n  audio: {\n    a3ds: 1,\n    'ac-3': 0.95,\n    'ac-4': 1,\n    alac: 0.9,\n    alaw: 1,\n    dra1: 1,\n    'dts+': 1,\n    'dts-': 1,\n    dtsc: 1,\n    dtse: 1,\n    dtsh: 1,\n    'ec-3': 0.9,\n    enca: 1,\n    fLaC: 0.9,\n    // MP4-RA listed codec entry for FLAC\n    flac: 0.9,\n    // legacy browser codec name for FLAC\n    FLAC: 0.9,\n    // some manifests may list \"FLAC\" with Apple's tools\n    g719: 1,\n    g726: 1,\n    m4ae: 1,\n    mha1: 1,\n    mha2: 1,\n    mhm1: 1,\n    mhm2: 1,\n    mlpa: 1,\n    mp4a: 1,\n    'raw ': 1,\n    Opus: 1,\n    opus: 1,\n    // browsers expect this to be lowercase despite MP4RA says 'Opus'\n    samr: 1,\n    sawb: 1,\n    sawp: 1,\n    sevc: 1,\n    sqcp: 1,\n    ssmv: 1,\n    twos: 1,\n    ulaw: 1\n  },\n  video: {\n    avc1: 1,\n    avc2: 1,\n    avc3: 1,\n    avc4: 1,\n    avcp: 1,\n    av01: 0.8,\n    dav1: 0.8,\n    drac: 1,\n    dva1: 1,\n    dvav: 1,\n    dvh1: 0.7,\n    dvhe: 0.7,\n    encv: 1,\n    hev1: 0.75,\n    hvc1: 0.75,\n    mjp2: 1,\n    mp4v: 1,\n    mvc1: 1,\n    mvc2: 1,\n    mvc3: 1,\n    mvc4: 1,\n    resv: 1,\n    rv60: 1,\n    s263: 1,\n    svc1: 1,\n    svc2: 1,\n    'vc-1': 1,\n    vp08: 1,\n    vp09: 0.9\n  },\n  text: {\n    stpp: 1,\n    wvtt: 1\n  }\n};\nfunction isCodecType(codec, type) {\n  const typeCodes = sampleEntryCodesISO[type];\n  return !!typeCodes && !!typeCodes[codec.slice(0, 4)];\n}\nfunction areCodecsMediaSourceSupported(codecs, type, preferManagedMediaSource = true) {\n  return !codecs.split(',').some(codec => !isCodecMediaSourceSupported(codec, type, preferManagedMediaSource));\n}\nfunction isCodecMediaSourceSupported(codec, type, preferManagedMediaSource = true) {\n  var _MediaSource$isTypeSu;\n  const MediaSource = getMediaSource(preferManagedMediaSource);\n  return (_MediaSource$isTypeSu = MediaSource == null ? void 0 : MediaSource.isTypeSupported(mimeTypeForCodec(codec, type))) != null ? _MediaSource$isTypeSu : false;\n}\nfunction mimeTypeForCodec(codec, type) {\n  return `${type}/mp4;codecs=${codec}`;\n}\nfunction videoCodecPreferenceValue(videoCodec) {\n  if (videoCodec) {\n    const fourCC = videoCodec.substring(0, 4);\n    return sampleEntryCodesISO.video[fourCC];\n  }\n  return 2;\n}\nfunction codecsSetSelectionPreferenceValue(codecSet) {\n  const limitedHevcSupport = userAgentHevcSupportIsInaccurate();\n  return codecSet.split(',').reduce((num, fourCC) => {\n    const lowerPriority = limitedHevcSupport && isHEVC(fourCC);\n    const preferenceValue = lowerPriority ? 9 : sampleEntryCodesISO.video[fourCC];\n    if (preferenceValue) {\n      return (preferenceValue * 2 + num) / (num ? 3 : 2);\n    }\n    return (sampleEntryCodesISO.audio[fourCC] + num) / (num ? 2 : 1);\n  }, 0);\n}\nconst CODEC_COMPATIBLE_NAMES = {};\nfunction getCodecCompatibleNameLower(lowerCaseCodec, preferManagedMediaSource = true) {\n  if (CODEC_COMPATIBLE_NAMES[lowerCaseCodec]) {\n    return CODEC_COMPATIBLE_NAMES[lowerCaseCodec];\n  }\n  const codecsToCheck = {\n    // Idealy fLaC and Opus would be first (spec-compliant) but\n    // some browsers will report that fLaC is supported then fail.\n    // see: https://bugs.chromium.org/p/chromium/issues/detail?id=1422728\n    flac: ['flac', 'fLaC', 'FLAC'],\n    opus: ['opus', 'Opus'],\n    // Replace audio codec info if browser does not support mp4a.40.34,\n    // and demuxer can fallback to 'audio/mpeg' or 'audio/mp4;codecs=\"mp3\"'\n    'mp4a.40.34': ['mp3']\n  }[lowerCaseCodec];\n  for (let i = 0; i < codecsToCheck.length; i++) {\n    var _getMediaSource;\n    if (isCodecMediaSourceSupported(codecsToCheck[i], 'audio', preferManagedMediaSource)) {\n      CODEC_COMPATIBLE_NAMES[lowerCaseCodec] = codecsToCheck[i];\n      return codecsToCheck[i];\n    } else if (codecsToCheck[i] === 'mp3' && (_getMediaSource = getMediaSource(preferManagedMediaSource)) != null && _getMediaSource.isTypeSupported('audio/mpeg')) {\n      return '';\n    }\n  }\n  return lowerCaseCodec;\n}\nconst AUDIO_CODEC_REGEXP = /flac|opus|mp4a\\.40\\.34/i;\nfunction getCodecCompatibleName(codec, preferManagedMediaSource = true) {\n  return codec.replace(AUDIO_CODEC_REGEXP, m => getCodecCompatibleNameLower(m.toLowerCase(), preferManagedMediaSource));\n}\nfunction replaceVideoCodec(originalCodecs, newVideoCodec) {\n  const codecs = [];\n  if (originalCodecs) {\n    const allCodecs = originalCodecs.split(',');\n    for (let i = 0; i < allCodecs.length; i++) {\n      if (!isCodecType(allCodecs[i], 'video')) {\n        codecs.push(allCodecs[i]);\n      }\n    }\n  }\n  if (newVideoCodec) {\n    codecs.push(newVideoCodec);\n  }\n  return codecs.join(',');\n}\nfunction pickMostCompleteCodecName(parsedCodec, levelCodec) {\n  // Parsing of mp4a codecs strings in mp4-tools from media is incomplete as of d8c6c7a\n  // so use level codec is parsed codec is unavailable or incomplete\n  if (parsedCodec && (parsedCodec.length > 4 || ['ac-3', 'ec-3', 'alac', 'fLaC', 'Opus'].indexOf(parsedCodec) !== -1)) {\n    if (isCodecSupportedAsType(parsedCodec, 'audio') || isCodecSupportedAsType(parsedCodec, 'video')) {\n      return parsedCodec;\n    }\n  }\n  if (levelCodec) {\n    const levelCodecs = levelCodec.split(',');\n    if (levelCodecs.length > 1) {\n      if (parsedCodec) {\n        for (let i = levelCodecs.length; i--;) {\n          if (levelCodecs[i].substring(0, 4) === parsedCodec.substring(0, 4)) {\n            return levelCodecs[i];\n          }\n        }\n      }\n      return levelCodecs[0];\n    }\n  }\n  return levelCodec || parsedCodec;\n}\nfunction isCodecSupportedAsType(codec, type) {\n  return isCodecType(codec, type) && isCodecMediaSourceSupported(codec, type);\n}\nfunction convertAVC1ToAVCOTI(videoCodecs) {\n  // Convert avc1 codec string from RFC-4281 to RFC-6381 for MediaSource.isTypeSupported\n  // Examples: avc1.66.30 to avc1.42001e and avc1.77.30,avc1.66.30 to avc1.4d001e,avc1.42001e.\n  const codecs = videoCodecs.split(',');\n  for (let i = 0; i < codecs.length; i++) {\n    const avcdata = codecs[i].split('.');\n    // only convert codec strings starting with avc1 (Examples: avc1.64001f,dvh1.05.07)\n    if (avcdata.length > 2 && avcdata[0] === 'avc1') {\n      codecs[i] = `avc1.${parseInt(avcdata[1]).toString(16)}${('000' + parseInt(avcdata[2]).toString(16)).slice(-4)}`;\n    }\n  }\n  return codecs.join(',');\n}\nfunction fillInMissingAV01Params(videoCodec) {\n  // Used to fill in incomplete AV1 playlist CODECS strings for mediaCapabilities.decodingInfo queries\n  if (videoCodec.startsWith('av01.')) {\n    const av1params = videoCodec.split('.');\n    const placeholders = ['0', '111', '01', '01', '01', '0'];\n    for (let i = av1params.length; i > 4 && i < 10; i++) {\n      av1params[i] = placeholders[i - 4];\n    }\n    return av1params.join('.');\n  }\n  return videoCodec;\n}\nfunction getM2TSSupportedAudioTypes(preferManagedMediaSource) {\n  const MediaSource = getMediaSource(preferManagedMediaSource) || {\n    isTypeSupported: () => false\n  };\n  return {\n    mpeg: MediaSource.isTypeSupported('audio/mpeg'),\n    mp3: MediaSource.isTypeSupported('audio/mp4; codecs=\"mp3\"'),\n    ac3: MediaSource.isTypeSupported('audio/mp4; codecs=\"ac-3\"') \n  };\n}\nfunction getCodecsForMimeType(mimeType) {\n  return mimeType.replace(/^.+codecs=[\"']?([^\"']+).*$/, '$1');\n}\n\n// @ts-ignore\nconst supportedResult = {\n  supported: true,\n  powerEfficient: true,\n  smooth: true\n  // keySystemAccess: null,\n};\n\n// @ts-ignore\nconst unsupportedResult = {\n  supported: false,\n  smooth: false,\n  powerEfficient: false\n  // keySystemAccess: null,\n};\nconst SUPPORTED_INFO_DEFAULT = {\n  supported: true,\n  configurations: [],\n  decodingInfoResults: [supportedResult]\n};\nfunction getUnsupportedResult(error, configurations) {\n  return {\n    supported: false,\n    configurations,\n    decodingInfoResults: [unsupportedResult],\n    error\n  };\n}\nfunction requiresMediaCapabilitiesDecodingInfo(level, audioTracksByGroup, currentVideoRange, currentFrameRate, currentBw, audioPreference) {\n  // Only test support when configuration is exceeds minimum options\n  const videoCodecs = level.videoCodec;\n  const audioGroups = level.audioCodec ? level.audioGroups : null;\n  const audioCodecPreference = audioPreference == null ? void 0 : audioPreference.audioCodec;\n  const channelsPreference = audioPreference == null ? void 0 : audioPreference.channels;\n  const maxChannels = channelsPreference ? parseInt(channelsPreference) : audioCodecPreference ? Infinity : 2;\n  let audioChannels = null;\n  if (audioGroups != null && audioGroups.length) {\n    try {\n      if (audioGroups.length === 1 && audioGroups[0]) {\n        audioChannels = audioTracksByGroup.groups[audioGroups[0]].channels;\n      } else {\n        audioChannels = audioGroups.reduce((acc, groupId) => {\n          if (groupId) {\n            const audioTrackGroup = audioTracksByGroup.groups[groupId];\n            if (!audioTrackGroup) {\n              throw new Error(`Audio track group ${groupId} not found`);\n            }\n            // Sum all channel key values\n            Object.keys(audioTrackGroup.channels).forEach(key => {\n              acc[key] = (acc[key] || 0) + audioTrackGroup.channels[key];\n            });\n          }\n          return acc;\n        }, {\n          2: 0\n        });\n      }\n    } catch (error) {\n      return true;\n    }\n  }\n  return videoCodecs !== undefined && (\n  // Force media capabilities check for HEVC to avoid failure on Windows\n  videoCodecs.split(',').some(videoCodec => isHEVC(videoCodec)) || level.width > 1920 && level.height > 1088 || level.height > 1920 && level.width > 1088 || level.frameRate > Math.max(currentFrameRate, 30) || level.videoRange !== 'SDR' && level.videoRange !== currentVideoRange || level.bitrate > Math.max(currentBw, 8e6)) || !!audioChannels && isFiniteNumber(maxChannels) && Object.keys(audioChannels).some(channels => parseInt(channels) > maxChannels);\n}\nfunction getMediaDecodingInfoPromise(level, audioTracksByGroup, mediaCapabilities, cache = {}) {\n  const videoCodecs = level.videoCodec;\n  if (!videoCodecs && !level.audioCodec || !mediaCapabilities) {\n    return Promise.resolve(SUPPORTED_INFO_DEFAULT);\n  }\n  const configurations = [];\n  const videoDecodeList = makeVideoConfigurations(level);\n  const videoCount = videoDecodeList.length;\n  const audioDecodeList = makeAudioConfigurations(level, audioTracksByGroup, videoCount > 0);\n  const audioCount = audioDecodeList.length;\n  for (let i = videoCount || 1 * audioCount || 1; i--;) {\n    const configuration = {\n      type: 'media-source'\n    };\n    if (videoCount) {\n      configuration.video = videoDecodeList[i % videoCount];\n    }\n    if (audioCount) {\n      configuration.audio = audioDecodeList[i % audioCount];\n      const audioBitrate = configuration.audio.bitrate;\n      if (configuration.video && audioBitrate) {\n        configuration.video.bitrate -= audioBitrate;\n      }\n    }\n    configurations.push(configuration);\n  }\n  if (videoCodecs) {\n    // Override Windows Firefox HEVC MediaCapabilities result (https://github.com/video-dev/hls.js/issues/7046)\n    const ua = navigator.userAgent;\n    if (videoCodecs.split(',').some(videoCodec => isHEVC(videoCodec)) && userAgentHevcSupportIsInaccurate()) {\n      return Promise.resolve(getUnsupportedResult(new Error(`Overriding Windows Firefox HEVC MediaCapabilities result based on user-agent string: (${ua})`), configurations));\n    }\n  }\n  return Promise.all(configurations.map(configuration => {\n    // Cache MediaCapabilities promises\n    const decodingInfoKey = getMediaDecodingInfoKey(configuration);\n    return cache[decodingInfoKey] || (cache[decodingInfoKey] = mediaCapabilities.decodingInfo(configuration));\n  })).then(decodingInfoResults => ({\n    supported: !decodingInfoResults.some(info => !info.supported),\n    configurations,\n    decodingInfoResults\n  })).catch(error => ({\n    supported: false,\n    configurations,\n    decodingInfoResults: [],\n    error\n  }));\n}\nfunction makeVideoConfigurations(level) {\n  var _level$videoCodec;\n  const videoCodecs = (_level$videoCodec = level.videoCodec) == null ? void 0 : _level$videoCodec.split(',');\n  const bitrate = getVariantDecodingBitrate(level);\n  const width = level.width || 640;\n  const height = level.height || 480;\n  // Assume a framerate of 30fps since MediaCapabilities will not accept Level default of 0.\n  const framerate = level.frameRate || 30;\n  const videoRange = level.videoRange.toLowerCase();\n  return videoCodecs ? videoCodecs.map(videoCodec => {\n    const videoConfiguration = {\n      contentType: mimeTypeForCodec(fillInMissingAV01Params(videoCodec), 'video'),\n      width,\n      height,\n      bitrate,\n      framerate\n    };\n    if (videoRange !== 'sdr') {\n      videoConfiguration.transferFunction = videoRange;\n    }\n    return videoConfiguration;\n  }) : [];\n}\nfunction makeAudioConfigurations(level, audioTracksByGroup, hasVideo) {\n  var _level$audioCodec;\n  const audioCodecs = (_level$audioCodec = level.audioCodec) == null ? void 0 : _level$audioCodec.split(',');\n  const combinedBitrate = getVariantDecodingBitrate(level);\n  if (audioCodecs && level.audioGroups) {\n    return level.audioGroups.reduce((configurations, audioGroupId) => {\n      var _audioTracksByGroup$g;\n      const tracks = audioGroupId ? (_audioTracksByGroup$g = audioTracksByGroup.groups[audioGroupId]) == null ? void 0 : _audioTracksByGroup$g.tracks : null;\n      if (tracks) {\n        return tracks.reduce((configs, audioTrack) => {\n          if (audioTrack.groupId === audioGroupId) {\n            const channelsNumber = parseFloat(audioTrack.channels || '');\n            audioCodecs.forEach(audioCodec => {\n              const audioConfiguration = {\n                contentType: mimeTypeForCodec(audioCodec, 'audio'),\n                bitrate: hasVideo ? estimatedAudioBitrate(audioCodec, combinedBitrate) : combinedBitrate\n              };\n              if (channelsNumber) {\n                audioConfiguration.channels = '' + channelsNumber;\n              }\n              configs.push(audioConfiguration);\n            });\n          }\n          return configs;\n        }, configurations);\n      }\n      return configurations;\n    }, []);\n  }\n  return [];\n}\nfunction estimatedAudioBitrate(audioCodec, levelBitrate) {\n  if (levelBitrate <= 1) {\n    return 1;\n  }\n  let audioBitrate = 128000;\n  if (audioCodec === 'ec-3') {\n    audioBitrate = 768000;\n  } else if (audioCodec === 'ac-3') {\n    audioBitrate = 640000;\n  }\n  return Math.min(levelBitrate / 2, audioBitrate); // Don't exceed some % of level bitrate\n}\nfunction getVariantDecodingBitrate(level) {\n  return Math.ceil(Math.max(level.bitrate * 0.9, level.averageBitrate) / 1000) * 1000 || 1;\n}\nfunction getMediaDecodingInfoKey(config) {\n  let key = '';\n  const {\n    audio,\n    video\n  } = config;\n  if (video) {\n    const codec = getCodecsForMimeType(video.contentType);\n    key += `${codec}_r${video.height}x${video.width}f${Math.ceil(video.framerate)}${video.transferFunction || 'sd'}_${Math.ceil(video.bitrate / 1e5)}`;\n  }\n  if (audio) {\n    const codec = getCodecsForMimeType(audio.contentType);\n    key += `${video ? '_' : ''}${codec}_c${audio.channels}`;\n  }\n  return key;\n}\n\nconst HdcpLevels = ['NONE', 'TYPE-0', 'TYPE-1', null];\nfunction isHdcpLevel(value) {\n  return HdcpLevels.indexOf(value) > -1;\n}\nconst VideoRangeValues = ['SDR', 'PQ', 'HLG'];\nfunction isVideoRange(value) {\n  return !!value && VideoRangeValues.indexOf(value) > -1;\n}\nvar HlsSkip = {\n  No: \"\",\n  Yes: \"YES\",\n  v2: \"v2\"\n};\nfunction getSkipValue(details) {\n  const {\n    canSkipUntil,\n    canSkipDateRanges,\n    age\n  } = details;\n  // A Client SHOULD NOT request a Playlist Delta Update unless it already\n  // has a version of the Playlist that is no older than one-half of the Skip Boundary.\n  // @see: https://datatracker.ietf.org/doc/html/draft-pantos-hls-rfc8216bis#section-6.3.7\n  const playlistRecentEnough = age < canSkipUntil / 2;\n  if (canSkipUntil && playlistRecentEnough) {\n    if (canSkipDateRanges) {\n      return HlsSkip.v2;\n    }\n    return HlsSkip.Yes;\n  }\n  return HlsSkip.No;\n}\nclass HlsUrlParameters {\n  constructor(msn, part, skip) {\n    this.msn = void 0;\n    this.part = void 0;\n    this.skip = void 0;\n    this.msn = msn;\n    this.part = part;\n    this.skip = skip;\n  }\n  addDirectives(uri) {\n    const url = new self.URL(uri);\n    if (this.msn !== undefined) {\n      url.searchParams.set('_HLS_msn', this.msn.toString());\n    }\n    if (this.part !== undefined) {\n      url.searchParams.set('_HLS_part', this.part.toString());\n    }\n    if (this.skip) {\n      url.searchParams.set('_HLS_skip', this.skip);\n    }\n    return url.href;\n  }\n}\nclass Level {\n  constructor(data) {\n    this._attrs = void 0;\n    this.audioCodec = void 0;\n    this.bitrate = void 0;\n    this.codecSet = void 0;\n    this.url = void 0;\n    this.frameRate = void 0;\n    this.height = void 0;\n    this.id = void 0;\n    this.name = void 0;\n    this.supplemental = void 0;\n    this.videoCodec = void 0;\n    this.width = void 0;\n    this.details = void 0;\n    this.fragmentError = 0;\n    this.loadError = 0;\n    this.loaded = void 0;\n    this.realBitrate = 0;\n    this.supportedPromise = void 0;\n    this.supportedResult = void 0;\n    this._avgBitrate = 0;\n    this._audioGroups = void 0;\n    this._subtitleGroups = void 0;\n    // Deprecated (retained for backwards compatibility)\n    this._urlId = 0;\n    this.url = [data.url];\n    this._attrs = [data.attrs];\n    this.bitrate = data.bitrate;\n    if (data.details) {\n      this.details = data.details;\n    }\n    this.id = data.id || 0;\n    this.name = data.name;\n    this.width = data.width || 0;\n    this.height = data.height || 0;\n    this.frameRate = data.attrs.optionalFloat('FRAME-RATE', 0);\n    this._avgBitrate = data.attrs.decimalInteger('AVERAGE-BANDWIDTH');\n    this.audioCodec = data.audioCodec;\n    this.videoCodec = data.videoCodec;\n    this.codecSet = [data.videoCodec, data.audioCodec].filter(c => !!c).map(s => s.substring(0, 4)).join(',');\n    if ('supplemental' in data) {\n      var _data$supplemental;\n      this.supplemental = data.supplemental;\n      const supplementalVideo = (_data$supplemental = data.supplemental) == null ? void 0 : _data$supplemental.videoCodec;\n      if (supplementalVideo && supplementalVideo !== data.videoCodec) {\n        this.codecSet += `,${supplementalVideo.substring(0, 4)}`;\n      }\n    }\n    this.addGroupId('audio', data.attrs.AUDIO);\n    this.addGroupId('text', data.attrs.SUBTITLES);\n  }\n  get maxBitrate() {\n    return Math.max(this.realBitrate, this.bitrate);\n  }\n  get averageBitrate() {\n    return this._avgBitrate || this.realBitrate || this.bitrate;\n  }\n  get attrs() {\n    return this._attrs[0];\n  }\n  get codecs() {\n    return this.attrs.CODECS || '';\n  }\n  get pathwayId() {\n    return this.attrs['PATHWAY-ID'] || '.';\n  }\n  get videoRange() {\n    return this.attrs['VIDEO-RANGE'] || 'SDR';\n  }\n  get score() {\n    return this.attrs.optionalFloat('SCORE', 0);\n  }\n  get uri() {\n    return this.url[0] || '';\n  }\n  hasAudioGroup(groupId) {\n    return hasGroup(this._audioGroups, groupId);\n  }\n  hasSubtitleGroup(groupId) {\n    return hasGroup(this._subtitleGroups, groupId);\n  }\n  get audioGroups() {\n    return this._audioGroups;\n  }\n  get subtitleGroups() {\n    return this._subtitleGroups;\n  }\n  addGroupId(type, groupId) {\n    if (!groupId) {\n      return;\n    }\n    if (type === 'audio') {\n      let audioGroups = this._audioGroups;\n      if (!audioGroups) {\n        audioGroups = this._audioGroups = [];\n      }\n      if (audioGroups.indexOf(groupId) === -1) {\n        audioGroups.push(groupId);\n      }\n    } else if (type === 'text') {\n      let subtitleGroups = this._subtitleGroups;\n      if (!subtitleGroups) {\n        subtitleGroups = this._subtitleGroups = [];\n      }\n      if (subtitleGroups.indexOf(groupId) === -1) {\n        subtitleGroups.push(groupId);\n      }\n    }\n  }\n\n  // Deprecated methods (retained for backwards compatibility)\n  get urlId() {\n    return 0;\n  }\n  set urlId(value) {}\n  get audioGroupIds() {\n    return this.audioGroups ? [this.audioGroupId] : undefined;\n  }\n  get textGroupIds() {\n    return this.subtitleGroups ? [this.textGroupId] : undefined;\n  }\n  get audioGroupId() {\n    var _this$audioGroups;\n    return (_this$audioGroups = this.audioGroups) == null ? void 0 : _this$audioGroups[0];\n  }\n  get textGroupId() {\n    var _this$subtitleGroups;\n    return (_this$subtitleGroups = this.subtitleGroups) == null ? void 0 : _this$subtitleGroups[0];\n  }\n  addFallback() {}\n}\nfunction hasGroup(groups, groupId) {\n  if (!groupId || !groups) {\n    return false;\n  }\n  return groups.indexOf(groupId) !== -1;\n}\n\n/**\n * @returns Whether we can detect and validate HDR capability within the window context\n */\nfunction isHdrSupported() {\n  if (typeof matchMedia === 'function') {\n    const mediaQueryList = matchMedia('(dynamic-range: high)');\n    const badQuery = matchMedia('bad query');\n    if (mediaQueryList.media !== badQuery.media) {\n      return mediaQueryList.matches === true;\n    }\n  }\n  return false;\n}\n\n/**\n * Sanitizes inputs to return the active video selection options for HDR/SDR.\n * When both inputs are null:\n *\n *    `{ preferHDR: false, allowedVideoRanges: [] }`\n *\n * When `currentVideoRange` non-null, maintain the active range:\n *\n *    `{ preferHDR: currentVideoRange !== 'SDR', allowedVideoRanges: [currentVideoRange] }`\n *\n * When VideoSelectionOption non-null:\n *\n *  - Allow all video ranges if `allowedVideoRanges` unspecified.\n *  - If `preferHDR` is non-null use the value to filter `allowedVideoRanges`.\n *  - Else check window for HDR support and set `preferHDR` to the result.\n *\n * @param currentVideoRange\n * @param videoPreference\n */\nfunction getVideoSelectionOptions(currentVideoRange, videoPreference) {\n  let preferHDR = false;\n  let allowedVideoRanges = [];\n  if (currentVideoRange) {\n    preferHDR = currentVideoRange !== 'SDR';\n    allowedVideoRanges = [currentVideoRange];\n  }\n  if (videoPreference) {\n    allowedVideoRanges = videoPreference.allowedVideoRanges || VideoRangeValues.slice(0);\n    const allowAutoPreferHDR = allowedVideoRanges.join('') !== 'SDR' && !videoPreference.videoCodec;\n    preferHDR = videoPreference.preferHDR !== undefined ? videoPreference.preferHDR : allowAutoPreferHDR && isHdrSupported();\n    if (!preferHDR) {\n      allowedVideoRanges = ['SDR'];\n    }\n  }\n  return {\n    preferHDR,\n    allowedVideoRanges\n  };\n}\n\nconst omitCircularRefsReplacer = replacer => {\n  const known = new WeakSet();\n  return (_, value) => {\n    if (replacer) {\n      value = replacer(_, value);\n    }\n    if (typeof value === 'object' && value !== null) {\n      if (known.has(value)) {\n        return;\n      }\n      known.add(value);\n    }\n    return value;\n  };\n};\nconst stringify = (object, replacer) => JSON.stringify(object, omitCircularRefsReplacer(replacer));\n\nfunction getStartCodecTier(codecTiers, currentVideoRange, currentBw, audioPreference, videoPreference) {\n  const codecSets = Object.keys(codecTiers);\n  const channelsPreference = audioPreference == null ? void 0 : audioPreference.channels;\n  const audioCodecPreference = audioPreference == null ? void 0 : audioPreference.audioCodec;\n  const videoCodecPreference = videoPreference == null ? void 0 : videoPreference.videoCodec;\n  const preferStereo = channelsPreference && parseInt(channelsPreference) === 2;\n  // Use first level set to determine stereo, and minimum resolution and framerate\n  let hasStereo = false;\n  let hasCurrentVideoRange = false;\n  let minHeight = Infinity;\n  let minFramerate = Infinity;\n  let minBitrate = Infinity;\n  let minIndex = Infinity;\n  let selectedScore = 0;\n  let videoRanges = [];\n  const {\n    preferHDR,\n    allowedVideoRanges\n  } = getVideoSelectionOptions(currentVideoRange, videoPreference);\n  for (let i = codecSets.length; i--;) {\n    const tier = codecTiers[codecSets[i]];\n    hasStereo || (hasStereo = tier.channels[2] > 0);\n    minHeight = Math.min(minHeight, tier.minHeight);\n    minFramerate = Math.min(minFramerate, tier.minFramerate);\n    minBitrate = Math.min(minBitrate, tier.minBitrate);\n    const matchingVideoRanges = allowedVideoRanges.filter(range => tier.videoRanges[range] > 0);\n    if (matchingVideoRanges.length > 0) {\n      hasCurrentVideoRange = true;\n    }\n  }\n  minHeight = isFiniteNumber(minHeight) ? minHeight : 0;\n  minFramerate = isFiniteNumber(minFramerate) ? minFramerate : 0;\n  const maxHeight = Math.max(1080, minHeight);\n  const maxFramerate = Math.max(30, minFramerate);\n  minBitrate = isFiniteNumber(minBitrate) ? minBitrate : currentBw;\n  currentBw = Math.max(minBitrate, currentBw);\n  // If there are no variants with matching preference, set currentVideoRange to undefined\n  if (!hasCurrentVideoRange) {\n    currentVideoRange = undefined;\n  }\n  const hasMultipleSets = codecSets.length > 1;\n  const codecSet = codecSets.reduce((selected, candidate) => {\n    // Remove candiates which do not meet bitrate, default audio, stereo or channels preference, 1080p or lower, 30fps or lower, or SDR/HDR selection if present\n    const candidateTier = codecTiers[candidate];\n    if (candidate === selected) {\n      return selected;\n    }\n    videoRanges = hasCurrentVideoRange ? allowedVideoRanges.filter(range => candidateTier.videoRanges[range] > 0) : [];\n    if (hasMultipleSets) {\n      if (candidateTier.minBitrate > currentBw) {\n        logStartCodecCandidateIgnored(candidate, `min bitrate of ${candidateTier.minBitrate} > current estimate of ${currentBw}`);\n        return selected;\n      }\n      if (!candidateTier.hasDefaultAudio) {\n        logStartCodecCandidateIgnored(candidate, `no renditions with default or auto-select sound found`);\n        return selected;\n      }\n      if (audioCodecPreference && candidate.indexOf(audioCodecPreference.substring(0, 4)) % 5 !== 0) {\n        logStartCodecCandidateIgnored(candidate, `audio codec preference \"${audioCodecPreference}\" not found`);\n        return selected;\n      }\n      if (channelsPreference && !preferStereo) {\n        if (!candidateTier.channels[channelsPreference]) {\n          logStartCodecCandidateIgnored(candidate, `no renditions with ${channelsPreference} channel sound found (channels options: ${Object.keys(candidateTier.channels)})`);\n          return selected;\n        }\n      } else if ((!audioCodecPreference || preferStereo) && hasStereo && candidateTier.channels['2'] === 0) {\n        logStartCodecCandidateIgnored(candidate, `no renditions with stereo sound found`);\n        return selected;\n      }\n      if (candidateTier.minHeight > maxHeight) {\n        logStartCodecCandidateIgnored(candidate, `min resolution of ${candidateTier.minHeight} > maximum of ${maxHeight}`);\n        return selected;\n      }\n      if (candidateTier.minFramerate > maxFramerate) {\n        logStartCodecCandidateIgnored(candidate, `min framerate of ${candidateTier.minFramerate} > maximum of ${maxFramerate}`);\n        return selected;\n      }\n      if (!videoRanges.some(range => candidateTier.videoRanges[range] > 0)) {\n        logStartCodecCandidateIgnored(candidate, `no variants with VIDEO-RANGE of ${stringify(videoRanges)} found`);\n        return selected;\n      }\n      if (videoCodecPreference && candidate.indexOf(videoCodecPreference.substring(0, 4)) % 5 !== 0) {\n        logStartCodecCandidateIgnored(candidate, `video codec preference \"${videoCodecPreference}\" not found`);\n        return selected;\n      }\n      if (candidateTier.maxScore < selectedScore) {\n        logStartCodecCandidateIgnored(candidate, `max score of ${candidateTier.maxScore} < selected max of ${selectedScore}`);\n        return selected;\n      }\n    }\n    // Remove candiates with less preferred codecs or more errors\n    if (selected && (codecsSetSelectionPreferenceValue(candidate) >= codecsSetSelectionPreferenceValue(selected) || candidateTier.fragmentError > codecTiers[selected].fragmentError)) {\n      return selected;\n    }\n    minIndex = candidateTier.minIndex;\n    selectedScore = candidateTier.maxScore;\n    return candidate;\n  }, undefined);\n  return {\n    codecSet,\n    videoRanges,\n    preferHDR,\n    minFramerate,\n    minBitrate,\n    minIndex\n  };\n}\nfunction logStartCodecCandidateIgnored(codeSet, reason) {\n  logger.log(`[abr] start candidates with \"${codeSet}\" ignored because ${reason}`);\n}\nfunction getAudioTracksByGroup(allAudioTracks) {\n  return allAudioTracks.reduce((audioTracksByGroup, track) => {\n    let trackGroup = audioTracksByGroup.groups[track.groupId];\n    if (!trackGroup) {\n      trackGroup = audioTracksByGroup.groups[track.groupId] = {\n        tracks: [],\n        channels: {\n          2: 0\n        },\n        hasDefault: false,\n        hasAutoSelect: false\n      };\n    }\n    trackGroup.tracks.push(track);\n    const channelsKey = track.channels || '2';\n    trackGroup.channels[channelsKey] = (trackGroup.channels[channelsKey] || 0) + 1;\n    trackGroup.hasDefault = trackGroup.hasDefault || track.default;\n    trackGroup.hasAutoSelect = trackGroup.hasAutoSelect || track.autoselect;\n    if (trackGroup.hasDefault) {\n      audioTracksByGroup.hasDefaultAudio = true;\n    }\n    if (trackGroup.hasAutoSelect) {\n      audioTracksByGroup.hasAutoSelectAudio = true;\n    }\n    return audioTracksByGroup;\n  }, {\n    hasDefaultAudio: false,\n    hasAutoSelectAudio: false,\n    groups: {}\n  });\n}\nfunction getCodecTiers(levels, audioTracksByGroup, minAutoLevel, maxAutoLevel) {\n  return levels.slice(minAutoLevel, maxAutoLevel + 1).reduce((tiers, level, index) => {\n    if (!level.codecSet) {\n      return tiers;\n    }\n    const audioGroups = level.audioGroups;\n    let tier = tiers[level.codecSet];\n    if (!tier) {\n      tiers[level.codecSet] = tier = {\n        minBitrate: Infinity,\n        minHeight: Infinity,\n        minFramerate: Infinity,\n        minIndex: index,\n        maxScore: 0,\n        videoRanges: {\n          SDR: 0\n        },\n        channels: {\n          '2': 0\n        },\n        hasDefaultAudio: !audioGroups,\n        fragmentError: 0\n      };\n    }\n    tier.minBitrate = Math.min(tier.minBitrate, level.bitrate);\n    const lesserWidthOrHeight = Math.min(level.height, level.width);\n    tier.minHeight = Math.min(tier.minHeight, lesserWidthOrHeight);\n    tier.minFramerate = Math.min(tier.minFramerate, level.frameRate);\n    tier.minIndex = Math.min(tier.minIndex, index);\n    tier.maxScore = Math.max(tier.maxScore, level.score);\n    tier.fragmentError += level.fragmentError;\n    tier.videoRanges[level.videoRange] = (tier.videoRanges[level.videoRange] || 0) + 1;\n    if (audioGroups) {\n      audioGroups.forEach(audioGroupId => {\n        if (!audioGroupId) {\n          return;\n        }\n        const audioGroup = audioTracksByGroup.groups[audioGroupId];\n        if (!audioGroup) {\n          return;\n        }\n        // Default audio is any group with DEFAULT=YES, or if missing then any group with AUTOSELECT=YES, or all variants\n        tier.hasDefaultAudio = tier.hasDefaultAudio || audioTracksByGroup.hasDefaultAudio ? audioGroup.hasDefault : audioGroup.hasAutoSelect || !audioTracksByGroup.hasDefaultAudio && !audioTracksByGroup.hasAutoSelectAudio;\n        Object.keys(audioGroup.channels).forEach(channels => {\n          tier.channels[channels] = (tier.channels[channels] || 0) + audioGroup.channels[channels];\n        });\n      });\n    }\n    return tiers;\n  }, {});\n}\nfunction getBasicSelectionOption(option) {\n  if (!option) {\n    return option;\n  }\n  const {\n    lang,\n    assocLang,\n    characteristics,\n    channels,\n    audioCodec\n  } = option;\n  return {\n    lang,\n    assocLang,\n    characteristics,\n    channels,\n    audioCodec\n  };\n}\nfunction findMatchingOption(option, tracks, matchPredicate) {\n  if ('attrs' in option) {\n    const index = tracks.indexOf(option);\n    if (index !== -1) {\n      return index;\n    }\n  }\n  for (let i = 0; i < tracks.length; i++) {\n    const track = tracks[i];\n    if (matchesOption(option, track, matchPredicate)) {\n      return i;\n    }\n  }\n  return -1;\n}\nfunction matchesOption(option, track, matchPredicate) {\n  const {\n    groupId,\n    name,\n    lang,\n    assocLang,\n    default: isDefault\n  } = option;\n  const forced = option.forced;\n  return (groupId === undefined || track.groupId === groupId) && (name === undefined || track.name === name) && (lang === undefined || languagesMatch(lang, track.lang)) && (lang === undefined || track.assocLang === assocLang) && (isDefault === undefined || track.default === isDefault) && (forced === undefined || track.forced === forced) && (!('characteristics' in option) || characteristicsMatch(option.characteristics || '', track.characteristics)) && (matchPredicate === undefined || matchPredicate(option, track));\n}\nfunction languagesMatch(languageA, languageB = '--') {\n  if (languageA.length === languageB.length) {\n    return languageA === languageB;\n  }\n  return languageA.startsWith(languageB) || languageB.startsWith(languageA);\n}\nfunction characteristicsMatch(characteristicsA, characteristicsB = '') {\n  const arrA = characteristicsA.split(',');\n  const arrB = characteristicsB.split(',');\n  // Expects each item to be unique:\n  return arrA.length === arrB.length && !arrA.some(el => arrB.indexOf(el) === -1);\n}\nfunction audioMatchPredicate(option, track) {\n  const {\n    audioCodec,\n    channels\n  } = option;\n  return (audioCodec === undefined || (track.audioCodec || '').substring(0, 4) === audioCodec.substring(0, 4)) && (channels === undefined || channels === (track.channels || '2'));\n}\nfunction findClosestLevelWithAudioGroup(option, levels, allAudioTracks, searchIndex, matchPredicate) {\n  const currentLevel = levels[searchIndex];\n  // Are there variants with same URI as current level?\n  // If so, find a match that does not require any level URI change\n  const variants = levels.reduce((variantMap, level, index) => {\n    const uri = level.uri;\n    const renditions = variantMap[uri] || (variantMap[uri] = []);\n    renditions.push(index);\n    return variantMap;\n  }, {});\n  const renditions = variants[currentLevel.uri];\n  if (renditions.length > 1) {\n    searchIndex = Math.max.apply(Math, renditions);\n  }\n  // Find best match\n  const currentVideoRange = currentLevel.videoRange;\n  const currentFrameRate = currentLevel.frameRate;\n  const currentVideoCodec = currentLevel.codecSet.substring(0, 4);\n  const matchingVideo = searchDownAndUpList(levels, searchIndex, level => {\n    if (level.videoRange !== currentVideoRange || level.frameRate !== currentFrameRate || level.codecSet.substring(0, 4) !== currentVideoCodec) {\n      return false;\n    }\n    const audioGroups = level.audioGroups;\n    const tracks = allAudioTracks.filter(track => !audioGroups || audioGroups.indexOf(track.groupId) !== -1);\n    return findMatchingOption(option, tracks, matchPredicate) > -1;\n  });\n  if (matchingVideo > -1) {\n    return matchingVideo;\n  }\n  return searchDownAndUpList(levels, searchIndex, level => {\n    const audioGroups = level.audioGroups;\n    const tracks = allAudioTracks.filter(track => !audioGroups || audioGroups.indexOf(track.groupId) !== -1);\n    return findMatchingOption(option, tracks, matchPredicate) > -1;\n  });\n}\nfunction searchDownAndUpList(arr, searchIndex, predicate) {\n  for (let i = searchIndex; i > -1; i--) {\n    if (predicate(arr[i])) {\n      return i;\n    }\n  }\n  for (let i = searchIndex + 1; i < arr.length; i++) {\n    if (predicate(arr[i])) {\n      return i;\n    }\n  }\n  return -1;\n}\nfunction useAlternateAudio(audioTrackUrl, hls) {\n  var _hls$loadLevelObj;\n  return !!audioTrackUrl && audioTrackUrl !== ((_hls$loadLevelObj = hls.loadLevelObj) == null ? void 0 : _hls$loadLevelObj.uri);\n}\n\nclass AbrController extends Logger {\n  constructor(_hls) {\n    super('abr', _hls.logger);\n    this.hls = void 0;\n    this.lastLevelLoadSec = 0;\n    this.lastLoadedFragLevel = -1;\n    this.firstSelection = -1;\n    this._nextAutoLevel = -1;\n    this.nextAutoLevelKey = '';\n    this.audioTracksByGroup = null;\n    this.codecTiers = null;\n    this.timer = -1;\n    this.fragCurrent = null;\n    this.partCurrent = null;\n    this.bitrateTestDelay = 0;\n    this.rebufferNotice = -1;\n    this.supportedCache = {};\n    this.bwEstimator = void 0;\n    /*\n        This method monitors the download rate of the current fragment, and will downswitch if that fragment will not load\n        quickly enough to prevent underbuffering\n      */\n    this._abandonRulesCheck = levelLoaded => {\n      var _ref;\n      const {\n        fragCurrent: frag,\n        partCurrent: part,\n        hls\n      } = this;\n      const {\n        autoLevelEnabled,\n        media\n      } = hls;\n      if (!frag || !media) {\n        return;\n      }\n      const now = performance.now();\n      const stats = part ? part.stats : frag.stats;\n      const duration = part ? part.duration : frag.duration;\n      const timeLoading = now - stats.loading.start;\n      const minAutoLevel = hls.minAutoLevel;\n      const loadingFragForLevel = frag.level;\n      const currentAutoLevel = this._nextAutoLevel;\n      // If frag loading is aborted, complete, or from lowest level, stop timer and return\n      if (stats.aborted || stats.loaded && stats.loaded === stats.total || loadingFragForLevel <= minAutoLevel) {\n        this.clearTimer();\n        // reset forced auto level value so that next level will be selected\n        this._nextAutoLevel = -1;\n        return;\n      }\n\n      // This check only runs if we're in ABR mode\n      if (!autoLevelEnabled) {\n        return;\n      }\n\n      // Must be loading/loaded a new level or be in a playing state\n      const fragBlockingSwitch = currentAutoLevel > -1 && currentAutoLevel !== loadingFragForLevel;\n      const levelChange = !!levelLoaded || fragBlockingSwitch;\n      if (!levelChange && (media.paused || !media.playbackRate || !media.readyState)) {\n        return;\n      }\n      const bufferInfo = hls.mainForwardBufferInfo;\n      if (!levelChange && bufferInfo === null) {\n        return;\n      }\n      const ttfbEstimate = this.bwEstimator.getEstimateTTFB();\n      const playbackRate = Math.abs(media.playbackRate);\n      // To maintain stable adaptive playback, only begin monitoring frag loading after half or more of its playback duration has passed\n      if (timeLoading <= Math.max(ttfbEstimate, 1000 * (duration / (playbackRate * 2)))) {\n        return;\n      }\n\n      // bufferStarvationDelay is an estimate of the amount time (in seconds) it will take to exhaust the buffer\n      const bufferStarvationDelay = bufferInfo ? bufferInfo.len / playbackRate : 0;\n      const ttfb = stats.loading.first ? stats.loading.first - stats.loading.start : -1;\n      const loadedFirstByte = stats.loaded && ttfb > -1;\n      const bwEstimate = this.getBwEstimate();\n      const levels = hls.levels;\n      const level = levels[loadingFragForLevel];\n      const expectedLen = Math.max(stats.loaded, Math.round(duration * (frag.bitrate || level.averageBitrate) / 8));\n      let timeStreaming = loadedFirstByte ? timeLoading - ttfb : timeLoading;\n      if (timeStreaming < 1 && loadedFirstByte) {\n        timeStreaming = Math.min(timeLoading, stats.loaded * 8 / bwEstimate);\n      }\n      const loadRate = loadedFirstByte ? stats.loaded * 1000 / timeStreaming : 0;\n      // fragLoadDelay is an estimate of the time (in seconds) it will take to buffer the remainder of the fragment\n      const ttfbSeconds = ttfbEstimate / 1000;\n      const fragLoadedDelay = loadRate ? (expectedLen - stats.loaded) / loadRate : expectedLen * 8 / bwEstimate + ttfbSeconds;\n      // Only downswitch if the time to finish loading the current fragment is greater than the amount of buffer left\n      if (fragLoadedDelay <= bufferStarvationDelay) {\n        return;\n      }\n      const bwe = loadRate ? loadRate * 8 : bwEstimate;\n      const live = ((_ref = (levelLoaded == null ? void 0 : levelLoaded.details) || this.hls.latestLevelDetails) == null ? void 0 : _ref.live) === true;\n      const abrBandWidthUpFactor = this.hls.config.abrBandWidthUpFactor;\n      let fragLevelNextLoadedDelay = Number.POSITIVE_INFINITY;\n      let nextLoadLevel;\n      // Iterate through lower level and try to find the largest one that avoids rebuffering\n      for (nextLoadLevel = loadingFragForLevel - 1; nextLoadLevel > minAutoLevel; nextLoadLevel--) {\n        // compute time to load next fragment at lower level\n        // 8 = bits per byte (bps/Bps)\n        const levelNextBitrate = levels[nextLoadLevel].maxBitrate;\n        const requiresLevelLoad = !levels[nextLoadLevel].details || live;\n        fragLevelNextLoadedDelay = this.getTimeToLoadFrag(ttfbSeconds, bwe, duration * levelNextBitrate, requiresLevelLoad);\n        if (fragLevelNextLoadedDelay < Math.min(bufferStarvationDelay, duration + ttfbSeconds)) {\n          break;\n        }\n      }\n      // Only emergency switch down if it takes less time to load a new fragment at lowest level instead of continuing\n      // to load the current one\n      if (fragLevelNextLoadedDelay >= fragLoadedDelay) {\n        return;\n      }\n\n      // if estimated load time of new segment is completely unreasonable, ignore and do not emergency switch down\n      if (fragLevelNextLoadedDelay > duration * 10) {\n        return;\n      }\n      if (loadedFirstByte) {\n        // If there has been loading progress, sample bandwidth using loading time offset by minimum TTFB time\n        this.bwEstimator.sample(timeLoading - Math.min(ttfbEstimate, ttfb), stats.loaded);\n      } else {\n        // If there has been no loading progress, sample TTFB\n        this.bwEstimator.sampleTTFB(timeLoading);\n      }\n      const nextLoadLevelBitrate = levels[nextLoadLevel].maxBitrate;\n      if (this.getBwEstimate() * abrBandWidthUpFactor > nextLoadLevelBitrate) {\n        this.resetEstimator(nextLoadLevelBitrate);\n      }\n      const bestSwitchLevel = this.findBestLevel(nextLoadLevelBitrate, minAutoLevel, nextLoadLevel, 0, bufferStarvationDelay, 1, 1);\n      if (bestSwitchLevel > -1) {\n        nextLoadLevel = bestSwitchLevel;\n      }\n      this.warn(`Fragment ${frag.sn}${part ? ' part ' + part.index : ''} of level ${loadingFragForLevel} is loading too slowly;\n      Fragment duration: ${frag.duration.toFixed(3)}\n      Time to underbuffer: ${bufferStarvationDelay.toFixed(3)} s\n      Estimated load time for current fragment: ${fragLoadedDelay.toFixed(3)} s\n      Estimated load time for down switch fragment: ${fragLevelNextLoadedDelay.toFixed(3)} s\n      TTFB estimate: ${ttfb | 0} ms\n      Current BW estimate: ${isFiniteNumber(bwEstimate) ? bwEstimate | 0 : 'Unknown'} bps\n      New BW estimate: ${this.getBwEstimate() | 0} bps\n      Switching to level ${nextLoadLevel} @ ${nextLoadLevelBitrate | 0} bps`);\n      hls.nextLoadLevel = hls.nextAutoLevel = nextLoadLevel;\n      this.clearTimer();\n      const abortAndSwitch = () => {\n        // Are nextLoadLevel details available or is stream-controller still in \"WAITING_LEVEL\" state?\n        this.clearTimer();\n        if (this.fragCurrent === frag && this.hls.loadLevel === nextLoadLevel && nextLoadLevel > 0) {\n          const bufferStarvationDelay = this.getStarvationDelay();\n          this.warn(`Aborting inflight request ${nextLoadLevel > 0 ? 'and switching down' : ''}\n      Fragment duration: ${frag.duration.toFixed(3)} s\n      Time to underbuffer: ${bufferStarvationDelay.toFixed(3)} s`);\n          frag.abortRequests();\n          this.fragCurrent = this.partCurrent = null;\n          if (nextLoadLevel > minAutoLevel) {\n            let lowestSwitchLevel = this.findBestLevel(this.hls.levels[minAutoLevel].bitrate, minAutoLevel, nextLoadLevel, 0, bufferStarvationDelay, 1, 1);\n            if (lowestSwitchLevel === -1) {\n              lowestSwitchLevel = minAutoLevel;\n            }\n            this.hls.nextLoadLevel = this.hls.nextAutoLevel = lowestSwitchLevel;\n            this.resetEstimator(this.hls.levels[lowestSwitchLevel].bitrate);\n          }\n        }\n      };\n      if (fragBlockingSwitch || fragLoadedDelay > fragLevelNextLoadedDelay * 2) {\n        abortAndSwitch();\n      } else {\n        this.timer = self.setInterval(abortAndSwitch, fragLevelNextLoadedDelay * 1000);\n      }\n      hls.trigger(Events.FRAG_LOAD_EMERGENCY_ABORTED, {\n        frag,\n        part,\n        stats\n      });\n    };\n    this.hls = _hls;\n    this.bwEstimator = this.initEstimator();\n    this.registerListeners();\n  }\n  resetEstimator(abrEwmaDefaultEstimate) {\n    if (abrEwmaDefaultEstimate) {\n      this.log(`setting initial bwe to ${abrEwmaDefaultEstimate}`);\n      this.hls.config.abrEwmaDefaultEstimate = abrEwmaDefaultEstimate;\n    }\n    this.firstSelection = -1;\n    this.bwEstimator = this.initEstimator();\n  }\n  initEstimator() {\n    const config = this.hls.config;\n    return new EwmaBandWidthEstimator(config.abrEwmaSlowVoD, config.abrEwmaFastVoD, config.abrEwmaDefaultEstimate);\n  }\n  registerListeners() {\n    const {\n      hls\n    } = this;\n    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.on(Events.FRAG_LOADING, this.onFragLoading, this);\n    hls.on(Events.FRAG_LOADED, this.onFragLoaded, this);\n    hls.on(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n    hls.on(Events.LEVEL_SWITCHING, this.onLevelSwitching, this);\n    hls.on(Events.LEVEL_LOADED, this.onLevelLoaded, this);\n    hls.on(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);\n    hls.on(Events.MAX_AUTO_LEVEL_UPDATED, this.onMaxAutoLevelUpdated, this);\n    hls.on(Events.ERROR, this.onError, this);\n  }\n  unregisterListeners() {\n    const {\n      hls\n    } = this;\n    if (!hls) {\n      return;\n    }\n    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.off(Events.FRAG_LOADING, this.onFragLoading, this);\n    hls.off(Events.FRAG_LOADED, this.onFragLoaded, this);\n    hls.off(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n    hls.off(Events.LEVEL_SWITCHING, this.onLevelSwitching, this);\n    hls.off(Events.LEVEL_LOADED, this.onLevelLoaded, this);\n    hls.off(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);\n    hls.off(Events.MAX_AUTO_LEVEL_UPDATED, this.onMaxAutoLevelUpdated, this);\n    hls.off(Events.ERROR, this.onError, this);\n  }\n  destroy() {\n    this.unregisterListeners();\n    this.clearTimer();\n    // @ts-ignore\n    this.hls = this._abandonRulesCheck = this.supportedCache = null;\n    this.fragCurrent = this.partCurrent = null;\n  }\n  onManifestLoading(event, data) {\n    this.lastLoadedFragLevel = -1;\n    this.firstSelection = -1;\n    this.lastLevelLoadSec = 0;\n    this.supportedCache = {};\n    this.fragCurrent = this.partCurrent = null;\n    this.onLevelsUpdated();\n    this.clearTimer();\n  }\n  onLevelsUpdated() {\n    if (this.lastLoadedFragLevel > -1 && this.fragCurrent) {\n      this.lastLoadedFragLevel = this.fragCurrent.level;\n    }\n    this._nextAutoLevel = -1;\n    this.onMaxAutoLevelUpdated();\n    this.codecTiers = null;\n    this.audioTracksByGroup = null;\n  }\n  onMaxAutoLevelUpdated() {\n    this.firstSelection = -1;\n    this.nextAutoLevelKey = '';\n  }\n  onFragLoading(event, data) {\n    const frag = data.frag;\n    if (this.ignoreFragment(frag)) {\n      return;\n    }\n    if (!frag.bitrateTest) {\n      var _data$part;\n      this.fragCurrent = frag;\n      this.partCurrent = (_data$part = data.part) != null ? _data$part : null;\n    }\n    this.clearTimer();\n    this.timer = self.setInterval(this._abandonRulesCheck, 100);\n  }\n  onLevelSwitching(event, data) {\n    this.clearTimer();\n  }\n  onError(event, data) {\n    if (data.fatal) {\n      return;\n    }\n    switch (data.details) {\n      case ErrorDetails.BUFFER_ADD_CODEC_ERROR:\n      case ErrorDetails.BUFFER_APPEND_ERROR:\n        // Reset last loaded level so that a new selection can be made after calling recoverMediaError\n        this.lastLoadedFragLevel = -1;\n        this.firstSelection = -1;\n        break;\n      case ErrorDetails.FRAG_LOAD_TIMEOUT:\n        {\n          const frag = data.frag;\n          const {\n            fragCurrent,\n            partCurrent: part\n          } = this;\n          if (frag && fragCurrent && frag.sn === fragCurrent.sn && frag.level === fragCurrent.level) {\n            const now = performance.now();\n            const stats = part ? part.stats : frag.stats;\n            const timeLoading = now - stats.loading.start;\n            const ttfb = stats.loading.first ? stats.loading.first - stats.loading.start : -1;\n            const loadedFirstByte = stats.loaded && ttfb > -1;\n            if (loadedFirstByte) {\n              const ttfbEstimate = this.bwEstimator.getEstimateTTFB();\n              this.bwEstimator.sample(timeLoading - Math.min(ttfbEstimate, ttfb), stats.loaded);\n            } else {\n              this.bwEstimator.sampleTTFB(timeLoading);\n            }\n          }\n          break;\n        }\n    }\n  }\n  getTimeToLoadFrag(timeToFirstByteSec, bandwidth, fragSizeBits, isSwitch) {\n    const fragLoadSec = timeToFirstByteSec + fragSizeBits / bandwidth;\n    const playlistLoadSec = isSwitch ? timeToFirstByteSec + this.lastLevelLoadSec : 0;\n    return fragLoadSec + playlistLoadSec;\n  }\n  onLevelLoaded(event, data) {\n    const config = this.hls.config;\n    const {\n      loading\n    } = data.stats;\n    const timeLoadingMs = loading.end - loading.first;\n    if (isFiniteNumber(timeLoadingMs)) {\n      this.lastLevelLoadSec = timeLoadingMs / 1000;\n    }\n    if (data.details.live) {\n      this.bwEstimator.update(config.abrEwmaSlowLive, config.abrEwmaFastLive);\n    } else {\n      this.bwEstimator.update(config.abrEwmaSlowVoD, config.abrEwmaFastVoD);\n    }\n    if (this.timer > -1) {\n      this._abandonRulesCheck(data.levelInfo);\n    }\n  }\n  onFragLoaded(event, {\n    frag,\n    part\n  }) {\n    const stats = part ? part.stats : frag.stats;\n    if (frag.type === PlaylistLevelType.MAIN) {\n      this.bwEstimator.sampleTTFB(stats.loading.first - stats.loading.start);\n    }\n    if (this.ignoreFragment(frag)) {\n      return;\n    }\n    // stop monitoring bw once frag loaded\n    this.clearTimer();\n    // reset forced auto level value so that next level will be selected\n    if (frag.level === this._nextAutoLevel) {\n      this._nextAutoLevel = -1;\n    }\n    this.firstSelection = -1;\n\n    // compute level average bitrate\n    if (this.hls.config.abrMaxWithRealBitrate) {\n      const duration = part ? part.duration : frag.duration;\n      const level = this.hls.levels[frag.level];\n      const loadedBytes = (level.loaded ? level.loaded.bytes : 0) + stats.loaded;\n      const loadedDuration = (level.loaded ? level.loaded.duration : 0) + duration;\n      level.loaded = {\n        bytes: loadedBytes,\n        duration: loadedDuration\n      };\n      level.realBitrate = Math.round(8 * loadedBytes / loadedDuration);\n    }\n    if (frag.bitrateTest) {\n      const fragBufferedData = {\n        stats,\n        frag,\n        part,\n        id: frag.type\n      };\n      this.onFragBuffered(Events.FRAG_BUFFERED, fragBufferedData);\n      frag.bitrateTest = false;\n    } else {\n      // store level id after successful fragment load for playback\n      this.lastLoadedFragLevel = frag.level;\n    }\n  }\n  onFragBuffered(event, data) {\n    const {\n      frag,\n      part\n    } = data;\n    const stats = part != null && part.stats.loaded ? part.stats : frag.stats;\n    if (stats.aborted) {\n      return;\n    }\n    if (this.ignoreFragment(frag)) {\n      return;\n    }\n    // Use the difference between parsing and request instead of buffering and request to compute fragLoadingProcessing;\n    // rationale is that buffer appending only happens once media is attached. This can happen when config.startFragPrefetch\n    // is used. If we used buffering in that case, our BW estimate sample will be very large.\n    const processingMs = stats.parsing.end - stats.loading.start - Math.min(stats.loading.first - stats.loading.start, this.bwEstimator.getEstimateTTFB());\n    this.bwEstimator.sample(processingMs, stats.loaded);\n    stats.bwEstimate = this.getBwEstimate();\n    if (frag.bitrateTest) {\n      this.bitrateTestDelay = processingMs / 1000;\n    } else {\n      this.bitrateTestDelay = 0;\n    }\n  }\n  ignoreFragment(frag) {\n    // Only count non-alt-audio frags which were actually buffered in our BW calculations\n    return frag.type !== PlaylistLevelType.MAIN || frag.sn === 'initSegment';\n  }\n  clearTimer() {\n    if (this.timer > -1) {\n      self.clearInterval(this.timer);\n      this.timer = -1;\n    }\n  }\n  get firstAutoLevel() {\n    const {\n      maxAutoLevel,\n      minAutoLevel\n    } = this.hls;\n    const bwEstimate = this.getBwEstimate();\n    const maxStartDelay = this.hls.config.maxStarvationDelay;\n    const abrAutoLevel = this.findBestLevel(bwEstimate, minAutoLevel, maxAutoLevel, 0, maxStartDelay, 1, 1);\n    if (abrAutoLevel > -1) {\n      return abrAutoLevel;\n    }\n    const firstLevel = this.hls.firstLevel;\n    const clamped = Math.min(Math.max(firstLevel, minAutoLevel), maxAutoLevel);\n    this.warn(`Could not find best starting auto level. Defaulting to first in playlist ${firstLevel} clamped to ${clamped}`);\n    return clamped;\n  }\n  get forcedAutoLevel() {\n    if (this.nextAutoLevelKey) {\n      return -1;\n    }\n    return this._nextAutoLevel;\n  }\n\n  // return next auto level\n  get nextAutoLevel() {\n    const forcedAutoLevel = this.forcedAutoLevel;\n    const bwEstimator = this.bwEstimator;\n    const useEstimate = bwEstimator.canEstimate();\n    const loadedFirstFrag = this.lastLoadedFragLevel > -1;\n    // in case next auto level has been forced, and bw not available or not reliable, return forced value\n    if (forcedAutoLevel !== -1 && (!useEstimate || !loadedFirstFrag || this.nextAutoLevelKey === this.getAutoLevelKey())) {\n      return forcedAutoLevel;\n    }\n\n    // compute next level using ABR logic\n    const nextABRAutoLevel = useEstimate && loadedFirstFrag ? this.getNextABRAutoLevel() : this.firstAutoLevel;\n\n    // use forced auto level while it hasn't errored more than ABR selection\n    if (forcedAutoLevel !== -1) {\n      const levels = this.hls.levels;\n      if (levels.length > Math.max(forcedAutoLevel, nextABRAutoLevel) && levels[forcedAutoLevel].loadError <= levels[nextABRAutoLevel].loadError) {\n        return forcedAutoLevel;\n      }\n    }\n\n    // save result until state has changed\n    this._nextAutoLevel = nextABRAutoLevel;\n    this.nextAutoLevelKey = this.getAutoLevelKey();\n    return nextABRAutoLevel;\n  }\n  getAutoLevelKey() {\n    return `${this.getBwEstimate()}_${this.getStarvationDelay().toFixed(2)}`;\n  }\n  getNextABRAutoLevel() {\n    const {\n      fragCurrent,\n      partCurrent,\n      hls\n    } = this;\n    if (hls.levels.length <= 1) {\n      return hls.loadLevel;\n    }\n    const {\n      maxAutoLevel,\n      config,\n      minAutoLevel\n    } = hls;\n    const currentFragDuration = partCurrent ? partCurrent.duration : fragCurrent ? fragCurrent.duration : 0;\n    const avgbw = this.getBwEstimate();\n    // bufferStarvationDelay is the wall-clock time left until the playback buffer is exhausted.\n    const bufferStarvationDelay = this.getStarvationDelay();\n    let bwFactor = config.abrBandWidthFactor;\n    let bwUpFactor = config.abrBandWidthUpFactor;\n\n    // First, look to see if we can find a level matching with our avg bandwidth AND that could also guarantee no rebuffering at all\n    if (bufferStarvationDelay) {\n      const _bestLevel = this.findBestLevel(avgbw, minAutoLevel, maxAutoLevel, bufferStarvationDelay, 0, bwFactor, bwUpFactor);\n      if (_bestLevel >= 0) {\n        this.rebufferNotice = -1;\n        return _bestLevel;\n      }\n    }\n    // not possible to get rid of rebuffering... try to find level that will guarantee less than maxStarvationDelay of rebuffering\n    let maxStarvationDelay = currentFragDuration ? Math.min(currentFragDuration, config.maxStarvationDelay) : config.maxStarvationDelay;\n    if (!bufferStarvationDelay) {\n      // in case buffer is empty, let's check if previous fragment was loaded to perform a bitrate test\n      const bitrateTestDelay = this.bitrateTestDelay;\n      if (bitrateTestDelay) {\n        // if it is the case, then we need to adjust our max starvation delay using maxLoadingDelay config value\n        // max video loading delay used in  automatic start level selection :\n        // in that mode ABR controller will ensure that video loading time (ie the time to fetch the first fragment at lowest quality level +\n        // the time to fetch the fragment at the appropriate quality level is less than ```maxLoadingDelay``` )\n        // cap maxLoadingDelay and ensure it is not bigger 'than bitrate test' frag duration\n        const maxLoadingDelay = currentFragDuration ? Math.min(currentFragDuration, config.maxLoadingDelay) : config.maxLoadingDelay;\n        maxStarvationDelay = maxLoadingDelay - bitrateTestDelay;\n        this.info(`bitrate test took ${Math.round(1000 * bitrateTestDelay)}ms, set first fragment max fetchDuration to ${Math.round(1000 * maxStarvationDelay)} ms`);\n        // don't use conservative factor on bitrate test\n        bwFactor = bwUpFactor = 1;\n      }\n    }\n    const bestLevel = this.findBestLevel(avgbw, minAutoLevel, maxAutoLevel, bufferStarvationDelay, maxStarvationDelay, bwFactor, bwUpFactor);\n    if (this.rebufferNotice !== bestLevel) {\n      this.rebufferNotice = bestLevel;\n      this.info(`${bufferStarvationDelay ? 'rebuffering expected' : 'buffer is empty'}, optimal quality level ${bestLevel}`);\n    }\n    if (bestLevel > -1) {\n      return bestLevel;\n    }\n    // If no matching level found, see if min auto level would be a better option\n    const minLevel = hls.levels[minAutoLevel];\n    const autoLevel = hls.loadLevelObj;\n    if (autoLevel && (minLevel == null ? void 0 : minLevel.bitrate) < autoLevel.bitrate) {\n      return minAutoLevel;\n    }\n    // or if bitrate is not lower, continue to use loadLevel\n    return hls.loadLevel;\n  }\n  getStarvationDelay() {\n    const hls = this.hls;\n    const media = hls.media;\n    if (!media) {\n      return Infinity;\n    }\n    // playbackRate is the absolute value of the playback rate; if media.playbackRate is 0, we use 1 to load as\n    // if we're playing back at the normal rate.\n    const playbackRate = media && media.playbackRate !== 0 ? Math.abs(media.playbackRate) : 1.0;\n    const bufferInfo = hls.mainForwardBufferInfo;\n    return (bufferInfo ? bufferInfo.len : 0) / playbackRate;\n  }\n  getBwEstimate() {\n    return this.bwEstimator.canEstimate() ? this.bwEstimator.getEstimate() : this.hls.config.abrEwmaDefaultEstimate;\n  }\n  findBestLevel(currentBw, minAutoLevel, maxAutoLevel, bufferStarvationDelay, maxStarvationDelay, bwFactor, bwUpFactor) {\n    var _this$hls$latestLevel;\n    const maxFetchDuration = bufferStarvationDelay + maxStarvationDelay;\n    const lastLoadedFragLevel = this.lastLoadedFragLevel;\n    const selectionBaseLevel = lastLoadedFragLevel === -1 ? this.hls.firstLevel : lastLoadedFragLevel;\n    const {\n      fragCurrent,\n      partCurrent\n    } = this;\n    const {\n      levels,\n      allAudioTracks,\n      loadLevel,\n      config\n    } = this.hls;\n    if (levels.length === 1) {\n      return 0;\n    }\n    const level = levels[selectionBaseLevel];\n    const live = !!((_this$hls$latestLevel = this.hls.latestLevelDetails) != null && _this$hls$latestLevel.live);\n    const firstSelection = loadLevel === -1 || lastLoadedFragLevel === -1;\n    let currentCodecSet;\n    let currentVideoRange = 'SDR';\n    let currentFrameRate = (level == null ? void 0 : level.frameRate) || 0;\n    const {\n      audioPreference,\n      videoPreference\n    } = config;\n    const audioTracksByGroup = this.audioTracksByGroup || (this.audioTracksByGroup = getAudioTracksByGroup(allAudioTracks));\n    let minStartIndex = -1;\n    if (firstSelection) {\n      if (this.firstSelection !== -1) {\n        return this.firstSelection;\n      }\n      const codecTiers = this.codecTiers || (this.codecTiers = getCodecTiers(levels, audioTracksByGroup, minAutoLevel, maxAutoLevel));\n      const startTier = getStartCodecTier(codecTiers, currentVideoRange, currentBw, audioPreference, videoPreference);\n      const {\n        codecSet,\n        videoRanges,\n        minFramerate,\n        minBitrate,\n        minIndex,\n        preferHDR\n      } = startTier;\n      minStartIndex = minIndex;\n      currentCodecSet = codecSet;\n      currentVideoRange = preferHDR ? videoRanges[videoRanges.length - 1] : videoRanges[0];\n      currentFrameRate = minFramerate;\n      currentBw = Math.max(currentBw, minBitrate);\n      this.log(`picked start tier ${stringify(startTier)}`);\n    } else {\n      currentCodecSet = level == null ? void 0 : level.codecSet;\n      currentVideoRange = level == null ? void 0 : level.videoRange;\n    }\n    const currentFragDuration = partCurrent ? partCurrent.duration : fragCurrent ? fragCurrent.duration : 0;\n    const ttfbEstimateSec = this.bwEstimator.getEstimateTTFB() / 1000;\n    const levelsSkipped = [];\n    for (let i = maxAutoLevel; i >= minAutoLevel; i--) {\n      var _levelInfo$supportedR;\n      const levelInfo = levels[i];\n      const upSwitch = i > selectionBaseLevel;\n      if (!levelInfo) {\n        continue;\n      }\n      if (config.useMediaCapabilities && !levelInfo.supportedResult && !levelInfo.supportedPromise) {\n        const mediaCapabilities = navigator.mediaCapabilities;\n        if (typeof (mediaCapabilities == null ? void 0 : mediaCapabilities.decodingInfo) === 'function' && requiresMediaCapabilitiesDecodingInfo(levelInfo, audioTracksByGroup, currentVideoRange, currentFrameRate, currentBw, audioPreference)) {\n          levelInfo.supportedPromise = getMediaDecodingInfoPromise(levelInfo, audioTracksByGroup, mediaCapabilities, this.supportedCache);\n          levelInfo.supportedPromise.then(decodingInfo => {\n            if (!this.hls) {\n              return;\n            }\n            levelInfo.supportedResult = decodingInfo;\n            const levels = this.hls.levels;\n            const index = levels.indexOf(levelInfo);\n            if (decodingInfo.error) {\n              this.warn(`MediaCapabilities decodingInfo error: \"${decodingInfo.error}\" for level ${index} ${stringify(decodingInfo)}`);\n            } else if (!decodingInfo.supported) {\n              this.warn(`Unsupported MediaCapabilities decodingInfo result for level ${index} ${stringify(decodingInfo)}`);\n              if (index > -1 && levels.length > 1) {\n                this.log(`Removing unsupported level ${index}`);\n                this.hls.removeLevel(index);\n                if (this.hls.loadLevel === -1) {\n                  this.hls.nextLoadLevel = 0;\n                }\n              }\n            } else if (decodingInfo.decodingInfoResults.some(info => info.smooth === false || info.powerEfficient === false)) {\n              this.log(`MediaCapabilities decodingInfo for level ${index} not smooth or powerEfficient: ${stringify(decodingInfo)}`);\n            }\n          }).catch(error => {\n            this.warn(`Error handling MediaCapabilities decodingInfo: ${error}`);\n          });\n        } else {\n          levelInfo.supportedResult = SUPPORTED_INFO_DEFAULT;\n        }\n      }\n\n      // skip candidates which change codec-family or video-range,\n      // and which decrease or increase frame-rate for up and down-switch respectfully\n      if (currentCodecSet && levelInfo.codecSet !== currentCodecSet || currentVideoRange && levelInfo.videoRange !== currentVideoRange || upSwitch && currentFrameRate > levelInfo.frameRate || !upSwitch && currentFrameRate > 0 && currentFrameRate < levelInfo.frameRate || (_levelInfo$supportedR = levelInfo.supportedResult) != null && (_levelInfo$supportedR = _levelInfo$supportedR.decodingInfoResults) != null && _levelInfo$supportedR.some(info => info.smooth === false)) {\n        if (!firstSelection || i !== minStartIndex) {\n          levelsSkipped.push(i);\n          continue;\n        }\n      }\n      const levelDetails = levelInfo.details;\n      const avgDuration = (partCurrent ? levelDetails == null ? void 0 : levelDetails.partTarget : levelDetails == null ? void 0 : levelDetails.averagetargetduration) || currentFragDuration;\n      let adjustedbw;\n      // follow algorithm captured from stagefright :\n      // https://android.googlesource.com/platform/frameworks/av/+/master/media/libstagefright/httplive/LiveSession.cpp\n      // Pick the highest bandwidth stream below or equal to estimated bandwidth.\n      // consider only 80% of the available bandwidth, but if we are switching up,\n      // be even more conservative (70%) to avoid overestimating and immediately\n      // switching back.\n      if (!upSwitch) {\n        adjustedbw = bwFactor * currentBw;\n      } else {\n        adjustedbw = bwUpFactor * currentBw;\n      }\n\n      // Use average bitrate when starvation delay (buffer length) is gt or eq two segment durations and rebuffering is not expected (maxStarvationDelay > 0)\n      const bitrate = currentFragDuration && bufferStarvationDelay >= currentFragDuration * 2 && maxStarvationDelay === 0 ? levelInfo.averageBitrate : levelInfo.maxBitrate;\n      const fetchDuration = this.getTimeToLoadFrag(ttfbEstimateSec, adjustedbw, bitrate * avgDuration, levelDetails === undefined);\n      const canSwitchWithinTolerance =\n      // if adjusted bw is greater than level bitrate AND\n      adjustedbw >= bitrate && (\n      // no level change, or new level has no error history\n      i === lastLoadedFragLevel || levelInfo.loadError === 0 && levelInfo.fragmentError === 0) && (\n      // fragment fetchDuration unknown OR live stream OR fragment fetchDuration less than max allowed fetch duration, then this level matches\n      // we don't account for max Fetch Duration for live streams, this is to avoid switching down when near the edge of live sliding window ...\n      // special case to support startLevel = -1 (bitrateTest) on live streams : in that case we should not exit loop so that findBestLevel will return -1\n      fetchDuration <= ttfbEstimateSec || !isFiniteNumber(fetchDuration) || live && !this.bitrateTestDelay || fetchDuration < maxFetchDuration);\n      if (canSwitchWithinTolerance) {\n        const forcedAutoLevel = this.forcedAutoLevel;\n        if (i !== loadLevel && (forcedAutoLevel === -1 || forcedAutoLevel !== loadLevel)) {\n          if (levelsSkipped.length) {\n            this.trace(`Skipped level(s) ${levelsSkipped.join(',')} of ${maxAutoLevel} max with CODECS and VIDEO-RANGE:\"${levels[levelsSkipped[0]].codecs}\" ${levels[levelsSkipped[0]].videoRange}; not compatible with \"${currentCodecSet}\" ${currentVideoRange}`);\n          }\n          this.info(`switch candidate:${selectionBaseLevel}->${i} adjustedbw(${Math.round(adjustedbw)})-bitrate=${Math.round(adjustedbw - bitrate)} ttfb:${ttfbEstimateSec.toFixed(1)} avgDuration:${avgDuration.toFixed(1)} maxFetchDuration:${maxFetchDuration.toFixed(1)} fetchDuration:${fetchDuration.toFixed(1)} firstSelection:${firstSelection} codecSet:${levelInfo.codecSet} videoRange:${levelInfo.videoRange} hls.loadLevel:${loadLevel}`);\n        }\n        if (firstSelection) {\n          this.firstSelection = i;\n        }\n        // as we are looping from highest to lowest, this will return the best achievable quality level\n        return i;\n      }\n    }\n    // not enough time budget even with quality level 0 ... rebuffering might happen\n    return -1;\n  }\n  set nextAutoLevel(nextLevel) {\n    const value = this.deriveNextAutoLevel(nextLevel);\n    if (this._nextAutoLevel !== value) {\n      this.nextAutoLevelKey = '';\n      this._nextAutoLevel = value;\n    }\n  }\n  deriveNextAutoLevel(nextLevel) {\n    const {\n      maxAutoLevel,\n      minAutoLevel\n    } = this.hls;\n    return Math.min(Math.max(nextLevel, minAutoLevel), maxAutoLevel);\n  }\n}\n\nconst BinarySearch = {\n  /**\n   * Searches for an item in an array which matches a certain condition.\n   * This requires the condition to only match one item in the array,\n   * and for the array to be ordered.\n   *\n   * @param list The array to search.\n   * @param comparisonFn\n   *      Called and provided a candidate item as the first argument.\n   *      Should return:\n   *          > -1 if the item should be located at a lower index than the provided item.\n   *          > 1 if the item should be located at a higher index than the provided item.\n   *          > 0 if the item is the item you're looking for.\n   *\n   * @returns the object if found, otherwise returns null\n   */\n  search: function (list, comparisonFn) {\n    let minIndex = 0;\n    let maxIndex = list.length - 1;\n    let currentIndex = null;\n    let currentElement = null;\n    while (minIndex <= maxIndex) {\n      currentIndex = (minIndex + maxIndex) / 2 | 0;\n      currentElement = list[currentIndex];\n      const comparisonResult = comparisonFn(currentElement);\n      if (comparisonResult > 0) {\n        minIndex = currentIndex + 1;\n      } else if (comparisonResult < 0) {\n        maxIndex = currentIndex - 1;\n      } else {\n        return currentElement;\n      }\n    }\n    return null;\n  }\n};\n\n/**\n * Returns first fragment whose endPdt value exceeds the given PDT, or null.\n * @param fragments - The array of candidate fragments\n * @param PDTValue - The PDT value which must be exceeded\n * @param maxFragLookUpTolerance - The amount of time that a fragment's start/end can be within in order to be considered contiguous\n */\nfunction findFragmentByPDT(fragments, PDTValue, maxFragLookUpTolerance) {\n  if (PDTValue === null || !Array.isArray(fragments) || !fragments.length || !isFiniteNumber(PDTValue)) {\n    return null;\n  }\n\n  // if less than start\n  const startPDT = fragments[0].programDateTime;\n  if (PDTValue < (startPDT || 0)) {\n    return null;\n  }\n  const endPDT = fragments[fragments.length - 1].endProgramDateTime;\n  if (PDTValue >= (endPDT || 0)) {\n    return null;\n  }\n  for (let seg = 0; seg < fragments.length; ++seg) {\n    const frag = fragments[seg];\n    if (pdtWithinToleranceTest(PDTValue, maxFragLookUpTolerance, frag)) {\n      return frag;\n    }\n  }\n  return null;\n}\n\n/**\n * Finds a fragment based on the SN of the previous fragment; or based on the needs of the current buffer.\n * This method compensates for small buffer gaps by applying a tolerance to the start of any candidate fragment, thus\n * breaking any traps which would cause the same fragment to be continuously selected within a small range.\n * @param fragPrevious - The last frag successfully appended\n * @param fragments - The array of candidate fragments\n * @param bufferEnd - The end of the contiguous buffered range the playhead is currently within\n * @param maxFragLookUpTolerance - The amount of time that a fragment's start/end can be within in order to be considered contiguous\n * @returns a matching fragment or null\n */\nfunction findFragmentByPTS(fragPrevious, fragments, bufferEnd = 0, maxFragLookUpTolerance = 0, nextFragLookupTolerance = 0.005) {\n  let fragNext = null;\n  if (fragPrevious) {\n    fragNext = fragments[1 + fragPrevious.sn - fragments[0].sn] || null;\n    // check for buffer-end rounding error\n    const bufferEdgeError = fragPrevious.endDTS - bufferEnd;\n    if (bufferEdgeError > 0 && bufferEdgeError < 0.0000015) {\n      bufferEnd += 0.0000015;\n    }\n    if (fragNext && fragPrevious.level !== fragNext.level && fragNext.end <= fragPrevious.end) {\n      fragNext = fragments[2 + fragPrevious.sn - fragments[0].sn] || null;\n    }\n  } else if (bufferEnd === 0 && fragments[0].start === 0) {\n    fragNext = fragments[0];\n  }\n  // Prefer the next fragment if it's within tolerance\n  if (fragNext && ((!fragPrevious || fragPrevious.level === fragNext.level) && fragmentWithinToleranceTest(bufferEnd, maxFragLookUpTolerance, fragNext) === 0 || fragmentWithinFastStartSwitch(fragNext, fragPrevious, Math.min(nextFragLookupTolerance, maxFragLookUpTolerance)))) {\n    return fragNext;\n  }\n  // We might be seeking past the tolerance so find the best match\n  const foundFragment = BinarySearch.search(fragments, fragmentWithinToleranceTest.bind(null, bufferEnd, maxFragLookUpTolerance));\n  if (foundFragment && (foundFragment !== fragPrevious || !fragNext)) {\n    return foundFragment;\n  }\n  // If no match was found return the next fragment after fragPrevious, or null\n  return fragNext;\n}\nfunction fragmentWithinFastStartSwitch(fragNext, fragPrevious, nextFragLookupTolerance) {\n  if (fragPrevious && fragPrevious.start === 0 && fragPrevious.level < fragNext.level && (fragPrevious.endPTS || 0) > 0) {\n    const firstDuration = fragPrevious.tagList.reduce((duration, tag) => {\n      if (tag[0] === 'INF') {\n        duration += parseFloat(tag[1]);\n      }\n      return duration;\n    }, nextFragLookupTolerance);\n    return fragNext.start <= firstDuration;\n  }\n  return false;\n}\n\n/**\n * The test function used by the findFragmentBySn's BinarySearch to look for the best match to the current buffer conditions.\n * @param candidate - The fragment to test\n * @param bufferEnd - The end of the current buffered range the playhead is currently within\n * @param maxFragLookUpTolerance - The amount of time that a fragment's start can be within in order to be considered contiguous\n * @returns 0 if it matches, 1 if too low, -1 if too high\n */\nfunction fragmentWithinToleranceTest(bufferEnd = 0, maxFragLookUpTolerance = 0, candidate) {\n  // eagerly accept an accurate match (no tolerance)\n  if (candidate.start <= bufferEnd && candidate.start + candidate.duration > bufferEnd) {\n    return 0;\n  }\n  // offset should be within fragment boundary - config.maxFragLookUpTolerance\n  // this is to cope with situations like\n  // bufferEnd = 9.991\n  // frag[] : [0,10]\n  // frag[1] : [10,20]\n  // bufferEnd is within frag[0] range ... although what we are expecting is to return frag[1] here\n  //              frag start               frag start+duration\n  //                  |-----------------------------|\n  //              <--->                         <--->\n  //  ...--------><-----------------------------><---------....\n  // previous frag         matching fragment         next frag\n  //  return -1             return 0                 return 1\n  // logger.log(`level/sn/start/end/bufEnd:${level}/${candidate.sn}/${candidate.start}/${(candidate.start+candidate.duration)}/${bufferEnd}`);\n  // Set the lookup tolerance to be small enough to detect the current segment - ensures we don't skip over very small segments\n  const candidateLookupTolerance = Math.min(maxFragLookUpTolerance, candidate.duration + (candidate.deltaPTS ? candidate.deltaPTS : 0));\n  if (candidate.start + candidate.duration - candidateLookupTolerance <= bufferEnd) {\n    return 1;\n  } else if (candidate.start - candidateLookupTolerance > bufferEnd && candidate.start) {\n    // if maxFragLookUpTolerance will have negative value then don't return -1 for first element\n    return -1;\n  }\n  return 0;\n}\n\n/**\n * The test function used by the findFragmentByPdt's BinarySearch to look for the best match to the current buffer conditions.\n * This function tests the candidate's program date time values, as represented in Unix time\n * @param candidate - The fragment to test\n * @param pdtBufferEnd - The Unix time representing the end of the current buffered range\n * @param maxFragLookUpTolerance - The amount of time that a fragment's start can be within in order to be considered contiguous\n * @returns true if contiguous, false otherwise\n */\nfunction pdtWithinToleranceTest(pdtBufferEnd, maxFragLookUpTolerance, candidate) {\n  const candidateLookupTolerance = Math.min(maxFragLookUpTolerance, candidate.duration + (candidate.deltaPTS ? candidate.deltaPTS : 0)) * 1000;\n\n  // endProgramDateTime can be null, default to zero\n  const endProgramDateTime = candidate.endProgramDateTime || 0;\n  return endProgramDateTime - candidateLookupTolerance > pdtBufferEnd;\n}\nfunction findNearestWithCC(details, cc, pos) {\n  if (details) {\n    if (details.startCC <= cc && details.endCC >= cc) {\n      let fragments = details.fragments;\n      const {\n        fragmentHint\n      } = details;\n      if (fragmentHint) {\n        fragments = fragments.concat(fragmentHint);\n      }\n      let closest;\n      BinarySearch.search(fragments, candidate => {\n        if (candidate.cc < cc) {\n          return 1;\n        }\n        if (candidate.cc > cc) {\n          return -1;\n        }\n        closest = candidate;\n        if (candidate.end <= pos) {\n          return 1;\n        }\n        if (candidate.start > pos) {\n          return -1;\n        }\n        return 0;\n      });\n      return closest || null;\n    }\n  }\n  return null;\n}\n\nfunction isTimeoutError(error) {\n  switch (error.details) {\n    case ErrorDetails.FRAG_LOAD_TIMEOUT:\n    case ErrorDetails.KEY_LOAD_TIMEOUT:\n    case ErrorDetails.LEVEL_LOAD_TIMEOUT:\n    case ErrorDetails.MANIFEST_LOAD_TIMEOUT:\n      return true;\n  }\n  return false;\n}\nfunction isKeyError(error) {\n  return error.details.startsWith('key');\n}\nfunction isUnusableKeyError(error) {\n  return isKeyError(error) && !!error.frag && !error.frag.decryptdata;\n}\nfunction getRetryConfig(loadPolicy, error) {\n  const isTimeout = isTimeoutError(error);\n  return loadPolicy.default[`${isTimeout ? 'timeout' : 'error'}Retry`];\n}\nfunction getRetryDelay(retryConfig, retryCount) {\n  // exponential backoff capped to max retry delay\n  const backoffFactor = retryConfig.backoff === 'linear' ? 1 : Math.pow(2, retryCount);\n  return Math.min(backoffFactor * retryConfig.retryDelayMs, retryConfig.maxRetryDelayMs);\n}\nfunction getLoaderConfigWithoutReties(loderConfig) {\n  return _objectSpread2(_objectSpread2({}, loderConfig), {\n    errorRetry: null,\n    timeoutRetry: null\n  });\n}\nfunction shouldRetry(retryConfig, retryCount, isTimeout, loaderResponse) {\n  if (!retryConfig) {\n    return false;\n  }\n  const httpStatus = loaderResponse == null ? void 0 : loaderResponse.code;\n  const retry = retryCount < retryConfig.maxNumRetry && (retryForHttpStatus(httpStatus) || !!isTimeout);\n  return retryConfig.shouldRetry ? retryConfig.shouldRetry(retryConfig, retryCount, isTimeout, loaderResponse, retry) : retry;\n}\nfunction retryForHttpStatus(httpStatus) {\n  // Do not retry on status 4xx, status 0 (CORS error), or undefined (decrypt/gap/parse error)\n  return offlineHttpStatus(httpStatus) || !!httpStatus && (httpStatus < 400 || httpStatus > 499);\n}\nfunction offlineHttpStatus(httpStatus) {\n  return httpStatus === 0 && navigator.onLine === false;\n}\n\nvar NetworkErrorAction = {\n  DoNothing: 0,\n  SendEndCallback: 1,\n  SendAlternateToPenaltyBox: 2,\n  RemoveAlternatePermanently: 3,\n  InsertDiscontinuity: 4,\n  RetryRequest: 5\n};\nvar ErrorActionFlags = {\n  None: 0,\n  MoveAllAlternatesMatchingHost: 1,\n  MoveAllAlternatesMatchingHDCP: 2,\n  MoveAllAlternatesMatchingKey: 4,\n  SwitchToSDR: 8\n};\nclass ErrorController extends Logger {\n  constructor(hls) {\n    super('error-controller', hls.logger);\n    this.hls = void 0;\n    this.playlistError = 0;\n    this.hls = hls;\n    this.registerListeners();\n  }\n  registerListeners() {\n    const hls = this.hls;\n    hls.on(Events.ERROR, this.onError, this);\n    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.on(Events.LEVEL_UPDATED, this.onLevelUpdated, this);\n  }\n  unregisterListeners() {\n    const hls = this.hls;\n    if (!hls) {\n      return;\n    }\n    hls.off(Events.ERROR, this.onError, this);\n    hls.off(Events.ERROR, this.onErrorOut, this);\n    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.off(Events.LEVEL_UPDATED, this.onLevelUpdated, this);\n  }\n  destroy() {\n    this.unregisterListeners();\n    // @ts-ignore\n    this.hls = null;\n  }\n  startLoad(startPosition) {}\n  stopLoad() {\n    this.playlistError = 0;\n  }\n  getVariantLevelIndex(frag) {\n    if ((frag == null ? void 0 : frag.type) === PlaylistLevelType.MAIN) {\n      return frag.level;\n    }\n    return this.getVariantIndex();\n  }\n  getVariantIndex() {\n    var _hls$loadLevelObj;\n    const hls = this.hls;\n    const currentLevel = hls.currentLevel;\n    if ((_hls$loadLevelObj = hls.loadLevelObj) != null && _hls$loadLevelObj.details || currentLevel === -1) {\n      return hls.loadLevel;\n    }\n    return currentLevel;\n  }\n  variantHasKey(level, keyInError) {\n    if (level) {\n      var _level$details;\n      if ((_level$details = level.details) != null && _level$details.hasKey(keyInError)) {\n        return true;\n      }\n      const audioGroupsIds = level.audioGroups;\n      if (audioGroupsIds) {\n        const audioTracks = this.hls.allAudioTracks.filter(track => audioGroupsIds.indexOf(track.groupId) >= 0);\n        return audioTracks.some(track => {\n          var _track$details;\n          return (_track$details = track.details) == null ? void 0 : _track$details.hasKey(keyInError);\n        });\n      }\n    }\n    return false;\n  }\n  onManifestLoading() {\n    this.playlistError = 0;\n  }\n  onLevelUpdated() {\n    this.playlistError = 0;\n  }\n  onError(event, data) {\n    var _data$frag;\n    if (data.fatal) {\n      return;\n    }\n    const hls = this.hls;\n    const context = data.context;\n    switch (data.details) {\n      case ErrorDetails.FRAG_LOAD_ERROR:\n      case ErrorDetails.FRAG_LOAD_TIMEOUT:\n      case ErrorDetails.KEY_LOAD_ERROR:\n      case ErrorDetails.KEY_LOAD_TIMEOUT:\n        data.errorAction = this.getFragRetryOrSwitchAction(data);\n        return;\n      case ErrorDetails.FRAG_PARSING_ERROR:\n        // ignore empty segment errors marked as gap\n        if ((_data$frag = data.frag) != null && _data$frag.gap) {\n          data.errorAction = createDoNothingErrorAction();\n          return;\n        }\n      // falls through\n      case ErrorDetails.FRAG_GAP:\n      case ErrorDetails.FRAG_DECRYPT_ERROR:\n        {\n          // Switch level if possible, otherwise allow retry count to reach max error retries\n          data.errorAction = this.getFragRetryOrSwitchAction(data);\n          data.errorAction.action = NetworkErrorAction.SendAlternateToPenaltyBox;\n          return;\n        }\n      case ErrorDetails.LEVEL_EMPTY_ERROR:\n      case ErrorDetails.LEVEL_PARSING_ERROR:\n        {\n          var _data$context;\n          // Only retry when empty and live\n          const levelIndex = data.parent === PlaylistLevelType.MAIN ? data.level : hls.loadLevel;\n          if (data.details === ErrorDetails.LEVEL_EMPTY_ERROR && !!((_data$context = data.context) != null && (_data$context = _data$context.levelDetails) != null && _data$context.live)) {\n            data.errorAction = this.getPlaylistRetryOrSwitchAction(data, levelIndex);\n          } else {\n            // Escalate to fatal if not retrying or switching\n            data.levelRetry = false;\n            data.errorAction = this.getLevelSwitchAction(data, levelIndex);\n          }\n        }\n        return;\n      case ErrorDetails.LEVEL_LOAD_ERROR:\n      case ErrorDetails.LEVEL_LOAD_TIMEOUT:\n        if (typeof (context == null ? void 0 : context.level) === 'number') {\n          data.errorAction = this.getPlaylistRetryOrSwitchAction(data, context.level);\n        }\n        return;\n      case ErrorDetails.AUDIO_TRACK_LOAD_ERROR:\n      case ErrorDetails.AUDIO_TRACK_LOAD_TIMEOUT:\n      case ErrorDetails.SUBTITLE_LOAD_ERROR:\n      case ErrorDetails.SUBTITLE_TRACK_LOAD_TIMEOUT:\n        if (context) {\n          const level = hls.loadLevelObj;\n          if (level && (context.type === PlaylistContextType.AUDIO_TRACK && level.hasAudioGroup(context.groupId) || context.type === PlaylistContextType.SUBTITLE_TRACK && level.hasSubtitleGroup(context.groupId))) {\n            // Perform Pathway switch or Redundant failover if possible for fastest recovery\n            // otherwise allow playlist retry count to reach max error retries\n            data.errorAction = this.getPlaylistRetryOrSwitchAction(data, hls.loadLevel);\n            data.errorAction.action = NetworkErrorAction.SendAlternateToPenaltyBox;\n            data.errorAction.flags = ErrorActionFlags.MoveAllAlternatesMatchingHost;\n            return;\n          }\n        }\n        return;\n      case ErrorDetails.KEY_SYSTEM_STATUS_OUTPUT_RESTRICTED:\n        {\n          data.errorAction = {\n            action: NetworkErrorAction.SendAlternateToPenaltyBox,\n            flags: ErrorActionFlags.MoveAllAlternatesMatchingHDCP\n          };\n        }\n        return;\n      case ErrorDetails.KEY_SYSTEM_SESSION_UPDATE_FAILED:\n      case ErrorDetails.KEY_SYSTEM_STATUS_INTERNAL_ERROR:\n      case ErrorDetails.KEY_SYSTEM_NO_SESSION:\n        {\n          data.errorAction = {\n            action: NetworkErrorAction.SendAlternateToPenaltyBox,\n            flags: ErrorActionFlags.MoveAllAlternatesMatchingKey\n          };\n        }\n        return;\n      case ErrorDetails.BUFFER_ADD_CODEC_ERROR:\n      case ErrorDetails.REMUX_ALLOC_ERROR:\n      case ErrorDetails.BUFFER_APPEND_ERROR:\n        // Buffer-controller can set errorAction when append errors can be ignored or resolved locally\n        if (!data.errorAction) {\n          var _data$level;\n          data.errorAction = this.getLevelSwitchAction(data, (_data$level = data.level) != null ? _data$level : hls.loadLevel);\n        }\n        return;\n      case ErrorDetails.INTERNAL_EXCEPTION:\n      case ErrorDetails.BUFFER_APPENDING_ERROR:\n      case ErrorDetails.BUFFER_FULL_ERROR:\n      case ErrorDetails.LEVEL_SWITCH_ERROR:\n      case ErrorDetails.BUFFER_STALLED_ERROR:\n      case ErrorDetails.BUFFER_SEEK_OVER_HOLE:\n      case ErrorDetails.BUFFER_NUDGE_ON_STALL:\n        data.errorAction = createDoNothingErrorAction();\n        return;\n    }\n    if (data.type === ErrorTypes.KEY_SYSTEM_ERROR) {\n      // Do not retry level. Should be fatal if ErrorDetails.KEY_SYSTEM_<ERROR> not handled with early return above.\n      data.levelRetry = false;\n      data.errorAction = createDoNothingErrorAction();\n    }\n  }\n  getPlaylistRetryOrSwitchAction(data, levelIndex) {\n    const hls = this.hls;\n    const retryConfig = getRetryConfig(hls.config.playlistLoadPolicy, data);\n    const retryCount = this.playlistError++;\n    const retry = shouldRetry(retryConfig, retryCount, isTimeoutError(data), data.response);\n    if (retry) {\n      return {\n        action: NetworkErrorAction.RetryRequest,\n        flags: ErrorActionFlags.None,\n        retryConfig,\n        retryCount\n      };\n    }\n    const errorAction = this.getLevelSwitchAction(data, levelIndex);\n    if (retryConfig) {\n      errorAction.retryConfig = retryConfig;\n      errorAction.retryCount = retryCount;\n    }\n    return errorAction;\n  }\n  getFragRetryOrSwitchAction(data) {\n    const hls = this.hls;\n    // Share fragment error count accross media options (main, audio, subs)\n    // This allows for level based rendition switching when media option assets fail\n    const variantLevelIndex = this.getVariantLevelIndex(data.frag);\n    const level = hls.levels[variantLevelIndex];\n    const {\n      fragLoadPolicy,\n      keyLoadPolicy\n    } = hls.config;\n    const retryConfig = getRetryConfig(isKeyError(data) ? keyLoadPolicy : fragLoadPolicy, data);\n    const fragmentErrors = hls.levels.reduce((acc, level) => acc + level.fragmentError, 0);\n    // Switch levels when out of retried or level index out of bounds\n    if (level) {\n      if (data.details !== ErrorDetails.FRAG_GAP) {\n        level.fragmentError++;\n      }\n      if (!isUnusableKeyError(data)) {\n        const retry = shouldRetry(retryConfig, fragmentErrors, isTimeoutError(data), data.response);\n        if (retry) {\n          return {\n            action: NetworkErrorAction.RetryRequest,\n            flags: ErrorActionFlags.None,\n            retryConfig,\n            retryCount: fragmentErrors\n          };\n        }\n      }\n    }\n    // Reach max retry count, or Missing level reference\n    // Switch to valid index\n    const errorAction = this.getLevelSwitchAction(data, variantLevelIndex);\n    // Add retry details to allow skipping of FRAG_PARSING_ERROR\n    if (retryConfig) {\n      errorAction.retryConfig = retryConfig;\n      errorAction.retryCount = fragmentErrors;\n    }\n    return errorAction;\n  }\n  getLevelSwitchAction(data, levelIndex) {\n    const hls = this.hls;\n    if (levelIndex === null || levelIndex === undefined) {\n      levelIndex = hls.loadLevel;\n    }\n    const level = this.hls.levels[levelIndex];\n    if (level) {\n      var _data$frag2, _data$context2;\n      const errorDetails = data.details;\n      level.loadError++;\n      if (errorDetails === ErrorDetails.BUFFER_APPEND_ERROR) {\n        level.fragmentError++;\n      }\n      // Search for next level to retry\n      let nextLevel = -1;\n      const {\n        levels,\n        loadLevel,\n        minAutoLevel,\n        maxAutoLevel\n      } = hls;\n      if (!hls.autoLevelEnabled && !hls.config.preserveManualLevelOnError) {\n        hls.loadLevel = -1;\n      }\n      const fragErrorType = (_data$frag2 = data.frag) == null ? void 0 : _data$frag2.type;\n      // Find alternate audio codec if available on audio codec error\n      const isAudioCodecError = fragErrorType === PlaylistLevelType.AUDIO && errorDetails === ErrorDetails.FRAG_PARSING_ERROR || data.sourceBufferName === 'audio' && (errorDetails === ErrorDetails.BUFFER_ADD_CODEC_ERROR || errorDetails === ErrorDetails.BUFFER_APPEND_ERROR);\n      const findAudioCodecAlternate = isAudioCodecError && levels.some(({\n        audioCodec\n      }) => level.audioCodec !== audioCodec);\n      // Find alternate video codec if available on video codec error\n      const isVideoCodecError = data.sourceBufferName === 'video' && (errorDetails === ErrorDetails.BUFFER_ADD_CODEC_ERROR || errorDetails === ErrorDetails.BUFFER_APPEND_ERROR);\n      const findVideoCodecAlternate = isVideoCodecError && levels.some(({\n        codecSet,\n        audioCodec\n      }) => level.codecSet !== codecSet && level.audioCodec === audioCodec);\n      const {\n        type: playlistErrorType,\n        groupId: playlistErrorGroupId\n      } = (_data$context2 = data.context) != null ? _data$context2 : {};\n      for (let i = levels.length; i--;) {\n        const candidate = (i + loadLevel) % levels.length;\n        if (candidate !== loadLevel && candidate >= minAutoLevel && candidate <= maxAutoLevel && levels[candidate].loadError === 0) {\n          var _level$audioGroups, _level$subtitleGroups;\n          const levelCandidate = levels[candidate];\n          // Skip level switch if GAP tag is found in next level at same position\n          if (errorDetails === ErrorDetails.FRAG_GAP && fragErrorType === PlaylistLevelType.MAIN && data.frag) {\n            const levelDetails = levels[candidate].details;\n            if (levelDetails) {\n              const fragCandidate = findFragmentByPTS(data.frag, levelDetails.fragments, data.frag.start);\n              if (fragCandidate != null && fragCandidate.gap) {\n                continue;\n              }\n            }\n          } else if (playlistErrorType === PlaylistContextType.AUDIO_TRACK && levelCandidate.hasAudioGroup(playlistErrorGroupId) || playlistErrorType === PlaylistContextType.SUBTITLE_TRACK && levelCandidate.hasSubtitleGroup(playlistErrorGroupId)) {\n            // For audio/subs playlist errors find another group ID or fallthrough to redundant fail-over\n            continue;\n          } else if (fragErrorType === PlaylistLevelType.AUDIO && (_level$audioGroups = level.audioGroups) != null && _level$audioGroups.some(groupId => levelCandidate.hasAudioGroup(groupId)) || fragErrorType === PlaylistLevelType.SUBTITLE && (_level$subtitleGroups = level.subtitleGroups) != null && _level$subtitleGroups.some(groupId => levelCandidate.hasSubtitleGroup(groupId)) || findAudioCodecAlternate && level.audioCodec === levelCandidate.audioCodec || findVideoCodecAlternate && level.codecSet === levelCandidate.codecSet || !findAudioCodecAlternate && level.codecSet !== levelCandidate.codecSet) {\n            // For video/audio/subs frag errors find another group ID or fallthrough to redundant fail-over\n            continue;\n          }\n          nextLevel = candidate;\n          break;\n        }\n      }\n      if (nextLevel > -1 && hls.loadLevel !== nextLevel) {\n        data.levelRetry = true;\n        this.playlistError = 0;\n        return {\n          action: NetworkErrorAction.SendAlternateToPenaltyBox,\n          flags: ErrorActionFlags.None,\n          nextAutoLevel: nextLevel\n        };\n      }\n    }\n    // No levels to switch / Manual level selection / Level not found\n    // Resolve with Pathway switch, Redundant fail-over, or stay on lowest Level\n    return {\n      action: NetworkErrorAction.SendAlternateToPenaltyBox,\n      flags: ErrorActionFlags.MoveAllAlternatesMatchingHost\n    };\n  }\n  onErrorOut(event, data) {\n    var _data$errorAction;\n    switch ((_data$errorAction = data.errorAction) == null ? void 0 : _data$errorAction.action) {\n      case NetworkErrorAction.DoNothing:\n        break;\n      case NetworkErrorAction.SendAlternateToPenaltyBox:\n        this.sendAlternateToPenaltyBox(data);\n        if (!data.errorAction.resolved && data.details !== ErrorDetails.FRAG_GAP) {\n          data.fatal = true;\n        } else if (/MediaSource readyState: ended/.test(data.error.message)) {\n          this.warn(`MediaSource ended after \"${data.sourceBufferName}\" sourceBuffer append error. Attempting to recover from media error.`);\n          this.hls.recoverMediaError();\n        }\n        break;\n      case NetworkErrorAction.RetryRequest:\n        // handled by stream and playlist/level controllers\n        break;\n    }\n    if (data.fatal) {\n      this.hls.stopLoad();\n      return;\n    }\n  }\n  sendAlternateToPenaltyBox(data) {\n    const hls = this.hls;\n    const errorAction = data.errorAction;\n    if (!errorAction) {\n      return;\n    }\n    const {\n      flags\n    } = errorAction;\n    const nextAutoLevel = errorAction.nextAutoLevel;\n    switch (flags) {\n      case ErrorActionFlags.None:\n        this.switchLevel(data, nextAutoLevel);\n        break;\n      case ErrorActionFlags.MoveAllAlternatesMatchingHDCP:\n        {\n          const levelIndex = this.getVariantLevelIndex(data.frag);\n          const level = hls.levels[levelIndex];\n          const restrictedHdcpLevel = level == null ? void 0 : level.attrs['HDCP-LEVEL'];\n          errorAction.hdcpLevel = restrictedHdcpLevel;\n          if (restrictedHdcpLevel === 'NONE') {\n            this.warn(`HDCP policy resticted output with HDCP-LEVEL=NONE`);\n          } else if (restrictedHdcpLevel) {\n            hls.maxHdcpLevel = HdcpLevels[HdcpLevels.indexOf(restrictedHdcpLevel) - 1];\n            errorAction.resolved = true;\n            this.warn(`Restricting playback to HDCP-LEVEL of \"${hls.maxHdcpLevel}\" or lower`);\n            break;\n          }\n          // Fallthrough when no HDCP-LEVEL attribute is found\n        }\n      // eslint-disable-next-line no-fallthrough\n      case ErrorActionFlags.MoveAllAlternatesMatchingKey:\n        {\n          const levelKey = data.decryptdata;\n          if (levelKey) {\n            // Penalize all levels with key\n            const levels = this.hls.levels;\n            const levelCountWithError = levels.length;\n            for (let i = levelCountWithError; i--;) {\n              if (this.variantHasKey(levels[i], levelKey)) {\n                var _levels$i$audioGroups, _data$frag3;\n                this.log(`Banned key found in level ${i} (${levels[i].bitrate}bps) or audio group \"${(_levels$i$audioGroups = levels[i].audioGroups) == null ? void 0 : _levels$i$audioGroups.join(',')}\" (${(_data$frag3 = data.frag) == null ? void 0 : _data$frag3.type} fragment) ${arrayToHex(levelKey.keyId || [])}`);\n                levels[i].fragmentError++;\n                levels[i].loadError++;\n                this.log(`Removing level ${i} with key error (${data.error})`);\n                this.hls.removeLevel(i);\n              }\n            }\n            const frag = data.frag;\n            if (this.hls.levels.length < levelCountWithError) {\n              errorAction.resolved = true;\n            } else if (frag && frag.type !== PlaylistLevelType.MAIN) {\n              // Ignore key error for audio track with unmatched key (main session error)\n              const fragLevelKey = frag.decryptdata;\n              if (fragLevelKey && !levelKey.matches(fragLevelKey)) {\n                errorAction.resolved = true;\n              }\n            }\n          }\n          break;\n        }\n    }\n    // If not resolved by previous actions try to switch to next level\n    if (!errorAction.resolved) {\n      this.switchLevel(data, nextAutoLevel);\n    }\n  }\n  switchLevel(data, levelIndex) {\n    if (levelIndex !== undefined && data.errorAction) {\n      this.warn(`switching to level ${levelIndex} after ${data.details}`);\n      this.hls.nextAutoLevel = levelIndex;\n      data.errorAction.resolved = true;\n      // Stream controller is responsible for this but won't switch on false start\n      this.hls.nextLoadLevel = this.hls.nextAutoLevel;\n      if (data.details === ErrorDetails.BUFFER_ADD_CODEC_ERROR && data.mimeType && data.sourceBufferName !== 'audiovideo') {\n        const codec = getCodecsForMimeType(data.mimeType);\n        const levels = this.hls.levels;\n        for (let i = levels.length; i--;) {\n          if (levels[i][`${data.sourceBufferName}Codec`] === codec) {\n            this.log(`Removing level ${i} for ${data.details} (\"${codec}\" not supported)`);\n            this.hls.removeLevel(i);\n          }\n        }\n      }\n    }\n  }\n}\nfunction createDoNothingErrorAction(resolved) {\n  const errorAction = {\n    action: NetworkErrorAction.DoNothing,\n    flags: ErrorActionFlags.None\n  };\n  if (resolved) {\n    errorAction.resolved = true;\n  }\n  return errorAction;\n}\n\nvar FragmentState = {\n  NOT_LOADED: \"NOT_LOADED\",\n  APPENDING: \"APPENDING\",\n  PARTIAL: \"PARTIAL\",\n  OK: \"OK\"\n};\nclass FragmentTracker {\n  constructor(hls) {\n    this.activePartLists = Object.create(null);\n    this.endListFragments = Object.create(null);\n    this.fragments = Object.create(null);\n    this.timeRanges = Object.create(null);\n    this.bufferPadding = 0.2;\n    this.hls = void 0;\n    this.hasGaps = false;\n    this.hls = hls;\n    this._registerListeners();\n  }\n  _registerListeners() {\n    const {\n      hls\n    } = this;\n    if (hls) {\n      hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      hls.on(Events.BUFFER_APPENDED, this.onBufferAppended, this);\n      hls.on(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n      hls.on(Events.FRAG_LOADED, this.onFragLoaded, this);\n    }\n  }\n  _unregisterListeners() {\n    const {\n      hls\n    } = this;\n    if (hls) {\n      hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      hls.off(Events.BUFFER_APPENDED, this.onBufferAppended, this);\n      hls.off(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n      hls.off(Events.FRAG_LOADED, this.onFragLoaded, this);\n    }\n  }\n  destroy() {\n    this._unregisterListeners();\n    // @ts-ignore\n    this.hls =\n    // @ts-ignore\n    this.fragments =\n    // @ts-ignore\n    this.activePartLists =\n    // @ts-ignore\n    this.endListFragments = this.timeRanges = null;\n  }\n\n  /**\n   * Return a Fragment or Part with an appended range that matches the position and levelType\n   * Otherwise, return null\n   */\n  getAppendedFrag(position, levelType) {\n    const activeParts = this.activePartLists[levelType];\n    if (activeParts) {\n      for (let i = activeParts.length; i--;) {\n        const activePart = activeParts[i];\n        if (!activePart) {\n          break;\n        }\n        if (activePart.start <= position && position <= activePart.end && activePart.loaded) {\n          return activePart;\n        }\n      }\n    }\n    return this.getBufferedFrag(position, levelType);\n  }\n\n  /**\n   * Return a buffered Fragment that matches the position and levelType.\n   * A buffered Fragment is one whose loading, parsing and appending is done (completed or \"partial\" meaning aborted).\n   * If not found any Fragment, return null\n   */\n  getBufferedFrag(position, levelType) {\n    return this.getFragAtPos(position, levelType, true);\n  }\n  getFragAtPos(position, levelType, buffered) {\n    const {\n      fragments\n    } = this;\n    const keys = Object.keys(fragments);\n    for (let i = keys.length; i--;) {\n      const fragmentEntity = fragments[keys[i]];\n      if ((fragmentEntity == null ? void 0 : fragmentEntity.body.type) === levelType && (!buffered || fragmentEntity.buffered)) {\n        const frag = fragmentEntity.body;\n        if (frag.start <= position && position <= frag.end) {\n          return frag;\n        }\n      }\n    }\n    return null;\n  }\n\n  /**\n   * Partial fragments effected by coded frame eviction will be removed\n   * The browser will unload parts of the buffer to free up memory for new buffer data\n   * Fragments will need to be reloaded when the buffer is freed up, removing partial fragments will allow them to reload(since there might be parts that are still playable)\n   */\n  detectEvictedFragments(elementaryStream, timeRange, playlistType, appendedPart, removeAppending) {\n    if (this.timeRanges) {\n      this.timeRanges[elementaryStream] = timeRange;\n    }\n    // Check if any flagged fragments have been unloaded\n    // excluding anything newer than appendedPartSn\n    const appendedPartSn = (appendedPart == null ? void 0 : appendedPart.fragment.sn) || -1;\n    Object.keys(this.fragments).forEach(key => {\n      const fragmentEntity = this.fragments[key];\n      if (!fragmentEntity) {\n        return;\n      }\n      if (appendedPartSn >= fragmentEntity.body.sn) {\n        return;\n      }\n      if (!fragmentEntity.buffered && (!fragmentEntity.loaded || removeAppending)) {\n        if (fragmentEntity.body.type === playlistType) {\n          this.removeFragment(fragmentEntity.body);\n        }\n        return;\n      }\n      const esData = fragmentEntity.range[elementaryStream];\n      if (!esData) {\n        return;\n      }\n      if (esData.time.length === 0) {\n        this.removeFragment(fragmentEntity.body);\n        return;\n      }\n      esData.time.some(time => {\n        const isNotBuffered = !this.isTimeBuffered(time.startPTS, time.endPTS, timeRange);\n        if (isNotBuffered) {\n          // Unregister partial fragment as it needs to load again to be reused\n          this.removeFragment(fragmentEntity.body);\n        }\n        return isNotBuffered;\n      });\n    });\n  }\n\n  /**\n   * Checks if the fragment passed in is loaded in the buffer properly\n   * Partially loaded fragments will be registered as a partial fragment\n   */\n  detectPartialFragments(data) {\n    const timeRanges = this.timeRanges;\n    if (!timeRanges || data.frag.sn === 'initSegment') {\n      return;\n    }\n    const frag = data.frag;\n    const fragKey = getFragmentKey(frag);\n    const fragmentEntity = this.fragments[fragKey];\n    if (!fragmentEntity || fragmentEntity.buffered && frag.gap) {\n      return;\n    }\n    const isFragHint = !frag.relurl;\n    Object.keys(timeRanges).forEach(elementaryStream => {\n      const streamInfo = frag.elementaryStreams[elementaryStream];\n      if (!streamInfo) {\n        return;\n      }\n      const timeRange = timeRanges[elementaryStream];\n      const partial = isFragHint || streamInfo.partial === true;\n      fragmentEntity.range[elementaryStream] = this.getBufferedTimes(frag, data.part, partial, timeRange);\n    });\n    fragmentEntity.loaded = null;\n    if (Object.keys(fragmentEntity.range).length) {\n      this.bufferedEnd(fragmentEntity, frag);\n      if (!isPartial(fragmentEntity)) {\n        // Remove older fragment parts from lookup after frag is tracked as buffered\n        this.removeParts(frag.sn - 1, frag.type);\n      }\n    } else {\n      // remove fragment if nothing was appended\n      this.removeFragment(fragmentEntity.body);\n    }\n  }\n  bufferedEnd(fragmentEntity, frag) {\n    fragmentEntity.buffered = true;\n    const endList = fragmentEntity.body.endList = frag.endList || fragmentEntity.body.endList;\n    if (endList) {\n      this.endListFragments[fragmentEntity.body.type] = fragmentEntity;\n    }\n  }\n  removeParts(snToKeep, levelType) {\n    const activeParts = this.activePartLists[levelType];\n    if (!activeParts) {\n      return;\n    }\n    this.activePartLists[levelType] = filterParts(activeParts, part => part.fragment.sn >= snToKeep);\n  }\n  fragBuffered(frag, force) {\n    const fragKey = getFragmentKey(frag);\n    let fragmentEntity = this.fragments[fragKey];\n    if (!fragmentEntity && force) {\n      fragmentEntity = this.fragments[fragKey] = {\n        body: frag,\n        appendedPTS: null,\n        loaded: null,\n        buffered: false,\n        range: Object.create(null)\n      };\n      if (frag.gap) {\n        this.hasGaps = true;\n      }\n    }\n    if (fragmentEntity) {\n      fragmentEntity.loaded = null;\n      this.bufferedEnd(fragmentEntity, frag);\n    }\n  }\n  getBufferedTimes(fragment, part, partial, timeRange) {\n    const buffered = {\n      time: [],\n      partial\n    };\n    const startPTS = fragment.start;\n    const endPTS = fragment.end;\n    const minEndPTS = fragment.minEndPTS || endPTS;\n    const maxStartPTS = fragment.maxStartPTS || startPTS;\n    for (let i = 0; i < timeRange.length; i++) {\n      const startTime = timeRange.start(i) - this.bufferPadding;\n      const endTime = timeRange.end(i) + this.bufferPadding;\n      if (maxStartPTS >= startTime && minEndPTS <= endTime) {\n        // Fragment is entirely contained in buffer\n        // No need to check the other timeRange times since it's completely playable\n        buffered.time.push({\n          startPTS: Math.max(startPTS, timeRange.start(i)),\n          endPTS: Math.min(endPTS, timeRange.end(i))\n        });\n        break;\n      } else if (startPTS < endTime && endPTS > startTime) {\n        const start = Math.max(startPTS, timeRange.start(i));\n        const end = Math.min(endPTS, timeRange.end(i));\n        if (end > start) {\n          buffered.partial = true;\n          // Check for intersection with buffer\n          // Get playable sections of the fragment\n          buffered.time.push({\n            startPTS: start,\n            endPTS: end\n          });\n        }\n      } else if (endPTS <= startTime) {\n        // No need to check the rest of the timeRange as it is in order\n        break;\n      }\n    }\n    return buffered;\n  }\n\n  /**\n   * Gets the partial fragment for a certain time\n   */\n  getPartialFragment(time) {\n    let bestFragment = null;\n    let timePadding;\n    let startTime;\n    let endTime;\n    let bestOverlap = 0;\n    const {\n      bufferPadding,\n      fragments\n    } = this;\n    Object.keys(fragments).forEach(key => {\n      const fragmentEntity = fragments[key];\n      if (!fragmentEntity) {\n        return;\n      }\n      if (isPartial(fragmentEntity)) {\n        startTime = fragmentEntity.body.start - bufferPadding;\n        endTime = fragmentEntity.body.end + bufferPadding;\n        if (time >= startTime && time <= endTime) {\n          // Use the fragment that has the most padding from start and end time\n          timePadding = Math.min(time - startTime, endTime - time);\n          if (bestOverlap <= timePadding) {\n            bestFragment = fragmentEntity.body;\n            bestOverlap = timePadding;\n          }\n        }\n      }\n    });\n    return bestFragment;\n  }\n  isEndListAppended(type) {\n    const lastFragmentEntity = this.endListFragments[type];\n    return lastFragmentEntity !== undefined && (lastFragmentEntity.buffered || isPartial(lastFragmentEntity));\n  }\n  getState(fragment) {\n    const fragKey = getFragmentKey(fragment);\n    const fragmentEntity = this.fragments[fragKey];\n    if (fragmentEntity) {\n      if (!fragmentEntity.buffered) {\n        return FragmentState.APPENDING;\n      } else if (isPartial(fragmentEntity)) {\n        return FragmentState.PARTIAL;\n      } else {\n        return FragmentState.OK;\n      }\n    }\n    return FragmentState.NOT_LOADED;\n  }\n  isTimeBuffered(startPTS, endPTS, timeRange) {\n    let startTime;\n    let endTime;\n    for (let i = 0; i < timeRange.length; i++) {\n      startTime = timeRange.start(i) - this.bufferPadding;\n      endTime = timeRange.end(i) + this.bufferPadding;\n      if (startPTS >= startTime && endPTS <= endTime) {\n        return true;\n      }\n      if (endPTS <= startTime) {\n        // No need to check the rest of the timeRange as it is in order\n        return false;\n      }\n    }\n    return false;\n  }\n  onManifestLoading() {\n    this.removeAllFragments();\n  }\n  onFragLoaded(event, data) {\n    // don't track initsegment (for which sn is not a number)\n    // don't track frags used for bitrateTest, they're irrelevant.\n    if (data.frag.sn === 'initSegment' || data.frag.bitrateTest) {\n      return;\n    }\n    const frag = data.frag;\n    // Fragment entity `loaded` FragLoadedData is null when loading parts\n    const loaded = data.part ? null : data;\n    const fragKey = getFragmentKey(frag);\n    this.fragments[fragKey] = {\n      body: frag,\n      appendedPTS: null,\n      loaded,\n      buffered: false,\n      range: Object.create(null)\n    };\n  }\n  onBufferAppended(event, data) {\n    const {\n      frag,\n      part,\n      timeRanges,\n      type\n    } = data;\n    if (frag.sn === 'initSegment') {\n      return;\n    }\n    const playlistType = frag.type;\n    if (part) {\n      let activeParts = this.activePartLists[playlistType];\n      if (!activeParts) {\n        this.activePartLists[playlistType] = activeParts = [];\n      }\n      activeParts.push(part);\n    }\n    // Store the latest timeRanges loaded in the buffer\n    this.timeRanges = timeRanges;\n    const timeRange = timeRanges[type];\n    this.detectEvictedFragments(type, timeRange, playlistType, part);\n  }\n  onFragBuffered(event, data) {\n    this.detectPartialFragments(data);\n  }\n  hasFragment(fragment) {\n    const fragKey = getFragmentKey(fragment);\n    return !!this.fragments[fragKey];\n  }\n  hasFragments(type) {\n    const {\n      fragments\n    } = this;\n    const keys = Object.keys(fragments);\n    if (!type) {\n      return keys.length > 0;\n    }\n    for (let i = keys.length; i--;) {\n      const fragmentEntity = fragments[keys[i]];\n      if ((fragmentEntity == null ? void 0 : fragmentEntity.body.type) === type) {\n        return true;\n      }\n    }\n    return false;\n  }\n  hasParts(type) {\n    var _this$activePartLists;\n    return !!((_this$activePartLists = this.activePartLists[type]) != null && _this$activePartLists.length);\n  }\n  removeFragmentsInRange(start, end, playlistType, withGapOnly, unbufferedOnly) {\n    if (withGapOnly && !this.hasGaps) {\n      return;\n    }\n    Object.keys(this.fragments).forEach(key => {\n      const fragmentEntity = this.fragments[key];\n      if (!fragmentEntity) {\n        return;\n      }\n      const frag = fragmentEntity.body;\n      if (frag.type !== playlistType || withGapOnly && !frag.gap) {\n        return;\n      }\n      if (frag.start < end && frag.end > start && (fragmentEntity.buffered || unbufferedOnly)) {\n        this.removeFragment(frag);\n      }\n    });\n  }\n  removeFragment(fragment) {\n    const fragKey = getFragmentKey(fragment);\n    fragment.clearElementaryStreamInfo();\n    const activeParts = this.activePartLists[fragment.type];\n    if (activeParts) {\n      const snToRemove = fragment.sn;\n      this.activePartLists[fragment.type] = filterParts(activeParts, part => part.fragment.sn !== snToRemove);\n    }\n    delete this.fragments[fragKey];\n    if (fragment.endList) {\n      delete this.endListFragments[fragment.type];\n    }\n  }\n  removeAllFragments() {\n    var _this$hls;\n    this.fragments = Object.create(null);\n    this.endListFragments = Object.create(null);\n    this.activePartLists = Object.create(null);\n    this.hasGaps = false;\n    const partlist = (_this$hls = this.hls) == null || (_this$hls = _this$hls.latestLevelDetails) == null ? void 0 : _this$hls.partList;\n    if (partlist) {\n      partlist.forEach(part => part.clearElementaryStreamInfo());\n    }\n  }\n}\nfunction isPartial(fragmentEntity) {\n  var _fragmentEntity$range, _fragmentEntity$range2, _fragmentEntity$range3;\n  return fragmentEntity.buffered && !!(fragmentEntity.body.gap || (_fragmentEntity$range = fragmentEntity.range.video) != null && _fragmentEntity$range.partial || (_fragmentEntity$range2 = fragmentEntity.range.audio) != null && _fragmentEntity$range2.partial || (_fragmentEntity$range3 = fragmentEntity.range.audiovideo) != null && _fragmentEntity$range3.partial);\n}\nfunction getFragmentKey(fragment) {\n  return `${fragment.type}_${fragment.level}_${fragment.sn}`;\n}\nfunction filterParts(partList, predicate) {\n  return partList.filter(part => {\n    const keep = predicate(part);\n    if (!keep) {\n      part.clearElementaryStreamInfo();\n    }\n    return keep;\n  });\n}\n\nvar DecrypterAesMode = {\n  cbc: 0,\n  ctr: 1\n};\n\nclass AESCrypto {\n  constructor(subtle, iv, aesMode) {\n    this.subtle = void 0;\n    this.aesIV = void 0;\n    this.aesMode = void 0;\n    this.subtle = subtle;\n    this.aesIV = iv;\n    this.aesMode = aesMode;\n  }\n  decrypt(data, key) {\n    switch (this.aesMode) {\n      case DecrypterAesMode.cbc:\n        return this.subtle.decrypt({\n          name: 'AES-CBC',\n          iv: this.aesIV\n        }, key, data);\n      case DecrypterAesMode.ctr:\n        return this.subtle.decrypt({\n          name: 'AES-CTR',\n          counter: this.aesIV,\n          length: 64\n        },\n        //64 : NIST SP800-38A standard suggests that the counter should occupy half of the counter block\n        key, data);\n      default:\n        throw new Error(`[AESCrypto] invalid aes mode ${this.aesMode}`);\n    }\n  }\n}\n\n// PKCS7\nfunction removePadding(array) {\n  const outputBytes = array.byteLength;\n  const paddingBytes = outputBytes && new DataView(array.buffer).getUint8(outputBytes - 1);\n  if (paddingBytes) {\n    return array.slice(0, outputBytes - paddingBytes);\n  }\n  return array;\n}\nclass AESDecryptor {\n  constructor() {\n    this.rcon = [0x0, 0x1, 0x2, 0x4, 0x8, 0x10, 0x20, 0x40, 0x80, 0x1b, 0x36];\n    this.subMix = [new Uint32Array(256), new Uint32Array(256), new Uint32Array(256), new Uint32Array(256)];\n    this.invSubMix = [new Uint32Array(256), new Uint32Array(256), new Uint32Array(256), new Uint32Array(256)];\n    this.sBox = new Uint32Array(256);\n    this.invSBox = new Uint32Array(256);\n    this.key = new Uint32Array(0);\n    this.ksRows = 0;\n    this.keySize = 0;\n    this.keySchedule = void 0;\n    this.invKeySchedule = void 0;\n    this.initTable();\n  }\n\n  // Using view.getUint32() also swaps the byte order.\n  uint8ArrayToUint32Array_(arrayBuffer) {\n    const view = new DataView(arrayBuffer);\n    const newArray = new Uint32Array(4);\n    for (let i = 0; i < 4; i++) {\n      newArray[i] = view.getUint32(i * 4);\n    }\n    return newArray;\n  }\n  initTable() {\n    const sBox = this.sBox;\n    const invSBox = this.invSBox;\n    const subMix = this.subMix;\n    const subMix0 = subMix[0];\n    const subMix1 = subMix[1];\n    const subMix2 = subMix[2];\n    const subMix3 = subMix[3];\n    const invSubMix = this.invSubMix;\n    const invSubMix0 = invSubMix[0];\n    const invSubMix1 = invSubMix[1];\n    const invSubMix2 = invSubMix[2];\n    const invSubMix3 = invSubMix[3];\n    const d = new Uint32Array(256);\n    let x = 0;\n    let xi = 0;\n    let i = 0;\n    for (i = 0; i < 256; i++) {\n      if (i < 128) {\n        d[i] = i << 1;\n      } else {\n        d[i] = i << 1 ^ 0x11b;\n      }\n    }\n    for (i = 0; i < 256; i++) {\n      let sx = xi ^ xi << 1 ^ xi << 2 ^ xi << 3 ^ xi << 4;\n      sx = sx >>> 8 ^ sx & 0xff ^ 0x63;\n      sBox[x] = sx;\n      invSBox[sx] = x;\n\n      // Compute multiplication\n      const x2 = d[x];\n      const x4 = d[x2];\n      const x8 = d[x4];\n\n      // Compute sub/invSub bytes, mix columns tables\n      let t = d[sx] * 0x101 ^ sx * 0x1010100;\n      subMix0[x] = t << 24 | t >>> 8;\n      subMix1[x] = t << 16 | t >>> 16;\n      subMix2[x] = t << 8 | t >>> 24;\n      subMix3[x] = t;\n\n      // Compute inv sub bytes, inv mix columns tables\n      t = x8 * 0x1010101 ^ x4 * 0x10001 ^ x2 * 0x101 ^ x * 0x1010100;\n      invSubMix0[sx] = t << 24 | t >>> 8;\n      invSubMix1[sx] = t << 16 | t >>> 16;\n      invSubMix2[sx] = t << 8 | t >>> 24;\n      invSubMix3[sx] = t;\n\n      // Compute next counter\n      if (!x) {\n        x = xi = 1;\n      } else {\n        x = x2 ^ d[d[d[x8 ^ x2]]];\n        xi ^= d[d[xi]];\n      }\n    }\n  }\n  expandKey(keyBuffer) {\n    // convert keyBuffer to Uint32Array\n    const key = this.uint8ArrayToUint32Array_(keyBuffer);\n    let sameKey = true;\n    let offset = 0;\n    while (offset < key.length && sameKey) {\n      sameKey = key[offset] === this.key[offset];\n      offset++;\n    }\n    if (sameKey) {\n      return;\n    }\n    this.key = key;\n    const keySize = this.keySize = key.length;\n    if (keySize !== 4 && keySize !== 6 && keySize !== 8) {\n      throw new Error('Invalid aes key size=' + keySize);\n    }\n    const ksRows = this.ksRows = (keySize + 6 + 1) * 4;\n    let ksRow;\n    let invKsRow;\n    const keySchedule = this.keySchedule = new Uint32Array(ksRows);\n    const invKeySchedule = this.invKeySchedule = new Uint32Array(ksRows);\n    const sbox = this.sBox;\n    const rcon = this.rcon;\n    const invSubMix = this.invSubMix;\n    const invSubMix0 = invSubMix[0];\n    const invSubMix1 = invSubMix[1];\n    const invSubMix2 = invSubMix[2];\n    const invSubMix3 = invSubMix[3];\n    let prev;\n    let t;\n    for (ksRow = 0; ksRow < ksRows; ksRow++) {\n      if (ksRow < keySize) {\n        prev = keySchedule[ksRow] = key[ksRow];\n        continue;\n      }\n      t = prev;\n      if (ksRow % keySize === 0) {\n        // Rot word\n        t = t << 8 | t >>> 24;\n\n        // Sub word\n        t = sbox[t >>> 24] << 24 | sbox[t >>> 16 & 0xff] << 16 | sbox[t >>> 8 & 0xff] << 8 | sbox[t & 0xff];\n\n        // Mix Rcon\n        t ^= rcon[ksRow / keySize | 0] << 24;\n      } else if (keySize > 6 && ksRow % keySize === 4) {\n        // Sub word\n        t = sbox[t >>> 24] << 24 | sbox[t >>> 16 & 0xff] << 16 | sbox[t >>> 8 & 0xff] << 8 | sbox[t & 0xff];\n      }\n      keySchedule[ksRow] = prev = (keySchedule[ksRow - keySize] ^ t) >>> 0;\n    }\n    for (invKsRow = 0; invKsRow < ksRows; invKsRow++) {\n      ksRow = ksRows - invKsRow;\n      if (invKsRow & 3) {\n        t = keySchedule[ksRow];\n      } else {\n        t = keySchedule[ksRow - 4];\n      }\n      if (invKsRow < 4 || ksRow <= 4) {\n        invKeySchedule[invKsRow] = t;\n      } else {\n        invKeySchedule[invKsRow] = invSubMix0[sbox[t >>> 24]] ^ invSubMix1[sbox[t >>> 16 & 0xff]] ^ invSubMix2[sbox[t >>> 8 & 0xff]] ^ invSubMix3[sbox[t & 0xff]];\n      }\n      invKeySchedule[invKsRow] = invKeySchedule[invKsRow] >>> 0;\n    }\n  }\n\n  // Adding this as a method greatly improves performance.\n  networkToHostOrderSwap(word) {\n    return word << 24 | (word & 0xff00) << 8 | (word & 0xff0000) >> 8 | word >>> 24;\n  }\n  decrypt(inputArrayBuffer, offset, aesIV) {\n    const nRounds = this.keySize + 6;\n    const invKeySchedule = this.invKeySchedule;\n    const invSBOX = this.invSBox;\n    const invSubMix = this.invSubMix;\n    const invSubMix0 = invSubMix[0];\n    const invSubMix1 = invSubMix[1];\n    const invSubMix2 = invSubMix[2];\n    const invSubMix3 = invSubMix[3];\n    const initVector = this.uint8ArrayToUint32Array_(aesIV);\n    let initVector0 = initVector[0];\n    let initVector1 = initVector[1];\n    let initVector2 = initVector[2];\n    let initVector3 = initVector[3];\n    const inputInt32 = new Int32Array(inputArrayBuffer);\n    const outputInt32 = new Int32Array(inputInt32.length);\n    let t0, t1, t2, t3;\n    let s0, s1, s2, s3;\n    let inputWords0, inputWords1, inputWords2, inputWords3;\n    let ksRow, i;\n    const swapWord = this.networkToHostOrderSwap;\n    while (offset < inputInt32.length) {\n      inputWords0 = swapWord(inputInt32[offset]);\n      inputWords1 = swapWord(inputInt32[offset + 1]);\n      inputWords2 = swapWord(inputInt32[offset + 2]);\n      inputWords3 = swapWord(inputInt32[offset + 3]);\n      s0 = inputWords0 ^ invKeySchedule[0];\n      s1 = inputWords3 ^ invKeySchedule[1];\n      s2 = inputWords2 ^ invKeySchedule[2];\n      s3 = inputWords1 ^ invKeySchedule[3];\n      ksRow = 4;\n\n      // Iterate through the rounds of decryption\n      for (i = 1; i < nRounds; i++) {\n        t0 = invSubMix0[s0 >>> 24] ^ invSubMix1[s1 >> 16 & 0xff] ^ invSubMix2[s2 >> 8 & 0xff] ^ invSubMix3[s3 & 0xff] ^ invKeySchedule[ksRow];\n        t1 = invSubMix0[s1 >>> 24] ^ invSubMix1[s2 >> 16 & 0xff] ^ invSubMix2[s3 >> 8 & 0xff] ^ invSubMix3[s0 & 0xff] ^ invKeySchedule[ksRow + 1];\n        t2 = invSubMix0[s2 >>> 24] ^ invSubMix1[s3 >> 16 & 0xff] ^ invSubMix2[s0 >> 8 & 0xff] ^ invSubMix3[s1 & 0xff] ^ invKeySchedule[ksRow + 2];\n        t3 = invSubMix0[s3 >>> 24] ^ invSubMix1[s0 >> 16 & 0xff] ^ invSubMix2[s1 >> 8 & 0xff] ^ invSubMix3[s2 & 0xff] ^ invKeySchedule[ksRow + 3];\n        // Update state\n        s0 = t0;\n        s1 = t1;\n        s2 = t2;\n        s3 = t3;\n        ksRow = ksRow + 4;\n      }\n\n      // Shift rows, sub bytes, add round key\n      t0 = invSBOX[s0 >>> 24] << 24 ^ invSBOX[s1 >> 16 & 0xff] << 16 ^ invSBOX[s2 >> 8 & 0xff] << 8 ^ invSBOX[s3 & 0xff] ^ invKeySchedule[ksRow];\n      t1 = invSBOX[s1 >>> 24] << 24 ^ invSBOX[s2 >> 16 & 0xff] << 16 ^ invSBOX[s3 >> 8 & 0xff] << 8 ^ invSBOX[s0 & 0xff] ^ invKeySchedule[ksRow + 1];\n      t2 = invSBOX[s2 >>> 24] << 24 ^ invSBOX[s3 >> 16 & 0xff] << 16 ^ invSBOX[s0 >> 8 & 0xff] << 8 ^ invSBOX[s1 & 0xff] ^ invKeySchedule[ksRow + 2];\n      t3 = invSBOX[s3 >>> 24] << 24 ^ invSBOX[s0 >> 16 & 0xff] << 16 ^ invSBOX[s1 >> 8 & 0xff] << 8 ^ invSBOX[s2 & 0xff] ^ invKeySchedule[ksRow + 3];\n\n      // Write\n      outputInt32[offset] = swapWord(t0 ^ initVector0);\n      outputInt32[offset + 1] = swapWord(t3 ^ initVector1);\n      outputInt32[offset + 2] = swapWord(t2 ^ initVector2);\n      outputInt32[offset + 3] = swapWord(t1 ^ initVector3);\n\n      // reset initVector to last 4 unsigned int\n      initVector0 = inputWords0;\n      initVector1 = inputWords1;\n      initVector2 = inputWords2;\n      initVector3 = inputWords3;\n      offset = offset + 4;\n    }\n    return outputInt32.buffer;\n  }\n}\n\nclass FastAESKey {\n  constructor(subtle, key, aesMode) {\n    this.subtle = void 0;\n    this.key = void 0;\n    this.aesMode = void 0;\n    this.subtle = subtle;\n    this.key = key;\n    this.aesMode = aesMode;\n  }\n  expandKey() {\n    const subtleAlgoName = getSubtleAlgoName(this.aesMode);\n    return this.subtle.importKey('raw', this.key, {\n      name: subtleAlgoName\n    }, false, ['encrypt', 'decrypt']);\n  }\n}\nfunction getSubtleAlgoName(aesMode) {\n  switch (aesMode) {\n    case DecrypterAesMode.cbc:\n      return 'AES-CBC';\n    case DecrypterAesMode.ctr:\n      return 'AES-CTR';\n    default:\n      throw new Error(`[FastAESKey] invalid aes mode ${aesMode}`);\n  }\n}\n\nconst CHUNK_SIZE = 16; // 16 bytes, 128 bits\n\nclass Decrypter {\n  constructor(config, {\n    removePKCS7Padding = true\n  } = {}) {\n    this.logEnabled = true;\n    this.removePKCS7Padding = void 0;\n    this.subtle = null;\n    this.softwareDecrypter = null;\n    this.key = null;\n    this.fastAesKey = null;\n    this.remainderData = null;\n    this.currentIV = null;\n    this.currentResult = null;\n    this.useSoftware = void 0;\n    this.enableSoftwareAES = void 0;\n    this.enableSoftwareAES = config.enableSoftwareAES;\n    this.removePKCS7Padding = removePKCS7Padding;\n    // built in decryptor expects PKCS7 padding\n    if (removePKCS7Padding) {\n      try {\n        const browserCrypto = self.crypto;\n        if (browserCrypto) {\n          this.subtle = browserCrypto.subtle || browserCrypto.webkitSubtle;\n        }\n      } catch (e) {\n        /* no-op */\n      }\n    }\n    this.useSoftware = !this.subtle;\n  }\n  destroy() {\n    this.subtle = null;\n    this.softwareDecrypter = null;\n    this.key = null;\n    this.fastAesKey = null;\n    this.remainderData = null;\n    this.currentIV = null;\n    this.currentResult = null;\n  }\n  isSync() {\n    return this.useSoftware;\n  }\n  flush() {\n    const {\n      currentResult,\n      remainderData\n    } = this;\n    if (!currentResult || remainderData) {\n      this.reset();\n      return null;\n    }\n    const data = new Uint8Array(currentResult);\n    this.reset();\n    if (this.removePKCS7Padding) {\n      return removePadding(data);\n    }\n    return data;\n  }\n  reset() {\n    this.currentResult = null;\n    this.currentIV = null;\n    this.remainderData = null;\n    if (this.softwareDecrypter) {\n      this.softwareDecrypter = null;\n    }\n  }\n  decrypt(data, key, iv, aesMode) {\n    if (this.useSoftware) {\n      return new Promise((resolve, reject) => {\n        const dataView = ArrayBuffer.isView(data) ? data : new Uint8Array(data);\n        this.softwareDecrypt(dataView, key, iv, aesMode);\n        const decryptResult = this.flush();\n        if (decryptResult) {\n          resolve(decryptResult.buffer);\n        } else {\n          reject(new Error('[softwareDecrypt] Failed to decrypt data'));\n        }\n      });\n    }\n    return this.webCryptoDecrypt(new Uint8Array(data), key, iv, aesMode);\n  }\n\n  // Software decryption is progressive. Progressive decryption may not return a result on each call. Any cached\n  // data is handled in the flush() call\n  softwareDecrypt(data, key, iv, aesMode) {\n    const {\n      currentIV,\n      currentResult,\n      remainderData\n    } = this;\n    if (aesMode !== DecrypterAesMode.cbc || key.byteLength !== 16) {\n      logger.warn('SoftwareDecrypt: can only handle AES-128-CBC');\n      return null;\n    }\n    this.logOnce('JS AES decrypt');\n    // The output is staggered during progressive parsing - the current result is cached, and emitted on the next call\n    // This is done in order to strip PKCS7 padding, which is found at the end of each segment. We only know we've reached\n    // the end on flush(), but by that time we have already received all bytes for the segment.\n    // Progressive decryption does not work with WebCrypto\n\n    if (remainderData) {\n      data = appendUint8Array(remainderData, data);\n      this.remainderData = null;\n    }\n\n    // Byte length must be a multiple of 16 (AES-128 = 128 bit blocks = 16 bytes)\n    const currentChunk = this.getValidChunk(data);\n    if (!currentChunk.length) {\n      return null;\n    }\n    if (currentIV) {\n      iv = currentIV;\n    }\n    let softwareDecrypter = this.softwareDecrypter;\n    if (!softwareDecrypter) {\n      softwareDecrypter = this.softwareDecrypter = new AESDecryptor();\n    }\n    softwareDecrypter.expandKey(key);\n    const result = currentResult;\n    this.currentResult = softwareDecrypter.decrypt(currentChunk.buffer, 0, iv);\n    this.currentIV = currentChunk.slice(-16).buffer;\n    if (!result) {\n      return null;\n    }\n    return result;\n  }\n  webCryptoDecrypt(data, key, iv, aesMode) {\n    if (this.key !== key || !this.fastAesKey) {\n      if (!this.subtle) {\n        return Promise.resolve(this.onWebCryptoError(data, key, iv, aesMode));\n      }\n      this.key = key;\n      this.fastAesKey = new FastAESKey(this.subtle, key, aesMode);\n    }\n    return this.fastAesKey.expandKey().then(aesKey => {\n      // decrypt using web crypto\n      if (!this.subtle) {\n        return Promise.reject(new Error('web crypto not initialized'));\n      }\n      this.logOnce('WebCrypto AES decrypt');\n      const crypto = new AESCrypto(this.subtle, new Uint8Array(iv), aesMode);\n      return crypto.decrypt(data.buffer, aesKey);\n    }).catch(err => {\n      logger.warn(`[decrypter]: WebCrypto Error, disable WebCrypto API, ${err.name}: ${err.message}`);\n      return this.onWebCryptoError(data, key, iv, aesMode);\n    });\n  }\n  onWebCryptoError(data, key, iv, aesMode) {\n    const enableSoftwareAES = this.enableSoftwareAES;\n    if (enableSoftwareAES) {\n      this.useSoftware = true;\n      this.logEnabled = true;\n      this.softwareDecrypt(data, key, iv, aesMode);\n      const decryptResult = this.flush();\n      if (decryptResult) {\n        return decryptResult.buffer;\n      }\n    }\n    throw new Error('WebCrypto' + (enableSoftwareAES ? ' and softwareDecrypt' : '') + ': failed to decrypt data');\n  }\n  getValidChunk(data) {\n    let currentChunk = data;\n    const splitPoint = data.length - data.length % CHUNK_SIZE;\n    if (splitPoint !== data.length) {\n      currentChunk = data.slice(0, splitPoint);\n      this.remainderData = data.slice(splitPoint);\n    }\n    return currentChunk;\n  }\n  logOnce(msg) {\n    if (!this.logEnabled) {\n      return;\n    }\n    logger.log(`[decrypter]: ${msg}`);\n    this.logEnabled = false;\n  }\n}\n\nconst MIN_CHUNK_SIZE = Math.pow(2, 17); // 128kb\n\nclass FragmentLoader {\n  constructor(config) {\n    this.config = void 0;\n    this.loader = null;\n    this.partLoadTimeout = -1;\n    this.config = config;\n  }\n  destroy() {\n    if (this.loader) {\n      this.loader.destroy();\n      this.loader = null;\n    }\n  }\n  abort() {\n    if (this.loader) {\n      // Abort the loader for current fragment. Only one may load at any given time\n      this.loader.abort();\n    }\n  }\n  load(frag, onProgress) {\n    const url = frag.url;\n    if (!url) {\n      return Promise.reject(new LoadError({\n        type: ErrorTypes.NETWORK_ERROR,\n        details: ErrorDetails.FRAG_LOAD_ERROR,\n        fatal: false,\n        frag,\n        error: new Error(`Fragment does not have a ${url ? 'part list' : 'url'}`),\n        networkDetails: null\n      }));\n    }\n    this.abort();\n    const config = this.config;\n    const FragmentILoader = config.fLoader;\n    const DefaultILoader = config.loader;\n    return new Promise((resolve, reject) => {\n      if (this.loader) {\n        this.loader.destroy();\n      }\n      if (frag.gap) {\n        if (frag.tagList.some(tags => tags[0] === 'GAP')) {\n          reject(createGapLoadError(frag));\n          return;\n        } else {\n          // Reset temporary treatment as GAP tag\n          frag.gap = false;\n        }\n      }\n      const loader = this.loader = FragmentILoader ? new FragmentILoader(config) : new DefaultILoader(config);\n      const loaderContext = createLoaderContext(frag);\n      frag.loader = loader;\n      const loadPolicy = getLoaderConfigWithoutReties(config.fragLoadPolicy.default);\n      const loaderConfig = {\n        loadPolicy,\n        timeout: loadPolicy.maxLoadTimeMs,\n        maxRetry: 0,\n        retryDelay: 0,\n        maxRetryDelay: 0,\n        highWaterMark: frag.sn === 'initSegment' ? Infinity : MIN_CHUNK_SIZE\n      };\n      // Assign frag stats to the loader's stats reference\n      frag.stats = loader.stats;\n      const callbacks = {\n        onSuccess: (response, stats, context, networkDetails) => {\n          this.resetLoader(frag, loader);\n          let payload = response.data;\n          if (context.resetIV && frag.decryptdata) {\n            frag.decryptdata.iv = new Uint8Array(payload.slice(0, 16));\n            payload = payload.slice(16);\n          }\n          resolve({\n            frag,\n            part: null,\n            payload,\n            networkDetails\n          });\n        },\n        onError: (response, context, networkDetails, stats) => {\n          this.resetLoader(frag, loader);\n          reject(new LoadError({\n            type: ErrorTypes.NETWORK_ERROR,\n            details: ErrorDetails.FRAG_LOAD_ERROR,\n            fatal: false,\n            frag,\n            response: _objectSpread2({\n              url,\n              data: undefined\n            }, response),\n            error: new Error(`HTTP Error ${response.code} ${response.text}`),\n            networkDetails,\n            stats\n          }));\n        },\n        onAbort: (stats, context, networkDetails) => {\n          this.resetLoader(frag, loader);\n          reject(new LoadError({\n            type: ErrorTypes.NETWORK_ERROR,\n            details: ErrorDetails.INTERNAL_ABORTED,\n            fatal: false,\n            frag,\n            error: new Error('Aborted'),\n            networkDetails,\n            stats\n          }));\n        },\n        onTimeout: (stats, context, networkDetails) => {\n          this.resetLoader(frag, loader);\n          reject(new LoadError({\n            type: ErrorTypes.NETWORK_ERROR,\n            details: ErrorDetails.FRAG_LOAD_TIMEOUT,\n            fatal: false,\n            frag,\n            error: new Error(`Timeout after ${loaderConfig.timeout}ms`),\n            networkDetails,\n            stats\n          }));\n        }\n      };\n      if (onProgress) {\n        callbacks.onProgress = (stats, context, data, networkDetails) => onProgress({\n          frag,\n          part: null,\n          payload: data,\n          networkDetails\n        });\n      }\n      loader.load(loaderContext, loaderConfig, callbacks);\n    });\n  }\n  loadPart(frag, part, onProgress) {\n    this.abort();\n    const config = this.config;\n    const FragmentILoader = config.fLoader;\n    const DefaultILoader = config.loader;\n    return new Promise((resolve, reject) => {\n      if (this.loader) {\n        this.loader.destroy();\n      }\n      if (frag.gap || part.gap) {\n        reject(createGapLoadError(frag, part));\n        return;\n      }\n      const loader = this.loader = FragmentILoader ? new FragmentILoader(config) : new DefaultILoader(config);\n      const loaderContext = createLoaderContext(frag, part);\n      frag.loader = loader;\n      // Should we define another load policy for parts?\n      const loadPolicy = getLoaderConfigWithoutReties(config.fragLoadPolicy.default);\n      const loaderConfig = {\n        loadPolicy,\n        timeout: loadPolicy.maxLoadTimeMs,\n        maxRetry: 0,\n        retryDelay: 0,\n        maxRetryDelay: 0,\n        highWaterMark: MIN_CHUNK_SIZE\n      };\n      // Assign part stats to the loader's stats reference\n      part.stats = loader.stats;\n      loader.load(loaderContext, loaderConfig, {\n        onSuccess: (response, stats, context, networkDetails) => {\n          this.resetLoader(frag, loader);\n          this.updateStatsFromPart(frag, part);\n          const partLoadedData = {\n            frag,\n            part,\n            payload: response.data,\n            networkDetails\n          };\n          onProgress(partLoadedData);\n          resolve(partLoadedData);\n        },\n        onError: (response, context, networkDetails, stats) => {\n          this.resetLoader(frag, loader);\n          reject(new LoadError({\n            type: ErrorTypes.NETWORK_ERROR,\n            details: ErrorDetails.FRAG_LOAD_ERROR,\n            fatal: false,\n            frag,\n            part,\n            response: _objectSpread2({\n              url: loaderContext.url,\n              data: undefined\n            }, response),\n            error: new Error(`HTTP Error ${response.code} ${response.text}`),\n            networkDetails,\n            stats\n          }));\n        },\n        onAbort: (stats, context, networkDetails) => {\n          frag.stats.aborted = part.stats.aborted;\n          this.resetLoader(frag, loader);\n          reject(new LoadError({\n            type: ErrorTypes.NETWORK_ERROR,\n            details: ErrorDetails.INTERNAL_ABORTED,\n            fatal: false,\n            frag,\n            part,\n            error: new Error('Aborted'),\n            networkDetails,\n            stats\n          }));\n        },\n        onTimeout: (stats, context, networkDetails) => {\n          this.resetLoader(frag, loader);\n          reject(new LoadError({\n            type: ErrorTypes.NETWORK_ERROR,\n            details: ErrorDetails.FRAG_LOAD_TIMEOUT,\n            fatal: false,\n            frag,\n            part,\n            error: new Error(`Timeout after ${loaderConfig.timeout}ms`),\n            networkDetails,\n            stats\n          }));\n        }\n      });\n    });\n  }\n  updateStatsFromPart(frag, part) {\n    const fragStats = frag.stats;\n    const partStats = part.stats;\n    const partTotal = partStats.total;\n    fragStats.loaded += partStats.loaded;\n    if (partTotal) {\n      const estTotalParts = Math.round(frag.duration / part.duration);\n      const estLoadedParts = Math.min(Math.round(fragStats.loaded / partTotal), estTotalParts);\n      const estRemainingParts = estTotalParts - estLoadedParts;\n      const estRemainingBytes = estRemainingParts * Math.round(fragStats.loaded / estLoadedParts);\n      fragStats.total = fragStats.loaded + estRemainingBytes;\n    } else {\n      fragStats.total = Math.max(fragStats.loaded, fragStats.total);\n    }\n    const fragLoading = fragStats.loading;\n    const partLoading = partStats.loading;\n    if (fragLoading.start) {\n      // add to fragment loader latency\n      fragLoading.first += partLoading.first - partLoading.start;\n    } else {\n      fragLoading.start = partLoading.start;\n      fragLoading.first = partLoading.first;\n    }\n    fragLoading.end = partLoading.end;\n  }\n  resetLoader(frag, loader) {\n    frag.loader = null;\n    if (this.loader === loader) {\n      self.clearTimeout(this.partLoadTimeout);\n      this.loader = null;\n    }\n    loader.destroy();\n  }\n}\nfunction createLoaderContext(frag, part = null) {\n  const segment = part || frag;\n  const loaderContext = {\n    frag,\n    part,\n    responseType: 'arraybuffer',\n    url: segment.url,\n    headers: {},\n    rangeStart: 0,\n    rangeEnd: 0\n  };\n  const start = segment.byteRangeStartOffset;\n  const end = segment.byteRangeEndOffset;\n  if (isFiniteNumber(start) && isFiniteNumber(end)) {\n    var _frag$decryptdata;\n    let byteRangeStart = start;\n    let byteRangeEnd = end;\n    if (frag.sn === 'initSegment' && isMethodFullSegmentAesCbc((_frag$decryptdata = frag.decryptdata) == null ? void 0 : _frag$decryptdata.method)) {\n      // MAP segment encrypted with method 'AES-128' or 'AES-256' (cbc), when served with HTTP Range,\n      // has the unencrypted size specified in the range.\n      // Ref: https://tools.ietf.org/html/draft-pantos-hls-rfc8216bis-08#section-6.3.6\n      const fragmentLen = end - start;\n      if (fragmentLen % 16) {\n        byteRangeEnd = end + (16 - fragmentLen % 16);\n      }\n      if (start !== 0) {\n        loaderContext.resetIV = true;\n        byteRangeStart = start - 16;\n      }\n    }\n    loaderContext.rangeStart = byteRangeStart;\n    loaderContext.rangeEnd = byteRangeEnd;\n  }\n  return loaderContext;\n}\nfunction createGapLoadError(frag, part) {\n  const error = new Error(`GAP ${frag.gap ? 'tag' : 'attribute'} found`);\n  const errorData = {\n    type: ErrorTypes.MEDIA_ERROR,\n    details: ErrorDetails.FRAG_GAP,\n    fatal: false,\n    frag,\n    error,\n    networkDetails: null\n  };\n  if (part) {\n    errorData.part = part;\n  }\n  (part ? part : frag).stats.aborted = true;\n  return new LoadError(errorData);\n}\nfunction isMethodFullSegmentAesCbc(method) {\n  return method === 'AES-128' || method === 'AES-256';\n}\nclass LoadError extends Error {\n  constructor(data) {\n    super(data.error.message);\n    this.data = void 0;\n    this.data = data;\n  }\n}\n\n/**\n * @ignore\n * Sub-class specialization of EventHandler base class.\n *\n * TaskLoop allows to schedule a task function being called (optionnaly repeatedly) on the main loop,\n * scheduled asynchroneously, avoiding recursive calls in the same tick.\n *\n * The task itself is implemented in `doTick`. It can be requested and called for single execution\n * using the `tick` method.\n *\n * It will be assured that the task execution method (`tick`) only gets called once per main loop \"tick\",\n * no matter how often it gets requested for execution. Execution in further ticks will be scheduled accordingly.\n *\n * If further execution requests have already been scheduled on the next tick, it can be checked with `hasNextTick`,\n * and cancelled with `clearNextTick`.\n *\n * The task can be scheduled as an interval repeatedly with a period as parameter (see `setInterval`, `clearInterval`).\n *\n * Sub-classes need to implement the `doTick` method which will effectively have the task execution routine.\n *\n * Further explanations:\n *\n * The baseclass has a `tick` method that will schedule the doTick call. It may be called synchroneously\n * only for a stack-depth of one. On re-entrant calls, sub-sequent calls are scheduled for next main loop ticks.\n *\n * When the task execution (`tick` method) is called in re-entrant way this is detected and\n * we are limiting the task execution per call stack to exactly one, but scheduling/post-poning further\n * task processing on the next main loop iteration (also known as \"next tick\" in the Node/JS runtime lingo).\n */\nclass TaskLoop extends Logger {\n  constructor(label, logger) {\n    super(label, logger);\n    this._boundTick = void 0;\n    this._tickTimer = null;\n    this._tickInterval = null;\n    this._tickCallCount = 0;\n    this._boundTick = this.tick.bind(this);\n  }\n  destroy() {\n    this.onHandlerDestroying();\n    this.onHandlerDestroyed();\n  }\n  onHandlerDestroying() {\n    // clear all timers before unregistering from event bus\n    this.clearNextTick();\n    this.clearInterval();\n  }\n  onHandlerDestroyed() {}\n  hasInterval() {\n    return !!this._tickInterval;\n  }\n  hasNextTick() {\n    return !!this._tickTimer;\n  }\n\n  /**\n   * @param millis - Interval time (ms)\n   * @eturns True when interval has been scheduled, false when already scheduled (no effect)\n   */\n  setInterval(millis) {\n    if (!this._tickInterval) {\n      this._tickCallCount = 0;\n      this._tickInterval = self.setInterval(this._boundTick, millis);\n      return true;\n    }\n    return false;\n  }\n\n  /**\n   * @returns True when interval was cleared, false when none was set (no effect)\n   */\n  clearInterval() {\n    if (this._tickInterval) {\n      self.clearInterval(this._tickInterval);\n      this._tickInterval = null;\n      return true;\n    }\n    return false;\n  }\n\n  /**\n   * @returns True when timeout was cleared, false when none was set (no effect)\n   */\n  clearNextTick() {\n    if (this._tickTimer) {\n      self.clearTimeout(this._tickTimer);\n      this._tickTimer = null;\n      return true;\n    }\n    return false;\n  }\n\n  /**\n   * Will call the subclass doTick implementation in this main loop tick\n   * or in the next one (via setTimeout(,0)) in case it has already been called\n   * in this tick (in case this is a re-entrant call).\n   */\n  tick() {\n    this._tickCallCount++;\n    if (this._tickCallCount === 1) {\n      this.doTick();\n      // re-entrant call to tick from previous doTick call stack\n      // -> schedule a call on the next main loop iteration to process this task processing request\n      if (this._tickCallCount > 1) {\n        // make sure only one timer exists at any time at max\n        this.tickImmediate();\n      }\n      this._tickCallCount = 0;\n    }\n  }\n  tickImmediate() {\n    this.clearNextTick();\n    this._tickTimer = self.setTimeout(this._boundTick, 0);\n  }\n\n  /**\n   * For subclass to implement task logic\n   * @abstract\n   */\n  doTick() {}\n}\n\nclass ChunkMetadata {\n  constructor(level, sn, id, size = 0, part = -1, partial = false) {\n    this.level = void 0;\n    this.sn = void 0;\n    this.part = void 0;\n    this.id = void 0;\n    this.size = void 0;\n    this.partial = void 0;\n    this.transmuxing = getNewPerformanceTiming();\n    this.buffering = {\n      audio: getNewPerformanceTiming(),\n      video: getNewPerformanceTiming(),\n      audiovideo: getNewPerformanceTiming()\n    };\n    this.level = level;\n    this.sn = sn;\n    this.id = id;\n    this.size = size;\n    this.part = part;\n    this.partial = partial;\n  }\n}\nfunction getNewPerformanceTiming() {\n  return {\n    start: 0,\n    executeStart: 0,\n    executeEnd: 0,\n    end: 0\n  };\n}\n\n/**\n * Provides methods dealing with buffer length retrieval for example.\n *\n * In general, a helper around HTML5 MediaElement TimeRanges gathered from `buffered` property.\n *\n * Also @see https://developer.mozilla.org/en-US/docs/Web/API/HTMLMediaElement/buffered\n */\n\nconst noopBuffered = {\n  length: 0,\n  start: () => 0,\n  end: () => 0\n};\nclass BufferHelper {\n  /**\n   * Return true if `media`'s buffered include `position`\n   */\n  static isBuffered(media, position) {\n    if (media) {\n      const buffered = BufferHelper.getBuffered(media);\n      for (let i = buffered.length; i--;) {\n        if (position >= buffered.start(i) && position <= buffered.end(i)) {\n          return true;\n        }\n      }\n    }\n    return false;\n  }\n  static bufferedRanges(media) {\n    if (media) {\n      const timeRanges = BufferHelper.getBuffered(media);\n      return BufferHelper.timeRangesToArray(timeRanges);\n    }\n    return [];\n  }\n  static timeRangesToArray(timeRanges) {\n    const buffered = [];\n    for (let i = 0; i < timeRanges.length; i++) {\n      buffered.push({\n        start: timeRanges.start(i),\n        end: timeRanges.end(i)\n      });\n    }\n    return buffered;\n  }\n  static bufferInfo(media, pos, maxHoleDuration) {\n    if (media) {\n      const buffered = BufferHelper.bufferedRanges(media);\n      if (buffered.length) {\n        return BufferHelper.bufferedInfo(buffered, pos, maxHoleDuration);\n      }\n    }\n    return {\n      len: 0,\n      start: pos,\n      end: pos,\n      bufferedIndex: -1\n    };\n  }\n  static bufferedInfo(buffered, pos, maxHoleDuration) {\n    pos = Math.max(0, pos);\n    // sort on buffer.start/smaller end (IE does not always return sorted buffered range)\n    if (buffered.length > 1) {\n      buffered.sort((a, b) => a.start - b.start || b.end - a.end);\n    }\n    let bufferedIndex = -1;\n    let buffered2 = [];\n    if (maxHoleDuration) {\n      // there might be some small holes between buffer time range\n      // consider that holes smaller than maxHoleDuration are irrelevant and build another\n      // buffer time range representations that discards those holes\n      for (let i = 0; i < buffered.length; i++) {\n        if (pos >= buffered[i].start && pos <= buffered[i].end) {\n          bufferedIndex = i;\n        }\n        const buf2len = buffered2.length;\n        if (buf2len) {\n          const buf2end = buffered2[buf2len - 1].end;\n          // if small hole (value between 0 or maxHoleDuration ) or overlapping (negative)\n          if (buffered[i].start - buf2end < maxHoleDuration) {\n            // merge overlapping time ranges\n            // update lastRange.end only if smaller than item.end\n            // e.g.  [ 1, 15] with  [ 2,8] => [ 1,15] (no need to modify lastRange.end)\n            // whereas [ 1, 8] with  [ 2,15] => [ 1,15] ( lastRange should switch from [1,8] to [1,15])\n            if (buffered[i].end > buf2end) {\n              buffered2[buf2len - 1].end = buffered[i].end;\n            }\n          } else {\n            // big hole\n            buffered2.push(buffered[i]);\n          }\n        } else {\n          // first value\n          buffered2.push(buffered[i]);\n        }\n      }\n    } else {\n      buffered2 = buffered;\n    }\n    let bufferLen = 0;\n    let nextStart;\n\n    // bufferStart and bufferEnd are buffer boundaries around current playback position (pos)\n    let bufferStart = pos;\n    let bufferEnd = pos;\n    for (let i = 0; i < buffered2.length; i++) {\n      const start = buffered2[i].start;\n      const end = buffered2[i].end;\n      // logger.log('buf start/end:' + buffered.start(i) + '/' + buffered.end(i));\n      if (bufferedIndex === -1 && pos >= start && pos <= end) {\n        bufferedIndex = i;\n      }\n      if (pos + maxHoleDuration >= start && pos < end) {\n        // play position is inside this buffer TimeRange, retrieve end of buffer position and buffer length\n        bufferStart = start;\n        bufferEnd = end;\n        bufferLen = bufferEnd - pos;\n      } else if (pos + maxHoleDuration < start) {\n        nextStart = start;\n        break;\n      }\n    }\n    return {\n      len: bufferLen,\n      start: bufferStart || 0,\n      end: bufferEnd || 0,\n      nextStart,\n      buffered,\n      bufferedIndex\n    };\n  }\n\n  /**\n   * Safe method to get buffered property.\n   * SourceBuffer.buffered may throw if SourceBuffer is removed from it's MediaSource\n   */\n  static getBuffered(media) {\n    try {\n      return media.buffered || noopBuffered;\n    } catch (e) {\n      logger.log('failed to get media.buffered', e);\n      return noopBuffered;\n    }\n  }\n}\n\nconst VARIABLE_REPLACEMENT_REGEX = /\\{\\$([a-zA-Z0-9-_]+)\\}/g;\nfunction hasVariableReferences(str) {\n  return VARIABLE_REPLACEMENT_REGEX.test(str);\n}\nfunction substituteVariables(parsed, value) {\n  if (parsed.variableList !== null || parsed.hasVariableRefs) {\n    const variableList = parsed.variableList;\n    return value.replace(VARIABLE_REPLACEMENT_REGEX, variableReference => {\n      const variableName = variableReference.substring(2, variableReference.length - 1);\n      const variableValue = variableList == null ? void 0 : variableList[variableName];\n      if (variableValue === undefined) {\n        parsed.playlistParsingError || (parsed.playlistParsingError = new Error(`Missing preceding EXT-X-DEFINE tag for Variable Reference: \"${variableName}\"`));\n        return variableReference;\n      }\n      return variableValue;\n    });\n  }\n  return value;\n}\nfunction addVariableDefinition(parsed, attr, parentUrl) {\n  let variableList = parsed.variableList;\n  if (!variableList) {\n    parsed.variableList = variableList = {};\n  }\n  let NAME;\n  let VALUE;\n  if ('QUERYPARAM' in attr) {\n    NAME = attr.QUERYPARAM;\n    try {\n      const searchParams = new self.URL(parentUrl).searchParams;\n      if (searchParams.has(NAME)) {\n        VALUE = searchParams.get(NAME);\n      } else {\n        throw new Error(`\"${NAME}\" does not match any query parameter in URI: \"${parentUrl}\"`);\n      }\n    } catch (error) {\n      parsed.playlistParsingError || (parsed.playlistParsingError = new Error(`EXT-X-DEFINE QUERYPARAM: ${error.message}`));\n    }\n  } else {\n    NAME = attr.NAME;\n    VALUE = attr.VALUE;\n  }\n  if (NAME in variableList) {\n    parsed.playlistParsingError || (parsed.playlistParsingError = new Error(`EXT-X-DEFINE duplicate Variable Name declarations: \"${NAME}\"`));\n  } else {\n    variableList[NAME] = VALUE || '';\n  }\n}\nfunction importVariableDefinition(parsed, attr, sourceVariableList) {\n  const IMPORT = attr.IMPORT;\n  if (sourceVariableList && IMPORT in sourceVariableList) {\n    let variableList = parsed.variableList;\n    if (!variableList) {\n      parsed.variableList = variableList = {};\n    }\n    variableList[IMPORT] = sourceVariableList[IMPORT];\n  } else {\n    parsed.playlistParsingError || (parsed.playlistParsingError = new Error(`EXT-X-DEFINE IMPORT attribute not found in Multivariant Playlist: \"${IMPORT}\"`));\n  }\n}\n\nconst DECIMAL_RESOLUTION_REGEX = /^(\\d+)x(\\d+)$/;\nconst ATTR_LIST_REGEX = /(.+?)=(\".*?\"|.*?)(?:,|$)/g;\n\n// adapted from https://github.com/kanongil/node-m3u8parse/blob/master/attrlist.js\nclass AttrList {\n  constructor(attrs, parsed) {\n    if (typeof attrs === 'string') {\n      attrs = AttrList.parseAttrList(attrs, parsed);\n    }\n    _extends(this, attrs);\n  }\n  get clientAttrs() {\n    return Object.keys(this).filter(attr => attr.substring(0, 2) === 'X-');\n  }\n  decimalInteger(attrName) {\n    const intValue = parseInt(this[attrName], 10);\n    if (intValue > Number.MAX_SAFE_INTEGER) {\n      return Infinity;\n    }\n    return intValue;\n  }\n  hexadecimalInteger(attrName) {\n    if (this[attrName]) {\n      let stringValue = (this[attrName] || '0x').slice(2);\n      stringValue = (stringValue.length & 1 ? '0' : '') + stringValue;\n      const value = new Uint8Array(stringValue.length / 2);\n      for (let i = 0; i < stringValue.length / 2; i++) {\n        value[i] = parseInt(stringValue.slice(i * 2, i * 2 + 2), 16);\n      }\n      return value;\n    }\n    return null;\n  }\n  hexadecimalIntegerAsNumber(attrName) {\n    const intValue = parseInt(this[attrName], 16);\n    if (intValue > Number.MAX_SAFE_INTEGER) {\n      return Infinity;\n    }\n    return intValue;\n  }\n  decimalFloatingPoint(attrName) {\n    return parseFloat(this[attrName]);\n  }\n  optionalFloat(attrName, defaultValue) {\n    const value = this[attrName];\n    return value ? parseFloat(value) : defaultValue;\n  }\n  enumeratedString(attrName) {\n    return this[attrName];\n  }\n  enumeratedStringList(attrName, dict) {\n    const attrValue = this[attrName];\n    return (attrValue ? attrValue.split(/[ ,]+/) : []).reduce((result, identifier) => {\n      result[identifier.toLowerCase()] = true;\n      return result;\n    }, dict);\n  }\n  bool(attrName) {\n    return this[attrName] === 'YES';\n  }\n  decimalResolution(attrName) {\n    const res = DECIMAL_RESOLUTION_REGEX.exec(this[attrName]);\n    if (res === null) {\n      return undefined;\n    }\n    return {\n      width: parseInt(res[1], 10),\n      height: parseInt(res[2], 10)\n    };\n  }\n  static parseAttrList(input, parsed) {\n    let match;\n    const attrs = {};\n    const quote = '\"';\n    ATTR_LIST_REGEX.lastIndex = 0;\n    while ((match = ATTR_LIST_REGEX.exec(input)) !== null) {\n      const name = match[1].trim();\n      let value = match[2];\n      const quotedString = value.indexOf(quote) === 0 && value.lastIndexOf(quote) === value.length - 1;\n      let hexadecimalSequence = false;\n      if (quotedString) {\n        value = value.slice(1, -1);\n      } else {\n        switch (name) {\n          case 'IV':\n          case 'SCTE35-CMD':\n          case 'SCTE35-IN':\n          case 'SCTE35-OUT':\n            hexadecimalSequence = true;\n        }\n      }\n      if (parsed && (quotedString || hexadecimalSequence)) {\n        {\n          value = substituteVariables(parsed, value);\n        }\n      } else if (!hexadecimalSequence && !quotedString) {\n        switch (name) {\n          case 'CLOSED-CAPTIONS':\n            if (value === 'NONE') {\n              break;\n            }\n          // falls through\n          case 'ALLOWED-CPC':\n          case 'CLASS':\n          case 'ASSOC-LANGUAGE':\n          case 'AUDIO':\n          case 'BYTERANGE':\n          case 'CHANNELS':\n          case 'CHARACTERISTICS':\n          case 'CODECS':\n          case 'DATA-ID':\n          case 'END-DATE':\n          case 'GROUP-ID':\n          case 'ID':\n          case 'IMPORT':\n          case 'INSTREAM-ID':\n          case 'KEYFORMAT':\n          case 'KEYFORMATVERSIONS':\n          case 'LANGUAGE':\n          case 'NAME':\n          case 'PATHWAY-ID':\n          case 'QUERYPARAM':\n          case 'RECENTLY-REMOVED-DATERANGES':\n          case 'SERVER-URI':\n          case 'STABLE-RENDITION-ID':\n          case 'STABLE-VARIANT-ID':\n          case 'START-DATE':\n          case 'SUBTITLES':\n          case 'SUPPLEMENTAL-CODECS':\n          case 'URI':\n          case 'VALUE':\n          case 'VIDEO':\n          case 'X-ASSET-LIST':\n          case 'X-ASSET-URI':\n            // Since we are not checking tag:attribute combination, just warn rather than ignoring attribute\n            logger.warn(`${input}: attribute ${name} is missing quotes`);\n          // continue;\n        }\n      }\n      attrs[name] = value;\n    }\n    return attrs;\n  }\n}\n\n// Avoid exporting const enum so that these values can be inlined\n\nconst CLASS_INTERSTITIAL = 'com.apple.hls.interstitial';\nfunction isDateRangeCueAttribute(attrName) {\n  return attrName !== \"ID\" && attrName !== \"CLASS\" && attrName !== \"CUE\" && attrName !== \"START-DATE\" && attrName !== \"DURATION\" && attrName !== \"END-DATE\" && attrName !== \"END-ON-NEXT\";\n}\nfunction isSCTE35Attribute(attrName) {\n  return attrName === \"SCTE35-OUT\" || attrName === \"SCTE35-IN\" || attrName === \"SCTE35-CMD\";\n}\nclass DateRange {\n  constructor(dateRangeAttr, dateRangeWithSameId, tagCount = 0) {\n    var _dateRangeWithSameId$;\n    this.attr = void 0;\n    this.tagAnchor = void 0;\n    this.tagOrder = void 0;\n    this._startDate = void 0;\n    this._endDate = void 0;\n    this._dateAtEnd = void 0;\n    this._cue = void 0;\n    this._badValueForSameId = void 0;\n    this.tagAnchor = (dateRangeWithSameId == null ? void 0 : dateRangeWithSameId.tagAnchor) || null;\n    this.tagOrder = (_dateRangeWithSameId$ = dateRangeWithSameId == null ? void 0 : dateRangeWithSameId.tagOrder) != null ? _dateRangeWithSameId$ : tagCount;\n    if (dateRangeWithSameId) {\n      const previousAttr = dateRangeWithSameId.attr;\n      for (const key in previousAttr) {\n        if (Object.prototype.hasOwnProperty.call(dateRangeAttr, key) && dateRangeAttr[key] !== previousAttr[key]) {\n          logger.warn(`DATERANGE tag attribute: \"${key}\" does not match for tags with ID: \"${dateRangeAttr.ID}\"`);\n          this._badValueForSameId = key;\n          break;\n        }\n      }\n      // Merge DateRange tags with the same ID\n      dateRangeAttr = _extends(new AttrList({}), previousAttr, dateRangeAttr);\n    }\n    this.attr = dateRangeAttr;\n    if (dateRangeWithSameId) {\n      this._startDate = dateRangeWithSameId._startDate;\n      this._cue = dateRangeWithSameId._cue;\n      this._endDate = dateRangeWithSameId._endDate;\n      this._dateAtEnd = dateRangeWithSameId._dateAtEnd;\n    } else {\n      this._startDate = new Date(dateRangeAttr[\"START-DATE\"]);\n    }\n    if (\"END-DATE\" in this.attr) {\n      const endDate = (dateRangeWithSameId == null ? void 0 : dateRangeWithSameId.endDate) || new Date(this.attr[\"END-DATE\"]);\n      if (isFiniteNumber(endDate.getTime())) {\n        this._endDate = endDate;\n      }\n    }\n  }\n  get id() {\n    return this.attr.ID;\n  }\n  get class() {\n    return this.attr.CLASS;\n  }\n  get cue() {\n    const _cue = this._cue;\n    if (_cue === undefined) {\n      return this._cue = this.attr.enumeratedStringList(this.attr.CUE ? 'CUE' : 'X-CUE', {\n        pre: false,\n        post: false,\n        once: false\n      });\n    }\n    return _cue;\n  }\n  get startTime() {\n    const {\n      tagAnchor\n    } = this;\n    // eslint-disable-next-line @typescript-eslint/prefer-optional-chain\n    if (tagAnchor === null || tagAnchor.programDateTime === null) {\n      logger.warn(`Expected tagAnchor Fragment with PDT set for DateRange \"${this.id}\": ${tagAnchor}`);\n      return NaN;\n    }\n    return tagAnchor.start + (this.startDate.getTime() - tagAnchor.programDateTime) / 1000;\n  }\n  get startDate() {\n    return this._startDate;\n  }\n  get endDate() {\n    const dateAtEnd = this._endDate || this._dateAtEnd;\n    if (dateAtEnd) {\n      return dateAtEnd;\n    }\n    const duration = this.duration;\n    if (duration !== null) {\n      return this._dateAtEnd = new Date(this._startDate.getTime() + duration * 1000);\n    }\n    return null;\n  }\n  get duration() {\n    if (\"DURATION\" in this.attr) {\n      const duration = this.attr.decimalFloatingPoint(\"DURATION\");\n      if (isFiniteNumber(duration)) {\n        return duration;\n      }\n    } else if (this._endDate) {\n      return (this._endDate.getTime() - this._startDate.getTime()) / 1000;\n    }\n    return null;\n  }\n  get plannedDuration() {\n    if (\"PLANNED-DURATION\" in this.attr) {\n      return this.attr.decimalFloatingPoint(\"PLANNED-DURATION\");\n    }\n    return null;\n  }\n  get endOnNext() {\n    return this.attr.bool(\"END-ON-NEXT\");\n  }\n  get isInterstitial() {\n    return this.class === CLASS_INTERSTITIAL;\n  }\n  get isValid() {\n    return !!this.id && !this._badValueForSameId && isFiniteNumber(this.startDate.getTime()) && (this.duration === null || this.duration >= 0) && (!this.endOnNext || !!this.class) && (!this.attr.CUE || !this.cue.pre && !this.cue.post || this.cue.pre !== this.cue.post) && (!this.isInterstitial || 'X-ASSET-URI' in this.attr || 'X-ASSET-LIST' in this.attr);\n  }\n}\n\nconst DEFAULT_TARGET_DURATION = 10;\n\n/**\n * Object representing parsed data from an HLS Media Playlist. Found in {@link hls.js#Level.details}.\n */\nclass LevelDetails {\n  constructor(baseUrl) {\n    this.PTSKnown = false;\n    this.alignedSliding = false;\n    this.averagetargetduration = void 0;\n    this.endCC = 0;\n    this.endSN = 0;\n    this.fragments = void 0;\n    this.fragmentHint = void 0;\n    this.partList = null;\n    this.dateRanges = void 0;\n    this.dateRangeTagCount = 0;\n    this.live = true;\n    this.requestScheduled = -1;\n    this.ageHeader = 0;\n    this.advancedDateTime = void 0;\n    this.updated = true;\n    this.advanced = true;\n    this.misses = 0;\n    this.startCC = 0;\n    this.startSN = 0;\n    this.startTimeOffset = null;\n    this.targetduration = 0;\n    this.totalduration = 0;\n    this.type = null;\n    this.url = void 0;\n    this.m3u8 = '';\n    this.version = null;\n    this.canBlockReload = false;\n    this.canSkipUntil = 0;\n    this.canSkipDateRanges = false;\n    this.skippedSegments = 0;\n    this.recentlyRemovedDateranges = void 0;\n    this.partHoldBack = 0;\n    this.holdBack = 0;\n    this.partTarget = 0;\n    this.preloadHint = void 0;\n    this.renditionReports = void 0;\n    this.tuneInGoal = 0;\n    this.deltaUpdateFailed = void 0;\n    this.driftStartTime = 0;\n    this.driftEndTime = 0;\n    this.driftStart = 0;\n    this.driftEnd = 0;\n    this.encryptedFragments = void 0;\n    this.playlistParsingError = null;\n    this.variableList = null;\n    this.hasVariableRefs = false;\n    this.appliedTimelineOffset = void 0;\n    this.fragments = [];\n    this.encryptedFragments = [];\n    this.dateRanges = {};\n    this.url = baseUrl;\n  }\n  reloaded(previous) {\n    if (!previous) {\n      this.advanced = true;\n      this.updated = true;\n      return;\n    }\n    const partSnDiff = this.lastPartSn - previous.lastPartSn;\n    const partIndexDiff = this.lastPartIndex - previous.lastPartIndex;\n    this.updated = this.endSN !== previous.endSN || !!partIndexDiff || !!partSnDiff || !this.live;\n    this.advanced = this.endSN > previous.endSN || partSnDiff > 0 || partSnDiff === 0 && partIndexDiff > 0;\n    if (this.updated || this.advanced) {\n      this.misses = Math.floor(previous.misses * 0.6);\n    } else {\n      this.misses = previous.misses + 1;\n    }\n  }\n  hasKey(levelKey) {\n    return this.encryptedFragments.some(frag => {\n      let decryptdata = frag.decryptdata;\n      if (!decryptdata) {\n        frag.setKeyFormat(levelKey.keyFormat);\n        decryptdata = frag.decryptdata;\n      }\n      return !!decryptdata && levelKey.matches(decryptdata);\n    });\n  }\n  get hasProgramDateTime() {\n    if (this.fragments.length) {\n      return isFiniteNumber(this.fragments[this.fragments.length - 1].programDateTime);\n    }\n    return false;\n  }\n  get levelTargetDuration() {\n    return this.averagetargetduration || this.targetduration || DEFAULT_TARGET_DURATION;\n  }\n  get drift() {\n    const runTime = this.driftEndTime - this.driftStartTime;\n    if (runTime > 0) {\n      const runDuration = this.driftEnd - this.driftStart;\n      return runDuration * 1000 / runTime;\n    }\n    return 1;\n  }\n  get edge() {\n    return this.partEnd || this.fragmentEnd;\n  }\n  get partEnd() {\n    var _this$partList;\n    if ((_this$partList = this.partList) != null && _this$partList.length) {\n      return this.partList[this.partList.length - 1].end;\n    }\n    return this.fragmentEnd;\n  }\n  get fragmentEnd() {\n    if (this.fragments.length) {\n      return this.fragments[this.fragments.length - 1].end;\n    }\n    return 0;\n  }\n  get fragmentStart() {\n    if (this.fragments.length) {\n      return this.fragments[0].start;\n    }\n    return 0;\n  }\n  get age() {\n    if (this.advancedDateTime) {\n      return Math.max(Date.now() - this.advancedDateTime, 0) / 1000;\n    }\n    return 0;\n  }\n  get lastPartIndex() {\n    var _this$partList2;\n    if ((_this$partList2 = this.partList) != null && _this$partList2.length) {\n      return this.partList[this.partList.length - 1].index;\n    }\n    return -1;\n  }\n  get maxPartIndex() {\n    const partList = this.partList;\n    if (partList) {\n      const lastIndex = this.lastPartIndex;\n      if (lastIndex !== -1) {\n        for (let i = partList.length; i--;) {\n          if (partList[i].index > lastIndex) {\n            return partList[i].index;\n          }\n        }\n        return lastIndex;\n      }\n    }\n    return 0;\n  }\n  get lastPartSn() {\n    var _this$partList3;\n    if ((_this$partList3 = this.partList) != null && _this$partList3.length) {\n      return this.partList[this.partList.length - 1].fragment.sn;\n    }\n    return this.endSN;\n  }\n  get expired() {\n    if (this.live && this.age && this.misses < 3) {\n      const playlistWindowDuration = this.partEnd - this.fragmentStart;\n      return this.age > Math.max(playlistWindowDuration, this.totalduration) + this.levelTargetDuration;\n    }\n    return false;\n  }\n}\n\nfunction arrayValuesMatch(a, b) {\n  if (a.length === b.length) {\n    return !a.some((value, i) => value !== b[i]);\n  }\n  return false;\n}\nfunction optionalArrayValuesMatch(a, b) {\n  if (!a && !b) {\n    return true;\n  }\n  if (!a || !b) {\n    return false;\n  }\n  return arrayValuesMatch(a, b);\n}\n\nfunction isFullSegmentEncryption(method) {\n  return method === 'AES-128' || method === 'AES-256' || method === 'AES-256-CTR';\n}\nfunction getAesModeFromFullSegmentMethod(method) {\n  switch (method) {\n    case 'AES-128':\n    case 'AES-256':\n      return DecrypterAesMode.cbc;\n    case 'AES-256-CTR':\n      return DecrypterAesMode.ctr;\n    default:\n      throw new Error(`invalid full segment method ${method}`);\n  }\n}\n\nfunction base64Decode(base64encodedStr) {\n  return Uint8Array.from(atob(base64encodedStr), c => c.charCodeAt(0));\n}\n\n// breaking up those two types in order to clarify what is happening in the decoding path.\n\n// http://stackoverflow.com/questions/8936984/uint8array-to-string-in-javascript/22373197\n// http://www.onicos.com/staff/iz/amuse/javascript/expert/utf.txt\n/* utf.js - UTF-8 <=> UTF-16 convertion\n *\n * Copyright (C) 1999 Masanao Izumo <iz@onicos.co.jp>\n * Version: 1.0\n * LastModified: Dec 25 1999\n * This library is free.  You can redistribute it and/or modify it.\n */\n\nfunction strToUtf8array(str) {\n  return Uint8Array.from(unescape(encodeURIComponent(str)), c => c.charCodeAt(0));\n}\n\nfunction getKeyIdBytes(str) {\n  const keyIdbytes = strToUtf8array(str).subarray(0, 16);\n  const paddedkeyIdbytes = new Uint8Array(16);\n  paddedkeyIdbytes.set(keyIdbytes, 16 - keyIdbytes.length);\n  return paddedkeyIdbytes;\n}\nfunction changeEndianness(keyId) {\n  const swap = function swap(array, from, to) {\n    const cur = array[from];\n    array[from] = array[to];\n    array[to] = cur;\n  };\n  swap(keyId, 0, 3);\n  swap(keyId, 1, 2);\n  swap(keyId, 4, 5);\n  swap(keyId, 6, 7);\n}\nfunction convertDataUriToArrayBytes(uri) {\n  // data:[<media type][;attribute=value][;base64],<data>\n  const colonsplit = uri.split(':');\n  let keydata = null;\n  if (colonsplit[0] === 'data' && colonsplit.length === 2) {\n    const semicolonsplit = colonsplit[1].split(';');\n    const commasplit = semicolonsplit[semicolonsplit.length - 1].split(',');\n    if (commasplit.length === 2) {\n      const isbase64 = commasplit[0] === 'base64';\n      const data = commasplit[1];\n      if (isbase64) {\n        semicolonsplit.splice(-1, 1); // remove from processing\n        keydata = base64Decode(data);\n      } else {\n        keydata = getKeyIdBytes(data);\n      }\n    }\n  }\n  return keydata;\n}\n\n/** returns `undefined` is `self` is missing, e.g. in node */\nconst optionalSelf = typeof self !== 'undefined' ? self : undefined;\n\n/**\n * @see https://developer.mozilla.org/en-US/docs/Web/API/Navigator/requestMediaKeySystemAccess\n */\nvar KeySystems = {\n  CLEARKEY: \"org.w3.clearkey\",\n  FAIRPLAY: \"com.apple.fps\",\n  PLAYREADY: \"com.microsoft.playready\",\n  WIDEVINE: \"com.widevine.alpha\"\n};\n\n// Playlist #EXT-X-KEY KEYFORMAT values\nvar KeySystemFormats = {\n  CLEARKEY: \"org.w3.clearkey\",\n  FAIRPLAY: \"com.apple.streamingkeydelivery\",\n  PLAYREADY: \"com.microsoft.playready\",\n  WIDEVINE: \"urn:uuid:edef8ba9-79d6-4ace-a3c8-27dcd51d21ed\"\n};\nfunction keySystemFormatToKeySystemDomain(format) {\n  switch (format) {\n    case KeySystemFormats.FAIRPLAY:\n      return KeySystems.FAIRPLAY;\n    case KeySystemFormats.PLAYREADY:\n      return KeySystems.PLAYREADY;\n    case KeySystemFormats.WIDEVINE:\n      return KeySystems.WIDEVINE;\n    case KeySystemFormats.CLEARKEY:\n      return KeySystems.CLEARKEY;\n  }\n}\nfunction keySystemDomainToKeySystemFormat(keySystem) {\n  switch (keySystem) {\n    case KeySystems.FAIRPLAY:\n      return KeySystemFormats.FAIRPLAY;\n    case KeySystems.PLAYREADY:\n      return KeySystemFormats.PLAYREADY;\n    case KeySystems.WIDEVINE:\n      return KeySystemFormats.WIDEVINE;\n    case KeySystems.CLEARKEY:\n      return KeySystemFormats.CLEARKEY;\n  }\n}\nfunction getKeySystemsForConfig(config) {\n  const {\n    drmSystems,\n    widevineLicenseUrl\n  } = config;\n  const keySystemsToAttempt = drmSystems ? [KeySystems.FAIRPLAY, KeySystems.WIDEVINE, KeySystems.PLAYREADY, KeySystems.CLEARKEY].filter(keySystem => !!drmSystems[keySystem]) : [];\n  if (!keySystemsToAttempt[KeySystems.WIDEVINE] && widevineLicenseUrl) {\n    keySystemsToAttempt.push(KeySystems.WIDEVINE);\n  }\n  return keySystemsToAttempt;\n}\nconst requestMediaKeySystemAccess = function (_optionalSelf$navigat) {\n  if (optionalSelf != null && (_optionalSelf$navigat = optionalSelf.navigator) != null && _optionalSelf$navigat.requestMediaKeySystemAccess) {\n    return self.navigator.requestMediaKeySystemAccess.bind(self.navigator);\n  } else {\n    return null;\n  }\n}();\n\n/**\n * @see https://developer.mozilla.org/en-US/docs/Web/API/MediaKeySystemConfiguration\n */\nfunction getSupportedMediaKeySystemConfigurations(keySystem, audioCodecs, videoCodecs, drmSystemOptions) {\n  let initDataTypes;\n  switch (keySystem) {\n    case KeySystems.FAIRPLAY:\n      initDataTypes = ['cenc', 'sinf'];\n      break;\n    case KeySystems.WIDEVINE:\n    case KeySystems.PLAYREADY:\n      initDataTypes = ['cenc'];\n      break;\n    case KeySystems.CLEARKEY:\n      initDataTypes = ['cenc', 'keyids'];\n      break;\n    default:\n      throw new Error(`Unknown key-system: ${keySystem}`);\n  }\n  return createMediaKeySystemConfigurations(initDataTypes, audioCodecs, videoCodecs, drmSystemOptions);\n}\nfunction createMediaKeySystemConfigurations(initDataTypes, audioCodecs, videoCodecs, drmSystemOptions) {\n  const baseConfig = {\n    initDataTypes: initDataTypes,\n    persistentState: drmSystemOptions.persistentState || 'optional',\n    distinctiveIdentifier: drmSystemOptions.distinctiveIdentifier || 'optional',\n    sessionTypes: drmSystemOptions.sessionTypes || [drmSystemOptions.sessionType || 'temporary'],\n    audioCapabilities: audioCodecs.map(codec => ({\n      contentType: `audio/mp4; codecs=${codec}`,\n      robustness: drmSystemOptions.audioRobustness || '',\n      encryptionScheme: drmSystemOptions.audioEncryptionScheme || null\n    })),\n    videoCapabilities: videoCodecs.map(codec => ({\n      contentType: `video/mp4; codecs=${codec}`,\n      robustness: drmSystemOptions.videoRobustness || '',\n      encryptionScheme: drmSystemOptions.videoEncryptionScheme || null\n    }))\n  };\n  return [baseConfig];\n}\nfunction isPersistentSessionType(drmSystemOptions) {\n  var _drmSystemOptions$ses;\n  return !!drmSystemOptions && (drmSystemOptions.sessionType === 'persistent-license' || !!((_drmSystemOptions$ses = drmSystemOptions.sessionTypes) != null && _drmSystemOptions$ses.some(type => type === 'persistent-license')));\n}\nfunction parsePlayReadyWRM(keyBytes) {\n  const keyBytesUtf16 = new Uint16Array(keyBytes.buffer, keyBytes.byteOffset, keyBytes.byteLength / 2);\n  const keyByteStr = String.fromCharCode.apply(null, Array.from(keyBytesUtf16));\n\n  // Parse Playready WRMHeader XML\n  const xmlKeyBytes = keyByteStr.substring(keyByteStr.indexOf('<'), keyByteStr.length);\n  const parser = new DOMParser();\n  const xmlDoc = parser.parseFromString(xmlKeyBytes, 'text/xml');\n  const keyData = xmlDoc.getElementsByTagName('KID')[0];\n  if (keyData) {\n    const keyId = keyData.childNodes[0] ? keyData.childNodes[0].nodeValue : keyData.getAttribute('VALUE');\n    if (keyId) {\n      const keyIdArray = base64Decode(keyId).subarray(0, 16);\n      // KID value in PRO is a base64-encoded little endian GUID interpretation of UUID\n      // KID value in tenc is a big endian UUID GUID interpretation of UUID\n      changeEndianness(keyIdArray);\n      return keyIdArray;\n    }\n  }\n  return null;\n}\n\nlet keyUriToKeyIdMap = {};\nclass LevelKey {\n  static clearKeyUriToKeyIdMap() {\n    keyUriToKeyIdMap = {};\n  }\n  static setKeyIdForUri(uri, keyId) {\n    keyUriToKeyIdMap[uri] = keyId;\n  }\n  static addKeyIdForUri(uri) {\n    const val = Object.keys(keyUriToKeyIdMap).length % Number.MAX_SAFE_INTEGER;\n    const keyId = new Uint8Array(16);\n    const dv = new DataView(keyId.buffer, 12, 4); // Just set the last 4 bytes\n    dv.setUint32(0, val);\n    keyUriToKeyIdMap[uri] = keyId;\n    return keyId;\n  }\n  constructor(method, uri, format, formatversions = [1], iv = null, keyId) {\n    this.uri = void 0;\n    this.method = void 0;\n    this.keyFormat = void 0;\n    this.keyFormatVersions = void 0;\n    this.encrypted = void 0;\n    this.isCommonEncryption = void 0;\n    this.iv = null;\n    this.key = null;\n    this.keyId = null;\n    this.pssh = null;\n    this.method = method;\n    this.uri = uri;\n    this.keyFormat = format;\n    this.keyFormatVersions = formatversions;\n    this.iv = iv;\n    this.encrypted = method ? method !== 'NONE' : false;\n    this.isCommonEncryption = this.encrypted && !isFullSegmentEncryption(method);\n    if (keyId != null && keyId.startsWith('0x')) {\n      this.keyId = new Uint8Array(hexToArrayBuffer(keyId));\n    }\n  }\n  matches(key) {\n    return key.uri === this.uri && key.method === this.method && key.encrypted === this.encrypted && key.keyFormat === this.keyFormat && arrayValuesMatch(key.keyFormatVersions, this.keyFormatVersions) && optionalArrayValuesMatch(key.iv, this.iv) && optionalArrayValuesMatch(key.keyId, this.keyId);\n  }\n  isSupported() {\n    // If it's Segment encryption or No encryption, just select that key system\n    if (this.method) {\n      if (isFullSegmentEncryption(this.method) || this.method === 'NONE') {\n        return true;\n      }\n      if (this.keyFormat === 'identity') {\n        // Maintain support for clear SAMPLE-AES with MPEG-3 TS\n        return this.method === 'SAMPLE-AES';\n      } else {\n        switch (this.keyFormat) {\n          case KeySystemFormats.FAIRPLAY:\n          case KeySystemFormats.WIDEVINE:\n          case KeySystemFormats.PLAYREADY:\n          case KeySystemFormats.CLEARKEY:\n            return ['SAMPLE-AES', 'SAMPLE-AES-CENC', 'SAMPLE-AES-CTR'].indexOf(this.method) !== -1;\n        }\n      }\n    }\n    return false;\n  }\n  getDecryptData(sn, levelKeys) {\n    if (!this.encrypted || !this.uri) {\n      return null;\n    }\n    if (isFullSegmentEncryption(this.method)) {\n      let iv = this.iv;\n      if (!iv) {\n        if (typeof sn !== 'number') {\n          // We are fetching decryption data for a initialization segment\n          // If the segment was encrypted with AES-128/256\n          // It must have an IV defined. We cannot substitute the Segment Number in.\n          logger.warn(`missing IV for initialization segment with method=\"${this.method}\" - compliance issue`);\n\n          // Explicitly set sn to resulting value from implicit conversions 'initSegment' values for IV generation.\n          sn = 0;\n        }\n        iv = createInitializationVector(sn);\n      }\n      const decryptdata = new LevelKey(this.method, this.uri, 'identity', this.keyFormatVersions, iv);\n      return decryptdata;\n    }\n    if (this.keyId) {\n      // Handle case where key id is changed in KEY_LOADING event handler #7542#issuecomment-3305203929\n      const assignedKeyId = keyUriToKeyIdMap[this.uri];\n      if (assignedKeyId && !arrayValuesMatch(this.keyId, assignedKeyId)) {\n        LevelKey.setKeyIdForUri(this.uri, this.keyId);\n      }\n      if (this.pssh) {\n        return this;\n      }\n    }\n\n    // Key bytes are signalled the KEYID attribute, typically only found on WideVine KEY tags\n    // Initialize keyId if possible\n    const keyBytes = convertDataUriToArrayBytes(this.uri);\n    if (keyBytes) {\n      switch (this.keyFormat) {\n        case KeySystemFormats.WIDEVINE:\n          // Setting `pssh` on this LevelKey/DecryptData allows HLS.js to generate a session using\n          // the playlist-key before the \"encrypted\" event. (Comment out to only use \"encrypted\" path.)\n          this.pssh = keyBytes;\n          // In case of Widevine, if KEYID is not in the playlist, assume only two fields in the pssh KEY tag URI.\n          if (!this.keyId) {\n            const results = parseMultiPssh(keyBytes.buffer);\n            if (results.length) {\n              var _psshData$kids;\n              const psshData = results[0];\n              this.keyId = (_psshData$kids = psshData.kids) != null && _psshData$kids.length ? psshData.kids[0] : null;\n            }\n          }\n          if (!this.keyId) {\n            this.keyId = getKeyIdFromPlayReadyKey(levelKeys);\n          }\n          break;\n        case KeySystemFormats.PLAYREADY:\n          {\n            const PlayReadyKeySystemUUID = new Uint8Array([0x9a, 0x04, 0xf0, 0x79, 0x98, 0x40, 0x42, 0x86, 0xab, 0x92, 0xe6, 0x5b, 0xe0, 0x88, 0x5f, 0x95]);\n\n            // Setting `pssh` on this LevelKey/DecryptData allows HLS.js to generate a session using\n            // the playlist-key before the \"encrypted\" event. (Comment out to only use \"encrypted\" path.)\n            this.pssh = mp4pssh(PlayReadyKeySystemUUID, null, keyBytes);\n            this.keyId = parsePlayReadyWRM(keyBytes);\n            break;\n          }\n        default:\n          {\n            let keydata = keyBytes.subarray(0, 16);\n            if (keydata.length !== 16) {\n              const padded = new Uint8Array(16);\n              padded.set(keydata, 16 - keydata.length);\n              keydata = padded;\n            }\n            this.keyId = keydata;\n            break;\n          }\n      }\n    }\n\n    // Default behavior: get keyId from other KEY tag or URI lookup\n    if (!this.keyId || this.keyId.byteLength !== 16) {\n      let keyId;\n      keyId = getKeyIdFromWidevineKey(levelKeys);\n      if (!keyId) {\n        keyId = getKeyIdFromPlayReadyKey(levelKeys);\n        if (!keyId) {\n          keyId = keyUriToKeyIdMap[this.uri];\n        }\n      }\n      if (keyId) {\n        this.keyId = keyId;\n        LevelKey.setKeyIdForUri(this.uri, keyId);\n      }\n    }\n    return this;\n  }\n}\nfunction getKeyIdFromWidevineKey(levelKeys) {\n  const widevineKey = levelKeys == null ? void 0 : levelKeys[KeySystemFormats.WIDEVINE];\n  if (widevineKey) {\n    return widevineKey.keyId;\n  }\n  return null;\n}\nfunction getKeyIdFromPlayReadyKey(levelKeys) {\n  const playReadyKey = levelKeys == null ? void 0 : levelKeys[KeySystemFormats.PLAYREADY];\n  if (playReadyKey) {\n    const playReadyKeyBytes = convertDataUriToArrayBytes(playReadyKey.uri);\n    if (playReadyKeyBytes) {\n      return parsePlayReadyWRM(playReadyKeyBytes);\n    }\n  }\n  return null;\n}\nfunction createInitializationVector(segmentNumber) {\n  const uint8View = new Uint8Array(16);\n  for (let i = 12; i < 16; i++) {\n    uint8View[i] = segmentNumber >> 8 * (15 - i) & 0xff;\n  }\n  return uint8View;\n}\n\nconst MASTER_PLAYLIST_REGEX = /#EXT-X-STREAM-INF:([^\\r\\n]*)(?:[\\r\\n](?:#[^\\r\\n]*)?)*([^\\r\\n]+)|#EXT-X-(SESSION-DATA|SESSION-KEY|DEFINE|CONTENT-STEERING|START):([^\\r\\n]*)[\\r\\n]+/g;\nconst MASTER_PLAYLIST_MEDIA_REGEX = /#EXT-X-MEDIA:(.*)/g;\nconst IS_MEDIA_PLAYLIST = /^#EXT(?:INF|-X-TARGETDURATION):/m; // Handle empty Media Playlist (first EXTINF not signaled, but TARGETDURATION present)\n\nconst LEVEL_PLAYLIST_REGEX_FAST = new RegExp([/#EXTINF:\\s*(\\d*(?:\\.\\d+)?)(?:,(.*)\\s+)?/.source,\n// duration (#EXTINF:<duration>,<title>), group 1 => duration, group 2 => title\n/(?!#) *(\\S[^\\r\\n]*)/.source,\n// segment URI, group 3 => the URI (note newline is not eaten)\n/#.*/.source // All other non-segment oriented tags will match with all groups empty\n].join('|'), 'g');\nconst LEVEL_PLAYLIST_REGEX_SLOW = new RegExp([/#EXT-X-(PROGRAM-DATE-TIME|BYTERANGE|DATERANGE|DEFINE|KEY|MAP|PART|PART-INF|PLAYLIST-TYPE|PRELOAD-HINT|RENDITION-REPORT|SERVER-CONTROL|SKIP|START):(.+)/.source, /#EXT-X-(BITRATE|DISCONTINUITY-SEQUENCE|MEDIA-SEQUENCE|TARGETDURATION|VERSION): *(\\d+)/.source, /#EXT-X-(DISCONTINUITY|ENDLIST|GAP|INDEPENDENT-SEGMENTS)/.source, /(#)([^:]*):(.*)/.source, /(#)(.*)(?:.*)\\r?\\n?/.source].join('|'));\nclass M3U8Parser {\n  static findGroup(groups, mediaGroupId) {\n    for (let i = 0; i < groups.length; i++) {\n      const group = groups[i];\n      if (group.id === mediaGroupId) {\n        return group;\n      }\n    }\n  }\n  static resolve(url, baseUrl) {\n    return urlToolkitExports.buildAbsoluteURL(baseUrl, url, {\n      alwaysNormalize: true\n    });\n  }\n  static isMediaPlaylist(str) {\n    return IS_MEDIA_PLAYLIST.test(str);\n  }\n  static parseMasterPlaylist(string, baseurl) {\n    const hasVariableRefs = hasVariableReferences(string) ;\n    const parsed = {\n      contentSteering: null,\n      levels: [],\n      playlistParsingError: null,\n      sessionData: null,\n      sessionKeys: null,\n      startTimeOffset: null,\n      variableList: null,\n      hasVariableRefs\n    };\n    const levelsWithKnownCodecs = [];\n    MASTER_PLAYLIST_REGEX.lastIndex = 0;\n    if (!string.startsWith('#EXTM3U')) {\n      parsed.playlistParsingError = new Error('no EXTM3U delimiter');\n      return parsed;\n    }\n    let result;\n    while ((result = MASTER_PLAYLIST_REGEX.exec(string)) != null) {\n      if (result[1]) {\n        var _level$unknownCodecs;\n        // '#EXT-X-STREAM-INF' is found, parse level tag  in group 1\n        const attrs = new AttrList(result[1], parsed);\n        const uri = substituteVariables(parsed, result[2]) ;\n        const level = {\n          attrs,\n          bitrate: attrs.decimalInteger('BANDWIDTH') || attrs.decimalInteger('AVERAGE-BANDWIDTH'),\n          name: attrs.NAME,\n          url: M3U8Parser.resolve(uri, baseurl)\n        };\n        const resolution = attrs.decimalResolution('RESOLUTION');\n        if (resolution) {\n          level.width = resolution.width;\n          level.height = resolution.height;\n        }\n        setCodecs(attrs.CODECS, level);\n        const supplementalCodecs = attrs['SUPPLEMENTAL-CODECS'];\n        if (supplementalCodecs) {\n          level.supplemental = {};\n          setCodecs(supplementalCodecs, level.supplemental);\n        }\n        if (!((_level$unknownCodecs = level.unknownCodecs) != null && _level$unknownCodecs.length)) {\n          levelsWithKnownCodecs.push(level);\n        }\n        parsed.levels.push(level);\n      } else if (result[3]) {\n        const tag = result[3];\n        const attributes = result[4];\n        switch (tag) {\n          case 'SESSION-DATA':\n            {\n              // #EXT-X-SESSION-DATA\n              const sessionAttrs = new AttrList(attributes, parsed);\n              const dataId = sessionAttrs['DATA-ID'];\n              if (dataId) {\n                if (parsed.sessionData === null) {\n                  parsed.sessionData = {};\n                }\n                parsed.sessionData[dataId] = sessionAttrs;\n              }\n              break;\n            }\n          case 'SESSION-KEY':\n            {\n              // #EXT-X-SESSION-KEY\n              const sessionKey = parseKey(attributes, baseurl, parsed);\n              if (sessionKey.encrypted && sessionKey.isSupported()) {\n                if (parsed.sessionKeys === null) {\n                  parsed.sessionKeys = [];\n                }\n                parsed.sessionKeys.push(sessionKey);\n              } else {\n                logger.warn(`[Keys] Ignoring invalid EXT-X-SESSION-KEY tag: \"${attributes}\"`);\n              }\n              break;\n            }\n          case 'DEFINE':\n            {\n              // #EXT-X-DEFINE\n              {\n                const variableAttributes = new AttrList(attributes, parsed);\n                addVariableDefinition(parsed, variableAttributes, baseurl);\n              }\n              break;\n            }\n          case 'CONTENT-STEERING':\n            {\n              // #EXT-X-CONTENT-STEERING\n              const contentSteeringAttributes = new AttrList(attributes, parsed);\n              parsed.contentSteering = {\n                uri: M3U8Parser.resolve(contentSteeringAttributes['SERVER-URI'], baseurl),\n                pathwayId: contentSteeringAttributes['PATHWAY-ID'] || '.'\n              };\n              break;\n            }\n          case 'START':\n            {\n              // #EXT-X-START\n              parsed.startTimeOffset = parseStartTimeOffset(attributes);\n              break;\n            }\n        }\n      }\n    }\n    // Filter out levels with unknown codecs if it does not remove all levels\n    const stripUnknownCodecLevels = levelsWithKnownCodecs.length > 0 && levelsWithKnownCodecs.length < parsed.levels.length;\n    parsed.levels = stripUnknownCodecLevels ? levelsWithKnownCodecs : parsed.levels;\n    if (parsed.levels.length === 0) {\n      parsed.playlistParsingError = new Error('no levels found in manifest');\n    }\n    return parsed;\n  }\n  static parseMasterPlaylistMedia(string, baseurl, parsed) {\n    let result;\n    const results = {};\n    const levels = parsed.levels;\n    const groupsByType = {\n      AUDIO: levels.map(level => ({\n        id: level.attrs.AUDIO,\n        audioCodec: level.audioCodec\n      })),\n      SUBTITLES: levels.map(level => ({\n        id: level.attrs.SUBTITLES,\n        textCodec: level.textCodec\n      })),\n      'CLOSED-CAPTIONS': []\n    };\n    let id = 0;\n    MASTER_PLAYLIST_MEDIA_REGEX.lastIndex = 0;\n    while ((result = MASTER_PLAYLIST_MEDIA_REGEX.exec(string)) !== null) {\n      const attrs = new AttrList(result[1], parsed);\n      const type = attrs.TYPE;\n      if (type) {\n        const groups = groupsByType[type];\n        const medias = results[type] || [];\n        results[type] = medias;\n        const lang = attrs.LANGUAGE;\n        const assocLang = attrs['ASSOC-LANGUAGE'];\n        const channels = attrs.CHANNELS;\n        const characteristics = attrs.CHARACTERISTICS;\n        const instreamId = attrs['INSTREAM-ID'];\n        const media = {\n          attrs,\n          bitrate: 0,\n          id: id++,\n          groupId: attrs['GROUP-ID'] || '',\n          name: attrs.NAME || lang || '',\n          type,\n          default: attrs.bool('DEFAULT'),\n          autoselect: attrs.bool('AUTOSELECT'),\n          forced: attrs.bool('FORCED'),\n          lang,\n          url: attrs.URI ? M3U8Parser.resolve(attrs.URI, baseurl) : ''\n        };\n        if (assocLang) {\n          media.assocLang = assocLang;\n        }\n        if (channels) {\n          media.channels = channels;\n        }\n        if (characteristics) {\n          media.characteristics = characteristics;\n        }\n        if (instreamId) {\n          media.instreamId = instreamId;\n        }\n        if (groups != null && groups.length) {\n          // If there are audio or text groups signalled in the manifest, let's look for a matching codec string for this track\n          // If we don't find the track signalled, lets use the first audio groups codec we have\n          // Acting as a best guess\n          const groupCodec = M3U8Parser.findGroup(groups, media.groupId) || groups[0];\n          assignCodec(media, groupCodec, 'audioCodec');\n          assignCodec(media, groupCodec, 'textCodec');\n        }\n        medias.push(media);\n      }\n    }\n    return results;\n  }\n  static parseLevelPlaylist(string, baseurl, id, type, levelUrlId, multivariantVariableList) {\n    var _LEVEL_PLAYLIST_REGEX;\n    const base = {\n      url: baseurl\n    };\n    const level = new LevelDetails(baseurl);\n    const fragments = level.fragments;\n    const programDateTimes = [];\n    // The most recent init segment seen (applies to all subsequent segments)\n    let currentInitSegment = null;\n    let currentSN = 0;\n    let currentPart = 0;\n    let totalduration = 0;\n    let discontinuityCounter = 0;\n    let currentBitrate = 0;\n    let prevFrag = null;\n    let frag = new Fragment(type, base);\n    let result;\n    let i;\n    let levelkeys;\n    let firstPdtIndex = -1;\n    let createNextFrag = false;\n    let nextByteRange = null;\n    let serverControlAttrs;\n    LEVEL_PLAYLIST_REGEX_FAST.lastIndex = 0;\n    level.m3u8 = string;\n    level.hasVariableRefs = hasVariableReferences(string) ;\n    if (((_LEVEL_PLAYLIST_REGEX = LEVEL_PLAYLIST_REGEX_FAST.exec(string)) == null ? void 0 : _LEVEL_PLAYLIST_REGEX[0]) !== '#EXTM3U') {\n      level.playlistParsingError = new Error('Missing format identifier #EXTM3U');\n      return level;\n    }\n    while ((result = LEVEL_PLAYLIST_REGEX_FAST.exec(string)) !== null) {\n      if (createNextFrag) {\n        createNextFrag = false;\n        frag = new Fragment(type, base);\n        // setup the next fragment for part loading\n        frag.playlistOffset = totalduration;\n        frag.setStart(totalduration);\n        frag.sn = currentSN;\n        frag.cc = discontinuityCounter;\n        if (currentBitrate) {\n          frag.bitrate = currentBitrate;\n        }\n        frag.level = id;\n        if (currentInitSegment) {\n          frag.initSegment = currentInitSegment;\n          if (currentInitSegment.rawProgramDateTime) {\n            frag.rawProgramDateTime = currentInitSegment.rawProgramDateTime;\n            currentInitSegment.rawProgramDateTime = null;\n          }\n          if (nextByteRange) {\n            frag.setByteRange(nextByteRange);\n            nextByteRange = null;\n          }\n        }\n      }\n      const duration = result[1];\n      if (duration) {\n        // INF\n        frag.duration = parseFloat(duration);\n        // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939\n        const title = (' ' + result[2]).slice(1);\n        frag.title = title || null;\n        frag.tagList.push(title ? ['INF', duration, title] : ['INF', duration]);\n      } else if (result[3]) {\n        // url\n        if (isFiniteNumber(frag.duration)) {\n          frag.playlistOffset = totalduration;\n          frag.setStart(totalduration);\n          if (levelkeys) {\n            setFragLevelKeys(frag, levelkeys, level);\n          }\n          frag.sn = currentSN;\n          frag.level = id;\n          frag.cc = discontinuityCounter;\n          fragments.push(frag);\n          // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939\n          const uri = (' ' + result[3]).slice(1);\n          frag.relurl = substituteVariables(level, uri) ;\n          assignProgramDateTime(frag, prevFrag, programDateTimes);\n          prevFrag = frag;\n          totalduration += frag.duration;\n          currentSN++;\n          currentPart = 0;\n          createNextFrag = true;\n        }\n      } else {\n        result = result[0].match(LEVEL_PLAYLIST_REGEX_SLOW);\n        if (!result) {\n          logger.warn('No matches on slow regex match for level playlist!');\n          continue;\n        }\n        for (i = 1; i < result.length; i++) {\n          if (result[i] !== undefined) {\n            break;\n          }\n        }\n\n        // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939\n        const tag = (' ' + result[i]).slice(1);\n        const value1 = (' ' + result[i + 1]).slice(1);\n        const value2 = result[i + 2] ? (' ' + result[i + 2]).slice(1) : null;\n        switch (tag) {\n          case 'BYTERANGE':\n            if (prevFrag) {\n              frag.setByteRange(value1, prevFrag);\n            } else {\n              frag.setByteRange(value1);\n            }\n            break;\n          case 'PROGRAM-DATE-TIME':\n            // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939\n            frag.rawProgramDateTime = value1;\n            frag.tagList.push(['PROGRAM-DATE-TIME', value1]);\n            if (firstPdtIndex === -1) {\n              firstPdtIndex = fragments.length;\n            }\n            break;\n          case 'PLAYLIST-TYPE':\n            if (level.type) {\n              assignMultipleMediaPlaylistTagOccuranceError(level, tag, result);\n            }\n            level.type = value1.toUpperCase();\n            break;\n          case 'MEDIA-SEQUENCE':\n            if (level.startSN !== 0) {\n              assignMultipleMediaPlaylistTagOccuranceError(level, tag, result);\n            } else if (fragments.length > 0) {\n              assignMustAppearBeforeSegmentsError(level, tag, result);\n            }\n            currentSN = level.startSN = parseInt(value1);\n            break;\n          case 'SKIP':\n            {\n              if (level.skippedSegments) {\n                assignMultipleMediaPlaylistTagOccuranceError(level, tag, result);\n              }\n              const skipAttrs = new AttrList(value1, level);\n              const skippedSegments = skipAttrs.decimalInteger('SKIPPED-SEGMENTS');\n              if (isFiniteNumber(skippedSegments)) {\n                level.skippedSegments += skippedSegments;\n                // This will result in fragments[] containing undefined values, which we will fill in with `mergeDetails`\n                for (let _i = skippedSegments; _i--;) {\n                  fragments.push(null);\n                }\n                currentSN += skippedSegments;\n              }\n              const recentlyRemovedDateranges = skipAttrs.enumeratedString('RECENTLY-REMOVED-DATERANGES');\n              if (recentlyRemovedDateranges) {\n                level.recentlyRemovedDateranges = (level.recentlyRemovedDateranges || []).concat(recentlyRemovedDateranges.split('\\t'));\n              }\n              break;\n            }\n          case 'TARGETDURATION':\n            if (level.targetduration !== 0) {\n              assignMultipleMediaPlaylistTagOccuranceError(level, tag, result);\n            }\n            level.targetduration = Math.max(parseInt(value1), 1);\n            break;\n          case 'VERSION':\n            if (level.version !== null) {\n              assignMultipleMediaPlaylistTagOccuranceError(level, tag, result);\n            }\n            level.version = parseInt(value1);\n            break;\n          case 'INDEPENDENT-SEGMENTS':\n            break;\n          case 'ENDLIST':\n            if (!level.live) {\n              assignMultipleMediaPlaylistTagOccuranceError(level, tag, result);\n            }\n            level.live = false;\n            break;\n          case '#':\n            if (value1 || value2) {\n              frag.tagList.push(value2 ? [value1, value2] : [value1]);\n            }\n            break;\n          case 'DISCONTINUITY':\n            discontinuityCounter++;\n            frag.tagList.push(['DIS']);\n            break;\n          case 'GAP':\n            frag.gap = true;\n            frag.tagList.push([tag]);\n            break;\n          case 'BITRATE':\n            frag.tagList.push([tag, value1]);\n            currentBitrate = parseInt(value1) * 1000;\n            if (isFiniteNumber(currentBitrate)) {\n              frag.bitrate = currentBitrate;\n            } else {\n              currentBitrate = 0;\n            }\n            break;\n          case 'DATERANGE':\n            {\n              const dateRangeAttr = new AttrList(value1, level);\n              const dateRange = new DateRange(dateRangeAttr, level.dateRanges[dateRangeAttr.ID], level.dateRangeTagCount);\n              level.dateRangeTagCount++;\n              if (dateRange.isValid || level.skippedSegments) {\n                level.dateRanges[dateRange.id] = dateRange;\n              } else {\n                logger.warn(`Ignoring invalid DATERANGE tag: \"${value1}\"`);\n              }\n              // Add to fragment tag list for backwards compatibility (< v1.2.0)\n              frag.tagList.push(['EXT-X-DATERANGE', value1]);\n              break;\n            }\n          case 'DEFINE':\n            {\n              {\n                const variableAttributes = new AttrList(value1, level);\n                if ('IMPORT' in variableAttributes) {\n                  importVariableDefinition(level, variableAttributes, multivariantVariableList);\n                } else {\n                  addVariableDefinition(level, variableAttributes, baseurl);\n                }\n              }\n              break;\n            }\n          case 'DISCONTINUITY-SEQUENCE':\n            if (level.startCC !== 0) {\n              assignMultipleMediaPlaylistTagOccuranceError(level, tag, result);\n            } else if (fragments.length > 0) {\n              assignMustAppearBeforeSegmentsError(level, tag, result);\n            }\n            level.startCC = discontinuityCounter = parseInt(value1);\n            break;\n          case 'KEY':\n            {\n              const levelKey = parseKey(value1, baseurl, level);\n              if (levelKey.isSupported()) {\n                if (levelKey.method === 'NONE') {\n                  levelkeys = undefined;\n                  break;\n                }\n                if (!levelkeys) {\n                  levelkeys = {};\n                }\n                const currentKey = levelkeys[levelKey.keyFormat];\n                // Ignore duplicate playlist KEY tags\n                if (!(currentKey != null && currentKey.matches(levelKey))) {\n                  if (currentKey) {\n                    levelkeys = _extends({}, levelkeys);\n                  }\n                  levelkeys[levelKey.keyFormat] = levelKey;\n                }\n              } else {\n                logger.warn(`[Keys] Ignoring unsupported EXT-X-KEY tag: \"${value1}\"${'' }`);\n              }\n              break;\n            }\n          case 'START':\n            level.startTimeOffset = parseStartTimeOffset(value1);\n            break;\n          case 'MAP':\n            {\n              const mapAttrs = new AttrList(value1, level);\n              if (frag.duration) {\n                // Initial segment tag is after segment duration tag.\n                //   #EXTINF: 6.0\n                //   #EXT-X-MAP:URI=\"init.mp4\n                const init = new Fragment(type, base);\n                setInitSegment(init, mapAttrs, id, levelkeys);\n                currentInitSegment = init;\n                frag.initSegment = currentInitSegment;\n                if (currentInitSegment.rawProgramDateTime && !frag.rawProgramDateTime) {\n                  frag.rawProgramDateTime = currentInitSegment.rawProgramDateTime;\n                }\n              } else {\n                // Initial segment tag is before segment duration tag\n                // Handle case where EXT-X-MAP is declared after EXT-X-BYTERANGE\n                const end = frag.byteRangeEndOffset;\n                if (end) {\n                  const start = frag.byteRangeStartOffset;\n                  nextByteRange = `${end - start}@${start}`;\n                } else {\n                  nextByteRange = null;\n                }\n                setInitSegment(frag, mapAttrs, id, levelkeys);\n                currentInitSegment = frag;\n                createNextFrag = true;\n              }\n              currentInitSegment.cc = discontinuityCounter;\n              break;\n            }\n          case 'SERVER-CONTROL':\n            {\n              if (serverControlAttrs) {\n                assignMultipleMediaPlaylistTagOccuranceError(level, tag, result);\n              }\n              serverControlAttrs = new AttrList(value1);\n              level.canBlockReload = serverControlAttrs.bool('CAN-BLOCK-RELOAD');\n              level.canSkipUntil = serverControlAttrs.optionalFloat('CAN-SKIP-UNTIL', 0);\n              level.canSkipDateRanges = level.canSkipUntil > 0 && serverControlAttrs.bool('CAN-SKIP-DATERANGES');\n              level.partHoldBack = serverControlAttrs.optionalFloat('PART-HOLD-BACK', 0);\n              level.holdBack = serverControlAttrs.optionalFloat('HOLD-BACK', 0);\n              break;\n            }\n          case 'PART-INF':\n            {\n              if (level.partTarget) {\n                assignMultipleMediaPlaylistTagOccuranceError(level, tag, result);\n              }\n              const partInfAttrs = new AttrList(value1);\n              level.partTarget = partInfAttrs.decimalFloatingPoint('PART-TARGET');\n              break;\n            }\n          case 'PART':\n            {\n              let partList = level.partList;\n              if (!partList) {\n                partList = level.partList = [];\n              }\n              const previousFragmentPart = currentPart > 0 ? partList[partList.length - 1] : undefined;\n              const index = currentPart++;\n              const partAttrs = new AttrList(value1, level);\n              const part = new Part(partAttrs, frag, base, index, previousFragmentPart);\n              partList.push(part);\n              frag.duration += part.duration;\n              break;\n            }\n          case 'PRELOAD-HINT':\n            {\n              const preloadHintAttrs = new AttrList(value1, level);\n              level.preloadHint = preloadHintAttrs;\n              break;\n            }\n          case 'RENDITION-REPORT':\n            {\n              const renditionReportAttrs = new AttrList(value1, level);\n              level.renditionReports = level.renditionReports || [];\n              level.renditionReports.push(renditionReportAttrs);\n              break;\n            }\n          default:\n            logger.warn(`line parsed but not handled: ${result}`);\n            break;\n        }\n      }\n    }\n    if (prevFrag && !prevFrag.relurl) {\n      fragments.pop();\n      totalduration -= prevFrag.duration;\n      if (level.partList) {\n        level.fragmentHint = prevFrag;\n      }\n    } else if (level.partList) {\n      assignProgramDateTime(frag, prevFrag, programDateTimes);\n      frag.cc = discontinuityCounter;\n      level.fragmentHint = frag;\n      if (levelkeys) {\n        setFragLevelKeys(frag, levelkeys, level);\n      }\n    }\n    if (!level.targetduration) {\n      level.playlistParsingError = new Error(`Missing Target Duration`);\n    }\n    const fragmentLength = fragments.length;\n    const firstFragment = fragments[0];\n    const lastFragment = fragments[fragmentLength - 1];\n    totalduration += level.skippedSegments * level.targetduration;\n    if (totalduration > 0 && fragmentLength && lastFragment) {\n      level.averagetargetduration = totalduration / fragmentLength;\n      const lastSn = lastFragment.sn;\n      level.endSN = lastSn !== 'initSegment' ? lastSn : 0;\n      if (!level.live) {\n        lastFragment.endList = true;\n      }\n      /**\n       * Backfill any missing PDT values\n       * \"If the first EXT-X-PROGRAM-DATE-TIME tag in a Playlist appears after\n       * one or more Media Segment URIs, the client SHOULD extrapolate\n       * backward from that tag (using EXTINF durations and/or media\n       * timestamps) to associate dates with those segments.\"\n       * We have already extrapolated forward, but all fragments up to the first instance of PDT do not have their PDTs\n       * computed.\n       */\n      if (firstPdtIndex > 0) {\n        backfillProgramDateTimes(fragments, firstPdtIndex);\n        if (firstFragment) {\n          programDateTimes.unshift(firstFragment);\n        }\n      }\n    }\n    if (level.fragmentHint) {\n      totalduration += level.fragmentHint.duration;\n    }\n    level.totalduration = totalduration;\n    if (programDateTimes.length && level.dateRangeTagCount && firstFragment) {\n      mapDateRanges(programDateTimes, level);\n    }\n    level.endCC = discontinuityCounter;\n    return level;\n  }\n}\nfunction mapDateRanges(programDateTimes, details) {\n  // Make sure DateRanges are mapped to a ProgramDateTime tag that applies a date to a segment that overlaps with its start date\n  let programDateTimeCount = programDateTimes.length;\n  if (!programDateTimeCount) {\n    if (details.hasProgramDateTime) {\n      const lastFragment = details.fragments[details.fragments.length - 1];\n      programDateTimes.push(lastFragment);\n      programDateTimeCount++;\n    } else {\n      // no segments with EXT-X-PROGRAM-DATE-TIME references in playlist history\n      return;\n    }\n  }\n  const lastProgramDateTime = programDateTimes[programDateTimeCount - 1];\n  const playlistEnd = details.live ? Infinity : details.totalduration;\n  const dateRangeIds = Object.keys(details.dateRanges);\n  for (let i = dateRangeIds.length; i--;) {\n    const dateRange = details.dateRanges[dateRangeIds[i]];\n    const startDateTime = dateRange.startDate.getTime();\n    dateRange.tagAnchor = lastProgramDateTime.ref;\n    for (let j = programDateTimeCount; j--;) {\n      var _programDateTimes$j;\n      if (((_programDateTimes$j = programDateTimes[j]) == null ? void 0 : _programDateTimes$j.sn) < details.startSN) {\n        break;\n      }\n      const fragIndex = findFragmentWithStartDate(details, startDateTime, programDateTimes, j, playlistEnd);\n      if (fragIndex !== -1) {\n        dateRange.tagAnchor = details.fragments[fragIndex].ref;\n        break;\n      }\n    }\n  }\n}\nfunction findFragmentWithStartDate(details, startDateTime, programDateTimes, index, endTime) {\n  const pdtFragment = programDateTimes[index];\n  if (pdtFragment) {\n    // find matching range between PDT tags\n    const pdtStart = pdtFragment.programDateTime;\n    if (startDateTime >= pdtStart || index === 0) {\n      var _programDateTimes;\n      const durationBetweenPdt = (((_programDateTimes = programDateTimes[index + 1]) == null ? void 0 : _programDateTimes.start) || endTime) - pdtFragment.start;\n      if (startDateTime <= pdtStart + durationBetweenPdt * 1000) {\n        // map to fragment with date-time range\n        const startIndex = programDateTimes[index].sn - details.startSN;\n        if (startIndex < 0) {\n          return -1;\n        }\n        const fragments = details.fragments;\n        if (fragments.length > programDateTimes.length) {\n          const endSegment = programDateTimes[index + 1] || fragments[fragments.length - 1];\n          const endIndex = endSegment.sn - details.startSN;\n          for (let i = endIndex; i > startIndex; i--) {\n            const fragStartDateTime = fragments[i].programDateTime;\n            if (startDateTime >= fragStartDateTime && startDateTime < fragStartDateTime + fragments[i].duration * 1000) {\n              return i;\n            }\n          }\n        }\n        return startIndex;\n      }\n    }\n  }\n  return -1;\n}\nfunction parseKey(keyTagAttributes, baseurl, parsed) {\n  var _keyAttrs$METHOD, _keyAttrs$KEYFORMAT;\n  // https://tools.ietf.org/html/rfc8216#section-4.3.2.4\n  const keyAttrs = new AttrList(keyTagAttributes, parsed);\n  const decryptmethod = (_keyAttrs$METHOD = keyAttrs.METHOD) != null ? _keyAttrs$METHOD : '';\n  const decrypturi = keyAttrs.URI;\n  const decryptiv = keyAttrs.hexadecimalInteger('IV');\n  const decryptkeyformatversions = keyAttrs.KEYFORMATVERSIONS;\n  // From RFC: This attribute is OPTIONAL; its absence indicates an implicit value of \"identity\".\n  const decryptkeyformat = (_keyAttrs$KEYFORMAT = keyAttrs.KEYFORMAT) != null ? _keyAttrs$KEYFORMAT : 'identity';\n  if (decrypturi && keyAttrs.IV && !decryptiv) {\n    logger.error(`Invalid IV: ${keyAttrs.IV}`);\n  }\n  // If decrypturi is a URI with a scheme, then baseurl will be ignored\n  // No uri is allowed when METHOD is NONE\n  const resolvedUri = decrypturi ? M3U8Parser.resolve(decrypturi, baseurl) : '';\n  const keyFormatVersions = (decryptkeyformatversions ? decryptkeyformatversions : '1').split('/').map(Number).filter(Number.isFinite);\n  return new LevelKey(decryptmethod, resolvedUri, decryptkeyformat, keyFormatVersions, decryptiv, keyAttrs.KEYID);\n}\nfunction parseStartTimeOffset(startAttributes) {\n  const startAttrs = new AttrList(startAttributes);\n  const startTimeOffset = startAttrs.decimalFloatingPoint('TIME-OFFSET');\n  if (isFiniteNumber(startTimeOffset)) {\n    return startTimeOffset;\n  }\n  return null;\n}\nfunction setCodecs(codecsAttributeValue, level) {\n  let codecs = (codecsAttributeValue || '').split(/[ ,]+/).filter(c => c);\n  ['video', 'audio', 'text'].forEach(type => {\n    const filtered = codecs.filter(codec => isCodecType(codec, type));\n    if (filtered.length) {\n      // Comma separated list of all codecs for type\n      level[`${type}Codec`] = filtered.map(c => c.split('/')[0]).join(',');\n      // Remove known codecs so that only unknownCodecs are left after iterating through each type\n      codecs = codecs.filter(codec => filtered.indexOf(codec) === -1);\n    }\n  });\n  level.unknownCodecs = codecs;\n}\nfunction assignCodec(media, groupItem, codecProperty) {\n  const codecValue = groupItem[codecProperty];\n  if (codecValue) {\n    media[codecProperty] = codecValue;\n  }\n}\nfunction backfillProgramDateTimes(fragments, firstPdtIndex) {\n  let fragPrev = fragments[firstPdtIndex];\n  for (let i = firstPdtIndex; i--;) {\n    const frag = fragments[i];\n    // Exit on delta-playlist skipped segments\n    if (!frag) {\n      return;\n    }\n    frag.programDateTime = fragPrev.programDateTime - frag.duration * 1000;\n    fragPrev = frag;\n  }\n}\nfunction assignProgramDateTime(frag, prevFrag, programDateTimes) {\n  if (frag.rawProgramDateTime) {\n    programDateTimes.push(frag);\n  } else if (prevFrag != null && prevFrag.programDateTime) {\n    frag.programDateTime = prevFrag.endProgramDateTime;\n  }\n}\nfunction setInitSegment(frag, mapAttrs, id, levelkeys) {\n  frag.relurl = mapAttrs.URI;\n  if (mapAttrs.BYTERANGE) {\n    frag.setByteRange(mapAttrs.BYTERANGE);\n  }\n  frag.level = id;\n  frag.sn = 'initSegment';\n  if (levelkeys) {\n    frag.levelkeys = levelkeys;\n  }\n  frag.initSegment = null;\n}\nfunction setFragLevelKeys(frag, levelkeys, level) {\n  frag.levelkeys = levelkeys;\n  const {\n    encryptedFragments\n  } = level;\n  if ((!encryptedFragments.length || encryptedFragments[encryptedFragments.length - 1].levelkeys !== levelkeys) && Object.keys(levelkeys).some(format => levelkeys[format].isCommonEncryption)) {\n    encryptedFragments.push(frag);\n  }\n}\nfunction assignMultipleMediaPlaylistTagOccuranceError(level, tag, result) {\n  level.playlistParsingError = new Error(`#EXT-X-${tag} must not appear more than once (${result[0]})`);\n}\nfunction assignMustAppearBeforeSegmentsError(level, tag, result) {\n  level.playlistParsingError = new Error(`#EXT-X-${tag} must appear before the first Media Segment (${result[0]})`);\n}\n\nfunction updateFromToPTS(fragFrom, fragTo) {\n  const fragToPTS = fragTo.startPTS;\n  // if we know startPTS[toIdx]\n  if (isFiniteNumber(fragToPTS)) {\n    // update fragment duration.\n    // it helps to fix drifts between playlist reported duration and fragment real duration\n    let duration = 0;\n    let frag;\n    if (fragTo.sn > fragFrom.sn) {\n      duration = fragToPTS - fragFrom.start;\n      frag = fragFrom;\n    } else {\n      duration = fragFrom.start - fragToPTS;\n      frag = fragTo;\n    }\n    if (frag.duration !== duration) {\n      frag.setDuration(duration);\n    }\n    // we dont know startPTS[toIdx]\n  } else if (fragTo.sn > fragFrom.sn) {\n    const contiguous = fragFrom.cc === fragTo.cc;\n    // TODO: With part-loading end/durations we need to confirm the whole fragment is loaded before using (or setting) minEndPTS\n    if (contiguous && fragFrom.minEndPTS) {\n      fragTo.setStart(fragFrom.start + (fragFrom.minEndPTS - fragFrom.start));\n    } else {\n      fragTo.setStart(fragFrom.start + fragFrom.duration);\n    }\n  } else {\n    fragTo.setStart(Math.max(fragFrom.start - fragTo.duration, 0));\n  }\n}\nfunction updateFragPTSDTS(details, frag, startPTS, endPTS, startDTS, endDTS, logger) {\n  const parsedMediaDuration = endPTS - startPTS;\n  if (parsedMediaDuration <= 0) {\n    logger.warn('Fragment should have a positive duration', frag);\n    endPTS = startPTS + frag.duration;\n    endDTS = startDTS + frag.duration;\n  }\n  let maxStartPTS = startPTS;\n  let minEndPTS = endPTS;\n  const fragStartPts = frag.startPTS;\n  const fragEndPts = frag.endPTS;\n  if (isFiniteNumber(fragStartPts)) {\n    // delta PTS between audio and video\n    const deltaPTS = Math.abs(fragStartPts - startPTS);\n    if (details && deltaPTS > details.totalduration) {\n      logger.warn(`media timestamps and playlist times differ by ${deltaPTS}s for level ${frag.level} ${details.url}`);\n    } else if (!isFiniteNumber(frag.deltaPTS)) {\n      frag.deltaPTS = deltaPTS;\n    } else {\n      frag.deltaPTS = Math.max(deltaPTS, frag.deltaPTS);\n    }\n    maxStartPTS = Math.max(startPTS, fragStartPts);\n    startPTS = Math.min(startPTS, fragStartPts);\n    startDTS = frag.startDTS !== undefined ? Math.min(startDTS, frag.startDTS) : startDTS;\n    minEndPTS = Math.min(endPTS, fragEndPts);\n    endPTS = Math.max(endPTS, fragEndPts);\n    endDTS = frag.endDTS !== undefined ? Math.max(endDTS, frag.endDTS) : endDTS;\n  }\n  const drift = startPTS - frag.start;\n  if (frag.start !== 0) {\n    frag.setStart(startPTS);\n  }\n  frag.setDuration(endPTS - frag.start);\n  frag.startPTS = startPTS;\n  frag.maxStartPTS = maxStartPTS;\n  frag.startDTS = startDTS;\n  frag.endPTS = endPTS;\n  frag.minEndPTS = minEndPTS;\n  frag.endDTS = endDTS;\n  const sn = frag.sn;\n  // exit if sn out of range\n  if (!details || sn < details.startSN || sn > details.endSN) {\n    return 0;\n  }\n  let i;\n  const fragIdx = sn - details.startSN;\n  const fragments = details.fragments;\n  // update frag reference in fragments array\n  // rationale is that fragments array might not contain this frag object.\n  // this will happen if playlist has been refreshed between frag loading and call to updateFragPTSDTS()\n  // if we don't update frag, we won't be able to propagate PTS info on the playlist\n  // resulting in invalid sliding computation\n  fragments[fragIdx] = frag;\n  // adjust fragment PTS/duration from seqnum-1 to frag 0\n  for (i = fragIdx; i > 0; i--) {\n    updateFromToPTS(fragments[i], fragments[i - 1]);\n  }\n\n  // adjust fragment PTS/duration from seqnum to last frag\n  for (i = fragIdx; i < fragments.length - 1; i++) {\n    updateFromToPTS(fragments[i], fragments[i + 1]);\n  }\n  if (details.fragmentHint) {\n    updateFromToPTS(fragments[fragments.length - 1], details.fragmentHint);\n  }\n  details.PTSKnown = details.alignedSliding = true;\n  return drift;\n}\nfunction mergeDetails(oldDetails, newDetails, logger) {\n  if (oldDetails === newDetails) {\n    return;\n  }\n  // Track the last initSegment processed. Initialize it to the last one on the timeline.\n  let currentInitSegment = null;\n  const oldFragments = oldDetails.fragments;\n  for (let i = oldFragments.length - 1; i >= 0; i--) {\n    const oldInit = oldFragments[i].initSegment;\n    if (oldInit) {\n      currentInitSegment = oldInit;\n      break;\n    }\n  }\n  if (oldDetails.fragmentHint) {\n    // prevent PTS and duration from being adjusted on the next hint\n    delete oldDetails.fragmentHint.endPTS;\n  }\n  // check if old/new playlists have fragments in common\n  // loop through overlapping SN and update startPTS, cc, and duration if any found\n  let PTSFrag;\n  mapFragmentIntersection(oldDetails, newDetails, (oldFrag, newFrag, newFragIndex, newFragments) => {\n    if ((!newDetails.startCC || newDetails.skippedSegments) && newFrag.cc !== oldFrag.cc) {\n      const ccOffset = oldFrag.cc - newFrag.cc;\n      for (let i = newFragIndex; i < newFragments.length; i++) {\n        newFragments[i].cc += ccOffset;\n      }\n      newDetails.endCC = newFragments[newFragments.length - 1].cc;\n    }\n    if (isFiniteNumber(oldFrag.startPTS) && isFiniteNumber(oldFrag.endPTS)) {\n      newFrag.setStart(newFrag.startPTS = oldFrag.startPTS);\n      newFrag.startDTS = oldFrag.startDTS;\n      newFrag.maxStartPTS = oldFrag.maxStartPTS;\n      newFrag.endPTS = oldFrag.endPTS;\n      newFrag.endDTS = oldFrag.endDTS;\n      newFrag.minEndPTS = oldFrag.minEndPTS;\n      newFrag.setDuration(oldFrag.endPTS - oldFrag.startPTS);\n      if (newFrag.duration) {\n        PTSFrag = newFrag;\n      }\n\n      // PTS is known when any segment has startPTS and endPTS\n      newDetails.PTSKnown = newDetails.alignedSliding = true;\n    }\n    if (oldFrag.hasStreams) {\n      newFrag.elementaryStreams = oldFrag.elementaryStreams;\n    }\n    newFrag.loader = oldFrag.loader;\n    if (oldFrag.hasStats) {\n      newFrag.stats = oldFrag.stats;\n    }\n    if (oldFrag.initSegment) {\n      newFrag.initSegment = oldFrag.initSegment;\n      currentInitSegment = oldFrag.initSegment;\n    }\n  });\n  const newFragments = newDetails.fragments;\n  const fragmentsToCheck = newDetails.fragmentHint ? newFragments.concat(newDetails.fragmentHint) : newFragments;\n  if (currentInitSegment) {\n    fragmentsToCheck.forEach(frag => {\n      var _currentInitSegment;\n      if (frag && (!frag.initSegment || frag.initSegment.relurl === ((_currentInitSegment = currentInitSegment) == null ? void 0 : _currentInitSegment.relurl))) {\n        frag.initSegment = currentInitSegment;\n      }\n    });\n  }\n  if (newDetails.skippedSegments) {\n    newDetails.deltaUpdateFailed = newFragments.some(frag => !frag);\n    if (newDetails.deltaUpdateFailed) {\n      logger.warn('[level-helper] Previous playlist missing segments skipped in delta playlist');\n      for (let i = newDetails.skippedSegments; i--;) {\n        newFragments.shift();\n      }\n      newDetails.startSN = newFragments[0].sn;\n    } else {\n      if (newDetails.canSkipDateRanges) {\n        newDetails.dateRanges = mergeDateRanges(oldDetails.dateRanges, newDetails, logger);\n      }\n      const programDateTimes = oldDetails.fragments.filter(frag => frag.rawProgramDateTime);\n      if (oldDetails.hasProgramDateTime && !newDetails.hasProgramDateTime) {\n        for (let i = 1; i < fragmentsToCheck.length; i++) {\n          if (fragmentsToCheck[i].programDateTime === null) {\n            assignProgramDateTime(fragmentsToCheck[i], fragmentsToCheck[i - 1], programDateTimes);\n          }\n        }\n      }\n      mapDateRanges(programDateTimes, newDetails);\n    }\n    newDetails.endCC = newFragments[newFragments.length - 1].cc;\n  }\n  if (!newDetails.startCC) {\n    var _fragPriorToNewStart$;\n    const fragPriorToNewStart = getFragmentWithSN(oldDetails, newDetails.startSN - 1);\n    newDetails.startCC = (_fragPriorToNewStart$ = fragPriorToNewStart == null ? void 0 : fragPriorToNewStart.cc) != null ? _fragPriorToNewStart$ : newFragments[0].cc;\n  }\n\n  // Merge parts\n  mapPartIntersection(oldDetails.partList, newDetails.partList, (oldPart, newPart) => {\n    newPart.elementaryStreams = oldPart.elementaryStreams;\n    newPart.stats = oldPart.stats;\n  });\n\n  // if at least one fragment contains PTS info, recompute PTS information for all fragments\n  if (PTSFrag) {\n    updateFragPTSDTS(newDetails, PTSFrag, PTSFrag.startPTS, PTSFrag.endPTS, PTSFrag.startDTS, PTSFrag.endDTS, logger);\n  } else {\n    // ensure that delta is within oldFragments range\n    // also adjust sliding in case delta is 0 (we could have old=[50-60] and new=old=[50-61])\n    // in that case we also need to adjust start offset of all fragments\n    adjustSliding(oldDetails, newDetails);\n  }\n  if (newFragments.length) {\n    newDetails.totalduration = newDetails.edge - newFragments[0].start;\n  }\n  newDetails.driftStartTime = oldDetails.driftStartTime;\n  newDetails.driftStart = oldDetails.driftStart;\n  const advancedDateTime = newDetails.advancedDateTime;\n  if (newDetails.advanced && advancedDateTime) {\n    const edge = newDetails.edge;\n    if (!newDetails.driftStart) {\n      newDetails.driftStartTime = advancedDateTime;\n      newDetails.driftStart = edge;\n    }\n    newDetails.driftEndTime = advancedDateTime;\n    newDetails.driftEnd = edge;\n  } else {\n    newDetails.driftEndTime = oldDetails.driftEndTime;\n    newDetails.driftEnd = oldDetails.driftEnd;\n    newDetails.advancedDateTime = oldDetails.advancedDateTime;\n  }\n  if (newDetails.requestScheduled === -1) {\n    newDetails.requestScheduled = oldDetails.requestScheduled;\n  }\n}\nfunction mergeDateRanges(oldDateRanges, newDetails, logger) {\n  const {\n    dateRanges: deltaDateRanges,\n    recentlyRemovedDateranges\n  } = newDetails;\n  const dateRanges = _extends({}, oldDateRanges);\n  if (recentlyRemovedDateranges) {\n    recentlyRemovedDateranges.forEach(id => {\n      delete dateRanges[id];\n    });\n  }\n  const mergeIds = Object.keys(dateRanges);\n  const mergeCount = mergeIds.length;\n  if (!mergeCount) {\n    return deltaDateRanges;\n  }\n  Object.keys(deltaDateRanges).forEach(id => {\n    const mergedDateRange = dateRanges[id];\n    const dateRange = new DateRange(deltaDateRanges[id].attr, mergedDateRange);\n    if (dateRange.isValid) {\n      dateRanges[id] = dateRange;\n      if (!mergedDateRange) {\n        dateRange.tagOrder += mergeCount;\n      }\n    } else {\n      logger.warn(`Ignoring invalid Playlist Delta Update DATERANGE tag: \"${stringify(deltaDateRanges[id].attr)}\"`);\n    }\n  });\n  return dateRanges;\n}\nfunction mapPartIntersection(oldParts, newParts, intersectionFn) {\n  if (oldParts && newParts) {\n    let delta = 0;\n    for (let i = 0, len = oldParts.length; i <= len; i++) {\n      const oldPart = oldParts[i];\n      const newPart = newParts[i + delta];\n      if (oldPart && newPart && oldPart.index === newPart.index && oldPart.fragment.sn === newPart.fragment.sn) {\n        intersectionFn(oldPart, newPart);\n      } else {\n        delta--;\n      }\n    }\n  }\n}\nfunction mapFragmentIntersection(oldDetails, newDetails, intersectionFn) {\n  const skippedSegments = newDetails.skippedSegments;\n  const start = Math.max(oldDetails.startSN, newDetails.startSN) - newDetails.startSN;\n  const end = (oldDetails.fragmentHint ? 1 : 0) + (skippedSegments ? newDetails.endSN : Math.min(oldDetails.endSN, newDetails.endSN)) - newDetails.startSN;\n  const delta = newDetails.startSN - oldDetails.startSN;\n  const newFrags = newDetails.fragmentHint ? newDetails.fragments.concat(newDetails.fragmentHint) : newDetails.fragments;\n  const oldFrags = oldDetails.fragmentHint ? oldDetails.fragments.concat(oldDetails.fragmentHint) : oldDetails.fragments;\n  for (let i = start; i <= end; i++) {\n    const oldFrag = oldFrags[delta + i];\n    let newFrag = newFrags[i];\n    if (skippedSegments && !newFrag && oldFrag) {\n      // Fill in skipped segments in delta playlist\n      newFrag = newDetails.fragments[i] = oldFrag;\n    }\n    if (oldFrag && newFrag) {\n      intersectionFn(oldFrag, newFrag, i, newFrags);\n      const uriBefore = oldFrag.relurl;\n      const uriAfter = newFrag.relurl;\n      if (uriBefore && notEqualAfterStrippingQueries(uriBefore, uriAfter)) {\n        newDetails.playlistParsingError = getSequenceError(`media sequence mismatch ${newFrag.sn}:`, oldDetails, newDetails, oldFrag, newFrag);\n        return;\n      } else if (oldFrag.cc !== newFrag.cc) {\n        newDetails.playlistParsingError = getSequenceError(`discontinuity sequence mismatch (${oldFrag.cc}!=${newFrag.cc})`, oldDetails, newDetails, oldFrag, newFrag);\n        return;\n      }\n    }\n  }\n}\nfunction getSequenceError(message, oldDetails, newDetails, oldFrag, newFrag) {\n  return new Error(`${message} ${newFrag.url}\nPlaylist starting @${oldDetails.startSN}\n${oldDetails.m3u8}\n\nPlaylist starting @${newDetails.startSN}\n${newDetails.m3u8}`);\n}\nfunction adjustSliding(oldDetails, newDetails, matchingStableVariantOrRendition = true) {\n  const delta = newDetails.startSN + newDetails.skippedSegments - oldDetails.startSN;\n  const oldFragments = oldDetails.fragments;\n  const advancedOrStable = delta >= 0;\n  let sliding = 0;\n  if (advancedOrStable && delta < oldFragments.length) {\n    sliding = oldFragments[delta].start;\n  } else if (advancedOrStable && newDetails.startSN === oldDetails.endSN + 1) {\n    sliding = oldDetails.fragmentEnd;\n  } else if (advancedOrStable && matchingStableVariantOrRendition) {\n    // align with expected position (updated playlist start sequence is past end sequence of last update)\n    sliding = oldDetails.fragmentStart + delta * newDetails.levelTargetDuration;\n  } else if (!newDetails.skippedSegments && newDetails.fragmentStart === 0) {\n    // align new start with old (playlist switch has a sequence with no overlap and should not be used for alignment)\n    sliding = oldDetails.fragmentStart;\n  } else {\n    // new details already has a sliding offset or has skipped segments\n    return;\n  }\n  addSliding(newDetails, sliding);\n}\nfunction addSliding(details, sliding) {\n  if (sliding) {\n    const fragments = details.fragments;\n    for (let i = details.skippedSegments; i < fragments.length; i++) {\n      fragments[i].addStart(sliding);\n    }\n    if (details.fragmentHint) {\n      details.fragmentHint.addStart(sliding);\n    }\n  }\n}\nfunction computeReloadInterval(newDetails, distanceToLiveEdgeMs = Infinity) {\n  let reloadInterval = 1000 * newDetails.targetduration;\n  if (newDetails.updated) {\n    // Use last segment duration when shorter than target duration and near live edge\n    const fragments = newDetails.fragments;\n    const liveEdgeMaxTargetDurations = 4;\n    if (fragments.length && reloadInterval * liveEdgeMaxTargetDurations > distanceToLiveEdgeMs) {\n      const lastSegmentDuration = fragments[fragments.length - 1].duration * 1000;\n      if (lastSegmentDuration < reloadInterval) {\n        reloadInterval = lastSegmentDuration;\n      }\n    }\n  } else {\n    // estimate = 'miss half average';\n    // follow HLS Spec, If the client reloads a Playlist file and finds that it has not\n    // changed then it MUST wait for a period of one-half the target\n    // duration before retrying.\n    reloadInterval /= 2;\n  }\n  return Math.round(reloadInterval);\n}\nfunction getFragmentWithSN(details, sn, fragCurrent) {\n  if (!details) {\n    return null;\n  }\n  let fragment = details.fragments[sn - details.startSN];\n  if (fragment) {\n    return fragment;\n  }\n  fragment = details.fragmentHint;\n  if (fragment && fragment.sn === sn) {\n    return fragment;\n  }\n  if (sn < details.startSN && fragCurrent && fragCurrent.sn === sn) {\n    return fragCurrent;\n  }\n  return null;\n}\nfunction getPartWith(details, sn, partIndex) {\n  if (!details) {\n    return null;\n  }\n  return findPart(details.partList, sn, partIndex);\n}\nfunction findPart(partList, sn, partIndex) {\n  if (partList) {\n    for (let i = partList.length; i--;) {\n      const part = partList[i];\n      if (part.index === partIndex && part.fragment.sn === sn) {\n        return part;\n      }\n    }\n  }\n  return null;\n}\nfunction reassignFragmentLevelIndexes(levels) {\n  levels.forEach((level, index) => {\n    var _level$details;\n    (_level$details = level.details) == null || _level$details.fragments.forEach(fragment => {\n      fragment.level = index;\n      if (fragment.initSegment) {\n        fragment.initSegment.level = index;\n      }\n    });\n  });\n}\nfunction notEqualAfterStrippingQueries(uriBefore, uriAfter) {\n  if (uriBefore !== uriAfter && uriAfter) {\n    return stripQuery(uriBefore) !== stripQuery(uriAfter);\n  }\n  return false;\n}\nfunction stripQuery(uri) {\n  return uri.replace(/\\?[^?]*$/, '');\n}\n\nfunction findFirstFragWithCC(fragments, cc) {\n  for (let i = 0, len = fragments.length; i < len; i++) {\n    var _fragments$i;\n    if (((_fragments$i = fragments[i]) == null ? void 0 : _fragments$i.cc) === cc) {\n      return fragments[i];\n    }\n  }\n  return null;\n}\nfunction shouldAlignOnDiscontinuities(refDetails, details) {\n  if (refDetails) {\n    if (details.startCC < refDetails.endCC && details.endCC > refDetails.startCC) {\n      return true;\n    }\n  }\n  return false;\n}\nfunction adjustFragmentStart(frag, sliding) {\n  const start = frag.start + sliding;\n  frag.startPTS = start;\n  frag.setStart(start);\n  frag.endPTS = start + frag.duration;\n}\nfunction adjustSlidingStart(sliding, details) {\n  // Update segments\n  const fragments = details.fragments;\n  for (let i = 0, len = fragments.length; i < len; i++) {\n    adjustFragmentStart(fragments[i], sliding);\n  }\n  // Update LL-HLS parts at the end of the playlist\n  if (details.fragmentHint) {\n    adjustFragmentStart(details.fragmentHint, sliding);\n  }\n  details.alignedSliding = true;\n}\n\n/**\n * Using the parameters of the last level, this function computes PTS' of the new fragments so that they form a\n * contiguous stream with the last fragments.\n * The PTS of a fragment lets Hls.js know where it fits into a stream - by knowing every PTS, we know which fragment to\n * download at any given time. PTS is normally computed when the fragment is demuxed, so taking this step saves us time\n * and an extra download.\n * @param lastLevel\n * @param details\n */\nfunction alignStream(switchDetails, details) {\n  if (!switchDetails) {\n    return;\n  }\n  alignDiscontinuities(details, switchDetails);\n  if (!details.alignedSliding) {\n    // If the PTS wasn't figured out via discontinuity sequence that means there was no CC increase within the level.\n    // Aligning via Program Date Time should therefore be reliable, since PDT should be the same within the same\n    // discontinuity sequence.\n    alignMediaPlaylistByPDT(details, switchDetails);\n  }\n  if (!details.alignedSliding && !details.skippedSegments) {\n    // Try to align on sn so that we pick a better start fragment.\n    // Do not perform this on playlists with delta updates as this is only to align levels on switch\n    // and adjustSliding only adjusts fragments after skippedSegments.\n    adjustSliding(switchDetails, details, false);\n  }\n}\n\n/**\n * Ajust the start of fragments in `details` by the difference in time between fragments of the latest\n * shared discontinuity sequence change.\n * @param lastLevel - The details of the last loaded level\n * @param details - The details of the new level\n */\nfunction alignDiscontinuities(details, refDetails) {\n  if (!shouldAlignOnDiscontinuities(refDetails, details)) {\n    return;\n  }\n  const targetCC = Math.min(refDetails.endCC, details.endCC);\n  const refFrag = findFirstFragWithCC(refDetails.fragments, targetCC);\n  const frag = findFirstFragWithCC(details.fragments, targetCC);\n  if (!refFrag || !frag) {\n    return;\n  }\n  logger.log(`Aligning playlist at start of dicontinuity sequence ${targetCC}`);\n  const delta = refFrag.start - frag.start;\n  adjustSlidingStart(delta, details);\n}\n\n/**\n * Ensures appropriate time-alignment between renditions based on PDT.\n * This function assumes the timelines represented in `refDetails` are accurate, including the PDTs\n * for the last discontinuity sequence number shared by both playlists when present,\n * and uses the \"wallclock\"/PDT timeline as a cross-reference to `details`, adjusting the presentation\n * times/timelines of `details` accordingly.\n * Given the asynchronous nature of fetches and initial loads of live `main` and audio/subtitle tracks,\n * the primary purpose of this function is to ensure the \"local timelines\" of audio/subtitle tracks\n * are aligned to the main/video timeline, using PDT as the cross-reference/\"anchor\" that should\n * be consistent across playlists, per the HLS spec.\n * @param details - The details of the rendition you'd like to time-align (e.g. an audio rendition).\n * @param refDetails - The details of the reference rendition with start and PDT times for alignment.\n */\nfunction alignMediaPlaylistByPDT(details, refDetails) {\n  if (!details.hasProgramDateTime || !refDetails.hasProgramDateTime) {\n    return;\n  }\n  const fragments = details.fragments;\n  const refFragments = refDetails.fragments;\n  if (!fragments.length || !refFragments.length) {\n    return;\n  }\n\n  // Calculate a delta to apply to all fragments according to the delta in PDT times and start times\n  // of a fragment in the reference details, and a fragment in the target details of the same discontinuity.\n  // If a fragment of the same discontinuity was not found use the middle fragment of both.\n  let refFrag;\n  let frag;\n  const targetCC = Math.min(refDetails.endCC, details.endCC);\n  if (refDetails.startCC < targetCC && details.startCC < targetCC) {\n    refFrag = findFirstFragWithCC(refFragments, targetCC);\n    frag = findFirstFragWithCC(fragments, targetCC);\n  }\n  if (!refFrag || !frag) {\n    refFrag = refFragments[Math.floor(refFragments.length / 2)];\n    frag = findFirstFragWithCC(fragments, refFrag.cc) || fragments[Math.floor(fragments.length / 2)];\n  }\n  const refPDT = refFrag.programDateTime;\n  const targetPDT = frag.programDateTime;\n  if (!refPDT || !targetPDT) {\n    return;\n  }\n  const delta = (targetPDT - refPDT) / 1000 - (frag.start - refFrag.start);\n  adjustSlidingStart(delta, details);\n}\n\nfunction addEventListener(el, type, listener) {\n  removeEventListener(el, type, listener);\n  el.addEventListener(type, listener);\n}\nfunction removeEventListener(el, type, listener) {\n  el.removeEventListener(type, listener);\n}\n\n/**\n *  TimeRanges to string helper\n */\n\nconst TimeRanges = {\n  toString: function (r) {\n    let log = '';\n    const len = r.length;\n    for (let i = 0; i < len; i++) {\n      log += `[${r.start(i).toFixed(3)}-${r.end(i).toFixed(3)}]`;\n    }\n    return log;\n  }\n};\n\nconst State = {\n  STOPPED: 'STOPPED',\n  IDLE: 'IDLE',\n  KEY_LOADING: 'KEY_LOADING',\n  FRAG_LOADING: 'FRAG_LOADING',\n  FRAG_LOADING_WAITING_RETRY: 'FRAG_LOADING_WAITING_RETRY',\n  WAITING_TRACK: 'WAITING_TRACK',\n  PARSING: 'PARSING',\n  PARSED: 'PARSED',\n  ENDED: 'ENDED',\n  ERROR: 'ERROR',\n  WAITING_INIT_PTS: 'WAITING_INIT_PTS',\n  WAITING_LEVEL: 'WAITING_LEVEL'\n};\nclass BaseStreamController extends TaskLoop {\n  constructor(hls, fragmentTracker, keyLoader, logPrefix, playlistType) {\n    super(logPrefix, hls.logger);\n    this.hls = void 0;\n    this.fragPrevious = null;\n    this.fragCurrent = null;\n    this.fragmentTracker = void 0;\n    this.transmuxer = null;\n    this._state = State.STOPPED;\n    this.playlistType = void 0;\n    this.media = null;\n    this.mediaBuffer = null;\n    this.config = void 0;\n    this.bitrateTest = false;\n    this.lastCurrentTime = 0;\n    this.nextLoadPosition = 0;\n    this.startPosition = 0;\n    this.startTimeOffset = null;\n    this.retryDate = 0;\n    this.levels = null;\n    this.fragmentLoader = void 0;\n    this.keyLoader = void 0;\n    this.levelLastLoaded = null;\n    this.startFragRequested = false;\n    this.decrypter = void 0;\n    this.initPTS = [];\n    this.buffering = true;\n    this.loadingParts = false;\n    this.loopSn = void 0;\n    this.onMediaSeeking = () => {\n      const {\n        config,\n        fragCurrent,\n        media,\n        mediaBuffer,\n        state\n      } = this;\n      const currentTime = media ? media.currentTime : 0;\n      const bufferInfo = BufferHelper.bufferInfo(mediaBuffer ? mediaBuffer : media, currentTime, config.maxBufferHole);\n      const noFowardBuffer = !bufferInfo.len;\n      this.log(`Media seeking to ${isFiniteNumber(currentTime) ? currentTime.toFixed(3) : currentTime}, state: ${state}, ${noFowardBuffer ? 'out of' : 'in'} buffer`);\n      if (this.state === State.ENDED) {\n        this.resetLoadingState();\n      } else if (fragCurrent) {\n        // Seeking while frag load is in progress\n        const tolerance = config.maxFragLookUpTolerance;\n        const fragStartOffset = fragCurrent.start - tolerance;\n        const fragEndOffset = fragCurrent.start + fragCurrent.duration + tolerance;\n        // if seeking out of buffered range or into new one\n        if (noFowardBuffer || fragEndOffset < bufferInfo.start || fragStartOffset > bufferInfo.end) {\n          const pastFragment = currentTime > fragEndOffset;\n          // if the seek position is outside the current fragment range\n          if (currentTime < fragStartOffset || pastFragment) {\n            if (pastFragment && fragCurrent.loader) {\n              this.log(`Cancelling fragment load for seek (sn: ${fragCurrent.sn})`);\n              fragCurrent.abortRequests();\n              this.resetLoadingState();\n            }\n            this.fragPrevious = null;\n          }\n        }\n      }\n      if (media) {\n        // Remove gap fragments\n        this.fragmentTracker.removeFragmentsInRange(currentTime, Infinity, this.playlistType, true);\n\n        // Don't set lastCurrentTime with backward seeks (allows for frag selection with strict tolerances)\n        const lastCurrentTime = this.lastCurrentTime;\n        if (currentTime > lastCurrentTime) {\n          this.lastCurrentTime = currentTime;\n        }\n        if (!this.loadingParts) {\n          const bufferEnd = Math.max(bufferInfo.end, currentTime);\n          const shouldLoadParts = this.shouldLoadParts(this.getLevelDetails(), bufferEnd);\n          if (shouldLoadParts) {\n            this.log(`LL-Part loading ON after seeking to ${currentTime.toFixed(2)} with buffer @${bufferEnd.toFixed(2)}`);\n            this.loadingParts = shouldLoadParts;\n          }\n        }\n      }\n\n      // in case seeking occurs although no media buffered, adjust startPosition and nextLoadPosition to seek target\n      if (!this.hls.hasEnoughToStart) {\n        this.log(`Setting ${noFowardBuffer ? 'startPosition' : 'nextLoadPosition'} to ${currentTime} for seek without enough to start`);\n        this.nextLoadPosition = currentTime;\n        if (noFowardBuffer) {\n          this.startPosition = currentTime;\n        }\n      }\n      if (noFowardBuffer && this.state === State.IDLE) {\n        // Async tick to speed up processing\n        this.tickImmediate();\n      }\n    };\n    this.onMediaEnded = () => {\n      // reset startPosition and lastCurrentTime to restart playback @ stream beginning\n      this.log(`setting startPosition to 0 because media ended`);\n      this.startPosition = this.lastCurrentTime = 0;\n    };\n    this.playlistType = playlistType;\n    this.hls = hls;\n    this.fragmentLoader = new FragmentLoader(hls.config);\n    this.keyLoader = keyLoader;\n    this.fragmentTracker = fragmentTracker;\n    this.config = hls.config;\n    this.decrypter = new Decrypter(hls.config);\n  }\n  registerListeners() {\n    const {\n      hls\n    } = this;\n    hls.on(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n    hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.on(Events.MANIFEST_LOADED, this.onManifestLoaded, this);\n    hls.on(Events.ERROR, this.onError, this);\n  }\n  unregisterListeners() {\n    const {\n      hls\n    } = this;\n    hls.off(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n    hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.off(Events.MANIFEST_LOADED, this.onManifestLoaded, this);\n    hls.off(Events.ERROR, this.onError, this);\n  }\n  doTick() {\n    this.onTickEnd();\n  }\n  onTickEnd() {}\n  startLoad(startPosition) {}\n  stopLoad() {\n    if (this.state === State.STOPPED) {\n      return;\n    }\n    this.fragmentLoader.abort();\n    this.keyLoader.abort(this.playlistType);\n    const frag = this.fragCurrent;\n    if (frag != null && frag.loader) {\n      frag.abortRequests();\n      this.fragmentTracker.removeFragment(frag);\n    }\n    this.resetTransmuxer();\n    this.fragCurrent = null;\n    this.fragPrevious = null;\n    this.clearInterval();\n    this.clearNextTick();\n    this.state = State.STOPPED;\n  }\n  get startPositionValue() {\n    const {\n      nextLoadPosition,\n      startPosition\n    } = this;\n    if (startPosition === -1 && nextLoadPosition) {\n      return nextLoadPosition;\n    }\n    return startPosition;\n  }\n  get bufferingEnabled() {\n    return this.buffering;\n  }\n  pauseBuffering() {\n    this.buffering = false;\n  }\n  resumeBuffering() {\n    this.buffering = true;\n  }\n  get inFlightFrag() {\n    return {\n      frag: this.fragCurrent,\n      state: this.state\n    };\n  }\n  _streamEnded(bufferInfo, levelDetails) {\n    // Stream is never \"ended\" when playlist is live or media is detached\n    if (levelDetails.live || !this.media) {\n      return false;\n    }\n    // Stream is not \"ended\" when nothing is buffered past the start\n    const bufferEnd = bufferInfo.end || 0;\n    const timelineStart = this.config.timelineOffset || 0;\n    if (bufferEnd <= timelineStart) {\n      return false;\n    }\n    // Stream is not \"ended\" when there is a second buffered range starting before the end of the playlist\n    const bufferedRanges = bufferInfo.buffered;\n    if (this.config.maxBufferHole && bufferedRanges && bufferedRanges.length > 1) {\n      // make sure bufferInfo accounts for any gaps\n      bufferInfo = BufferHelper.bufferedInfo(bufferedRanges, bufferInfo.start, 0);\n    }\n    const nextStart = bufferInfo.nextStart;\n    const hasSecondBufferedRange = nextStart && nextStart > timelineStart && nextStart < levelDetails.edge;\n    if (hasSecondBufferedRange) {\n      return false;\n    }\n    // Playhead is in unbuffered region. Marking EoS now could result in Safari failing to dispatch \"ended\" event following seek on start.\n    if (this.media.currentTime < bufferInfo.start) {\n      return false;\n    }\n    const partList = levelDetails.partList;\n    // Since the last part isn't guaranteed to correspond to the last playlist segment for Low-Latency HLS,\n    // check instead if the last part is buffered.\n    if (partList != null && partList.length) {\n      const lastPart = partList[partList.length - 1];\n\n      // Checking the midpoint of the part for potential margin of error and related issues.\n      // NOTE: Technically I believe parts could yield content that is < the computed duration (including potential a duration of 0)\n      // and still be spec-compliant, so there may still be edge cases here. Likewise, there could be issues in end of stream\n      // part mismatches for independent audio and video playlists/segments.\n      const lastPartBuffered = BufferHelper.isBuffered(this.media, lastPart.start + lastPart.duration / 2);\n      return lastPartBuffered;\n    }\n    const playlistType = levelDetails.fragments[levelDetails.fragments.length - 1].type;\n    return this.fragmentTracker.isEndListAppended(playlistType);\n  }\n  getLevelDetails() {\n    if (this.levels && this.levelLastLoaded !== null) {\n      return this.levelLastLoaded.details;\n    }\n  }\n  get timelineOffset() {\n    const configuredTimelineOffset = this.config.timelineOffset;\n    if (configuredTimelineOffset) {\n      var _this$getLevelDetails;\n      return ((_this$getLevelDetails = this.getLevelDetails()) == null ? void 0 : _this$getLevelDetails.appliedTimelineOffset) || configuredTimelineOffset;\n    }\n    return 0;\n  }\n  onMediaAttached(event, data) {\n    const media = this.media = this.mediaBuffer = data.media;\n    addEventListener(media, 'seeking', this.onMediaSeeking);\n    addEventListener(media, 'ended', this.onMediaEnded);\n    const config = this.config;\n    if (this.levels && config.autoStartLoad && this.state === State.STOPPED) {\n      this.startLoad(config.startPosition);\n    }\n  }\n  onMediaDetaching(event, data) {\n    const transferringMedia = !!data.transferMedia;\n    const media = this.media;\n    if (media === null) {\n      return;\n    }\n    if (media.ended) {\n      this.log('MSE detaching and video ended, reset startPosition');\n      this.startPosition = this.lastCurrentTime = 0;\n    }\n\n    // remove video listeners\n    removeEventListener(media, 'seeking', this.onMediaSeeking);\n    removeEventListener(media, 'ended', this.onMediaEnded);\n    if (this.keyLoader && !transferringMedia) {\n      this.keyLoader.detach();\n    }\n    this.media = this.mediaBuffer = null;\n    this.loopSn = undefined;\n    if (transferringMedia) {\n      this.resetLoadingState();\n      this.resetTransmuxer();\n      return;\n    }\n    this.loadingParts = false;\n    this.fragmentTracker.removeAllFragments();\n    this.stopLoad();\n  }\n  onManifestLoading() {\n    this.initPTS = [];\n    this.levels = this.levelLastLoaded = this.fragCurrent = null;\n    this.lastCurrentTime = this.startPosition = 0;\n    this.startFragRequested = false;\n  }\n  onError(event, data) {}\n  onManifestLoaded(event, data) {\n    this.startTimeOffset = data.startTimeOffset;\n  }\n  onHandlerDestroying() {\n    this.stopLoad();\n    if (this.transmuxer) {\n      this.transmuxer.destroy();\n      this.transmuxer = null;\n    }\n    super.onHandlerDestroying();\n    // @ts-ignore\n    this.hls = this.onMediaSeeking = this.onMediaEnded = null;\n  }\n  onHandlerDestroyed() {\n    this.state = State.STOPPED;\n    if (this.fragmentLoader) {\n      this.fragmentLoader.destroy();\n    }\n    if (this.keyLoader) {\n      this.keyLoader.destroy();\n    }\n    if (this.decrypter) {\n      this.decrypter.destroy();\n    }\n    this.hls = this.log = this.warn = this.decrypter = this.keyLoader = this.fragmentLoader = this.fragmentTracker = null;\n    super.onHandlerDestroyed();\n  }\n  loadFragment(frag, level, targetBufferTime) {\n    this.startFragRequested = true;\n    this._loadFragForPlayback(frag, level, targetBufferTime);\n  }\n  _loadFragForPlayback(fragment, level, targetBufferTime) {\n    const progressCallback = data => {\n      const frag = data.frag;\n      if (this.fragContextChanged(frag)) {\n        this.warn(`${frag.type} sn: ${frag.sn}${data.part ? ' part: ' + data.part.index : ''} of ${this.fragInfo(frag, false, data.part)}) was dropped during download.`);\n        this.fragmentTracker.removeFragment(frag);\n        return;\n      }\n      frag.stats.chunkCount++;\n      this._handleFragmentLoadProgress(data);\n    };\n    this._doFragLoad(fragment, level, targetBufferTime, progressCallback).then(data => {\n      if (!data) {\n        // if we're here we probably needed to backtrack or are waiting for more parts\n        return;\n      }\n      const state = this.state;\n      const frag = data.frag;\n      if (this.fragContextChanged(frag)) {\n        if (state === State.FRAG_LOADING || !this.fragCurrent && state === State.PARSING) {\n          this.fragmentTracker.removeFragment(frag);\n          this.state = State.IDLE;\n        }\n        return;\n      }\n      if ('payload' in data) {\n        this.log(`Loaded ${frag.type} sn: ${frag.sn} of ${this.playlistLabel()} ${frag.level}`);\n        this.hls.trigger(Events.FRAG_LOADED, data);\n      }\n\n      // Pass through the whole payload; controllers not implementing progressive loading receive data from this callback\n      this._handleFragmentLoadComplete(data);\n    }).catch(reason => {\n      if (this.state === State.STOPPED || this.state === State.ERROR) {\n        return;\n      }\n      this.warn(`Frag error: ${(reason == null ? void 0 : reason.message) || reason}`);\n      this.resetFragmentLoading(fragment);\n    });\n  }\n  clearTrackerIfNeeded(frag) {\n    var _this$mediaBuffer;\n    const {\n      fragmentTracker\n    } = this;\n    const fragState = fragmentTracker.getState(frag);\n    if (fragState === FragmentState.APPENDING) {\n      // Lower the max buffer length and try again\n      const playlistType = frag.type;\n      const bufferedInfo = this.getFwdBufferInfo(this.mediaBuffer, playlistType);\n      const minForwardBufferLength = Math.max(frag.duration, bufferedInfo ? bufferedInfo.len : this.config.maxBufferLength);\n      // If backtracking, always remove from the tracker without reducing max buffer length\n      const backtrackFragment = this.backtrackFragment;\n      const backtracked = backtrackFragment ? frag.sn - backtrackFragment.sn : 0;\n      if (backtracked === 1 || this.reduceMaxBufferLength(minForwardBufferLength, frag.duration)) {\n        fragmentTracker.removeFragment(frag);\n      }\n    } else if (((_this$mediaBuffer = this.mediaBuffer) == null ? void 0 : _this$mediaBuffer.buffered.length) === 0) {\n      // Stop gap for bad tracker / buffer flush behavior\n      fragmentTracker.removeAllFragments();\n    } else if (fragmentTracker.hasParts(frag.type)) {\n      // In low latency mode, remove fragments for which only some parts were buffered\n      fragmentTracker.detectPartialFragments({\n        frag,\n        part: null,\n        stats: frag.stats,\n        id: frag.type\n      });\n      if (fragmentTracker.getState(frag) === FragmentState.PARTIAL) {\n        fragmentTracker.removeFragment(frag);\n      }\n    }\n  }\n  checkLiveUpdate(details) {\n    if (details.updated && !details.live) {\n      // Live stream ended, update fragment tracker\n      const lastFragment = details.fragments[details.fragments.length - 1];\n      this.fragmentTracker.detectPartialFragments({\n        frag: lastFragment,\n        part: null,\n        stats: lastFragment.stats,\n        id: lastFragment.type\n      });\n    }\n    if (!details.fragments[0]) {\n      details.deltaUpdateFailed = true;\n    }\n  }\n  waitForLive(levelInfo) {\n    const details = levelInfo.details;\n    return (details == null ? void 0 : details.live) && details.type !== 'EVENT' && (this.levelLastLoaded !== levelInfo || details.expired);\n  }\n  flushMainBuffer(startOffset, endOffset, type = null) {\n    if (!(startOffset - endOffset)) {\n      return;\n    }\n    // When alternate audio is playing, the audio-stream-controller is responsible for the audio buffer. Otherwise,\n    // passing a null type flushes both buffers\n    const flushScope = {\n      startOffset,\n      endOffset,\n      type\n    };\n    this.hls.trigger(Events.BUFFER_FLUSHING, flushScope);\n  }\n  _loadInitSegment(fragment, level) {\n    this._doFragLoad(fragment, level).then(data => {\n      const frag = data == null ? void 0 : data.frag;\n      if (!frag || this.fragContextChanged(frag) || !this.levels) {\n        throw new Error('init load aborted');\n      }\n      return data;\n    }).then(data => {\n      const {\n        hls\n      } = this;\n      const {\n        frag,\n        payload\n      } = data;\n      const decryptData = frag.decryptdata;\n\n      // check to see if the payload needs to be decrypted\n      if (payload && payload.byteLength > 0 && decryptData != null && decryptData.key && decryptData.iv && isFullSegmentEncryption(decryptData.method)) {\n        const startTime = self.performance.now();\n        // decrypt init segment data\n        return this.decrypter.decrypt(new Uint8Array(payload), decryptData.key.buffer, decryptData.iv.buffer, getAesModeFromFullSegmentMethod(decryptData.method)).catch(err => {\n          hls.trigger(Events.ERROR, {\n            type: ErrorTypes.MEDIA_ERROR,\n            details: ErrorDetails.FRAG_DECRYPT_ERROR,\n            fatal: false,\n            error: err,\n            reason: err.message,\n            frag\n          });\n          throw err;\n        }).then(decryptedData => {\n          const endTime = self.performance.now();\n          hls.trigger(Events.FRAG_DECRYPTED, {\n            frag,\n            payload: decryptedData,\n            stats: {\n              tstart: startTime,\n              tdecrypt: endTime\n            }\n          });\n          data.payload = decryptedData;\n          return this.completeInitSegmentLoad(data);\n        });\n      }\n      return this.completeInitSegmentLoad(data);\n    }).catch(reason => {\n      if (this.state === State.STOPPED || this.state === State.ERROR) {\n        return;\n      }\n      this.warn(reason);\n      this.resetFragmentLoading(fragment);\n    });\n  }\n  completeInitSegmentLoad(data) {\n    const {\n      levels\n    } = this;\n    if (!levels) {\n      throw new Error('init load aborted, missing levels');\n    }\n    const stats = data.frag.stats;\n    if (this.state !== State.STOPPED) {\n      this.state = State.IDLE;\n    }\n    data.frag.data = new Uint8Array(data.payload);\n    stats.parsing.start = stats.buffering.start = self.performance.now();\n    stats.parsing.end = stats.buffering.end = self.performance.now();\n    this.tick();\n  }\n  unhandledEncryptionError(initSegment, frag) {\n    var _tracks$audio, _tracks$video;\n    const tracks = initSegment.tracks;\n    if (tracks && !frag.encrypted && ((_tracks$audio = tracks.audio) != null && _tracks$audio.encrypted || (_tracks$video = tracks.video) != null && _tracks$video.encrypted) && (!this.config.emeEnabled || !this.keyLoader.emeController)) {\n      const media = this.media;\n      const error = new Error(`Encrypted track with no key in ${this.fragInfo(frag)} (media ${media ? 'attached mediaKeys: ' + media.mediaKeys : 'detached'})` );\n      this.warn(error.message);\n      // Ignore if media is detached or mediaKeys are set\n      if (!media || media.mediaKeys) {\n        return false;\n      }\n      this.hls.trigger(Events.ERROR, {\n        type: ErrorTypes.KEY_SYSTEM_ERROR,\n        details: ErrorDetails.KEY_SYSTEM_NO_KEYS,\n        fatal: false,\n        error,\n        frag\n      });\n      this.resetTransmuxer();\n      return true;\n    }\n    return false;\n  }\n  fragContextChanged(frag) {\n    const {\n      fragCurrent\n    } = this;\n    return !frag || !fragCurrent || frag.sn !== fragCurrent.sn || frag.level !== fragCurrent.level;\n  }\n  fragBufferedComplete(frag, part) {\n    const media = this.mediaBuffer ? this.mediaBuffer : this.media;\n    this.log(`Buffered ${frag.type} sn: ${frag.sn}${part ? ' part: ' + part.index : ''} of ${this.fragInfo(frag, false, part)} > buffer:${media ? TimeRanges.toString(BufferHelper.getBuffered(media)) : '(detached)'})`);\n    if (isMediaFragment(frag)) {\n      var _this$levels;\n      if (frag.type !== PlaylistLevelType.SUBTITLE) {\n        const el = frag.elementaryStreams;\n        if (!Object.keys(el).some(type => !!el[type])) {\n          // empty segment\n          this.state = State.IDLE;\n          return;\n        }\n      }\n      const level = (_this$levels = this.levels) == null ? void 0 : _this$levels[frag.level];\n      if (level != null && level.fragmentError) {\n        this.log(`Resetting level fragment error count of ${level.fragmentError} on frag buffered`);\n        level.fragmentError = 0;\n      }\n    }\n    this.state = State.IDLE;\n  }\n  _handleFragmentLoadComplete(fragLoadedEndData) {\n    const {\n      transmuxer\n    } = this;\n    if (!transmuxer) {\n      return;\n    }\n    const {\n      frag,\n      part,\n      partsLoaded\n    } = fragLoadedEndData;\n    // If we did not load parts, or loaded all parts, we have complete (not partial) fragment data\n    const complete = !partsLoaded || partsLoaded.length === 0 || partsLoaded.some(fragLoaded => !fragLoaded);\n    const chunkMeta = new ChunkMetadata(frag.level, frag.sn, frag.stats.chunkCount + 1, 0, part ? part.index : -1, !complete);\n    transmuxer.flush(chunkMeta);\n  }\n  _handleFragmentLoadProgress(frag) {}\n  _doFragLoad(frag, level, targetBufferTime = null, progressCallback) {\n    var _frag$decryptdata;\n    this.fragCurrent = frag;\n    const details = level.details;\n    if (!this.levels || !details) {\n      throw new Error(`frag load aborted, missing level${details ? '' : ' detail'}s`);\n    }\n    let keyLoadingPromise = null;\n    if (frag.encrypted && !((_frag$decryptdata = frag.decryptdata) != null && _frag$decryptdata.key)) {\n      this.log(`Loading key for ${frag.sn} of [${details.startSN}-${details.endSN}], ${this.playlistLabel()} ${frag.level}`);\n      this.state = State.KEY_LOADING;\n      this.fragCurrent = frag;\n      keyLoadingPromise = this.keyLoader.load(frag).then(keyLoadedData => {\n        if (!this.fragContextChanged(keyLoadedData.frag)) {\n          this.hls.trigger(Events.KEY_LOADED, keyLoadedData);\n          if (this.state === State.KEY_LOADING) {\n            this.state = State.IDLE;\n          }\n          return keyLoadedData;\n        }\n      });\n      this.hls.trigger(Events.KEY_LOADING, {\n        frag\n      });\n      if (this.fragCurrent === null) {\n        this.log(`context changed in KEY_LOADING`);\n        return Promise.resolve(null);\n      }\n    } else if (!frag.encrypted) {\n      keyLoadingPromise = this.keyLoader.loadClear(frag, details.encryptedFragments, this.startFragRequested);\n      if (keyLoadingPromise) {\n        this.log(`[eme] blocking frag load until media-keys acquired`);\n      }\n    }\n    const fragPrevious = this.fragPrevious;\n    if (isMediaFragment(frag) && (!fragPrevious || frag.sn !== fragPrevious.sn)) {\n      const shouldLoadParts = this.shouldLoadParts(level.details, frag.end);\n      if (shouldLoadParts !== this.loadingParts) {\n        this.log(`LL-Part loading ${shouldLoadParts ? 'ON' : 'OFF'} loading sn ${fragPrevious == null ? void 0 : fragPrevious.sn}->${frag.sn}`);\n        this.loadingParts = shouldLoadParts;\n      }\n    }\n    targetBufferTime = Math.max(frag.start, targetBufferTime || 0);\n    if (this.loadingParts && isMediaFragment(frag)) {\n      const partList = details.partList;\n      if (partList && progressCallback) {\n        if (targetBufferTime > details.fragmentEnd && details.fragmentHint) {\n          frag = details.fragmentHint;\n        }\n        const partIndex = this.getNextPart(partList, frag, targetBufferTime);\n        if (partIndex > -1) {\n          const part = partList[partIndex];\n          frag = this.fragCurrent = part.fragment;\n          this.log(`Loading ${frag.type} sn: ${frag.sn} part: ${part.index} (${partIndex}/${partList.length - 1}) of ${this.fragInfo(frag, false, part)}) cc: ${frag.cc} [${details.startSN}-${details.endSN}], target: ${parseFloat(targetBufferTime.toFixed(3))}`);\n          this.nextLoadPosition = part.start + part.duration;\n          this.state = State.FRAG_LOADING;\n          let _result;\n          if (keyLoadingPromise) {\n            _result = keyLoadingPromise.then(keyLoadedData => {\n              if (!keyLoadedData || this.fragContextChanged(keyLoadedData.frag)) {\n                return null;\n              }\n              return this.doFragPartsLoad(frag, part, level, progressCallback);\n            }).catch(error => this.handleFragLoadError(error));\n          } else {\n            _result = this.doFragPartsLoad(frag, part, level, progressCallback).catch(error => this.handleFragLoadError(error));\n          }\n          this.hls.trigger(Events.FRAG_LOADING, {\n            frag,\n            part,\n            targetBufferTime\n          });\n          if (this.fragCurrent === null) {\n            return Promise.reject(new Error(`frag load aborted, context changed in FRAG_LOADING parts`));\n          }\n          return _result;\n        } else if (!frag.url || this.loadedEndOfParts(partList, targetBufferTime)) {\n          // Fragment hint has no parts\n          return Promise.resolve(null);\n        }\n      }\n    }\n    if (isMediaFragment(frag) && this.loadingParts) {\n      var _details$partList;\n      this.log(`LL-Part loading OFF after next part miss @${targetBufferTime.toFixed(2)} Check buffer at sn: ${frag.sn} loaded parts: ${(_details$partList = details.partList) == null ? void 0 : _details$partList.filter(p => p.loaded).map(p => `[${p.start}-${p.end}]`)}`);\n      this.loadingParts = false;\n    } else if (!frag.url) {\n      // Selected fragment hint for part but not loading parts\n      return Promise.resolve(null);\n    }\n    this.log(`Loading ${frag.type} sn: ${frag.sn} of ${this.fragInfo(frag, false)}) cc: ${frag.cc} ${'[' + details.startSN + '-' + details.endSN + ']'}, target: ${parseFloat(targetBufferTime.toFixed(3))}`);\n    // Don't update nextLoadPosition for fragments which are not buffered\n    if (isFiniteNumber(frag.sn) && !this.bitrateTest) {\n      this.nextLoadPosition = frag.start + frag.duration;\n    }\n    this.state = State.FRAG_LOADING;\n\n    // Load key before streaming fragment data\n    const dataOnProgress = this.config.progressive && frag.type !== PlaylistLevelType.SUBTITLE;\n    let result;\n    if (dataOnProgress && keyLoadingPromise) {\n      result = keyLoadingPromise.then(keyLoadedData => {\n        if (!keyLoadedData || this.fragContextChanged(keyLoadedData.frag)) {\n          return null;\n        }\n        return this.fragmentLoader.load(frag, progressCallback);\n      }).catch(error => this.handleFragLoadError(error));\n    } else {\n      // load unencrypted fragment data with progress event,\n      // or handle fragment result after key and fragment are finished loading\n      result = Promise.all([this.fragmentLoader.load(frag, dataOnProgress ? progressCallback : undefined), keyLoadingPromise]).then(([fragLoadedData]) => {\n        if (!dataOnProgress && progressCallback) {\n          progressCallback(fragLoadedData);\n        }\n        return fragLoadedData;\n      }).catch(error => this.handleFragLoadError(error));\n    }\n    this.hls.trigger(Events.FRAG_LOADING, {\n      frag,\n      targetBufferTime\n    });\n    if (this.fragCurrent === null) {\n      return Promise.reject(new Error(`frag load aborted, context changed in FRAG_LOADING`));\n    }\n    return result;\n  }\n  doFragPartsLoad(frag, fromPart, level, progressCallback) {\n    return new Promise((resolve, reject) => {\n      var _level$details;\n      const partsLoaded = [];\n      const initialPartList = (_level$details = level.details) == null ? void 0 : _level$details.partList;\n      const loadPart = part => {\n        this.fragmentLoader.loadPart(frag, part, progressCallback).then(partLoadedData => {\n          partsLoaded[part.index] = partLoadedData;\n          const loadedPart = partLoadedData.part;\n          this.hls.trigger(Events.FRAG_LOADED, partLoadedData);\n          const nextPart = getPartWith(level.details, frag.sn, part.index + 1) || findPart(initialPartList, frag.sn, part.index + 1);\n          if (nextPart) {\n            loadPart(nextPart);\n          } else {\n            return resolve({\n              frag,\n              part: loadedPart,\n              partsLoaded\n            });\n          }\n        }).catch(reject);\n      };\n      loadPart(fromPart);\n    });\n  }\n  handleFragLoadError(error) {\n    if ('data' in error) {\n      const data = error.data;\n      if (data.frag && data.details === ErrorDetails.INTERNAL_ABORTED) {\n        this.handleFragLoadAborted(data.frag, data.part);\n      } else if (data.frag && data.type === ErrorTypes.KEY_SYSTEM_ERROR) {\n        data.frag.abortRequests();\n        this.resetStartWhenNotLoaded();\n        this.resetFragmentLoading(data.frag);\n      } else {\n        this.hls.trigger(Events.ERROR, data);\n      }\n    } else {\n      this.hls.trigger(Events.ERROR, {\n        type: ErrorTypes.OTHER_ERROR,\n        details: ErrorDetails.INTERNAL_EXCEPTION,\n        err: error,\n        error,\n        fatal: true\n      });\n    }\n    return null;\n  }\n  _handleTransmuxerFlush(chunkMeta) {\n    const context = this.getCurrentContext(chunkMeta);\n    if (!context || this.state !== State.PARSING) {\n      if (!this.fragCurrent && this.state !== State.STOPPED && this.state !== State.ERROR) {\n        this.state = State.IDLE;\n      }\n      return;\n    }\n    const {\n      frag,\n      part,\n      level\n    } = context;\n    const now = self.performance.now();\n    frag.stats.parsing.end = now;\n    if (part) {\n      part.stats.parsing.end = now;\n    }\n    // See if part loading should be disabled/enabled based on buffer and playback position.\n    const levelDetails = this.getLevelDetails();\n    const loadingPartsAtEdge = levelDetails && frag.sn > levelDetails.endSN;\n    const shouldLoadParts = loadingPartsAtEdge || this.shouldLoadParts(levelDetails, frag.end);\n    if (shouldLoadParts !== this.loadingParts) {\n      this.log(`LL-Part loading ${shouldLoadParts ? 'ON' : 'OFF'} after parsing segment ending @${frag.end.toFixed(2)}`);\n      this.loadingParts = shouldLoadParts;\n    }\n    this.updateLevelTiming(frag, part, level, chunkMeta.partial);\n  }\n  shouldLoadParts(details, bufferEnd) {\n    if (this.config.lowLatencyMode) {\n      if (!details) {\n        return this.loadingParts;\n      }\n      if (details.partList) {\n        var _details$fragmentHint;\n        // Buffer must be ahead of first part + duration of parts after last segment\n        // and playback must be at or past segment adjacent to part list\n        const firstPart = details.partList[0];\n        // Loading of VTT subtitle parts is not implemented in subtitle-stream-controller (#7460)\n        if (firstPart.fragment.type === PlaylistLevelType.SUBTITLE) {\n          return false;\n        }\n        const safePartStart = firstPart.end + (((_details$fragmentHint = details.fragmentHint) == null ? void 0 : _details$fragmentHint.duration) || 0);\n        if (bufferEnd >= safePartStart) {\n          var _this$media;\n          const playhead = this.hls.hasEnoughToStart ? ((_this$media = this.media) == null ? void 0 : _this$media.currentTime) || this.lastCurrentTime : this.getLoadPosition();\n          if (playhead > firstPart.start - firstPart.fragment.duration) {\n            return true;\n          }\n        }\n      }\n    }\n    return false;\n  }\n  getCurrentContext(chunkMeta) {\n    const {\n      levels,\n      fragCurrent\n    } = this;\n    const {\n      level: levelIndex,\n      sn,\n      part: partIndex\n    } = chunkMeta;\n    if (!(levels != null && levels[levelIndex])) {\n      this.warn(`Levels object was unset while buffering fragment ${sn} of ${this.playlistLabel()} ${levelIndex}. The current chunk will not be buffered.`);\n      return null;\n    }\n    const level = levels[levelIndex];\n    const levelDetails = level.details;\n    const part = partIndex > -1 ? getPartWith(levelDetails, sn, partIndex) : null;\n    const frag = part ? part.fragment : getFragmentWithSN(levelDetails, sn, fragCurrent);\n    if (!frag) {\n      return null;\n    }\n    if (fragCurrent && fragCurrent !== frag) {\n      frag.stats = fragCurrent.stats;\n    }\n    return {\n      frag,\n      part,\n      level\n    };\n  }\n  bufferFragmentData(data, frag, part, chunkMeta, noBacktracking) {\n    if (this.state !== State.PARSING) {\n      return;\n    }\n    const {\n      data1,\n      data2\n    } = data;\n    let buffer = data1;\n    if (data2) {\n      // Combine the moof + mdat so that we buffer with a single append\n      buffer = appendUint8Array(data1, data2);\n    }\n    if (!buffer.length) {\n      return;\n    }\n    const offsetTimestamp = this.initPTS[frag.cc];\n    const offset = offsetTimestamp ? -offsetTimestamp.baseTime / offsetTimestamp.timescale : undefined;\n    const segment = {\n      type: data.type,\n      frag,\n      part,\n      chunkMeta,\n      offset,\n      parent: frag.type,\n      data: buffer\n    };\n    this.hls.trigger(Events.BUFFER_APPENDING, segment);\n    if (data.dropped && data.independent && !part) {\n      if (noBacktracking) {\n        return;\n      }\n      // Clear buffer so that we reload previous segments sequentially if required\n      this.flushBufferGap(frag);\n    }\n  }\n  flushBufferGap(frag) {\n    const media = this.media;\n    if (!media) {\n      return;\n    }\n    // If currentTime is not buffered, clear the back buffer so that we can backtrack as much as needed\n    if (!BufferHelper.isBuffered(media, media.currentTime)) {\n      this.flushMainBuffer(0, frag.start);\n      return;\n    }\n    // Remove back-buffer without interrupting playback to allow back tracking\n    const currentTime = media.currentTime;\n    const bufferInfo = BufferHelper.bufferInfo(media, currentTime, 0);\n    const fragDuration = frag.duration;\n    const segmentFraction = Math.min(this.config.maxFragLookUpTolerance * 2, fragDuration * 0.25);\n    const start = Math.max(Math.min(frag.start - segmentFraction, bufferInfo.end - segmentFraction), currentTime + segmentFraction);\n    if (frag.start - start > segmentFraction) {\n      this.flushMainBuffer(start, frag.start);\n    }\n  }\n  getFwdBufferInfo(bufferable, type) {\n    var _this$media2;\n    const pos = this.getLoadPosition();\n    if (!isFiniteNumber(pos)) {\n      return null;\n    }\n    const backwardSeek = this.lastCurrentTime > pos;\n    const maxBufferHole = backwardSeek || (_this$media2 = this.media) != null && _this$media2.paused ? 0 : this.config.maxBufferHole;\n    return this.getFwdBufferInfoAtPos(bufferable, pos, type, maxBufferHole);\n  }\n  getFwdBufferInfoAtPos(bufferable, pos, type, maxBufferHole) {\n    const bufferInfo = BufferHelper.bufferInfo(bufferable, pos, maxBufferHole);\n    // Workaround flaw in getting forward buffer when maxBufferHole is smaller than gap at current pos\n    if (bufferInfo.len === 0 && bufferInfo.nextStart !== undefined) {\n      const bufferedFragAtPos = this.fragmentTracker.getBufferedFrag(pos, type);\n      if (bufferedFragAtPos && (bufferInfo.nextStart <= bufferedFragAtPos.end || bufferedFragAtPos.gap)) {\n        const gapDuration = Math.max(Math.min(bufferInfo.nextStart, bufferedFragAtPos.end) - pos, maxBufferHole);\n        return BufferHelper.bufferInfo(bufferable, pos, gapDuration);\n      }\n    }\n    return bufferInfo;\n  }\n  getMaxBufferLength(levelBitrate) {\n    const {\n      config\n    } = this;\n    let maxBufLen;\n    if (levelBitrate) {\n      maxBufLen = Math.max(8 * config.maxBufferSize / levelBitrate, config.maxBufferLength);\n    } else {\n      maxBufLen = config.maxBufferLength;\n    }\n    return Math.min(maxBufLen, config.maxMaxBufferLength);\n  }\n  reduceMaxBufferLength(threshold, fragDuration) {\n    const config = this.config;\n    const minLength = Math.max(Math.min(threshold - fragDuration, config.maxBufferLength), fragDuration);\n    const reducedLength = Math.max(threshold - fragDuration * 3, config.maxMaxBufferLength / 2, minLength);\n    if (reducedLength >= minLength) {\n      // reduce max buffer length as it might be too high. we do this to avoid loop flushing ...\n      config.maxMaxBufferLength = reducedLength;\n      this.warn(`Reduce max buffer length to ${reducedLength}s`);\n      return true;\n    }\n    return false;\n  }\n  getAppendedFrag(position, playlistType = PlaylistLevelType.MAIN) {\n    const fragOrPart = this.fragmentTracker ? this.fragmentTracker.getAppendedFrag(position, playlistType) : null;\n    if (fragOrPart && 'fragment' in fragOrPart) {\n      return fragOrPart.fragment;\n    }\n    return fragOrPart;\n  }\n  getNextFragment(pos, levelDetails) {\n    const fragments = levelDetails.fragments;\n    const fragLen = fragments.length;\n    if (!fragLen) {\n      return null;\n    }\n\n    // find fragment index, contiguous with end of buffer position\n    const {\n      config\n    } = this;\n    const start = fragments[0].start;\n    const canLoadParts = config.lowLatencyMode && !!levelDetails.partList;\n    let frag = null;\n    if (levelDetails.live) {\n      const initialLiveManifestSize = config.initialLiveManifestSize;\n      if (fragLen < initialLiveManifestSize) {\n        this.warn(`Not enough fragments to start playback (have: ${fragLen}, need: ${initialLiveManifestSize})`);\n        return null;\n      }\n      // The real fragment start times for a live stream are only known after the PTS range for that level is known.\n      // In order to discover the range, we load the best matching fragment for that level and demux it.\n      // Do not load using live logic if the starting frag is requested - we want to use getFragmentAtPosition() so that\n      // we get the fragment matching that start time\n      if (!levelDetails.PTSKnown && !this.startFragRequested && this.startPosition === -1 || pos < start) {\n        var _frag;\n        if (canLoadParts && !this.loadingParts) {\n          this.log(`LL-Part loading ON for initial live fragment`);\n          this.loadingParts = true;\n        }\n        frag = this.getInitialLiveFragment(levelDetails);\n        const mainStart = this.hls.startPosition;\n        const liveSyncPosition = this.hls.liveSyncPosition;\n        const startPosition = frag ? (mainStart !== -1 && mainStart >= start ? mainStart : liveSyncPosition) || frag.start : pos;\n        this.log(`Setting startPosition to ${startPosition} to match start frag at live edge. mainStart: ${mainStart} liveSyncPosition: ${liveSyncPosition} frag.start: ${(_frag = frag) == null ? void 0 : _frag.start}`);\n        this.startPosition = this.nextLoadPosition = startPosition;\n      }\n    } else if (pos <= start) {\n      // VoD playlist: if loadPosition before start of playlist, load first fragment\n      frag = fragments[0];\n    }\n\n    // If we haven't run into any special cases already, just load the fragment most closely matching the requested position\n    if (!frag) {\n      const end = this.loadingParts ? levelDetails.partEnd : levelDetails.fragmentEnd;\n      frag = this.getFragmentAtPosition(pos, end, levelDetails);\n    }\n    let programFrag = this.filterReplacedPrimary(frag, levelDetails);\n    if (!programFrag && frag) {\n      const curSNIdx = frag.sn - levelDetails.startSN;\n      programFrag = this.filterReplacedPrimary(fragments[curSNIdx + 1] || null, levelDetails);\n    }\n    return this.mapToInitFragWhenRequired(programFrag);\n  }\n  isLoopLoading(frag, targetBufferTime) {\n    const trackerState = this.fragmentTracker.getState(frag);\n    return (trackerState === FragmentState.OK || trackerState === FragmentState.PARTIAL && !!frag.gap) && this.nextLoadPosition > targetBufferTime;\n  }\n  getNextFragmentLoopLoading(frag, levelDetails, bufferInfo, playlistType, maxBufLen) {\n    let nextFragment = null;\n    if (frag.gap) {\n      nextFragment = this.getNextFragment(this.nextLoadPosition, levelDetails);\n      if (nextFragment && !nextFragment.gap && bufferInfo.nextStart) {\n        // Media buffered after GAP tags should not make the next buffer timerange exceed forward buffer length\n        const nextbufferInfo = this.getFwdBufferInfoAtPos(this.mediaBuffer ? this.mediaBuffer : this.media, bufferInfo.nextStart, playlistType, 0);\n        if (nextbufferInfo !== null && bufferInfo.len + nextbufferInfo.len >= maxBufLen) {\n          // Returning here might result in not finding an audio and video candiate to skip to\n          const sn = nextFragment.sn;\n          if (this.loopSn !== sn) {\n            this.log(`buffer full after gaps in \"${playlistType}\" playlist starting at sn: ${sn}`);\n            this.loopSn = sn;\n          }\n          return null;\n        }\n      }\n    }\n    this.loopSn = undefined;\n    return nextFragment;\n  }\n  get primaryPrefetch() {\n    if (interstitialsEnabled(this.config)) {\n      var _this$hls$interstitia;\n      const playingInterstitial = (_this$hls$interstitia = this.hls.interstitialsManager) == null || (_this$hls$interstitia = _this$hls$interstitia.playingItem) == null ? void 0 : _this$hls$interstitia.event;\n      if (playingInterstitial) {\n        return true;\n      }\n    }\n    return false;\n  }\n  filterReplacedPrimary(frag, details) {\n    if (!frag) {\n      return frag;\n    }\n    if (interstitialsEnabled(this.config) && frag.type !== PlaylistLevelType.SUBTITLE) {\n      // Do not load fragments outside the buffering schedule segment\n      const interstitials = this.hls.interstitialsManager;\n      const bufferingItem = interstitials == null ? void 0 : interstitials.bufferingItem;\n      if (bufferingItem) {\n        const bufferingInterstitial = bufferingItem.event;\n        if (bufferingInterstitial) {\n          // Do not stream fragments while buffering Interstitial Events (except for overlap at the start)\n          if (bufferingInterstitial.appendInPlace || Math.abs(frag.start - bufferingItem.start) > 1 || bufferingItem.start === 0) {\n            return null;\n          }\n        } else {\n          // Limit fragment loading to media in schedule item\n          if (frag.end <= bufferingItem.start && (details == null ? void 0 : details.live) === false) {\n            // fragment ends by schedule item start\n            // this.fragmentTracker.fragBuffered(frag, true);\n            return null;\n          }\n          if (frag.start > bufferingItem.end && bufferingItem.nextEvent) {\n            // fragment is past schedule item end\n            // allow some overflow when not appending in place to prevent stalls\n            if (bufferingItem.nextEvent.appendInPlace || frag.start - bufferingItem.end > 1) {\n              return null;\n            }\n          }\n        }\n      }\n      // Skip loading of fragments that overlap completely with appendInPlace interstitials\n      const playerQueue = interstitials == null ? void 0 : interstitials.playerQueue;\n      if (playerQueue) {\n        for (let i = playerQueue.length; i--;) {\n          const interstitial = playerQueue[i].interstitial;\n          if (interstitial.appendInPlace && frag.start >= interstitial.startTime && frag.end <= interstitial.resumeTime) {\n            return null;\n          }\n        }\n      }\n    }\n    return frag;\n  }\n  mapToInitFragWhenRequired(frag) {\n    // If an initSegment is present, it must be buffered first\n    if (frag != null && frag.initSegment && !frag.initSegment.data && !this.bitrateTest) {\n      return frag.initSegment;\n    }\n    return frag;\n  }\n  getNextPart(partList, frag, targetBufferTime) {\n    let nextPart = -1;\n    let contiguous = false;\n    let independentAttrOmitted = true;\n    for (let i = 0, len = partList.length; i < len; i++) {\n      const part = partList[i];\n      independentAttrOmitted = independentAttrOmitted && !part.independent;\n      if (nextPart > -1 && targetBufferTime < part.start) {\n        break;\n      }\n      const loaded = part.loaded;\n      if (loaded) {\n        nextPart = -1;\n      } else if (contiguous || (part.independent || independentAttrOmitted) && part.fragment === frag) {\n        if (part.fragment !== frag) {\n          this.warn(`Need buffer at ${targetBufferTime} but next unloaded part starts at ${part.start}`);\n        }\n        nextPart = i;\n      }\n      contiguous = loaded;\n    }\n    return nextPart;\n  }\n  loadedEndOfParts(partList, targetBufferTime) {\n    let part;\n    for (let i = partList.length; i--;) {\n      part = partList[i];\n      if (!part.loaded) {\n        return false;\n      }\n      if (targetBufferTime > part.start) {\n        return true;\n      }\n    }\n    return false;\n  }\n\n  /*\n   This method is used find the best matching first fragment for a live playlist. This fragment is used to calculate the\n   \"sliding\" of the playlist, which is its offset from the start of playback. After sliding we can compute the real\n   start and end times for each fragment in the playlist (after which this method will not need to be called).\n  */\n  getInitialLiveFragment(levelDetails) {\n    const fragments = levelDetails.fragments;\n    const fragPrevious = this.fragPrevious;\n    let frag = null;\n    if (fragPrevious) {\n      if (levelDetails.hasProgramDateTime) {\n        // Prefer using PDT, because it can be accurate enough to choose the correct fragment without knowing the level sliding\n        this.log(`Live playlist, switching playlist, load frag with same PDT: ${fragPrevious.programDateTime}`);\n        frag = findFragmentByPDT(fragments, fragPrevious.endProgramDateTime, this.config.maxFragLookUpTolerance);\n      }\n      if (!frag) {\n        // SN does not need to be accurate between renditions, but depending on the packaging it may be so.\n        const targetSN = fragPrevious.sn + 1;\n        if (targetSN >= levelDetails.startSN && targetSN <= levelDetails.endSN) {\n          const fragNext = fragments[targetSN - levelDetails.startSN];\n          // Ensure that we're staying within the continuity range, since PTS resets upon a new range\n          if (fragPrevious.cc === fragNext.cc) {\n            frag = fragNext;\n            this.log(`Live playlist, switching playlist, load frag with next SN: ${frag.sn}`);\n          }\n        }\n        // It's important to stay within the continuity range if available; otherwise the fragments in the playlist\n        // will have the wrong start times\n        if (!frag) {\n          frag = findNearestWithCC(levelDetails, fragPrevious.cc, fragPrevious.end);\n          if (frag) {\n            this.log(`Live playlist, switching playlist, load frag with same CC: ${frag.sn}`);\n          }\n        }\n      }\n    } else {\n      // Find a new start fragment when fragPrevious is null\n      const liveStart = this.hls.liveSyncPosition;\n      if (liveStart !== null) {\n        frag = this.getFragmentAtPosition(liveStart, this.bitrateTest ? levelDetails.fragmentEnd : levelDetails.edge, levelDetails);\n      }\n    }\n    return frag;\n  }\n\n  /*\n  This method finds the best matching fragment given the provided position.\n   */\n  getFragmentAtPosition(bufferEnd, end, levelDetails) {\n    const {\n      config\n    } = this;\n    let {\n      fragPrevious\n    } = this;\n    let {\n      fragments,\n      endSN\n    } = levelDetails;\n    const {\n      fragmentHint\n    } = levelDetails;\n    const {\n      maxFragLookUpTolerance\n    } = config;\n    const partList = levelDetails.partList;\n    const loadingParts = !!(this.loadingParts && partList != null && partList.length && fragmentHint);\n    if (loadingParts && !this.bitrateTest && partList[partList.length - 1].fragment.sn === fragmentHint.sn) {\n      // Include incomplete fragment with parts at end\n      fragments = fragments.concat(fragmentHint);\n      endSN = fragmentHint.sn;\n    }\n    let frag;\n    if (bufferEnd < end) {\n      var _this$media3;\n      const backwardSeek = bufferEnd < this.lastCurrentTime;\n      const lookupTolerance = backwardSeek || bufferEnd > end - maxFragLookUpTolerance || (_this$media3 = this.media) != null && _this$media3.paused || !this.startFragRequested ? 0 : maxFragLookUpTolerance;\n      // Remove the tolerance if it would put the bufferEnd past the actual end of stream\n      // Uses buffer and sequence number to calculate switch segment (required if using EXT-X-DISCONTINUITY-SEQUENCE)\n      frag = findFragmentByPTS(fragPrevious, fragments, bufferEnd, lookupTolerance);\n    } else {\n      // reach end of playlist\n      frag = fragments[fragments.length - 1];\n    }\n    if (frag) {\n      const curSNIdx = frag.sn - levelDetails.startSN;\n      // Move fragPrevious forward to support forcing the next fragment to load\n      // when the buffer catches up to a previously buffered range.\n      const fragState = this.fragmentTracker.getState(frag);\n      if (fragState === FragmentState.OK || fragState === FragmentState.PARTIAL && frag.gap) {\n        fragPrevious = frag;\n      }\n      if (fragPrevious && frag.sn === fragPrevious.sn && (!loadingParts || partList[0].fragment.sn > frag.sn || !levelDetails.live)) {\n        // Force the next fragment to load if the previous one was already selected. This can occasionally happen with\n        // non-uniform fragment durations\n        const sameLevel = frag.level === fragPrevious.level;\n        if (sameLevel) {\n          const nextFrag = fragments[curSNIdx + 1];\n          if (frag.sn < endSN && this.fragmentTracker.getState(nextFrag) !== FragmentState.OK) {\n            frag = nextFrag;\n          } else {\n            frag = null;\n          }\n        }\n      }\n    }\n    return frag;\n  }\n  alignPlaylists(details, previousDetails, switchDetails) {\n    // TODO: If not for `shouldAlignOnDiscontinuities` requiring fragPrevious.cc,\n    //  this could all go in level-helper mergeDetails()\n    const length = details.fragments.length;\n    if (!length) {\n      this.warn(`No fragments in live playlist`);\n      return 0;\n    }\n    const slidingStart = details.fragmentStart;\n    const firstLevelLoad = !previousDetails;\n    const aligned = details.alignedSliding && isFiniteNumber(slidingStart);\n    if (firstLevelLoad || !aligned && !slidingStart) {\n      alignStream(switchDetails, details);\n      const alignedSlidingStart = details.fragmentStart;\n      this.log(`Live playlist sliding: ${alignedSlidingStart.toFixed(2)} start-sn: ${previousDetails ? previousDetails.startSN : 'na'}->${details.startSN} fragments: ${length}`);\n      return alignedSlidingStart;\n    }\n    return slidingStart;\n  }\n  waitForCdnTuneIn(details) {\n    // Wait for Low-Latency CDN Tune-in to get an updated playlist\n    const advancePartLimit = 3;\n    return details.live && details.canBlockReload && details.partTarget && details.tuneInGoal > Math.max(details.partHoldBack, details.partTarget * advancePartLimit);\n  }\n  setStartPosition(details, sliding) {\n    // compute start position if set to -1. use it straight away if value is defined\n    let startPosition = this.startPosition;\n    if (startPosition < sliding) {\n      startPosition = -1;\n    }\n    const timelineOffset = this.timelineOffset;\n    if (startPosition === -1) {\n      // Use Playlist EXT-X-START:TIME-OFFSET when set\n      // Prioritize Multivariant Playlist offset so that main, audio, and subtitle stream-controller start times match\n      const offsetInMultivariantPlaylist = this.startTimeOffset !== null;\n      const startTimeOffset = offsetInMultivariantPlaylist ? this.startTimeOffset : details.startTimeOffset;\n      if (startTimeOffset !== null && isFiniteNumber(startTimeOffset)) {\n        startPosition = sliding + startTimeOffset;\n        if (startTimeOffset < 0) {\n          startPosition += details.edge;\n        }\n        startPosition = Math.min(Math.max(sliding, startPosition), sliding + details.totalduration);\n        this.log(`Setting startPosition to ${startPosition} for start time offset ${startTimeOffset} found in ${offsetInMultivariantPlaylist ? 'multivariant' : 'media'} playlist`);\n        this.startPosition = startPosition;\n      } else if (details.live) {\n        // Leave this.startPosition at -1, so that we can use `getInitialLiveFragment` logic when startPosition has\n        // not been specified via the config or an as an argument to startLoad (#3736).\n        startPosition = this.hls.liveSyncPosition || sliding;\n        this.log(`Setting startPosition to -1 to start at live edge ${startPosition}`);\n        this.startPosition = -1;\n      } else {\n        this.log(`setting startPosition to 0 by default`);\n        this.startPosition = startPosition = 0;\n      }\n      this.lastCurrentTime = startPosition + timelineOffset;\n    }\n    this.nextLoadPosition = startPosition + timelineOffset;\n  }\n  getLoadPosition() {\n    var _this$hls;\n    const {\n      media\n    } = this;\n    // if we have not yet loaded any fragment, start loading from start position\n    let pos = 0;\n    if ((_this$hls = this.hls) != null && _this$hls.hasEnoughToStart && media) {\n      pos = media.currentTime;\n    } else if (this.nextLoadPosition >= 0) {\n      pos = this.nextLoadPosition;\n    }\n    return pos;\n  }\n  handleFragLoadAborted(frag, part) {\n    if (this.transmuxer && frag.type === this.playlistType && isMediaFragment(frag) && frag.stats.aborted) {\n      this.log(`Fragment ${frag.sn}${part ? ' part ' + part.index : ''} of ${this.playlistLabel()} ${frag.level} was aborted`);\n      this.resetFragmentLoading(frag);\n    }\n  }\n  resetFragmentLoading(frag) {\n    if (!this.fragCurrent || !this.fragContextChanged(frag) && this.state !== State.FRAG_LOADING_WAITING_RETRY) {\n      this.state = State.IDLE;\n    }\n  }\n  onFragmentOrKeyLoadError(filterType, data) {\n    var _this$hls$latestLevel;\n    if (data.chunkMeta && !data.frag) {\n      const context = this.getCurrentContext(data.chunkMeta);\n      if (context) {\n        data.frag = context.frag;\n      }\n    }\n    const frag = data.frag;\n    // Handle frag error related to caller's filterType\n    if (!frag || frag.type !== filterType || !this.levels) {\n      return;\n    }\n    if (this.fragContextChanged(frag)) {\n      var _this$fragCurrent;\n      this.warn(`Frag load error must match current frag to retry ${frag.url} > ${(_this$fragCurrent = this.fragCurrent) == null ? void 0 : _this$fragCurrent.url}`);\n      return;\n    }\n    const gapTagEncountered = data.details === ErrorDetails.FRAG_GAP;\n    if (gapTagEncountered) {\n      this.fragmentTracker.fragBuffered(frag, true);\n    }\n    // keep retrying until the limit will be reached\n    const errorAction = data.errorAction;\n    if (!errorAction) {\n      this.state = State.ERROR;\n      return;\n    }\n    const {\n      action,\n      flags,\n      retryCount = 0,\n      retryConfig\n    } = errorAction;\n    const couldRetry = !!retryConfig;\n    const retry = couldRetry && action === NetworkErrorAction.RetryRequest;\n    const noAlternate = couldRetry && !errorAction.resolved && flags === ErrorActionFlags.MoveAllAlternatesMatchingHost;\n    const live = (_this$hls$latestLevel = this.hls.latestLevelDetails) == null ? void 0 : _this$hls$latestLevel.live;\n    if (!retry && noAlternate && isMediaFragment(frag) && !frag.endList && live && !isUnusableKeyError(data)) {\n      this.resetFragmentErrors(filterType);\n      this.treatAsGap(frag);\n      errorAction.resolved = true;\n    } else if ((retry || noAlternate) && retryCount < retryConfig.maxNumRetry) {\n      var _data$response;\n      const offlineStatus = offlineHttpStatus((_data$response = data.response) == null ? void 0 : _data$response.code);\n      const delay = getRetryDelay(retryConfig, retryCount);\n      this.resetStartWhenNotLoaded();\n      this.retryDate = self.performance.now() + delay;\n      this.state = State.FRAG_LOADING_WAITING_RETRY;\n      errorAction.resolved = true;\n      if (offlineStatus) {\n        this.log(`Waiting for connection (offline)`);\n        this.retryDate = Infinity;\n        data.reason = 'offline';\n        return;\n      }\n      this.warn(`Fragment ${frag.sn} of ${filterType} ${frag.level} errored with ${data.details}, retrying loading ${retryCount + 1}/${retryConfig.maxNumRetry} in ${delay}ms`);\n    } else if (retryConfig) {\n      this.resetFragmentErrors(filterType);\n      if (retryCount < retryConfig.maxNumRetry) {\n        // Network retry is skipped when level switch is preferred\n        if (!gapTagEncountered && action !== NetworkErrorAction.RemoveAlternatePermanently) {\n          errorAction.resolved = true;\n        }\n      } else {\n        this.warn(`${data.details} reached or exceeded max retry (${retryCount})`);\n        return;\n      }\n    } else if (action === NetworkErrorAction.SendAlternateToPenaltyBox) {\n      this.state = State.WAITING_LEVEL;\n    } else {\n      this.state = State.ERROR;\n    }\n    // Perform next async tick sooner to speed up error action resolution\n    this.tickImmediate();\n  }\n  checkRetryDate() {\n    const now = self.performance.now();\n    const retryDate = this.retryDate;\n    // if current time is gt than retryDate, or if media seeking let's switch to IDLE state to retry loading\n    const waitingForConnection = retryDate === Infinity;\n    if (!retryDate || now >= retryDate || waitingForConnection && !offlineHttpStatus(0)) {\n      if (waitingForConnection) {\n        this.log(`Connection restored (online)`);\n      }\n      this.resetStartWhenNotLoaded();\n      this.state = State.IDLE;\n    }\n  }\n  reduceLengthAndFlushBuffer(data) {\n    // if in appending state\n    if (this.state === State.PARSING || this.state === State.PARSED) {\n      const frag = data.frag;\n      const playlistType = data.parent;\n      const bufferedInfo = this.getFwdBufferInfo(this.mediaBuffer, playlistType);\n      // 0.5 : tolerance needed as some browsers stalls playback before reaching buffered end\n      // reduce max buf len if current position is buffered\n      const buffered = bufferedInfo && bufferedInfo.len > 0.5;\n      if (buffered) {\n        this.reduceMaxBufferLength(bufferedInfo.len, (frag == null ? void 0 : frag.duration) || 10);\n      }\n      const flushBuffer = !buffered;\n      if (flushBuffer) {\n        // current position is not buffered, but browser is still complaining about buffer full error\n        // this happens on IE/Edge, refer to https://github.com/video-dev/hls.js/pull/708\n        // in that case flush the whole audio buffer to recover\n        this.warn(`Buffer full error while media.currentTime (${this.getLoadPosition()}) is not buffered, flush ${playlistType} buffer`);\n      }\n      if (frag) {\n        this.fragmentTracker.removeFragment(frag);\n        this.nextLoadPosition = frag.start;\n      }\n      this.resetLoadingState();\n      return flushBuffer;\n    }\n    return false;\n  }\n  resetFragmentErrors(filterType) {\n    if (filterType === PlaylistLevelType.AUDIO) {\n      // Reset current fragment since audio track audio is essential and may not have a fail-over track\n      this.fragCurrent = null;\n    }\n    // Fragment errors that result in a level switch or redundant fail-over\n    // should reset the stream controller state to idle\n    if (!this.hls.hasEnoughToStart) {\n      this.startFragRequested = false;\n    }\n    if (this.state !== State.STOPPED) {\n      this.state = State.IDLE;\n    }\n  }\n  afterBufferFlushed(media, bufferType, playlistType) {\n    if (!media) {\n      return;\n    }\n    // After successful buffer flushing, filter flushed fragments from bufferedFrags use mediaBuffered instead of media\n    // (so that we will check against video.buffered ranges in case of alt audio track)\n    const bufferedTimeRanges = BufferHelper.getBuffered(media);\n    this.fragmentTracker.detectEvictedFragments(bufferType, bufferedTimeRanges, playlistType);\n    if (this.state === State.ENDED) {\n      this.resetLoadingState();\n    }\n  }\n  resetLoadingState() {\n    this.log('Reset loading state');\n    this.fragCurrent = null;\n    this.fragPrevious = null;\n    if (this.state !== State.STOPPED) {\n      this.state = State.IDLE;\n    }\n  }\n  resetStartWhenNotLoaded() {\n    // if loadedmetadata is not set, it means that first frag request failed\n    // in that case, reset startFragRequested flag\n    if (!this.hls.hasEnoughToStart) {\n      this.startFragRequested = false;\n      const level = this.levelLastLoaded;\n      const details = level ? level.details : null;\n      if (details != null && details.live) {\n        // Update the start position and return to IDLE to recover live start\n        this.log(`resetting startPosition for live start`);\n        this.startPosition = -1;\n        this.setStartPosition(details, details.fragmentStart);\n        this.resetLoadingState();\n      } else {\n        this.nextLoadPosition = this.startPosition;\n      }\n    }\n  }\n  resetWhenMissingContext(chunkMeta) {\n    this.log(`Loading context changed while buffering sn ${chunkMeta.sn} of ${this.playlistLabel()} ${chunkMeta.level === -1 ? '<removed>' : chunkMeta.level}. This chunk will not be buffered.`);\n    this.removeUnbufferedFrags();\n    this.resetStartWhenNotLoaded();\n    this.resetLoadingState();\n  }\n  removeUnbufferedFrags(start = 0) {\n    this.fragmentTracker.removeFragmentsInRange(start, Infinity, this.playlistType, false, true);\n  }\n  updateLevelTiming(frag, part, level, partial) {\n    const details = level.details;\n    if (!details) {\n      this.warn('level.details undefined');\n      return;\n    }\n    const parsed = Object.keys(frag.elementaryStreams).reduce((result, type) => {\n      const info = frag.elementaryStreams[type];\n      if (info) {\n        const parsedDuration = info.endPTS - info.startPTS;\n        if (parsedDuration <= 0) {\n          // Destroy the transmuxer after it's next time offset failed to advance because duration was <= 0.\n          // The new transmuxer will be configured with a time offset matching the next fragment start,\n          // preventing the timeline from shifting.\n          this.warn(`Could not parse fragment ${frag.sn} ${type} duration reliably (${parsedDuration})`);\n          return result || false;\n        }\n        const drift = partial ? 0 : updateFragPTSDTS(details, frag, info.startPTS, info.endPTS, info.startDTS, info.endDTS, this);\n        this.hls.trigger(Events.LEVEL_PTS_UPDATED, {\n          details,\n          level,\n          drift,\n          type,\n          frag,\n          start: info.startPTS,\n          end: info.endPTS\n        });\n        return true;\n      }\n      return result;\n    }, false);\n    if (!parsed) {\n      var _this$transmuxer;\n      const mediaNotFound = ((_this$transmuxer = this.transmuxer) == null ? void 0 : _this$transmuxer.error) === null;\n      if (level.fragmentError === 0 || mediaNotFound && (level.fragmentError < 2 || frag.endList)) {\n        // Mark and track the odd (or last) empty segment as a gap to avoid reloading\n        this.treatAsGap(frag, level);\n      }\n      if (mediaNotFound) {\n        const error = new Error(`Found no media in fragment ${frag.sn} of ${this.playlistLabel()} ${frag.level} resetting transmuxer to fallback to playlist timing`);\n        this.warn(error.message);\n        this.hls.trigger(Events.ERROR, {\n          type: ErrorTypes.MEDIA_ERROR,\n          details: ErrorDetails.FRAG_PARSING_ERROR,\n          fatal: false,\n          error,\n          frag,\n          reason: `Found no media in msn ${frag.sn} of ${this.playlistLabel()} \"${level.url}\"`\n        });\n        if (!this.hls) {\n          return;\n        }\n        this.resetTransmuxer();\n      }\n      // For this error fallthrough. Marking parsed will allow advancing to next fragment.\n    }\n    this.state = State.PARSED;\n    this.log(`Parsed ${frag.type} sn: ${frag.sn}${part ? ' part: ' + part.index : ''} of ${this.fragInfo(frag, false, part)})`);\n    this.hls.trigger(Events.FRAG_PARSED, {\n      frag,\n      part\n    });\n  }\n  playlistLabel() {\n    return this.playlistType === PlaylistLevelType.MAIN ? 'level' : 'track';\n  }\n  fragInfo(frag, pts = true, part) {\n    var _ref, _ref2;\n    return `${this.playlistLabel()} ${frag.level} (${part ? 'part' : 'frag'}:[${((_ref = pts && !part ? frag.startPTS : (part || frag).start) != null ? _ref : NaN).toFixed(3)}-${((_ref2 = pts && !part ? frag.endPTS : (part || frag).end) != null ? _ref2 : NaN).toFixed(3)}]${part && frag.type === 'main' ? 'INDEPENDENT=' + (part.independent ? 'YES' : 'NO') : ''}`;\n  }\n  treatAsGap(frag, level) {\n    if (level) {\n      level.fragmentError++;\n    }\n    frag.gap = true;\n    this.fragmentTracker.removeFragment(frag);\n    this.fragmentTracker.fragBuffered(frag, true);\n  }\n  resetTransmuxer() {\n    var _this$transmuxer2;\n    (_this$transmuxer2 = this.transmuxer) == null || _this$transmuxer2.reset();\n  }\n  recoverWorkerError(data) {\n    if (data.event === 'demuxerWorker') {\n      this.fragmentTracker.removeAllFragments();\n      if (this.transmuxer) {\n        this.transmuxer.destroy();\n        this.transmuxer = null;\n      }\n      this.resetStartWhenNotLoaded();\n      this.resetLoadingState();\n    }\n  }\n  set state(nextState) {\n    const previousState = this._state;\n    if (previousState !== nextState) {\n      this._state = nextState;\n      this.log(`${previousState}->${nextState}`);\n    }\n  }\n  get state() {\n    return this._state;\n  }\n}\nfunction interstitialsEnabled(config) {\n  return !!config.interstitialsController && config.enableInterstitialPlayback !== false;\n}\n\nclass ChunkCache {\n  constructor() {\n    this.chunks = [];\n    this.dataLength = 0;\n  }\n  push(chunk) {\n    this.chunks.push(chunk);\n    this.dataLength += chunk.length;\n  }\n  flush() {\n    const {\n      chunks,\n      dataLength\n    } = this;\n    let result;\n    if (!chunks.length) {\n      return new Uint8Array(0);\n    } else if (chunks.length === 1) {\n      result = chunks[0];\n    } else {\n      result = concatUint8Arrays(chunks, dataLength);\n    }\n    this.reset();\n    return result;\n  }\n  reset() {\n    this.chunks.length = 0;\n    this.dataLength = 0;\n  }\n}\nfunction concatUint8Arrays(chunks, dataLength) {\n  const result = new Uint8Array(dataLength);\n  let offset = 0;\n  for (let i = 0; i < chunks.length; i++) {\n    const chunk = chunks[i];\n    result.set(chunk, offset);\n    offset += chunk.length;\n  }\n  return result;\n}\n\nvar eventemitter3 = {exports: {}};\n\nvar hasRequiredEventemitter3;\n\nfunction requireEventemitter3 () {\n\tif (hasRequiredEventemitter3) return eventemitter3.exports;\n\thasRequiredEventemitter3 = 1;\n\t(function (module) {\n\n\t\tvar has = Object.prototype.hasOwnProperty\n\t\t  , prefix = '~';\n\n\t\t/**\n\t\t * Constructor to create a storage for our `EE` objects.\n\t\t * An `Events` instance is a plain object whose properties are event names.\n\t\t *\n\t\t * @constructor\n\t\t * @private\n\t\t */\n\t\tfunction Events() {}\n\n\t\t//\n\t\t// We try to not inherit from `Object.prototype`. In some engines creating an\n\t\t// instance in this way is faster than calling `Object.create(null)` directly.\n\t\t// If `Object.create(null)` is not supported we prefix the event names with a\n\t\t// character to make sure that the built-in object properties are not\n\t\t// overridden or used as an attack vector.\n\t\t//\n\t\tif (Object.create) {\n\t\t  Events.prototype = Object.create(null);\n\n\t\t  //\n\t\t  // This hack is needed because the `__proto__` property is still inherited in\n\t\t  // some old browsers like Android 4, iPhone 5.1, Opera 11 and Safari 5.\n\t\t  //\n\t\t  if (!new Events().__proto__) prefix = false;\n\t\t}\n\n\t\t/**\n\t\t * Representation of a single event listener.\n\t\t *\n\t\t * @param {Function} fn The listener function.\n\t\t * @param {*} context The context to invoke the listener with.\n\t\t * @param {Boolean} [once=false] Specify if the listener is a one-time listener.\n\t\t * @constructor\n\t\t * @private\n\t\t */\n\t\tfunction EE(fn, context, once) {\n\t\t  this.fn = fn;\n\t\t  this.context = context;\n\t\t  this.once = once || false;\n\t\t}\n\n\t\t/**\n\t\t * Add a listener for a given event.\n\t\t *\n\t\t * @param {EventEmitter} emitter Reference to the `EventEmitter` instance.\n\t\t * @param {(String|Symbol)} event The event name.\n\t\t * @param {Function} fn The listener function.\n\t\t * @param {*} context The context to invoke the listener with.\n\t\t * @param {Boolean} once Specify if the listener is a one-time listener.\n\t\t * @returns {EventEmitter}\n\t\t * @private\n\t\t */\n\t\tfunction addListener(emitter, event, fn, context, once) {\n\t\t  if (typeof fn !== 'function') {\n\t\t    throw new TypeError('The listener must be a function');\n\t\t  }\n\n\t\t  var listener = new EE(fn, context || emitter, once)\n\t\t    , evt = prefix ? prefix + event : event;\n\n\t\t  if (!emitter._events[evt]) emitter._events[evt] = listener, emitter._eventsCount++;\n\t\t  else if (!emitter._events[evt].fn) emitter._events[evt].push(listener);\n\t\t  else emitter._events[evt] = [emitter._events[evt], listener];\n\n\t\t  return emitter;\n\t\t}\n\n\t\t/**\n\t\t * Clear event by name.\n\t\t *\n\t\t * @param {EventEmitter} emitter Reference to the `EventEmitter` instance.\n\t\t * @param {(String|Symbol)} evt The Event name.\n\t\t * @private\n\t\t */\n\t\tfunction clearEvent(emitter, evt) {\n\t\t  if (--emitter._eventsCount === 0) emitter._events = new Events();\n\t\t  else delete emitter._events[evt];\n\t\t}\n\n\t\t/**\n\t\t * Minimal `EventEmitter` interface that is molded against the Node.js\n\t\t * `EventEmitter` interface.\n\t\t *\n\t\t * @constructor\n\t\t * @public\n\t\t */\n\t\tfunction EventEmitter() {\n\t\t  this._events = new Events();\n\t\t  this._eventsCount = 0;\n\t\t}\n\n\t\t/**\n\t\t * Return an array listing the events for which the emitter has registered\n\t\t * listeners.\n\t\t *\n\t\t * @returns {Array}\n\t\t * @public\n\t\t */\n\t\tEventEmitter.prototype.eventNames = function eventNames() {\n\t\t  var names = []\n\t\t    , events\n\t\t    , name;\n\n\t\t  if (this._eventsCount === 0) return names;\n\n\t\t  for (name in (events = this._events)) {\n\t\t    if (has.call(events, name)) names.push(prefix ? name.slice(1) : name);\n\t\t  }\n\n\t\t  if (Object.getOwnPropertySymbols) {\n\t\t    return names.concat(Object.getOwnPropertySymbols(events));\n\t\t  }\n\n\t\t  return names;\n\t\t};\n\n\t\t/**\n\t\t * Return the listeners registered for a given event.\n\t\t *\n\t\t * @param {(String|Symbol)} event The event name.\n\t\t * @returns {Array} The registered listeners.\n\t\t * @public\n\t\t */\n\t\tEventEmitter.prototype.listeners = function listeners(event) {\n\t\t  var evt = prefix ? prefix + event : event\n\t\t    , handlers = this._events[evt];\n\n\t\t  if (!handlers) return [];\n\t\t  if (handlers.fn) return [handlers.fn];\n\n\t\t  for (var i = 0, l = handlers.length, ee = new Array(l); i < l; i++) {\n\t\t    ee[i] = handlers[i].fn;\n\t\t  }\n\n\t\t  return ee;\n\t\t};\n\n\t\t/**\n\t\t * Return the number of listeners listening to a given event.\n\t\t *\n\t\t * @param {(String|Symbol)} event The event name.\n\t\t * @returns {Number} The number of listeners.\n\t\t * @public\n\t\t */\n\t\tEventEmitter.prototype.listenerCount = function listenerCount(event) {\n\t\t  var evt = prefix ? prefix + event : event\n\t\t    , listeners = this._events[evt];\n\n\t\t  if (!listeners) return 0;\n\t\t  if (listeners.fn) return 1;\n\t\t  return listeners.length;\n\t\t};\n\n\t\t/**\n\t\t * Calls each of the listeners registered for a given event.\n\t\t *\n\t\t * @param {(String|Symbol)} event The event name.\n\t\t * @returns {Boolean} `true` if the event had listeners, else `false`.\n\t\t * @public\n\t\t */\n\t\tEventEmitter.prototype.emit = function emit(event, a1, a2, a3, a4, a5) {\n\t\t  var evt = prefix ? prefix + event : event;\n\n\t\t  if (!this._events[evt]) return false;\n\n\t\t  var listeners = this._events[evt]\n\t\t    , len = arguments.length\n\t\t    , args\n\t\t    , i;\n\n\t\t  if (listeners.fn) {\n\t\t    if (listeners.once) this.removeListener(event, listeners.fn, undefined, true);\n\n\t\t    switch (len) {\n\t\t      case 1: return listeners.fn.call(listeners.context), true;\n\t\t      case 2: return listeners.fn.call(listeners.context, a1), true;\n\t\t      case 3: return listeners.fn.call(listeners.context, a1, a2), true;\n\t\t      case 4: return listeners.fn.call(listeners.context, a1, a2, a3), true;\n\t\t      case 5: return listeners.fn.call(listeners.context, a1, a2, a3, a4), true;\n\t\t      case 6: return listeners.fn.call(listeners.context, a1, a2, a3, a4, a5), true;\n\t\t    }\n\n\t\t    for (i = 1, args = new Array(len -1); i < len; i++) {\n\t\t      args[i - 1] = arguments[i];\n\t\t    }\n\n\t\t    listeners.fn.apply(listeners.context, args);\n\t\t  } else {\n\t\t    var length = listeners.length\n\t\t      , j;\n\n\t\t    for (i = 0; i < length; i++) {\n\t\t      if (listeners[i].once) this.removeListener(event, listeners[i].fn, undefined, true);\n\n\t\t      switch (len) {\n\t\t        case 1: listeners[i].fn.call(listeners[i].context); break;\n\t\t        case 2: listeners[i].fn.call(listeners[i].context, a1); break;\n\t\t        case 3: listeners[i].fn.call(listeners[i].context, a1, a2); break;\n\t\t        case 4: listeners[i].fn.call(listeners[i].context, a1, a2, a3); break;\n\t\t        default:\n\t\t          if (!args) for (j = 1, args = new Array(len -1); j < len; j++) {\n\t\t            args[j - 1] = arguments[j];\n\t\t          }\n\n\t\t          listeners[i].fn.apply(listeners[i].context, args);\n\t\t      }\n\t\t    }\n\t\t  }\n\n\t\t  return true;\n\t\t};\n\n\t\t/**\n\t\t * Add a listener for a given event.\n\t\t *\n\t\t * @param {(String|Symbol)} event The event name.\n\t\t * @param {Function} fn The listener function.\n\t\t * @param {*} [context=this] The context to invoke the listener with.\n\t\t * @returns {EventEmitter} `this`.\n\t\t * @public\n\t\t */\n\t\tEventEmitter.prototype.on = function on(event, fn, context) {\n\t\t  return addListener(this, event, fn, context, false);\n\t\t};\n\n\t\t/**\n\t\t * Add a one-time listener for a given event.\n\t\t *\n\t\t * @param {(String|Symbol)} event The event name.\n\t\t * @param {Function} fn The listener function.\n\t\t * @param {*} [context=this] The context to invoke the listener with.\n\t\t * @returns {EventEmitter} `this`.\n\t\t * @public\n\t\t */\n\t\tEventEmitter.prototype.once = function once(event, fn, context) {\n\t\t  return addListener(this, event, fn, context, true);\n\t\t};\n\n\t\t/**\n\t\t * Remove the listeners of a given event.\n\t\t *\n\t\t * @param {(String|Symbol)} event The event name.\n\t\t * @param {Function} fn Only remove the listeners that match this function.\n\t\t * @param {*} context Only remove the listeners that have this context.\n\t\t * @param {Boolean} once Only remove one-time listeners.\n\t\t * @returns {EventEmitter} `this`.\n\t\t * @public\n\t\t */\n\t\tEventEmitter.prototype.removeListener = function removeListener(event, fn, context, once) {\n\t\t  var evt = prefix ? prefix + event : event;\n\n\t\t  if (!this._events[evt]) return this;\n\t\t  if (!fn) {\n\t\t    clearEvent(this, evt);\n\t\t    return this;\n\t\t  }\n\n\t\t  var listeners = this._events[evt];\n\n\t\t  if (listeners.fn) {\n\t\t    if (\n\t\t      listeners.fn === fn &&\n\t\t      (!once || listeners.once) &&\n\t\t      (!context || listeners.context === context)\n\t\t    ) {\n\t\t      clearEvent(this, evt);\n\t\t    }\n\t\t  } else {\n\t\t    for (var i = 0, events = [], length = listeners.length; i < length; i++) {\n\t\t      if (\n\t\t        listeners[i].fn !== fn ||\n\t\t        (once && !listeners[i].once) ||\n\t\t        (context && listeners[i].context !== context)\n\t\t      ) {\n\t\t        events.push(listeners[i]);\n\t\t      }\n\t\t    }\n\n\t\t    //\n\t\t    // Reset the array, or remove it completely if we have no more listeners.\n\t\t    //\n\t\t    if (events.length) this._events[evt] = events.length === 1 ? events[0] : events;\n\t\t    else clearEvent(this, evt);\n\t\t  }\n\n\t\t  return this;\n\t\t};\n\n\t\t/**\n\t\t * Remove all listeners, or those of the specified event.\n\t\t *\n\t\t * @param {(String|Symbol)} [event] The event name.\n\t\t * @returns {EventEmitter} `this`.\n\t\t * @public\n\t\t */\n\t\tEventEmitter.prototype.removeAllListeners = function removeAllListeners(event) {\n\t\t  var evt;\n\n\t\t  if (event) {\n\t\t    evt = prefix ? prefix + event : event;\n\t\t    if (this._events[evt]) clearEvent(this, evt);\n\t\t  } else {\n\t\t    this._events = new Events();\n\t\t    this._eventsCount = 0;\n\t\t  }\n\n\t\t  return this;\n\t\t};\n\n\t\t//\n\t\t// Alias methods names because people roll like that.\n\t\t//\n\t\tEventEmitter.prototype.off = EventEmitter.prototype.removeListener;\n\t\tEventEmitter.prototype.addListener = EventEmitter.prototype.on;\n\n\t\t//\n\t\t// Expose the prefix.\n\t\t//\n\t\tEventEmitter.prefixed = prefix;\n\n\t\t//\n\t\t// Allow `EventEmitter` to be imported as module namespace.\n\t\t//\n\t\tEventEmitter.EventEmitter = EventEmitter;\n\n\t\t//\n\t\t// Expose the module.\n\t\t//\n\t\t{\n\t\t  module.exports = EventEmitter;\n\t\t} \n\t} (eventemitter3));\n\treturn eventemitter3.exports;\n}\n\nvar eventemitter3Exports = requireEventemitter3();\nvar EventEmitter = /*@__PURE__*/getDefaultExportFromCjs(eventemitter3Exports);\n\nconst version = \"1.6.15\";\n\n// ensure the worker ends up in the bundle\n// If the worker should not be included this gets aliased to empty.js\nconst workerStore = {};\nfunction hasUMDWorker() {\n  return typeof __HLS_WORKER_BUNDLE__ === 'function';\n}\nfunction injectWorker() {\n  const workerContext = workerStore[version];\n  if (workerContext) {\n    workerContext.clientCount++;\n    return workerContext;\n  }\n  const blob = new self.Blob([`var exports={};var module={exports:exports};function define(f){f()};define.amd=true;(${__HLS_WORKER_BUNDLE__.toString()})(true);`], {\n    type: 'text/javascript'\n  });\n  const objectURL = self.URL.createObjectURL(blob);\n  const worker = new self.Worker(objectURL);\n  const result = {\n    worker,\n    objectURL,\n    clientCount: 1\n  };\n  workerStore[version] = result;\n  return result;\n}\nfunction loadWorker(path) {\n  const workerContext = workerStore[path];\n  if (workerContext) {\n    workerContext.clientCount++;\n    return workerContext;\n  }\n  const scriptURL = new self.URL(path, self.location.href).href;\n  const worker = new self.Worker(scriptURL);\n  const result = {\n    worker,\n    scriptURL,\n    clientCount: 1\n  };\n  workerStore[path] = result;\n  return result;\n}\nfunction removeWorkerFromStore(path) {\n  const workerContext = workerStore[path || version];\n  if (workerContext) {\n    const clientCount = workerContext.clientCount--;\n    if (clientCount === 1) {\n      const {\n        worker,\n        objectURL\n      } = workerContext;\n      delete workerStore[path || version];\n      if (objectURL) {\n        // revoke the Object URL that was used to create transmuxer worker, so as not to leak it\n        self.URL.revokeObjectURL(objectURL);\n      }\n      worker.terminate();\n    }\n  }\n}\n\n/**\n * Returns true if an ID3 footer can be found at offset in data\n *\n * @param data - The data to search in\n * @param offset - The offset at which to start searching\n *\n * @returns `true` if an ID3 footer is found\n *\n * @internal\n *\n * @group ID3\n */\nfunction isId3Footer(data, offset) {\n  /*\n   * The footer is a copy of the header, but with a different identifier\n   */\n  if (offset + 10 <= data.length) {\n    // look for '3DI' identifier\n    if (data[offset] === 0x33 && data[offset + 1] === 0x44 && data[offset + 2] === 0x49) {\n      // check version is within range\n      if (data[offset + 3] < 0xff && data[offset + 4] < 0xff) {\n        // check size is within range\n        if (data[offset + 6] < 0x80 && data[offset + 7] < 0x80 && data[offset + 8] < 0x80 && data[offset + 9] < 0x80) {\n          return true;\n        }\n      }\n    }\n  }\n  return false;\n}\n\n/**\n * Returns true if an ID3 header can be found at offset in data\n *\n * @param data - The data to search in\n * @param offset - The offset at which to start searching\n *\n * @returns `true` if an ID3 header is found\n *\n * @internal\n *\n * @group ID3\n */\nfunction isId3Header(data, offset) {\n  /*\n   * http://id3.org/id3v2.3.0\n   * [0]     = 'I'\n   * [1]     = 'D'\n   * [2]     = '3'\n   * [3,4]   = {Version}\n   * [5]     = {Flags}\n   * [6-9]   = {ID3 Size}\n   *\n   * An ID3v2 tag can be detected with the following pattern:\n   *  $49 44 33 yy yy xx zz zz zz zz\n   * Where yy is less than $FF, xx is the 'flags' byte and zz is less than $80\n   */\n  if (offset + 10 <= data.length) {\n    // look for 'ID3' identifier\n    if (data[offset] === 0x49 && data[offset + 1] === 0x44 && data[offset + 2] === 0x33) {\n      // check version is within range\n      if (data[offset + 3] < 0xff && data[offset + 4] < 0xff) {\n        // check size is within range\n        if (data[offset + 6] < 0x80 && data[offset + 7] < 0x80 && data[offset + 8] < 0x80 && data[offset + 9] < 0x80) {\n          return true;\n        }\n      }\n    }\n  }\n  return false;\n}\n\n/**\n * Read ID3 size\n *\n * @param data - The data to read from\n * @param offset - The offset at which to start reading\n *\n * @returns The size\n *\n * @internal\n *\n * @group ID3\n */\nfunction readId3Size(data, offset) {\n  let size = 0;\n  size = (data[offset] & 0x7f) << 21;\n  size |= (data[offset + 1] & 0x7f) << 14;\n  size |= (data[offset + 2] & 0x7f) << 7;\n  size |= data[offset + 3] & 0x7f;\n  return size;\n}\n\n/**\n * Returns any adjacent ID3 tags found in data starting at offset, as one block of data\n *\n * @param data - The data to search in\n * @param offset - The offset at which to start searching\n *\n * @returns The block of data containing any ID3 tags found\n * or `undefined` if no header is found at the starting offset\n *\n * @internal\n *\n * @group ID3\n */\nfunction getId3Data(data, offset) {\n  const front = offset;\n  let length = 0;\n  while (isId3Header(data, offset)) {\n    // ID3 header is 10 bytes\n    length += 10;\n    const size = readId3Size(data, offset + 6);\n    length += size;\n    if (isId3Footer(data, offset + 10)) {\n      // ID3 footer is 10 bytes\n      length += 10;\n    }\n    offset += length;\n  }\n  if (length > 0) {\n    return data.subarray(front, front + length);\n  }\n  return undefined;\n}\n\nfunction getAudioConfig(observer, data, offset, manifestCodec) {\n  const adtsSamplingRates = [96000, 88200, 64000, 48000, 44100, 32000, 24000, 22050, 16000, 12000, 11025, 8000, 7350];\n  const byte2 = data[offset + 2];\n  const adtsSamplingIndex = byte2 >> 2 & 0xf;\n  if (adtsSamplingIndex > 12) {\n    const error = new Error(`invalid ADTS sampling index:${adtsSamplingIndex}`);\n    observer.emit(Events.ERROR, Events.ERROR, {\n      type: ErrorTypes.MEDIA_ERROR,\n      details: ErrorDetails.FRAG_PARSING_ERROR,\n      fatal: true,\n      error,\n      reason: error.message\n    });\n    return;\n  }\n  // MPEG-4 Audio Object Type (profile_ObjectType+1)\n  const adtsObjectType = (byte2 >> 6 & 0x3) + 1;\n  const channelCount = data[offset + 3] >> 6 & 0x3 | (byte2 & 1) << 2;\n  const codec = 'mp4a.40.' + adtsObjectType;\n  /* refer to http://wiki.multimedia.cx/index.php?title=MPEG-4_Audio#Audio_Specific_Config\n      ISO/IEC 14496-3 - Table 1.13  Syntax of AudioSpecificConfig()\n    Audio Profile / Audio Object Type\n    0: Null\n    1: AAC Main\n    2: AAC LC (Low Complexity)\n    3: AAC SSR (Scalable Sample Rate)\n    4: AAC LTP (Long Term Prediction)\n    5: SBR (Spectral Band Replication)\n    6: AAC Scalable\n   sampling freq\n    0: 96000 Hz\n    1: 88200 Hz\n    2: 64000 Hz\n    3: 48000 Hz\n    4: 44100 Hz\n    5: 32000 Hz\n    6: 24000 Hz\n    7: 22050 Hz\n    8: 16000 Hz\n    9: 12000 Hz\n    10: 11025 Hz\n    11: 8000 Hz\n    12: 7350 Hz\n    13: Reserved\n    14: Reserved\n    15: frequency is written explictly\n    Channel Configurations\n    These are the channel configurations:\n    0: Defined in AOT Specifc Config\n    1: 1 channel: front-center\n    2: 2 channels: front-left, front-right\n  */\n  // audioObjectType = profile => profile, the MPEG-4 Audio Object Type minus 1\n  const samplerate = adtsSamplingRates[adtsSamplingIndex];\n  let aacSampleIndex = adtsSamplingIndex;\n  if (adtsObjectType === 5 || adtsObjectType === 29) {\n    // HE-AAC uses SBR (Spectral Band Replication) , high frequencies are constructed from low frequencies\n    // there is a factor 2 between frame sample rate and output sample rate\n    // multiply frequency by 2 (see table above, equivalent to substract 3)\n    aacSampleIndex -= 3;\n  }\n  const config = [adtsObjectType << 3 | (aacSampleIndex & 0x0e) >> 1, (aacSampleIndex & 0x01) << 7 | channelCount << 3];\n  logger.log(`manifest codec:${manifestCodec}, parsed codec:${codec}, channels:${channelCount}, rate:${samplerate} (ADTS object type:${adtsObjectType} sampling index:${adtsSamplingIndex})`);\n  return {\n    config,\n    samplerate,\n    channelCount,\n    codec,\n    parsedCodec: codec,\n    manifestCodec\n  };\n}\nfunction isHeaderPattern$1(data, offset) {\n  return data[offset] === 0xff && (data[offset + 1] & 0xf6) === 0xf0;\n}\nfunction getHeaderLength(data, offset) {\n  return data[offset + 1] & 0x01 ? 7 : 9;\n}\nfunction getFullFrameLength(data, offset) {\n  return (data[offset + 3] & 0x03) << 11 | data[offset + 4] << 3 | (data[offset + 5] & 0xe0) >>> 5;\n}\nfunction canGetFrameLength(data, offset) {\n  return offset + 5 < data.length;\n}\nfunction isHeader$1(data, offset) {\n  // Look for ADTS header | 1111 1111 | 1111 X00X | where X can be either 0 or 1\n  // Layer bits (position 14 and 15) in header should be always 0 for ADTS\n  // More info https://wiki.multimedia.cx/index.php?title=ADTS\n  return offset + 1 < data.length && isHeaderPattern$1(data, offset);\n}\nfunction canParse$1(data, offset) {\n  return canGetFrameLength(data, offset) && isHeaderPattern$1(data, offset) && getFullFrameLength(data, offset) <= data.length - offset;\n}\nfunction probe$1(data, offset) {\n  // same as isHeader but we also check that ADTS frame follows last ADTS frame\n  // or end of data is reached\n  if (isHeader$1(data, offset)) {\n    // ADTS header Length\n    const headerLength = getHeaderLength(data, offset);\n    if (offset + headerLength >= data.length) {\n      return false;\n    }\n    // ADTS frame Length\n    const frameLength = getFullFrameLength(data, offset);\n    if (frameLength <= headerLength) {\n      return false;\n    }\n    const newOffset = offset + frameLength;\n    return newOffset === data.length || isHeader$1(data, newOffset);\n  }\n  return false;\n}\nfunction initTrackConfig(track, observer, data, offset, audioCodec) {\n  if (!track.samplerate) {\n    const config = getAudioConfig(observer, data, offset, audioCodec);\n    if (!config) {\n      return;\n    }\n    _extends(track, config);\n  }\n}\nfunction getFrameDuration(samplerate) {\n  return 1024 * 90000 / samplerate;\n}\nfunction parseFrameHeader(data, offset) {\n  // The protection skip bit tells us if we have 2 bytes of CRC data at the end of the ADTS header\n  const headerLength = getHeaderLength(data, offset);\n  if (offset + headerLength <= data.length) {\n    // retrieve frame size\n    const frameLength = getFullFrameLength(data, offset) - headerLength;\n    if (frameLength > 0) {\n      // logger.log(`AAC frame, offset/length/total/pts:${offset+headerLength}/${frameLength}/${data.byteLength}`);\n      return {\n        headerLength,\n        frameLength\n      };\n    }\n  }\n}\nfunction appendFrame$2(track, data, offset, pts, frameIndex) {\n  const frameDuration = getFrameDuration(track.samplerate);\n  const stamp = pts + frameIndex * frameDuration;\n  const header = parseFrameHeader(data, offset);\n  let unit;\n  if (header) {\n    const {\n      frameLength,\n      headerLength\n    } = header;\n    const _length = headerLength + frameLength;\n    const missing = Math.max(0, offset + _length - data.length);\n    // logger.log(`AAC frame ${frameIndex}, pts:${stamp} length@offset/total: ${frameLength}@${offset+headerLength}/${data.byteLength} missing: ${missing}`);\n    if (missing) {\n      unit = new Uint8Array(_length - headerLength);\n      unit.set(data.subarray(offset + headerLength, data.length), 0);\n    } else {\n      unit = data.subarray(offset + headerLength, offset + _length);\n    }\n    const _sample = {\n      unit,\n      pts: stamp\n    };\n    if (!missing) {\n      track.samples.push(_sample);\n    }\n    return {\n      sample: _sample,\n      length: _length,\n      missing\n    };\n  }\n  // overflow incomplete header\n  const length = data.length - offset;\n  unit = new Uint8Array(length);\n  unit.set(data.subarray(offset, data.length), 0);\n  const sample = {\n    unit,\n    pts: stamp\n  };\n  return {\n    sample,\n    length,\n    missing: -1\n  };\n}\n\n/**\n * Checks if the given data contains an ID3 tag.\n *\n * @param data - The data to check\n * @param offset - The offset at which to start checking\n *\n * @returns `true` if an ID3 tag is found\n *\n * @group ID3\n *\n * @beta\n */\nfunction canParseId3(data, offset) {\n  return isId3Header(data, offset) && readId3Size(data, offset + 6) + 10 <= data.length - offset;\n}\n\nfunction toArrayBuffer(view) {\n  if (view instanceof ArrayBuffer) {\n    return view;\n  } else {\n    if (view.byteOffset == 0 && view.byteLength == view.buffer.byteLength) {\n      // This is a TypedArray over the whole buffer.\n      return view.buffer;\n    }\n    // This is a 'view' on the buffer.  Create a new buffer that only contains\n    // the data.  Note that since this isn't an ArrayBuffer, the 'new' call\n    // will allocate a new buffer to hold the copy.\n    return new Uint8Array(view).buffer;\n  }\n}\n\nfunction toUint8(data, offset = 0, length = Infinity) {\n  return view(data, offset, length, Uint8Array);\n}\nfunction view(data, offset, length, Type) {\n  const buffer = unsafeGetArrayBuffer(data);\n  let bytesPerElement = 1;\n  if ('BYTES_PER_ELEMENT' in Type) {\n    bytesPerElement = Type.BYTES_PER_ELEMENT;\n  }\n  // Absolute end of the |data| view within |buffer|.\n  const dataOffset = isArrayBufferView(data) ? data.byteOffset : 0;\n  const dataEnd = (dataOffset + data.byteLength) / bytesPerElement;\n  // Absolute start of the result within |buffer|.\n  const rawStart = (dataOffset + offset) / bytesPerElement;\n  const start = Math.floor(Math.max(0, Math.min(rawStart, dataEnd)));\n  // Absolute end of the result within |buffer|.\n  const end = Math.floor(Math.min(start + Math.max(length, 0), dataEnd));\n  return new Type(buffer, start, end - start);\n}\nfunction unsafeGetArrayBuffer(view) {\n  if (view instanceof ArrayBuffer) {\n    return view;\n  } else {\n    return view.buffer;\n  }\n}\nfunction isArrayBufferView(obj) {\n  return obj && obj.buffer instanceof ArrayBuffer && obj.byteLength !== undefined && obj.byteOffset !== undefined;\n}\n\nfunction decodeId3ImageFrame(frame) {\n  const metadataFrame = {\n    key: frame.type,\n    description: '',\n    data: '',\n    mimeType: null,\n    pictureType: null\n  };\n  const utf8Encoding = 0x03;\n  if (frame.size < 2) {\n    return undefined;\n  }\n  if (frame.data[0] !== utf8Encoding) {\n    console.log('Ignore frame with unrecognized character ' + 'encoding');\n    return undefined;\n  }\n  const mimeTypeEndIndex = frame.data.subarray(1).indexOf(0);\n  if (mimeTypeEndIndex === -1) {\n    return undefined;\n  }\n  const mimeType = utf8ArrayToStr(toUint8(frame.data, 1, mimeTypeEndIndex));\n  const pictureType = frame.data[2 + mimeTypeEndIndex];\n  const descriptionEndIndex = frame.data.subarray(3 + mimeTypeEndIndex).indexOf(0);\n  if (descriptionEndIndex === -1) {\n    return undefined;\n  }\n  const description = utf8ArrayToStr(toUint8(frame.data, 3 + mimeTypeEndIndex, descriptionEndIndex));\n  let data;\n  if (mimeType === '-->') {\n    data = utf8ArrayToStr(toUint8(frame.data, 4 + mimeTypeEndIndex + descriptionEndIndex));\n  } else {\n    data = toArrayBuffer(frame.data.subarray(4 + mimeTypeEndIndex + descriptionEndIndex));\n  }\n  metadataFrame.mimeType = mimeType;\n  metadataFrame.pictureType = pictureType;\n  metadataFrame.description = description;\n  metadataFrame.data = data;\n  return metadataFrame;\n}\n\n/**\n * Decode an ID3 PRIV frame.\n *\n * @param frame - the ID3 PRIV frame\n *\n * @returns The decoded ID3 PRIV frame\n *\n * @internal\n *\n * @group ID3\n */\nfunction decodeId3PrivFrame(frame) {\n  /*\n  Format: <text string>\\0<binary data>\n  */\n  if (frame.size < 2) {\n    return undefined;\n  }\n  const owner = utf8ArrayToStr(frame.data, true);\n  const privateData = new Uint8Array(frame.data.subarray(owner.length + 1));\n  return {\n    key: frame.type,\n    info: owner,\n    data: privateData.buffer\n  };\n}\n\n/**\n * Decodes an ID3 text frame\n *\n * @param frame - the ID3 text frame\n *\n * @returns The decoded ID3 text frame\n *\n * @internal\n *\n * @group ID3\n */\nfunction decodeId3TextFrame(frame) {\n  if (frame.size < 2) {\n    return undefined;\n  }\n  if (frame.type === 'TXXX') {\n    /*\n    Format:\n    [0]   = {Text Encoding}\n    [1-?] = {Description}\\0{Value}\n    */\n    let index = 1;\n    const description = utf8ArrayToStr(frame.data.subarray(index), true);\n    index += description.length + 1;\n    const value = utf8ArrayToStr(frame.data.subarray(index));\n    return {\n      key: frame.type,\n      info: description,\n      data: value\n    };\n  }\n  /*\n  Format:\n  [0]   = {Text Encoding}\n  [1-?] = {Value}\n  */\n  const text = utf8ArrayToStr(frame.data.subarray(1));\n  return {\n    key: frame.type,\n    info: '',\n    data: text\n  };\n}\n\n/**\n * Decode a URL frame\n *\n * @param frame - the ID3 URL frame\n *\n * @returns The decoded ID3 URL frame\n *\n * @internal\n *\n * @group ID3\n */\nfunction decodeId3UrlFrame(frame) {\n  if (frame.type === 'WXXX') {\n    /*\n    Format:\n    [0]   = {Text Encoding}\n    [1-?] = {Description}\\0{URL}\n    */\n    if (frame.size < 2) {\n      return undefined;\n    }\n    let index = 1;\n    const description = utf8ArrayToStr(frame.data.subarray(index), true);\n    index += description.length + 1;\n    const value = utf8ArrayToStr(frame.data.subarray(index));\n    return {\n      key: frame.type,\n      info: description,\n      data: value\n    };\n  }\n  /*\n  Format:\n  [0-?] = {URL}\n  */\n  const url = utf8ArrayToStr(frame.data);\n  return {\n    key: frame.type,\n    info: '',\n    data: url\n  };\n}\n\n/**\n * Decode an ID3 frame.\n *\n * @param frame - the ID3 frame\n *\n * @returns The decoded ID3 frame\n *\n * @internal\n *\n * @group ID3\n */\nfunction decodeId3Frame(frame) {\n  if (frame.type === 'PRIV') {\n    return decodeId3PrivFrame(frame);\n  } else if (frame.type[0] === 'W') {\n    return decodeId3UrlFrame(frame);\n  } else if (frame.type === 'APIC') {\n    return decodeId3ImageFrame(frame);\n  }\n  return decodeId3TextFrame(frame);\n}\n\n/**\n * Returns the data of an ID3 frame.\n *\n * @param data - The data to read from\n *\n * @returns The data of the ID3 frame\n *\n * @internal\n *\n * @group ID3\n */\nfunction getId3FrameData(data) {\n  /*\n  Frame ID       $xx xx xx xx (four characters)\n  Size           $xx xx xx xx\n  Flags          $xx xx\n  */\n  const type = String.fromCharCode(data[0], data[1], data[2], data[3]);\n  const size = readId3Size(data, 4);\n  // skip frame id, size, and flags\n  const offset = 10;\n  return {\n    type,\n    size,\n    data: data.subarray(offset, offset + size)\n  };\n}\n\nconst HEADER_FOOTER_SIZE = 10;\nconst FRAME_SIZE = 10;\n/**\n * Returns an array of ID3 frames found in all the ID3 tags in the id3Data\n *\n * @param id3Data - The ID3 data containing one or more ID3 tags\n *\n * @returns Array of ID3 frame objects\n *\n * @group ID3\n *\n * @beta\n */\nfunction getId3Frames(id3Data) {\n  let offset = 0;\n  const frames = [];\n  while (isId3Header(id3Data, offset)) {\n    const size = readId3Size(id3Data, offset + 6);\n    if (id3Data[offset + 5] >> 6 & 1) {\n      // skip extended header\n      offset += HEADER_FOOTER_SIZE;\n    }\n    // skip past ID3 header\n    offset += HEADER_FOOTER_SIZE;\n    const end = offset + size;\n    // loop through frames in the ID3 tag\n    while (offset + FRAME_SIZE < end) {\n      const frameData = getId3FrameData(id3Data.subarray(offset));\n      const frame = decodeId3Frame(frameData);\n      if (frame) {\n        frames.push(frame);\n      }\n      // skip frame header and frame data\n      offset += frameData.size + HEADER_FOOTER_SIZE;\n    }\n    if (isId3Footer(id3Data, offset)) {\n      offset += HEADER_FOOTER_SIZE;\n    }\n  }\n  return frames;\n}\n\n/**\n * Returns true if the ID3 frame is an Elementary Stream timestamp frame\n *\n * @param frame - the ID3 frame\n *\n * @returns `true` if the ID3 frame is an Elementary Stream timestamp frame\n *\n * @internal\n *\n * @group ID3\n */\nfunction isId3TimestampFrame(frame) {\n  return frame && frame.key === 'PRIV' && frame.info === 'com.apple.streaming.transportStreamTimestamp';\n}\n\n/**\n * Read a 33 bit timestamp from an ID3 frame.\n *\n * @param timeStampFrame - the ID3 frame\n *\n * @returns The timestamp\n *\n * @internal\n *\n * @group ID3\n */\nfunction readId3Timestamp(timeStampFrame) {\n  if (timeStampFrame.data.byteLength === 8) {\n    const data = new Uint8Array(timeStampFrame.data);\n    // timestamp is 33 bit expressed as a big-endian eight-octet number,\n    // with the upper 31 bits set to zero.\n    const pts33Bit = data[3] & 0x1;\n    let timestamp = (data[4] << 23) + (data[5] << 15) + (data[6] << 7) + data[7];\n    timestamp /= 45;\n    if (pts33Bit) {\n      timestamp += 47721858.84;\n    } // 2^32 / 90\n    return Math.round(timestamp);\n  }\n  return undefined;\n}\n\n/**\n * Searches for the Elementary Stream timestamp found in the ID3 data chunk\n *\n * @param data - Block of data containing one or more ID3 tags\n *\n * @returns The timestamp\n *\n * @group ID3\n *\n * @beta\n */\nfunction getId3Timestamp(data) {\n  const frames = getId3Frames(data);\n  for (let i = 0; i < frames.length; i++) {\n    const frame = frames[i];\n    if (isId3TimestampFrame(frame)) {\n      return readId3Timestamp(frame);\n    }\n  }\n  return undefined;\n}\n\nlet MetadataSchema = /*#__PURE__*/function (MetadataSchema) {\n  MetadataSchema[\"audioId3\"] = \"org.id3\";\n  MetadataSchema[\"dateRange\"] = \"com.apple.quicktime.HLS\";\n  MetadataSchema[\"emsg\"] = \"https://aomedia.org/emsg/ID3\";\n  MetadataSchema[\"misbklv\"] = \"urn:misb:KLV:bin:1910.1\";\n  return MetadataSchema;\n}({});\n\nfunction dummyTrack(type = '', inputTimeScale = 90000) {\n  return {\n    type,\n    id: -1,\n    pid: -1,\n    inputTimeScale,\n    sequenceNumber: -1,\n    samples: [],\n    dropped: 0\n  };\n}\n\nclass BaseAudioDemuxer {\n  constructor() {\n    this._audioTrack = void 0;\n    this._id3Track = void 0;\n    this.frameIndex = 0;\n    this.cachedData = null;\n    this.basePTS = null;\n    this.initPTS = null;\n    this.lastPTS = null;\n  }\n  resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration) {\n    this._id3Track = {\n      type: 'id3',\n      id: 3,\n      pid: -1,\n      inputTimeScale: 90000,\n      sequenceNumber: 0,\n      samples: [],\n      dropped: 0\n    };\n  }\n  resetTimeStamp(deaultTimestamp) {\n    this.initPTS = deaultTimestamp;\n    this.resetContiguity();\n  }\n  resetContiguity() {\n    this.basePTS = null;\n    this.lastPTS = null;\n    this.frameIndex = 0;\n  }\n  canParse(data, offset) {\n    return false;\n  }\n  appendFrame(track, data, offset) {}\n\n  // feed incoming data to the front of the parsing pipeline\n  demux(data, timeOffset) {\n    if (this.cachedData) {\n      data = appendUint8Array(this.cachedData, data);\n      this.cachedData = null;\n    }\n    let id3Data = getId3Data(data, 0);\n    let offset = id3Data ? id3Data.length : 0;\n    let lastDataIndex;\n    const track = this._audioTrack;\n    const id3Track = this._id3Track;\n    const timestamp = id3Data ? getId3Timestamp(id3Data) : undefined;\n    const length = data.length;\n    if (this.basePTS === null || this.frameIndex === 0 && isFiniteNumber(timestamp)) {\n      this.basePTS = initPTSFn(timestamp, timeOffset, this.initPTS);\n      this.lastPTS = this.basePTS;\n    }\n    if (this.lastPTS === null) {\n      this.lastPTS = this.basePTS;\n    }\n\n    // more expressive than alternative: id3Data?.length\n    if (id3Data && id3Data.length > 0) {\n      id3Track.samples.push({\n        pts: this.lastPTS,\n        dts: this.lastPTS,\n        data: id3Data,\n        type: MetadataSchema.audioId3,\n        duration: Number.POSITIVE_INFINITY\n      });\n    }\n    while (offset < length) {\n      if (this.canParse(data, offset)) {\n        const frame = this.appendFrame(track, data, offset);\n        if (frame) {\n          this.frameIndex++;\n          this.lastPTS = frame.sample.pts;\n          offset += frame.length;\n          lastDataIndex = offset;\n        } else {\n          offset = length;\n        }\n      } else if (canParseId3(data, offset)) {\n        // after a canParse, a call to getId3Data *should* always returns some data\n        id3Data = getId3Data(data, offset);\n        id3Track.samples.push({\n          pts: this.lastPTS,\n          dts: this.lastPTS,\n          data: id3Data,\n          type: MetadataSchema.audioId3,\n          duration: Number.POSITIVE_INFINITY\n        });\n        offset += id3Data.length;\n        lastDataIndex = offset;\n      } else {\n        offset++;\n      }\n      if (offset === length && lastDataIndex !== length) {\n        const partialData = data.slice(lastDataIndex);\n        if (this.cachedData) {\n          this.cachedData = appendUint8Array(this.cachedData, partialData);\n        } else {\n          this.cachedData = partialData;\n        }\n      }\n    }\n    return {\n      audioTrack: track,\n      videoTrack: dummyTrack(),\n      id3Track,\n      textTrack: dummyTrack()\n    };\n  }\n  demuxSampleAes(data, keyData, timeOffset) {\n    return Promise.reject(new Error(`[${this}] This demuxer does not support Sample-AES decryption`));\n  }\n  flush(timeOffset) {\n    // Parse cache in case of remaining frames.\n    const cachedData = this.cachedData;\n    if (cachedData) {\n      this.cachedData = null;\n      this.demux(cachedData, 0);\n    }\n    return {\n      audioTrack: this._audioTrack,\n      videoTrack: dummyTrack(),\n      id3Track: this._id3Track,\n      textTrack: dummyTrack()\n    };\n  }\n  destroy() {\n    this.cachedData = null;\n    // @ts-ignore\n    this._audioTrack = this._id3Track = undefined;\n  }\n}\n\n/**\n * Initialize PTS\n * <p>\n *    use timestamp unless it is undefined, NaN or Infinity\n * </p>\n */\nconst initPTSFn = (timestamp, timeOffset, initPTS) => {\n  if (isFiniteNumber(timestamp)) {\n    return timestamp * 90;\n  }\n  const init90kHz = initPTS ? initPTS.baseTime * 90000 / initPTS.timescale : 0;\n  return timeOffset * 90000 + init90kHz;\n};\n\n/**\n *  MPEG parser helper\n */\n\nlet chromeVersion$1 = null;\nconst BitratesMap = [32, 64, 96, 128, 160, 192, 224, 256, 288, 320, 352, 384, 416, 448, 32, 48, 56, 64, 80, 96, 112, 128, 160, 192, 224, 256, 320, 384, 32, 40, 48, 56, 64, 80, 96, 112, 128, 160, 192, 224, 256, 320, 32, 48, 56, 64, 80, 96, 112, 128, 144, 160, 176, 192, 224, 256, 8, 16, 24, 32, 40, 48, 56, 64, 80, 96, 112, 128, 144, 160];\nconst SamplingRateMap = [44100, 48000, 32000, 22050, 24000, 16000, 11025, 12000, 8000];\nconst SamplesCoefficients = [\n// MPEG 2.5\n[0,\n// Reserved\n72,\n// Layer3\n144,\n// Layer2\n12 // Layer1\n],\n// Reserved\n[0,\n// Reserved\n0,\n// Layer3\n0,\n// Layer2\n0 // Layer1\n],\n// MPEG 2\n[0,\n// Reserved\n72,\n// Layer3\n144,\n// Layer2\n12 // Layer1\n],\n// MPEG 1\n[0,\n// Reserved\n144,\n// Layer3\n144,\n// Layer2\n12 // Layer1\n]];\nconst BytesInSlot = [0,\n// Reserved\n1,\n// Layer3\n1,\n// Layer2\n4 // Layer1\n];\nfunction appendFrame$1(track, data, offset, pts, frameIndex) {\n  // Using http://www.datavoyage.com/mpgscript/mpeghdr.htm as a reference\n  if (offset + 24 > data.length) {\n    return;\n  }\n  const header = parseHeader(data, offset);\n  if (header && offset + header.frameLength <= data.length) {\n    const frameDuration = header.samplesPerFrame * 90000 / header.sampleRate;\n    const stamp = pts + frameIndex * frameDuration;\n    const sample = {\n      unit: data.subarray(offset, offset + header.frameLength),\n      pts: stamp,\n      dts: stamp\n    };\n    track.config = [];\n    track.channelCount = header.channelCount;\n    track.samplerate = header.sampleRate;\n    track.samples.push(sample);\n    return {\n      sample,\n      length: header.frameLength,\n      missing: 0\n    };\n  }\n}\nfunction parseHeader(data, offset) {\n  const mpegVersion = data[offset + 1] >> 3 & 3;\n  const mpegLayer = data[offset + 1] >> 1 & 3;\n  const bitRateIndex = data[offset + 2] >> 4 & 15;\n  const sampleRateIndex = data[offset + 2] >> 2 & 3;\n  if (mpegVersion !== 1 && bitRateIndex !== 0 && bitRateIndex !== 15 && sampleRateIndex !== 3) {\n    const paddingBit = data[offset + 2] >> 1 & 1;\n    const channelMode = data[offset + 3] >> 6;\n    const columnInBitrates = mpegVersion === 3 ? 3 - mpegLayer : mpegLayer === 3 ? 3 : 4;\n    const bitRate = BitratesMap[columnInBitrates * 14 + bitRateIndex - 1] * 1000;\n    const columnInSampleRates = mpegVersion === 3 ? 0 : mpegVersion === 2 ? 1 : 2;\n    const sampleRate = SamplingRateMap[columnInSampleRates * 3 + sampleRateIndex];\n    const channelCount = channelMode === 3 ? 1 : 2; // If bits of channel mode are `11` then it is a single channel (Mono)\n    const sampleCoefficient = SamplesCoefficients[mpegVersion][mpegLayer];\n    const bytesInSlot = BytesInSlot[mpegLayer];\n    const samplesPerFrame = sampleCoefficient * 8 * bytesInSlot;\n    const frameLength = Math.floor(sampleCoefficient * bitRate / sampleRate + paddingBit) * bytesInSlot;\n    if (chromeVersion$1 === null) {\n      const userAgent = navigator.userAgent || '';\n      const result = userAgent.match(/Chrome\\/(\\d+)/i);\n      chromeVersion$1 = result ? parseInt(result[1]) : 0;\n    }\n    const needChromeFix = !!chromeVersion$1 && chromeVersion$1 <= 87;\n    if (needChromeFix && mpegLayer === 2 && bitRate >= 224000 && channelMode === 0) {\n      // Work around bug in Chromium by setting channelMode to dual-channel (01) instead of stereo (00)\n      data[offset + 3] = data[offset + 3] | 0x80;\n    }\n    return {\n      sampleRate,\n      channelCount,\n      frameLength,\n      samplesPerFrame\n    };\n  }\n}\nfunction isHeaderPattern(data, offset) {\n  return data[offset] === 0xff && (data[offset + 1] & 0xe0) === 0xe0 && (data[offset + 1] & 0x06) !== 0x00;\n}\nfunction isHeader(data, offset) {\n  // Look for MPEG header | 1111 1111 | 111X XYZX | where X can be either 0 or 1 and Y or Z should be 1\n  // Layer bits (position 14 and 15) in header should be always different from 0 (Layer I or Layer II or Layer III)\n  // More info http://www.mp3-tech.org/programmer/frame_header.html\n  return offset + 1 < data.length && isHeaderPattern(data, offset);\n}\nfunction canParse(data, offset) {\n  const headerSize = 4;\n  return isHeaderPattern(data, offset) && headerSize <= data.length - offset;\n}\nfunction probe(data, offset) {\n  // same as isHeader but we also check that MPEG frame follows last MPEG frame\n  // or end of data is reached\n  if (offset + 1 < data.length && isHeaderPattern(data, offset)) {\n    // MPEG header Length\n    const headerLength = 4;\n    // MPEG frame Length\n    const header = parseHeader(data, offset);\n    let frameLength = headerLength;\n    if (header != null && header.frameLength) {\n      frameLength = header.frameLength;\n    }\n    const newOffset = offset + frameLength;\n    return newOffset === data.length || isHeader(data, newOffset);\n  }\n  return false;\n}\n\n/**\n * AAC demuxer\n */\nclass AACDemuxer extends BaseAudioDemuxer {\n  constructor(observer, config) {\n    super();\n    this.observer = void 0;\n    this.config = void 0;\n    this.observer = observer;\n    this.config = config;\n  }\n  resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration) {\n    super.resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration);\n    this._audioTrack = {\n      container: 'audio/adts',\n      type: 'audio',\n      id: 2,\n      pid: -1,\n      sequenceNumber: 0,\n      segmentCodec: 'aac',\n      samples: [],\n      manifestCodec: audioCodec,\n      duration: trackDuration,\n      inputTimeScale: 90000,\n      dropped: 0\n    };\n  }\n\n  // Source for probe info - https://wiki.multimedia.cx/index.php?title=ADTS\n  static probe(data, logger) {\n    if (!data) {\n      return false;\n    }\n\n    // Check for the ADTS sync word\n    // Look for ADTS header | 1111 1111 | 1111 X00X | where X can be either 0 or 1\n    // Layer bits (position 14 and 15) in header should be always 0 for ADTS\n    // More info https://wiki.multimedia.cx/index.php?title=ADTS\n    const id3Data = getId3Data(data, 0);\n    let offset = (id3Data == null ? void 0 : id3Data.length) || 0;\n    if (probe(data, offset)) {\n      return false;\n    }\n    for (let length = data.length; offset < length; offset++) {\n      if (probe$1(data, offset)) {\n        logger.log('ADTS sync word found !');\n        return true;\n      }\n    }\n    return false;\n  }\n  canParse(data, offset) {\n    return canParse$1(data, offset);\n  }\n  appendFrame(track, data, offset) {\n    initTrackConfig(track, this.observer, data, offset, track.manifestCodec);\n    const frame = appendFrame$2(track, data, offset, this.basePTS, this.frameIndex);\n    if (frame && frame.missing === 0) {\n      return frame;\n    }\n  }\n}\n\nconst getAudioBSID = (data, offset) => {\n  // check the bsid to confirm ac-3 | ec-3\n  let bsid = 0;\n  let numBits = 5;\n  offset += numBits;\n  const temp = new Uint32Array(1); // unsigned 32 bit for temporary storage\n  const mask = new Uint32Array(1); // unsigned 32 bit mask value\n  const byte = new Uint8Array(1); // unsigned 8 bit for temporary storage\n  while (numBits > 0) {\n    byte[0] = data[offset];\n    // read remaining bits, upto 8 bits at a time\n    const bits = Math.min(numBits, 8);\n    const shift = 8 - bits;\n    mask[0] = 0xff000000 >>> 24 + shift << shift;\n    temp[0] = (byte[0] & mask[0]) >> shift;\n    bsid = !bsid ? temp[0] : bsid << bits | temp[0];\n    offset += 1;\n    numBits -= bits;\n  }\n  return bsid;\n};\n\nclass AC3Demuxer extends BaseAudioDemuxer {\n  constructor(observer) {\n    super();\n    this.observer = void 0;\n    this.observer = observer;\n  }\n  resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration) {\n    super.resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration);\n    this._audioTrack = {\n      container: 'audio/ac-3',\n      type: 'audio',\n      id: 2,\n      pid: -1,\n      sequenceNumber: 0,\n      segmentCodec: 'ac3',\n      samples: [],\n      manifestCodec: audioCodec,\n      duration: trackDuration,\n      inputTimeScale: 90000,\n      dropped: 0\n    };\n  }\n  canParse(data, offset) {\n    return offset + 64 < data.length;\n  }\n  appendFrame(track, data, offset) {\n    const frameLength = appendFrame(track, data, offset, this.basePTS, this.frameIndex);\n    if (frameLength !== -1) {\n      const sample = track.samples[track.samples.length - 1];\n      return {\n        sample,\n        length: frameLength,\n        missing: 0\n      };\n    }\n  }\n  static probe(data) {\n    if (!data) {\n      return false;\n    }\n    const id3Data = getId3Data(data, 0);\n    if (!id3Data) {\n      return false;\n    }\n\n    // look for the ac-3 sync bytes\n    const offset = id3Data.length;\n    if (data[offset] === 0x0b && data[offset + 1] === 0x77 && getId3Timestamp(id3Data) !== undefined &&\n    // check the bsid to confirm ac-3\n    getAudioBSID(data, offset) < 16) {\n      return true;\n    }\n    return false;\n  }\n}\nfunction appendFrame(track, data, start, pts, frameIndex) {\n  if (start + 8 > data.length) {\n    return -1; // not enough bytes left\n  }\n  if (data[start] !== 0x0b || data[start + 1] !== 0x77) {\n    return -1; // invalid magic\n  }\n\n  // get sample rate\n  const samplingRateCode = data[start + 4] >> 6;\n  if (samplingRateCode >= 3) {\n    return -1; // invalid sampling rate\n  }\n  const samplingRateMap = [48000, 44100, 32000];\n  const sampleRate = samplingRateMap[samplingRateCode];\n\n  // get frame size\n  const frameSizeCode = data[start + 4] & 0x3f;\n  const frameSizeMap = [64, 69, 96, 64, 70, 96, 80, 87, 120, 80, 88, 120, 96, 104, 144, 96, 105, 144, 112, 121, 168, 112, 122, 168, 128, 139, 192, 128, 140, 192, 160, 174, 240, 160, 175, 240, 192, 208, 288, 192, 209, 288, 224, 243, 336, 224, 244, 336, 256, 278, 384, 256, 279, 384, 320, 348, 480, 320, 349, 480, 384, 417, 576, 384, 418, 576, 448, 487, 672, 448, 488, 672, 512, 557, 768, 512, 558, 768, 640, 696, 960, 640, 697, 960, 768, 835, 1152, 768, 836, 1152, 896, 975, 1344, 896, 976, 1344, 1024, 1114, 1536, 1024, 1115, 1536, 1152, 1253, 1728, 1152, 1254, 1728, 1280, 1393, 1920, 1280, 1394, 1920];\n  const frameLength = frameSizeMap[frameSizeCode * 3 + samplingRateCode] * 2;\n  if (start + frameLength > data.length) {\n    return -1;\n  }\n\n  // get channel count\n  const channelMode = data[start + 6] >> 5;\n  let skipCount = 0;\n  if (channelMode === 2) {\n    skipCount += 2;\n  } else {\n    if (channelMode & 1 && channelMode !== 1) {\n      skipCount += 2;\n    }\n    if (channelMode & 4) {\n      skipCount += 2;\n    }\n  }\n  const lfeon = (data[start + 6] << 8 | data[start + 7]) >> 12 - skipCount & 1;\n  const channelsMap = [2, 1, 2, 3, 3, 4, 4, 5];\n  const channelCount = channelsMap[channelMode] + lfeon;\n\n  // build dac3 box\n  const bsid = data[start + 5] >> 3;\n  const bsmod = data[start + 5] & 7;\n  const config = new Uint8Array([samplingRateCode << 6 | bsid << 1 | bsmod >> 2, (bsmod & 3) << 6 | channelMode << 3 | lfeon << 2 | frameSizeCode >> 4, frameSizeCode << 4 & 0xe0]);\n  const frameDuration = 1536 / sampleRate * 90000;\n  const stamp = pts + frameIndex * frameDuration;\n  const unit = data.subarray(start, start + frameLength);\n  track.config = config;\n  track.channelCount = channelCount;\n  track.samplerate = sampleRate;\n  track.samples.push({\n    unit,\n    pts: stamp\n  });\n  return frameLength;\n}\n\n/**\n * MP3 demuxer\n */\nclass MP3Demuxer extends BaseAudioDemuxer {\n  resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration) {\n    super.resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration);\n    this._audioTrack = {\n      container: 'audio/mpeg',\n      type: 'audio',\n      id: 2,\n      pid: -1,\n      sequenceNumber: 0,\n      segmentCodec: 'mp3',\n      samples: [],\n      manifestCodec: audioCodec,\n      duration: trackDuration,\n      inputTimeScale: 90000,\n      dropped: 0\n    };\n  }\n  static probe(data) {\n    if (!data) {\n      return false;\n    }\n\n    // check if data contains ID3 timestamp and MPEG sync word\n    // Look for MPEG header | 1111 1111 | 111X XYZX | where X can be either 0 or 1 and Y or Z should be 1\n    // Layer bits (position 14 and 15) in header should be always different from 0 (Layer I or Layer II or Layer III)\n    // More info http://www.mp3-tech.org/programmer/frame_header.html\n    const id3Data = getId3Data(data, 0);\n    let offset = (id3Data == null ? void 0 : id3Data.length) || 0;\n\n    // Check for ac-3|ec-3 sync bytes and return false if present\n    if (id3Data && data[offset] === 0x0b && data[offset + 1] === 0x77 && getId3Timestamp(id3Data) !== undefined &&\n    // check the bsid to confirm ac-3 or ec-3 (not mp3)\n    getAudioBSID(data, offset) <= 16) {\n      return false;\n    }\n    for (let length = data.length; offset < length; offset++) {\n      if (probe(data, offset)) {\n        logger.log('MPEG Audio sync word found !');\n        return true;\n      }\n    }\n    return false;\n  }\n  canParse(data, offset) {\n    return canParse(data, offset);\n  }\n  appendFrame(track, data, offset) {\n    if (this.basePTS === null) {\n      return;\n    }\n    return appendFrame$1(track, data, offset, this.basePTS, this.frameIndex);\n  }\n}\n\nconst emsgSchemePattern = /\\/emsg[-/]ID3/i;\nclass MP4Demuxer {\n  constructor(observer, config) {\n    this.remainderData = null;\n    this.timeOffset = 0;\n    this.config = void 0;\n    this.videoTrack = void 0;\n    this.audioTrack = void 0;\n    this.id3Track = void 0;\n    this.txtTrack = void 0;\n    this.config = config;\n  }\n  resetTimeStamp() {}\n  resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration) {\n    const videoTrack = this.videoTrack = dummyTrack('video', 1);\n    const audioTrack = this.audioTrack = dummyTrack('audio', 1);\n    const captionTrack = this.txtTrack = dummyTrack('text', 1);\n    this.id3Track = dummyTrack('id3', 1);\n    this.timeOffset = 0;\n    if (!(initSegment != null && initSegment.byteLength)) {\n      return;\n    }\n    const initData = parseInitSegment(initSegment);\n    if (initData.video) {\n      const {\n        id,\n        timescale,\n        codec,\n        supplemental\n      } = initData.video;\n      videoTrack.id = id;\n      videoTrack.timescale = captionTrack.timescale = timescale;\n      videoTrack.codec = codec;\n      videoTrack.supplemental = supplemental;\n    }\n    if (initData.audio) {\n      const {\n        id,\n        timescale,\n        codec\n      } = initData.audio;\n      audioTrack.id = id;\n      audioTrack.timescale = timescale;\n      audioTrack.codec = codec;\n    }\n    captionTrack.id = RemuxerTrackIdConfig.text;\n    videoTrack.sampleDuration = 0;\n    videoTrack.duration = audioTrack.duration = trackDuration;\n  }\n  resetContiguity() {\n    this.remainderData = null;\n  }\n  static probe(data) {\n    return hasMoofData(data);\n  }\n  demux(data, timeOffset) {\n    this.timeOffset = timeOffset;\n    // Load all data into the avc track. The CMAF remuxer will look for the data in the samples object; the rest of the fields do not matter\n    let videoSamples = data;\n    const videoTrack = this.videoTrack;\n    const textTrack = this.txtTrack;\n    if (this.config.progressive) {\n      // Split the bytestream into two ranges: one encompassing all data up until the start of the last moof, and everything else.\n      // This is done to guarantee that we're sending valid data to MSE - when demuxing progressively, we have no guarantee\n      // that the fetch loader gives us flush moof+mdat pairs. If we push jagged data to MSE, it will throw an exception.\n      if (this.remainderData) {\n        videoSamples = appendUint8Array(this.remainderData, data);\n      }\n      const segmentedData = segmentValidRange(videoSamples);\n      this.remainderData = segmentedData.remainder;\n      videoTrack.samples = segmentedData.valid || new Uint8Array();\n    } else {\n      videoTrack.samples = videoSamples;\n    }\n    const id3Track = this.extractID3Track(videoTrack, timeOffset);\n    textTrack.samples = parseSamples(timeOffset, videoTrack);\n    return {\n      videoTrack,\n      audioTrack: this.audioTrack,\n      id3Track,\n      textTrack: this.txtTrack\n    };\n  }\n  flush() {\n    const timeOffset = this.timeOffset;\n    const videoTrack = this.videoTrack;\n    const textTrack = this.txtTrack;\n    videoTrack.samples = this.remainderData || new Uint8Array();\n    this.remainderData = null;\n    const id3Track = this.extractID3Track(videoTrack, this.timeOffset);\n    textTrack.samples = parseSamples(timeOffset, videoTrack);\n    return {\n      videoTrack,\n      audioTrack: dummyTrack(),\n      id3Track,\n      textTrack: dummyTrack()\n    };\n  }\n  extractID3Track(videoTrack, timeOffset) {\n    const id3Track = this.id3Track;\n    if (videoTrack.samples.length) {\n      const emsgs = findBox(videoTrack.samples, ['emsg']);\n      if (emsgs) {\n        emsgs.forEach(data => {\n          const emsgInfo = parseEmsg(data);\n          if (emsgSchemePattern.test(emsgInfo.schemeIdUri)) {\n            const pts = getEmsgStartTime(emsgInfo, timeOffset);\n            let duration = emsgInfo.eventDuration === 0xffffffff ? Number.POSITIVE_INFINITY : emsgInfo.eventDuration / emsgInfo.timeScale;\n            // Safari takes anything <= 0.001 seconds and maps it to Infinity\n            if (duration <= 0.001) {\n              duration = Number.POSITIVE_INFINITY;\n            }\n            const payload = emsgInfo.payload;\n            id3Track.samples.push({\n              data: payload,\n              len: payload.byteLength,\n              dts: pts,\n              pts: pts,\n              type: MetadataSchema.emsg,\n              duration: duration\n            });\n          } else if (this.config.enableEmsgKLVMetadata && emsgInfo.schemeIdUri.startsWith('urn:misb:KLV:bin:1910.1')) {\n            const pts = getEmsgStartTime(emsgInfo, timeOffset);\n            id3Track.samples.push({\n              data: emsgInfo.payload,\n              len: emsgInfo.payload.byteLength,\n              dts: pts,\n              pts: pts,\n              type: MetadataSchema.misbklv,\n              duration: Number.POSITIVE_INFINITY\n            });\n          }\n        });\n      }\n    }\n    return id3Track;\n  }\n  demuxSampleAes(data, keyData, timeOffset) {\n    return Promise.reject(new Error('The MP4 demuxer does not support SAMPLE-AES decryption'));\n  }\n  destroy() {\n    // @ts-ignore\n    this.config = null;\n    this.remainderData = null;\n    this.videoTrack = this.audioTrack = this.id3Track = this.txtTrack = undefined;\n  }\n}\nfunction getEmsgStartTime(emsgInfo, timeOffset) {\n  return isFiniteNumber(emsgInfo.presentationTime) ? emsgInfo.presentationTime / emsgInfo.timeScale : timeOffset + emsgInfo.presentationTimeDelta / emsgInfo.timeScale;\n}\n\n/**\n * SAMPLE-AES decrypter\n */\n\nclass SampleAesDecrypter {\n  constructor(observer, config, keyData) {\n    this.keyData = void 0;\n    this.decrypter = void 0;\n    this.keyData = keyData;\n    this.decrypter = new Decrypter(config, {\n      removePKCS7Padding: false\n    });\n  }\n  decryptBuffer(encryptedData) {\n    return this.decrypter.decrypt(encryptedData, this.keyData.key.buffer, this.keyData.iv.buffer, DecrypterAesMode.cbc);\n  }\n\n  // AAC - encrypt all full 16 bytes blocks starting from offset 16\n  decryptAacSample(samples, sampleIndex, callback) {\n    const curUnit = samples[sampleIndex].unit;\n    if (curUnit.length <= 16) {\n      // No encrypted portion in this sample (first 16 bytes is not\n      // encrypted, see https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/HLS_Sample_Encryption/Encryption/Encryption.html),\n      return;\n    }\n    const encryptedData = curUnit.subarray(16, curUnit.length - curUnit.length % 16);\n    const encryptedBuffer = encryptedData.buffer.slice(encryptedData.byteOffset, encryptedData.byteOffset + encryptedData.length);\n    this.decryptBuffer(encryptedBuffer).then(decryptedBuffer => {\n      const decryptedData = new Uint8Array(decryptedBuffer);\n      curUnit.set(decryptedData, 16);\n      if (!this.decrypter.isSync()) {\n        this.decryptAacSamples(samples, sampleIndex + 1, callback);\n      }\n    }).catch(callback);\n  }\n  decryptAacSamples(samples, sampleIndex, callback) {\n    for (;; sampleIndex++) {\n      if (sampleIndex >= samples.length) {\n        callback();\n        return;\n      }\n      if (samples[sampleIndex].unit.length < 32) {\n        continue;\n      }\n      this.decryptAacSample(samples, sampleIndex, callback);\n      if (!this.decrypter.isSync()) {\n        return;\n      }\n    }\n  }\n\n  // AVC - encrypt one 16 bytes block out of ten, starting from offset 32\n  getAvcEncryptedData(decodedData) {\n    const encryptedDataLen = Math.floor((decodedData.length - 48) / 160) * 16 + 16;\n    const encryptedData = new Int8Array(encryptedDataLen);\n    let outputPos = 0;\n    for (let inputPos = 32; inputPos < decodedData.length - 16; inputPos += 160, outputPos += 16) {\n      encryptedData.set(decodedData.subarray(inputPos, inputPos + 16), outputPos);\n    }\n    return encryptedData;\n  }\n  getAvcDecryptedUnit(decodedData, decryptedData) {\n    const uint8DecryptedData = new Uint8Array(decryptedData);\n    let inputPos = 0;\n    for (let outputPos = 32; outputPos < decodedData.length - 16; outputPos += 160, inputPos += 16) {\n      decodedData.set(uint8DecryptedData.subarray(inputPos, inputPos + 16), outputPos);\n    }\n    return decodedData;\n  }\n  decryptAvcSample(samples, sampleIndex, unitIndex, callback, curUnit) {\n    const decodedData = discardEPB(curUnit.data);\n    const encryptedData = this.getAvcEncryptedData(decodedData);\n    this.decryptBuffer(encryptedData.buffer).then(decryptedBuffer => {\n      curUnit.data = this.getAvcDecryptedUnit(decodedData, decryptedBuffer);\n      if (!this.decrypter.isSync()) {\n        this.decryptAvcSamples(samples, sampleIndex, unitIndex + 1, callback);\n      }\n    }).catch(callback);\n  }\n  decryptAvcSamples(samples, sampleIndex, unitIndex, callback) {\n    if (samples instanceof Uint8Array) {\n      throw new Error('Cannot decrypt samples of type Uint8Array');\n    }\n    for (;; sampleIndex++, unitIndex = 0) {\n      if (sampleIndex >= samples.length) {\n        callback();\n        return;\n      }\n      const curUnits = samples[sampleIndex].units;\n      for (;; unitIndex++) {\n        if (unitIndex >= curUnits.length) {\n          break;\n        }\n        const curUnit = curUnits[unitIndex];\n        if (curUnit.data.length <= 48 || curUnit.type !== 1 && curUnit.type !== 5) {\n          continue;\n        }\n        this.decryptAvcSample(samples, sampleIndex, unitIndex, callback, curUnit);\n        if (!this.decrypter.isSync()) {\n          return;\n        }\n      }\n    }\n  }\n}\n\nclass BaseVideoParser {\n  constructor() {\n    this.VideoSample = null;\n  }\n  createVideoSample(key, pts, dts) {\n    return {\n      key,\n      frame: false,\n      pts,\n      dts,\n      units: [],\n      length: 0\n    };\n  }\n  getLastNalUnit(samples) {\n    var _VideoSample;\n    let VideoSample = this.VideoSample;\n    let lastUnit;\n    // try to fallback to previous sample if current one is empty\n    if (!VideoSample || VideoSample.units.length === 0) {\n      VideoSample = samples[samples.length - 1];\n    }\n    if ((_VideoSample = VideoSample) != null && _VideoSample.units) {\n      const units = VideoSample.units;\n      lastUnit = units[units.length - 1];\n    }\n    return lastUnit;\n  }\n  pushAccessUnit(VideoSample, videoTrack) {\n    if (VideoSample.units.length && VideoSample.frame) {\n      // if sample does not have PTS/DTS, patch with last sample PTS/DTS\n      if (VideoSample.pts === undefined) {\n        const samples = videoTrack.samples;\n        const nbSamples = samples.length;\n        if (nbSamples) {\n          const lastSample = samples[nbSamples - 1];\n          VideoSample.pts = lastSample.pts;\n          VideoSample.dts = lastSample.dts;\n        } else {\n          // dropping samples, no timestamp found\n          videoTrack.dropped++;\n          return;\n        }\n      }\n      videoTrack.samples.push(VideoSample);\n    }\n  }\n  parseNALu(track, array, endOfSegment) {\n    const len = array.byteLength;\n    let state = track.naluState || 0;\n    const lastState = state;\n    const units = [];\n    let i = 0;\n    let value;\n    let overflow;\n    let unitType;\n    let lastUnitStart = -1;\n    let lastUnitType = 0;\n    // logger.log('PES:' + Hex.hexDump(array));\n\n    if (state === -1) {\n      // special use case where we found 3 or 4-byte start codes exactly at the end of previous PES packet\n      lastUnitStart = 0;\n      // NALu type is value read from offset 0\n      lastUnitType = this.getNALuType(array, 0);\n      state = 0;\n      i = 1;\n    }\n    while (i < len) {\n      value = array[i++];\n      // optimization. state 0 and 1 are the predominant case. let's handle them outside of the switch/case\n      if (!state) {\n        state = value ? 0 : 1;\n        continue;\n      }\n      if (state === 1) {\n        state = value ? 0 : 2;\n        continue;\n      }\n      // here we have state either equal to 2 or 3\n      if (!value) {\n        state = 3;\n      } else if (value === 1) {\n        overflow = i - state - 1;\n        if (lastUnitStart >= 0) {\n          const unit = {\n            data: array.subarray(lastUnitStart, overflow),\n            type: lastUnitType\n          };\n          // logger.log('pushing NALU, type/size:' + unit.type + '/' + unit.data.byteLength);\n          units.push(unit);\n        } else {\n          // lastUnitStart is undefined => this is the first start code found in this PES packet\n          // first check if start code delimiter is overlapping between 2 PES packets,\n          // ie it started in last packet (lastState not zero)\n          // and ended at the beginning of this PES packet (i <= 4 - lastState)\n          const lastUnit = this.getLastNalUnit(track.samples);\n          if (lastUnit) {\n            if (lastState && i <= 4 - lastState) {\n              // start delimiter overlapping between PES packets\n              // strip start delimiter bytes from the end of last NAL unit\n              // check if lastUnit had a state different from zero\n              if (lastUnit.state) {\n                // strip last bytes\n                lastUnit.data = lastUnit.data.subarray(0, lastUnit.data.byteLength - lastState);\n              }\n            }\n            // If NAL units are not starting right at the beginning of the PES packet, push preceding data into previous NAL unit.\n\n            if (overflow > 0) {\n              // logger.log('first NALU found with overflow:' + overflow);\n              lastUnit.data = appendUint8Array(lastUnit.data, array.subarray(0, overflow));\n              lastUnit.state = 0;\n            }\n          }\n        }\n        // check if we can read unit type\n        if (i < len) {\n          unitType = this.getNALuType(array, i);\n          // logger.log('find NALU @ offset:' + i + ',type:' + unitType);\n          lastUnitStart = i;\n          lastUnitType = unitType;\n          state = 0;\n        } else {\n          // not enough byte to read unit type. let's read it on next PES parsing\n          state = -1;\n        }\n      } else {\n        state = 0;\n      }\n    }\n    if (lastUnitStart >= 0 && state >= 0) {\n      const unit = {\n        data: array.subarray(lastUnitStart, len),\n        type: lastUnitType,\n        state: state\n      };\n      units.push(unit);\n      // logger.log('pushing NALU, type/size/state:' + unit.type + '/' + unit.data.byteLength + '/' + state);\n    }\n    // no NALu found\n    if (units.length === 0) {\n      // append pes.data to previous NAL unit\n      const lastUnit = this.getLastNalUnit(track.samples);\n      if (lastUnit) {\n        lastUnit.data = appendUint8Array(lastUnit.data, array);\n      }\n    }\n    track.naluState = state;\n    return units;\n  }\n}\n\n/**\n * Parser for exponential Golomb codes, a variable-bitwidth number encoding scheme used by h264.\n */\n\nclass ExpGolomb {\n  constructor(data) {\n    this.data = void 0;\n    this.bytesAvailable = void 0;\n    this.word = void 0;\n    this.bitsAvailable = void 0;\n    this.data = data;\n    // the number of bytes left to examine in this.data\n    this.bytesAvailable = data.byteLength;\n    // the current word being examined\n    this.word = 0; // :uint\n    // the number of bits left to examine in the current word\n    this.bitsAvailable = 0; // :uint\n  }\n\n  // ():void\n  loadWord() {\n    const data = this.data;\n    const bytesAvailable = this.bytesAvailable;\n    const position = data.byteLength - bytesAvailable;\n    const workingBytes = new Uint8Array(4);\n    const availableBytes = Math.min(4, bytesAvailable);\n    if (availableBytes === 0) {\n      throw new Error('no bytes available');\n    }\n    workingBytes.set(data.subarray(position, position + availableBytes));\n    this.word = new DataView(workingBytes.buffer).getUint32(0);\n    // track the amount of this.data that has been processed\n    this.bitsAvailable = availableBytes * 8;\n    this.bytesAvailable -= availableBytes;\n  }\n\n  // (count:int):void\n  skipBits(count) {\n    let skipBytes; // :int\n    count = Math.min(count, this.bytesAvailable * 8 + this.bitsAvailable);\n    if (this.bitsAvailable > count) {\n      this.word <<= count;\n      this.bitsAvailable -= count;\n    } else {\n      count -= this.bitsAvailable;\n      skipBytes = count >> 3;\n      count -= skipBytes << 3;\n      this.bytesAvailable -= skipBytes;\n      this.loadWord();\n      this.word <<= count;\n      this.bitsAvailable -= count;\n    }\n  }\n\n  // (size:int):uint\n  readBits(size) {\n    let bits = Math.min(this.bitsAvailable, size); // :uint\n    const valu = this.word >>> 32 - bits; // :uint\n    if (size > 32) {\n      logger.error('Cannot read more than 32 bits at a time');\n    }\n    this.bitsAvailable -= bits;\n    if (this.bitsAvailable > 0) {\n      this.word <<= bits;\n    } else if (this.bytesAvailable > 0) {\n      this.loadWord();\n    } else {\n      throw new Error('no bits available');\n    }\n    bits = size - bits;\n    if (bits > 0 && this.bitsAvailable) {\n      return valu << bits | this.readBits(bits);\n    } else {\n      return valu;\n    }\n  }\n\n  // ():uint\n  skipLZ() {\n    let leadingZeroCount; // :uint\n    for (leadingZeroCount = 0; leadingZeroCount < this.bitsAvailable; ++leadingZeroCount) {\n      if ((this.word & 0x80000000 >>> leadingZeroCount) !== 0) {\n        // the first bit of working word is 1\n        this.word <<= leadingZeroCount;\n        this.bitsAvailable -= leadingZeroCount;\n        return leadingZeroCount;\n      }\n    }\n    // we exhausted word and still have not found a 1\n    this.loadWord();\n    return leadingZeroCount + this.skipLZ();\n  }\n\n  // ():void\n  skipUEG() {\n    this.skipBits(1 + this.skipLZ());\n  }\n\n  // ():void\n  skipEG() {\n    this.skipBits(1 + this.skipLZ());\n  }\n\n  // ():uint\n  readUEG() {\n    const clz = this.skipLZ(); // :uint\n    return this.readBits(clz + 1) - 1;\n  }\n\n  // ():int\n  readEG() {\n    const valu = this.readUEG(); // :int\n    if (0x01 & valu) {\n      // the number is odd if the low order bit is set\n      return 1 + valu >>> 1; // add 1 to make it even, and divide by 2\n    } else {\n      return -1 * (valu >>> 1); // divide by two then make it negative\n    }\n  }\n\n  // Some convenience functions\n  // :Boolean\n  readBoolean() {\n    return this.readBits(1) === 1;\n  }\n\n  // ():int\n  readUByte() {\n    return this.readBits(8);\n  }\n\n  // ():int\n  readUShort() {\n    return this.readBits(16);\n  }\n\n  // ():int\n  readUInt() {\n    return this.readBits(32);\n  }\n}\n\nclass AvcVideoParser extends BaseVideoParser {\n  parsePES(track, textTrack, pes, endOfSegment) {\n    const units = this.parseNALu(track, pes.data, endOfSegment);\n    let VideoSample = this.VideoSample;\n    let push;\n    let spsfound = false;\n    // free pes.data to save up some memory\n    pes.data = null;\n\n    // if new NAL units found and last sample still there, let's push ...\n    // this helps parsing streams with missing AUD (only do this if AUD never found)\n    if (VideoSample && units.length && !track.audFound) {\n      this.pushAccessUnit(VideoSample, track);\n      VideoSample = this.VideoSample = this.createVideoSample(false, pes.pts, pes.dts);\n    }\n    units.forEach(unit => {\n      var _VideoSample2, _VideoSample3;\n      switch (unit.type) {\n        // NDR\n        case 1:\n          {\n            let iskey = false;\n            push = true;\n            const data = unit.data;\n            // only check slice type to detect KF in case SPS found in same packet (any keyframe is preceded by SPS ...)\n            if (spsfound && data.length > 4) {\n              // retrieve slice type by parsing beginning of NAL unit (follow H264 spec, slice_header definition) to detect keyframe embedded in NDR\n              const sliceType = this.readSliceType(data);\n              // 2 : I slice, 4 : SI slice, 7 : I slice, 9: SI slice\n              // SI slice : A slice that is coded using intra prediction only and using quantisation of the prediction samples.\n              // An SI slice can be coded such that its decoded samples can be constructed identically to an SP slice.\n              // I slice: A slice that is not an SI slice that is decoded using intra prediction only.\n              // if (sliceType === 2 || sliceType === 7) {\n              if (sliceType === 2 || sliceType === 4 || sliceType === 7 || sliceType === 9) {\n                iskey = true;\n              }\n            }\n            if (iskey) {\n              var _VideoSample;\n              // if we have non-keyframe data already, that cannot belong to the same frame as a keyframe, so force a push\n              if ((_VideoSample = VideoSample) != null && _VideoSample.frame && !VideoSample.key) {\n                this.pushAccessUnit(VideoSample, track);\n                VideoSample = this.VideoSample = null;\n              }\n            }\n            if (!VideoSample) {\n              VideoSample = this.VideoSample = this.createVideoSample(true, pes.pts, pes.dts);\n            }\n            VideoSample.frame = true;\n            VideoSample.key = iskey;\n            break;\n            // IDR\n          }\n        case 5:\n          push = true;\n          // handle PES not starting with AUD\n          // if we have frame data already, that cannot belong to the same frame, so force a push\n          if ((_VideoSample2 = VideoSample) != null && _VideoSample2.frame && !VideoSample.key) {\n            this.pushAccessUnit(VideoSample, track);\n            VideoSample = this.VideoSample = null;\n          }\n          if (!VideoSample) {\n            VideoSample = this.VideoSample = this.createVideoSample(true, pes.pts, pes.dts);\n          }\n          VideoSample.key = true;\n          VideoSample.frame = true;\n          break;\n        // SEI\n        case 6:\n          {\n            push = true;\n            parseSEIMessageFromNALu(unit.data, 1, pes.pts, textTrack.samples);\n            break;\n            // SPS\n          }\n        case 7:\n          {\n            var _track$pixelRatio, _track$pixelRatio2;\n            push = true;\n            spsfound = true;\n            const sps = unit.data;\n            const config = this.readSPS(sps);\n            if (!track.sps || track.width !== config.width || track.height !== config.height || ((_track$pixelRatio = track.pixelRatio) == null ? void 0 : _track$pixelRatio[0]) !== config.pixelRatio[0] || ((_track$pixelRatio2 = track.pixelRatio) == null ? void 0 : _track$pixelRatio2[1]) !== config.pixelRatio[1]) {\n              track.width = config.width;\n              track.height = config.height;\n              track.pixelRatio = config.pixelRatio;\n              track.sps = [sps];\n              const codecarray = sps.subarray(1, 4);\n              let codecstring = 'avc1.';\n              for (let i = 0; i < 3; i++) {\n                let h = codecarray[i].toString(16);\n                if (h.length < 2) {\n                  h = '0' + h;\n                }\n                codecstring += h;\n              }\n              track.codec = codecstring;\n            }\n            break;\n          }\n        // PPS\n        case 8:\n          push = true;\n          track.pps = [unit.data];\n          break;\n        // AUD\n        case 9:\n          push = true;\n          track.audFound = true;\n          if ((_VideoSample3 = VideoSample) != null && _VideoSample3.frame) {\n            this.pushAccessUnit(VideoSample, track);\n            VideoSample = null;\n          }\n          if (!VideoSample) {\n            VideoSample = this.VideoSample = this.createVideoSample(false, pes.pts, pes.dts);\n          }\n          break;\n        // Filler Data\n        case 12:\n          push = true;\n          break;\n        default:\n          push = false;\n          break;\n      }\n      if (VideoSample && push) {\n        const units = VideoSample.units;\n        units.push(unit);\n      }\n    });\n    // if last PES packet, push samples\n    if (endOfSegment && VideoSample) {\n      this.pushAccessUnit(VideoSample, track);\n      this.VideoSample = null;\n    }\n  }\n  getNALuType(data, offset) {\n    return data[offset] & 0x1f;\n  }\n  readSliceType(data) {\n    const eg = new ExpGolomb(data);\n    // skip NALu type\n    eg.readUByte();\n    // discard first_mb_in_slice\n    eg.readUEG();\n    // return slice_type\n    return eg.readUEG();\n  }\n\n  /**\n   * The scaling list is optionally transmitted as part of a sequence parameter\n   * set and is not relevant to transmuxing.\n   * @param count the number of entries in this scaling list\n   * @see Recommendation ITU-T H.264, Section 7.3.2.1.1.1\n   */\n  skipScalingList(count, reader) {\n    let lastScale = 8;\n    let nextScale = 8;\n    let deltaScale;\n    for (let j = 0; j < count; j++) {\n      if (nextScale !== 0) {\n        deltaScale = reader.readEG();\n        nextScale = (lastScale + deltaScale + 256) % 256;\n      }\n      lastScale = nextScale === 0 ? lastScale : nextScale;\n    }\n  }\n\n  /**\n   * Read a sequence parameter set and return some interesting video\n   * properties. A sequence parameter set is the H264 metadata that\n   * describes the properties of upcoming video frames.\n   * @returns an object with configuration parsed from the\n   * sequence parameter set, including the dimensions of the\n   * associated video frames.\n   */\n  readSPS(sps) {\n    const eg = new ExpGolomb(sps);\n    let frameCropLeftOffset = 0;\n    let frameCropRightOffset = 0;\n    let frameCropTopOffset = 0;\n    let frameCropBottomOffset = 0;\n    let numRefFramesInPicOrderCntCycle;\n    let scalingListCount;\n    let i;\n    const readUByte = eg.readUByte.bind(eg);\n    const readBits = eg.readBits.bind(eg);\n    const readUEG = eg.readUEG.bind(eg);\n    const readBoolean = eg.readBoolean.bind(eg);\n    const skipBits = eg.skipBits.bind(eg);\n    const skipEG = eg.skipEG.bind(eg);\n    const skipUEG = eg.skipUEG.bind(eg);\n    const skipScalingList = this.skipScalingList.bind(this);\n    readUByte();\n    const profileIdc = readUByte(); // profile_idc\n    readBits(5); // profileCompat constraint_set[0-4]_flag, u(5)\n    skipBits(3); // reserved_zero_3bits u(3),\n    readUByte(); // level_idc u(8)\n    skipUEG(); // seq_parameter_set_id\n    // some profiles have more optional data we don't need\n    if (profileIdc === 100 || profileIdc === 110 || profileIdc === 122 || profileIdc === 244 || profileIdc === 44 || profileIdc === 83 || profileIdc === 86 || profileIdc === 118 || profileIdc === 128) {\n      const chromaFormatIdc = readUEG();\n      if (chromaFormatIdc === 3) {\n        skipBits(1);\n      } // separate_colour_plane_flag\n\n      skipUEG(); // bit_depth_luma_minus8\n      skipUEG(); // bit_depth_chroma_minus8\n      skipBits(1); // qpprime_y_zero_transform_bypass_flag\n      if (readBoolean()) {\n        // seq_scaling_matrix_present_flag\n        scalingListCount = chromaFormatIdc !== 3 ? 8 : 12;\n        for (i = 0; i < scalingListCount; i++) {\n          if (readBoolean()) {\n            // seq_scaling_list_present_flag[ i ]\n            if (i < 6) {\n              skipScalingList(16, eg);\n            } else {\n              skipScalingList(64, eg);\n            }\n          }\n        }\n      }\n    }\n    skipUEG(); // log2_max_frame_num_minus4\n    const picOrderCntType = readUEG();\n    if (picOrderCntType === 0) {\n      readUEG(); // log2_max_pic_order_cnt_lsb_minus4\n    } else if (picOrderCntType === 1) {\n      skipBits(1); // delta_pic_order_always_zero_flag\n      skipEG(); // offset_for_non_ref_pic\n      skipEG(); // offset_for_top_to_bottom_field\n      numRefFramesInPicOrderCntCycle = readUEG();\n      for (i = 0; i < numRefFramesInPicOrderCntCycle; i++) {\n        skipEG();\n      } // offset_for_ref_frame[ i ]\n    }\n    skipUEG(); // max_num_ref_frames\n    skipBits(1); // gaps_in_frame_num_value_allowed_flag\n    const picWidthInMbsMinus1 = readUEG();\n    const picHeightInMapUnitsMinus1 = readUEG();\n    const frameMbsOnlyFlag = readBits(1);\n    if (frameMbsOnlyFlag === 0) {\n      skipBits(1);\n    } // mb_adaptive_frame_field_flag\n\n    skipBits(1); // direct_8x8_inference_flag\n    if (readBoolean()) {\n      // frame_cropping_flag\n      frameCropLeftOffset = readUEG();\n      frameCropRightOffset = readUEG();\n      frameCropTopOffset = readUEG();\n      frameCropBottomOffset = readUEG();\n    }\n    let pixelRatio = [1, 1];\n    if (readBoolean()) {\n      // vui_parameters_present_flag\n      if (readBoolean()) {\n        // aspect_ratio_info_present_flag\n        const aspectRatioIdc = readUByte();\n        switch (aspectRatioIdc) {\n          case 1:\n            pixelRatio = [1, 1];\n            break;\n          case 2:\n            pixelRatio = [12, 11];\n            break;\n          case 3:\n            pixelRatio = [10, 11];\n            break;\n          case 4:\n            pixelRatio = [16, 11];\n            break;\n          case 5:\n            pixelRatio = [40, 33];\n            break;\n          case 6:\n            pixelRatio = [24, 11];\n            break;\n          case 7:\n            pixelRatio = [20, 11];\n            break;\n          case 8:\n            pixelRatio = [32, 11];\n            break;\n          case 9:\n            pixelRatio = [80, 33];\n            break;\n          case 10:\n            pixelRatio = [18, 11];\n            break;\n          case 11:\n            pixelRatio = [15, 11];\n            break;\n          case 12:\n            pixelRatio = [64, 33];\n            break;\n          case 13:\n            pixelRatio = [160, 99];\n            break;\n          case 14:\n            pixelRatio = [4, 3];\n            break;\n          case 15:\n            pixelRatio = [3, 2];\n            break;\n          case 16:\n            pixelRatio = [2, 1];\n            break;\n          case 255:\n            {\n              pixelRatio = [readUByte() << 8 | readUByte(), readUByte() << 8 | readUByte()];\n              break;\n            }\n        }\n      }\n    }\n    return {\n      width: Math.ceil((picWidthInMbsMinus1 + 1) * 16 - frameCropLeftOffset * 2 - frameCropRightOffset * 2),\n      height: (2 - frameMbsOnlyFlag) * (picHeightInMapUnitsMinus1 + 1) * 16 - (frameMbsOnlyFlag ? 2 : 4) * (frameCropTopOffset + frameCropBottomOffset),\n      pixelRatio: pixelRatio\n    };\n  }\n}\n\nclass HevcVideoParser extends BaseVideoParser {\n  constructor(...args) {\n    super(...args);\n    this.initVPS = null;\n  }\n  parsePES(track, textTrack, pes, endOfSegment) {\n    const units = this.parseNALu(track, pes.data, endOfSegment);\n    let VideoSample = this.VideoSample;\n    let push;\n    let spsfound = false;\n    // free pes.data to save up some memory\n    pes.data = null;\n\n    // if new NAL units found and last sample still there, let's push ...\n    // this helps parsing streams with missing AUD (only do this if AUD never found)\n    if (VideoSample && units.length && !track.audFound) {\n      this.pushAccessUnit(VideoSample, track);\n      VideoSample = this.VideoSample = this.createVideoSample(false, pes.pts, pes.dts);\n    }\n    units.forEach(unit => {\n      var _VideoSample2, _VideoSample3;\n      switch (unit.type) {\n        // NON-IDR, NON RANDOM ACCESS SLICE\n        case 0:\n        case 1:\n        case 2:\n        case 3:\n        case 4:\n        case 5:\n        case 6:\n        case 7:\n        case 8:\n        case 9:\n          if (!VideoSample) {\n            VideoSample = this.VideoSample = this.createVideoSample(false, pes.pts, pes.dts);\n          }\n          VideoSample.frame = true;\n          push = true;\n          break;\n\n        // CRA, BLA (random access picture)\n        case 16:\n        case 17:\n        case 18:\n        case 21:\n          push = true;\n          if (spsfound) {\n            var _VideoSample;\n            // handle PES not starting with AUD\n            // if we have frame data already, that cannot belong to the same frame, so force a push\n            if ((_VideoSample = VideoSample) != null && _VideoSample.frame && !VideoSample.key) {\n              this.pushAccessUnit(VideoSample, track);\n              VideoSample = this.VideoSample = null;\n            }\n          }\n          if (!VideoSample) {\n            VideoSample = this.VideoSample = this.createVideoSample(true, pes.pts, pes.dts);\n          }\n          VideoSample.key = true;\n          VideoSample.frame = true;\n          break;\n\n        // IDR\n        case 19:\n        case 20:\n          push = true;\n          // handle PES not starting with AUD\n          // if we have frame data already, that cannot belong to the same frame, so force a push\n          if ((_VideoSample2 = VideoSample) != null && _VideoSample2.frame && !VideoSample.key) {\n            this.pushAccessUnit(VideoSample, track);\n            VideoSample = this.VideoSample = null;\n          }\n          if (!VideoSample) {\n            VideoSample = this.VideoSample = this.createVideoSample(true, pes.pts, pes.dts);\n          }\n          VideoSample.key = true;\n          VideoSample.frame = true;\n          break;\n\n        // SEI\n        case 39:\n          push = true;\n          parseSEIMessageFromNALu(unit.data, 2,\n          // NALu header size\n          pes.pts, textTrack.samples);\n          break;\n\n        // VPS\n        case 32:\n          push = true;\n          if (!track.vps) {\n            if (typeof track.params !== 'object') {\n              track.params = {};\n            }\n            track.params = _extends(track.params, this.readVPS(unit.data));\n            this.initVPS = unit.data;\n          }\n          track.vps = [unit.data];\n          break;\n\n        // SPS\n        case 33:\n          push = true;\n          spsfound = true;\n          if (track.vps !== undefined && track.vps[0] !== this.initVPS && track.sps !== undefined && !this.matchSPS(track.sps[0], unit.data)) {\n            this.initVPS = track.vps[0];\n            track.sps = track.pps = undefined;\n          }\n          if (!track.sps) {\n            const config = this.readSPS(unit.data);\n            track.width = config.width;\n            track.height = config.height;\n            track.pixelRatio = config.pixelRatio;\n            track.codec = config.codecString;\n            track.sps = [];\n            if (typeof track.params !== 'object') {\n              track.params = {};\n            }\n            for (const prop in config.params) {\n              track.params[prop] = config.params[prop];\n            }\n          }\n          this.pushParameterSet(track.sps, unit.data, track.vps);\n          if (!VideoSample) {\n            VideoSample = this.VideoSample = this.createVideoSample(true, pes.pts, pes.dts);\n          }\n          VideoSample.key = true;\n          break;\n\n        // PPS\n        case 34:\n          push = true;\n          if (typeof track.params === 'object') {\n            if (!track.pps) {\n              track.pps = [];\n              const config = this.readPPS(unit.data);\n              for (const prop in config) {\n                track.params[prop] = config[prop];\n              }\n            }\n            this.pushParameterSet(track.pps, unit.data, track.vps);\n          }\n          break;\n\n        // ACCESS UNIT DELIMITER\n        case 35:\n          push = true;\n          track.audFound = true;\n          if ((_VideoSample3 = VideoSample) != null && _VideoSample3.frame) {\n            this.pushAccessUnit(VideoSample, track);\n            VideoSample = null;\n          }\n          if (!VideoSample) {\n            VideoSample = this.VideoSample = this.createVideoSample(false, pes.pts, pes.dts);\n          }\n          break;\n        default:\n          push = false;\n          break;\n      }\n      if (VideoSample && push) {\n        const units = VideoSample.units;\n        units.push(unit);\n      }\n    });\n    // if last PES packet, push samples\n    if (endOfSegment && VideoSample) {\n      this.pushAccessUnit(VideoSample, track);\n      this.VideoSample = null;\n    }\n  }\n  pushParameterSet(parameterSets, data, vps) {\n    if (vps && vps[0] === this.initVPS || !vps && !parameterSets.length) {\n      parameterSets.push(data);\n    }\n  }\n  getNALuType(data, offset) {\n    return (data[offset] & 0x7e) >>> 1;\n  }\n  ebsp2rbsp(arr) {\n    const dst = new Uint8Array(arr.byteLength);\n    let dstIdx = 0;\n    for (let i = 0; i < arr.byteLength; i++) {\n      if (i >= 2) {\n        // Unescape: Skip 0x03 after 00 00\n        if (arr[i] === 0x03 && arr[i - 1] === 0x00 && arr[i - 2] === 0x00) {\n          continue;\n        }\n      }\n      dst[dstIdx] = arr[i];\n      dstIdx++;\n    }\n    return new Uint8Array(dst.buffer, 0, dstIdx);\n  }\n  pushAccessUnit(VideoSample, videoTrack) {\n    super.pushAccessUnit(VideoSample, videoTrack);\n    if (this.initVPS) {\n      this.initVPS = null; // null initVPS to prevent possible track's sps/pps growth until next VPS\n    }\n  }\n  readVPS(vps) {\n    const eg = new ExpGolomb(vps);\n    // remove header\n    eg.readUByte();\n    eg.readUByte();\n    eg.readBits(4); // video_parameter_set_id\n    eg.skipBits(2);\n    eg.readBits(6); // max_layers_minus1\n    const max_sub_layers_minus1 = eg.readBits(3);\n    const temporal_id_nesting_flag = eg.readBoolean();\n    // ...vui fps can be here, but empty fps value is not critical for metadata\n\n    return {\n      numTemporalLayers: max_sub_layers_minus1 + 1,\n      temporalIdNested: temporal_id_nesting_flag\n    };\n  }\n  readSPS(sps) {\n    const eg = new ExpGolomb(this.ebsp2rbsp(sps));\n    eg.readUByte();\n    eg.readUByte();\n    eg.readBits(4); //video_parameter_set_id\n    const max_sub_layers_minus1 = eg.readBits(3);\n    eg.readBoolean(); // temporal_id_nesting_flag\n\n    // profile_tier_level\n    const general_profile_space = eg.readBits(2);\n    const general_tier_flag = eg.readBoolean();\n    const general_profile_idc = eg.readBits(5);\n    const general_profile_compatibility_flags_1 = eg.readUByte();\n    const general_profile_compatibility_flags_2 = eg.readUByte();\n    const general_profile_compatibility_flags_3 = eg.readUByte();\n    const general_profile_compatibility_flags_4 = eg.readUByte();\n    const general_constraint_indicator_flags_1 = eg.readUByte();\n    const general_constraint_indicator_flags_2 = eg.readUByte();\n    const general_constraint_indicator_flags_3 = eg.readUByte();\n    const general_constraint_indicator_flags_4 = eg.readUByte();\n    const general_constraint_indicator_flags_5 = eg.readUByte();\n    const general_constraint_indicator_flags_6 = eg.readUByte();\n    const general_level_idc = eg.readUByte();\n    const sub_layer_profile_present_flags = [];\n    const sub_layer_level_present_flags = [];\n    for (let i = 0; i < max_sub_layers_minus1; i++) {\n      sub_layer_profile_present_flags.push(eg.readBoolean());\n      sub_layer_level_present_flags.push(eg.readBoolean());\n    }\n    if (max_sub_layers_minus1 > 0) {\n      for (let i = max_sub_layers_minus1; i < 8; i++) {\n        eg.readBits(2);\n      }\n    }\n    for (let i = 0; i < max_sub_layers_minus1; i++) {\n      if (sub_layer_profile_present_flags[i]) {\n        eg.readUByte(); // sub_layer_profile_space, sub_layer_tier_flag, sub_layer_profile_idc\n        eg.readUByte();\n        eg.readUByte();\n        eg.readUByte();\n        eg.readUByte(); // sub_layer_profile_compatibility_flag\n        eg.readUByte();\n        eg.readUByte();\n        eg.readUByte();\n        eg.readUByte();\n        eg.readUByte();\n        eg.readUByte();\n      }\n      if (sub_layer_level_present_flags[i]) {\n        eg.readUByte();\n      }\n    }\n    eg.readUEG(); // seq_parameter_set_id\n    const chroma_format_idc = eg.readUEG();\n    if (chroma_format_idc == 3) {\n      eg.skipBits(1); //separate_colour_plane_flag\n    }\n    const pic_width_in_luma_samples = eg.readUEG();\n    const pic_height_in_luma_samples = eg.readUEG();\n    const conformance_window_flag = eg.readBoolean();\n    let pic_left_offset = 0,\n      pic_right_offset = 0,\n      pic_top_offset = 0,\n      pic_bottom_offset = 0;\n    if (conformance_window_flag) {\n      pic_left_offset += eg.readUEG();\n      pic_right_offset += eg.readUEG();\n      pic_top_offset += eg.readUEG();\n      pic_bottom_offset += eg.readUEG();\n    }\n    const bit_depth_luma_minus8 = eg.readUEG();\n    const bit_depth_chroma_minus8 = eg.readUEG();\n    const log2_max_pic_order_cnt_lsb_minus4 = eg.readUEG();\n    const sub_layer_ordering_info_present_flag = eg.readBoolean();\n    for (let i = sub_layer_ordering_info_present_flag ? 0 : max_sub_layers_minus1; i <= max_sub_layers_minus1; i++) {\n      eg.skipUEG(); // max_dec_pic_buffering_minus1[i]\n      eg.skipUEG(); // max_num_reorder_pics[i]\n      eg.skipUEG(); // max_latency_increase_plus1[i]\n    }\n    eg.skipUEG(); // log2_min_luma_coding_block_size_minus3\n    eg.skipUEG(); // log2_diff_max_min_luma_coding_block_size\n    eg.skipUEG(); // log2_min_transform_block_size_minus2\n    eg.skipUEG(); // log2_diff_max_min_transform_block_size\n    eg.skipUEG(); // max_transform_hierarchy_depth_inter\n    eg.skipUEG(); // max_transform_hierarchy_depth_intra\n    const scaling_list_enabled_flag = eg.readBoolean();\n    if (scaling_list_enabled_flag) {\n      const sps_scaling_list_data_present_flag = eg.readBoolean();\n      if (sps_scaling_list_data_present_flag) {\n        for (let sizeId = 0; sizeId < 4; sizeId++) {\n          for (let matrixId = 0; matrixId < (sizeId === 3 ? 2 : 6); matrixId++) {\n            const scaling_list_pred_mode_flag = eg.readBoolean();\n            if (!scaling_list_pred_mode_flag) {\n              eg.readUEG(); // scaling_list_pred_matrix_id_delta\n            } else {\n              const coefNum = Math.min(64, 1 << 4 + (sizeId << 1));\n              if (sizeId > 1) {\n                eg.readEG();\n              }\n              for (let i = 0; i < coefNum; i++) {\n                eg.readEG();\n              }\n            }\n          }\n        }\n      }\n    }\n    eg.readBoolean(); // amp_enabled_flag\n    eg.readBoolean(); // sample_adaptive_offset_enabled_flag\n    const pcm_enabled_flag = eg.readBoolean();\n    if (pcm_enabled_flag) {\n      eg.readUByte();\n      eg.skipUEG();\n      eg.skipUEG();\n      eg.readBoolean();\n    }\n    const num_short_term_ref_pic_sets = eg.readUEG();\n    let num_delta_pocs = 0;\n    for (let i = 0; i < num_short_term_ref_pic_sets; i++) {\n      let inter_ref_pic_set_prediction_flag = false;\n      if (i !== 0) {\n        inter_ref_pic_set_prediction_flag = eg.readBoolean();\n      }\n      if (inter_ref_pic_set_prediction_flag) {\n        if (i === num_short_term_ref_pic_sets) {\n          eg.readUEG();\n        }\n        eg.readBoolean();\n        eg.readUEG();\n        let next_num_delta_pocs = 0;\n        for (let j = 0; j <= num_delta_pocs; j++) {\n          const used_by_curr_pic_flag = eg.readBoolean();\n          let use_delta_flag = false;\n          if (!used_by_curr_pic_flag) {\n            use_delta_flag = eg.readBoolean();\n          }\n          if (used_by_curr_pic_flag || use_delta_flag) {\n            next_num_delta_pocs++;\n          }\n        }\n        num_delta_pocs = next_num_delta_pocs;\n      } else {\n        const num_negative_pics = eg.readUEG();\n        const num_positive_pics = eg.readUEG();\n        num_delta_pocs = num_negative_pics + num_positive_pics;\n        for (let j = 0; j < num_negative_pics; j++) {\n          eg.readUEG();\n          eg.readBoolean();\n        }\n        for (let j = 0; j < num_positive_pics; j++) {\n          eg.readUEG();\n          eg.readBoolean();\n        }\n      }\n    }\n    const long_term_ref_pics_present_flag = eg.readBoolean();\n    if (long_term_ref_pics_present_flag) {\n      const num_long_term_ref_pics_sps = eg.readUEG();\n      for (let i = 0; i < num_long_term_ref_pics_sps; i++) {\n        for (let j = 0; j < log2_max_pic_order_cnt_lsb_minus4 + 4; j++) {\n          eg.readBits(1);\n        }\n        eg.readBits(1);\n      }\n    }\n    let min_spatial_segmentation_idc = 0;\n    let sar_width = 1,\n      sar_height = 1;\n    let fps_fixed = true,\n      fps_den = 1,\n      fps_num = 0;\n    eg.readBoolean(); // sps_temporal_mvp_enabled_flag\n    eg.readBoolean(); // strong_intra_smoothing_enabled_flag\n    let default_display_window_flag = false;\n    const vui_parameters_present_flag = eg.readBoolean();\n    if (vui_parameters_present_flag) {\n      const aspect_ratio_info_present_flag = eg.readBoolean();\n      if (aspect_ratio_info_present_flag) {\n        const aspect_ratio_idc = eg.readUByte();\n        const sar_width_table = [1, 12, 10, 16, 40, 24, 20, 32, 80, 18, 15, 64, 160, 4, 3, 2];\n        const sar_height_table = [1, 11, 11, 11, 33, 11, 11, 11, 33, 11, 11, 33, 99, 3, 2, 1];\n        if (aspect_ratio_idc > 0 && aspect_ratio_idc < 16) {\n          sar_width = sar_width_table[aspect_ratio_idc - 1];\n          sar_height = sar_height_table[aspect_ratio_idc - 1];\n        } else if (aspect_ratio_idc === 255) {\n          sar_width = eg.readBits(16);\n          sar_height = eg.readBits(16);\n        }\n      }\n      const overscan_info_present_flag = eg.readBoolean();\n      if (overscan_info_present_flag) {\n        eg.readBoolean();\n      }\n      const video_signal_type_present_flag = eg.readBoolean();\n      if (video_signal_type_present_flag) {\n        eg.readBits(3);\n        eg.readBoolean();\n        const colour_description_present_flag = eg.readBoolean();\n        if (colour_description_present_flag) {\n          eg.readUByte();\n          eg.readUByte();\n          eg.readUByte();\n        }\n      }\n      const chroma_loc_info_present_flag = eg.readBoolean();\n      if (chroma_loc_info_present_flag) {\n        eg.readUEG();\n        eg.readUEG();\n      }\n      eg.readBoolean(); // neutral_chroma_indication_flag\n      eg.readBoolean(); // field_seq_flag\n      eg.readBoolean(); // frame_field_info_present_flag\n      default_display_window_flag = eg.readBoolean();\n      if (default_display_window_flag) {\n        eg.skipUEG();\n        eg.skipUEG();\n        eg.skipUEG();\n        eg.skipUEG();\n      }\n      const vui_timing_info_present_flag = eg.readBoolean();\n      if (vui_timing_info_present_flag) {\n        fps_den = eg.readBits(32);\n        fps_num = eg.readBits(32);\n        const vui_poc_proportional_to_timing_flag = eg.readBoolean();\n        if (vui_poc_proportional_to_timing_flag) {\n          eg.readUEG();\n        }\n        const vui_hrd_parameters_present_flag = eg.readBoolean();\n        if (vui_hrd_parameters_present_flag) {\n          //const commonInfPresentFlag = true;\n          //if (commonInfPresentFlag) {\n          const nal_hrd_parameters_present_flag = eg.readBoolean();\n          const vcl_hrd_parameters_present_flag = eg.readBoolean();\n          let sub_pic_hrd_params_present_flag = false;\n          if (nal_hrd_parameters_present_flag || vcl_hrd_parameters_present_flag) {\n            sub_pic_hrd_params_present_flag = eg.readBoolean();\n            if (sub_pic_hrd_params_present_flag) {\n              eg.readUByte();\n              eg.readBits(5);\n              eg.readBoolean();\n              eg.readBits(5);\n            }\n            eg.readBits(4); // bit_rate_scale\n            eg.readBits(4); // cpb_size_scale\n            if (sub_pic_hrd_params_present_flag) {\n              eg.readBits(4);\n            }\n            eg.readBits(5);\n            eg.readBits(5);\n            eg.readBits(5);\n          }\n          //}\n          for (let i = 0; i <= max_sub_layers_minus1; i++) {\n            fps_fixed = eg.readBoolean(); // fixed_pic_rate_general_flag\n            const fixed_pic_rate_within_cvs_flag = fps_fixed || eg.readBoolean();\n            let low_delay_hrd_flag = false;\n            if (fixed_pic_rate_within_cvs_flag) {\n              eg.readEG();\n            } else {\n              low_delay_hrd_flag = eg.readBoolean();\n            }\n            const cpb_cnt = low_delay_hrd_flag ? 1 : eg.readUEG() + 1;\n            if (nal_hrd_parameters_present_flag) {\n              for (let j = 0; j < cpb_cnt; j++) {\n                eg.readUEG();\n                eg.readUEG();\n                if (sub_pic_hrd_params_present_flag) {\n                  eg.readUEG();\n                  eg.readUEG();\n                }\n                eg.skipBits(1);\n              }\n            }\n            if (vcl_hrd_parameters_present_flag) {\n              for (let j = 0; j < cpb_cnt; j++) {\n                eg.readUEG();\n                eg.readUEG();\n                if (sub_pic_hrd_params_present_flag) {\n                  eg.readUEG();\n                  eg.readUEG();\n                }\n                eg.skipBits(1);\n              }\n            }\n          }\n        }\n      }\n      const bitstream_restriction_flag = eg.readBoolean();\n      if (bitstream_restriction_flag) {\n        eg.readBoolean(); // tiles_fixed_structure_flag\n        eg.readBoolean(); // motion_vectors_over_pic_boundaries_flag\n        eg.readBoolean(); // restricted_ref_pic_lists_flag\n        min_spatial_segmentation_idc = eg.readUEG();\n      }\n    }\n    let width = pic_width_in_luma_samples,\n      height = pic_height_in_luma_samples;\n    if (conformance_window_flag) {\n      let chroma_scale_w = 1,\n        chroma_scale_h = 1;\n      if (chroma_format_idc === 1) {\n        // YUV 420\n        chroma_scale_w = chroma_scale_h = 2;\n      } else if (chroma_format_idc == 2) {\n        // YUV 422\n        chroma_scale_w = 2;\n      }\n      width = pic_width_in_luma_samples - chroma_scale_w * pic_right_offset - chroma_scale_w * pic_left_offset;\n      height = pic_height_in_luma_samples - chroma_scale_h * pic_bottom_offset - chroma_scale_h * pic_top_offset;\n    }\n    const profile_space_string = general_profile_space ? ['A', 'B', 'C'][general_profile_space] : '';\n    const profile_compatibility_buf = general_profile_compatibility_flags_1 << 24 | general_profile_compatibility_flags_2 << 16 | general_profile_compatibility_flags_3 << 8 | general_profile_compatibility_flags_4;\n    let profile_compatibility_rev = 0;\n    for (let i = 0; i < 32; i++) {\n      profile_compatibility_rev = (profile_compatibility_rev | (profile_compatibility_buf >> i & 1) << 31 - i) >>> 0; // reverse bit position (and cast as UInt32)\n    }\n    let profile_compatibility_flags_string = profile_compatibility_rev.toString(16);\n    if (general_profile_idc === 1 && profile_compatibility_flags_string === '2') {\n      profile_compatibility_flags_string = '6';\n    }\n    const tier_flag_string = general_tier_flag ? 'H' : 'L';\n    return {\n      codecString: `hvc1.${profile_space_string}${general_profile_idc}.${profile_compatibility_flags_string}.${tier_flag_string}${general_level_idc}.B0`,\n      params: {\n        general_tier_flag,\n        general_profile_idc,\n        general_profile_space,\n        general_profile_compatibility_flags: [general_profile_compatibility_flags_1, general_profile_compatibility_flags_2, general_profile_compatibility_flags_3, general_profile_compatibility_flags_4],\n        general_constraint_indicator_flags: [general_constraint_indicator_flags_1, general_constraint_indicator_flags_2, general_constraint_indicator_flags_3, general_constraint_indicator_flags_4, general_constraint_indicator_flags_5, general_constraint_indicator_flags_6],\n        general_level_idc,\n        bit_depth: bit_depth_luma_minus8 + 8,\n        bit_depth_luma_minus8,\n        bit_depth_chroma_minus8,\n        min_spatial_segmentation_idc,\n        chroma_format_idc: chroma_format_idc,\n        frame_rate: {\n          fixed: fps_fixed,\n          fps: fps_num / fps_den\n        }\n      },\n      width,\n      height,\n      pixelRatio: [sar_width, sar_height]\n    };\n  }\n  readPPS(pps) {\n    const eg = new ExpGolomb(this.ebsp2rbsp(pps));\n    eg.readUByte();\n    eg.readUByte();\n    eg.skipUEG(); // pic_parameter_set_id\n    eg.skipUEG(); // seq_parameter_set_id\n    eg.skipBits(2); // dependent_slice_segments_enabled_flag, output_flag_present_flag\n    eg.skipBits(3); // num_extra_slice_header_bits\n    eg.skipBits(2); // sign_data_hiding_enabled_flag, cabac_init_present_flag\n    eg.skipUEG();\n    eg.skipUEG();\n    eg.skipEG(); // init_qp_minus26\n    eg.skipBits(2); // constrained_intra_pred_flag, transform_skip_enabled_flag\n    const cu_qp_delta_enabled_flag = eg.readBoolean();\n    if (cu_qp_delta_enabled_flag) {\n      eg.skipUEG();\n    }\n    eg.skipEG(); // cb_qp_offset\n    eg.skipEG(); // cr_qp_offset\n    eg.skipBits(4); // pps_slice_chroma_qp_offsets_present_flag, weighted_pred_flag, weighted_bipred_flag, transquant_bypass_enabled_flag\n    const tiles_enabled_flag = eg.readBoolean();\n    const entropy_coding_sync_enabled_flag = eg.readBoolean();\n    let parallelismType = 1; // slice-based parallel decoding\n    if (entropy_coding_sync_enabled_flag && tiles_enabled_flag) {\n      parallelismType = 0; // mixed-type parallel decoding\n    } else if (entropy_coding_sync_enabled_flag) {\n      parallelismType = 3; // wavefront-based parallel decoding\n    } else if (tiles_enabled_flag) {\n      parallelismType = 2; // tile-based parallel decoding\n    }\n    return {\n      parallelismType\n    };\n  }\n  matchSPS(sps1, sps2) {\n    // compare without headers and VPS related params\n    return String.fromCharCode.apply(null, sps1).substr(3) === String.fromCharCode.apply(null, sps2).substr(3);\n  }\n}\n\nconst PACKET_LENGTH = 188;\nclass TSDemuxer {\n  constructor(observer, config, typeSupported, logger) {\n    this.logger = void 0;\n    this.observer = void 0;\n    this.config = void 0;\n    this.typeSupported = void 0;\n    this.sampleAes = null;\n    this.pmtParsed = false;\n    this.audioCodec = void 0;\n    this.videoCodec = void 0;\n    this._pmtId = -1;\n    this._videoTrack = void 0;\n    this._audioTrack = void 0;\n    this._id3Track = void 0;\n    this._txtTrack = void 0;\n    this.aacOverFlow = null;\n    this.remainderData = null;\n    this.videoParser = void 0;\n    this.observer = observer;\n    this.config = config;\n    this.typeSupported = typeSupported;\n    this.logger = logger;\n    this.videoParser = null;\n  }\n  static probe(data, logger) {\n    const syncOffset = TSDemuxer.syncOffset(data);\n    if (syncOffset > 0) {\n      logger.warn(`MPEG2-TS detected but first sync word found @ offset ${syncOffset}`);\n    }\n    return syncOffset !== -1;\n  }\n  static syncOffset(data) {\n    const length = data.length;\n    let scanwindow = Math.min(PACKET_LENGTH * 5, length - PACKET_LENGTH) + 1;\n    let i = 0;\n    while (i < scanwindow) {\n      // a TS init segment should contain at least 2 TS packets: PAT and PMT, each starting with 0x47\n      let foundPat = false;\n      let packetStart = -1;\n      let tsPackets = 0;\n      for (let j = i; j < length; j += PACKET_LENGTH) {\n        if (data[j] === 0x47 && (length - j === PACKET_LENGTH || data[j + PACKET_LENGTH] === 0x47)) {\n          tsPackets++;\n          if (packetStart === -1) {\n            packetStart = j;\n            // First sync word found at offset, increase scan length (#5251)\n            if (packetStart !== 0) {\n              scanwindow = Math.min(packetStart + PACKET_LENGTH * 99, data.length - PACKET_LENGTH) + 1;\n            }\n          }\n          if (!foundPat) {\n            foundPat = parsePID(data, j) === 0;\n          }\n          // Sync word found at 0 with 3 packets, or found at offset least 2 packets up to scanwindow (#5501)\n          if (foundPat && tsPackets > 1 && (packetStart === 0 && tsPackets > 2 || j + PACKET_LENGTH > scanwindow)) {\n            return packetStart;\n          }\n        } else if (tsPackets) {\n          // Exit if sync word found, but does not contain contiguous packets\n          return -1;\n        } else {\n          break;\n        }\n      }\n      i++;\n    }\n    return -1;\n  }\n\n  /**\n   * Creates a track model internal to demuxer used to drive remuxing input\n   */\n  static createTrack(type, duration) {\n    return {\n      container: type === 'video' || type === 'audio' ? 'video/mp2t' : undefined,\n      type,\n      id: RemuxerTrackIdConfig[type],\n      pid: -1,\n      inputTimeScale: 90000,\n      sequenceNumber: 0,\n      samples: [],\n      dropped: 0,\n      duration: type === 'audio' ? duration : undefined\n    };\n  }\n\n  /**\n   * Initializes a new init segment on the demuxer/remuxer interface. Needed for discontinuities/track-switches (or at stream start)\n   * Resets all internal track instances of the demuxer.\n   */\n  resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration) {\n    this.pmtParsed = false;\n    this._pmtId = -1;\n    this._videoTrack = TSDemuxer.createTrack('video');\n    this._videoTrack.duration = trackDuration;\n    this._audioTrack = TSDemuxer.createTrack('audio', trackDuration);\n    this._id3Track = TSDemuxer.createTrack('id3');\n    this._txtTrack = TSDemuxer.createTrack('text');\n    this._audioTrack.segmentCodec = 'aac';\n\n    // flush any partial content\n    this.videoParser = null;\n    this.aacOverFlow = null;\n    this.remainderData = null;\n    this.audioCodec = audioCodec;\n    this.videoCodec = videoCodec;\n  }\n  resetTimeStamp() {}\n  resetContiguity() {\n    const {\n      _audioTrack,\n      _videoTrack,\n      _id3Track\n    } = this;\n    if (_audioTrack) {\n      _audioTrack.pesData = null;\n    }\n    if (_videoTrack) {\n      _videoTrack.pesData = null;\n    }\n    if (_id3Track) {\n      _id3Track.pesData = null;\n    }\n    this.aacOverFlow = null;\n    this.remainderData = null;\n  }\n  demux(data, timeOffset, isSampleAes = false, flush = false) {\n    if (!isSampleAes) {\n      this.sampleAes = null;\n    }\n    let pes;\n    const videoTrack = this._videoTrack;\n    const audioTrack = this._audioTrack;\n    const id3Track = this._id3Track;\n    const textTrack = this._txtTrack;\n    let videoPid = videoTrack.pid;\n    let videoData = videoTrack.pesData;\n    let audioPid = audioTrack.pid;\n    let id3Pid = id3Track.pid;\n    let audioData = audioTrack.pesData;\n    let id3Data = id3Track.pesData;\n    let unknownPID = null;\n    let pmtParsed = this.pmtParsed;\n    let pmtId = this._pmtId;\n    let len = data.length;\n    if (this.remainderData) {\n      data = appendUint8Array(this.remainderData, data);\n      len = data.length;\n      this.remainderData = null;\n    }\n    if (len < PACKET_LENGTH && !flush) {\n      this.remainderData = data;\n      return {\n        audioTrack,\n        videoTrack,\n        id3Track,\n        textTrack\n      };\n    }\n    const syncOffset = Math.max(0, TSDemuxer.syncOffset(data));\n    len -= (len - syncOffset) % PACKET_LENGTH;\n    if (len < data.byteLength && !flush) {\n      this.remainderData = new Uint8Array(data.buffer, len, data.buffer.byteLength - len);\n    }\n\n    // loop through TS packets\n    let tsPacketErrors = 0;\n    for (let start = syncOffset; start < len; start += PACKET_LENGTH) {\n      if (data[start] === 0x47) {\n        const stt = !!(data[start + 1] & 0x40);\n        const pid = parsePID(data, start);\n        const atf = (data[start + 3] & 0x30) >> 4;\n\n        // if an adaption field is present, its length is specified by the fifth byte of the TS packet header.\n        let offset;\n        if (atf > 1) {\n          offset = start + 5 + data[start + 4];\n          // continue if there is only adaptation field\n          if (offset === start + PACKET_LENGTH) {\n            continue;\n          }\n        } else {\n          offset = start + 4;\n        }\n        switch (pid) {\n          case videoPid:\n            if (stt) {\n              if (videoData && (pes = parsePES(videoData, this.logger))) {\n                this.readyVideoParser(videoTrack.segmentCodec);\n                if (this.videoParser !== null) {\n                  this.videoParser.parsePES(videoTrack, textTrack, pes, false);\n                }\n              }\n              videoData = {\n                data: [],\n                size: 0\n              };\n            }\n            if (videoData) {\n              videoData.data.push(data.subarray(offset, start + PACKET_LENGTH));\n              videoData.size += start + PACKET_LENGTH - offset;\n            }\n            break;\n          case audioPid:\n            if (stt) {\n              if (audioData && (pes = parsePES(audioData, this.logger))) {\n                switch (audioTrack.segmentCodec) {\n                  case 'aac':\n                    this.parseAACPES(audioTrack, pes);\n                    break;\n                  case 'mp3':\n                    this.parseMPEGPES(audioTrack, pes);\n                    break;\n                  case 'ac3':\n                    {\n                      this.parseAC3PES(audioTrack, pes);\n                    }\n                    break;\n                }\n              }\n              audioData = {\n                data: [],\n                size: 0\n              };\n            }\n            if (audioData) {\n              audioData.data.push(data.subarray(offset, start + PACKET_LENGTH));\n              audioData.size += start + PACKET_LENGTH - offset;\n            }\n            break;\n          case id3Pid:\n            if (stt) {\n              if (id3Data && (pes = parsePES(id3Data, this.logger))) {\n                this.parseID3PES(id3Track, pes);\n              }\n              id3Data = {\n                data: [],\n                size: 0\n              };\n            }\n            if (id3Data) {\n              id3Data.data.push(data.subarray(offset, start + PACKET_LENGTH));\n              id3Data.size += start + PACKET_LENGTH - offset;\n            }\n            break;\n          case 0:\n            if (stt) {\n              offset += data[offset] + 1;\n            }\n            pmtId = this._pmtId = parsePAT(data, offset);\n            // this.logger.log('PMT PID:'  + this._pmtId);\n            break;\n          case pmtId:\n            {\n              if (stt) {\n                offset += data[offset] + 1;\n              }\n              const parsedPIDs = parsePMT(data, offset, this.typeSupported, isSampleAes, this.observer, this.logger);\n\n              // only update track id if track PID found while parsing PMT\n              // this is to avoid resetting the PID to -1 in case\n              // track PID transiently disappears from the stream\n              // this could happen in case of transient missing audio samples for example\n              // NOTE this is only the PID of the track as found in TS,\n              // but we are not using this for MP4 track IDs.\n              videoPid = parsedPIDs.videoPid;\n              if (videoPid > 0) {\n                videoTrack.pid = videoPid;\n                videoTrack.segmentCodec = parsedPIDs.segmentVideoCodec;\n              }\n              audioPid = parsedPIDs.audioPid;\n              if (audioPid > 0) {\n                audioTrack.pid = audioPid;\n                audioTrack.segmentCodec = parsedPIDs.segmentAudioCodec;\n              }\n              id3Pid = parsedPIDs.id3Pid;\n              if (id3Pid > 0) {\n                id3Track.pid = id3Pid;\n              }\n              if (unknownPID !== null && !pmtParsed) {\n                this.logger.warn(`MPEG-TS PMT found at ${start} after unknown PID '${unknownPID}'. Backtracking to sync byte @${syncOffset} to parse all TS packets.`);\n                unknownPID = null;\n                // we set it to -188, the += 188 in the for loop will reset start to 0\n                start = syncOffset - 188;\n              }\n              pmtParsed = this.pmtParsed = true;\n              break;\n            }\n          case 0x11:\n          case 0x1fff:\n            break;\n          default:\n            unknownPID = pid;\n            break;\n        }\n      } else {\n        tsPacketErrors++;\n      }\n    }\n    if (tsPacketErrors > 0) {\n      emitParsingError(this.observer, new Error(`Found ${tsPacketErrors} TS packet/s that do not start with 0x47`), undefined, this.logger);\n    }\n    videoTrack.pesData = videoData;\n    audioTrack.pesData = audioData;\n    id3Track.pesData = id3Data;\n    const demuxResult = {\n      audioTrack,\n      videoTrack,\n      id3Track,\n      textTrack\n    };\n    if (flush) {\n      this.extractRemainingSamples(demuxResult);\n    }\n    return demuxResult;\n  }\n  flush() {\n    const {\n      remainderData\n    } = this;\n    this.remainderData = null;\n    let result;\n    if (remainderData) {\n      result = this.demux(remainderData, -1, false, true);\n    } else {\n      result = {\n        videoTrack: this._videoTrack,\n        audioTrack: this._audioTrack,\n        id3Track: this._id3Track,\n        textTrack: this._txtTrack\n      };\n    }\n    this.extractRemainingSamples(result);\n    if (this.sampleAes) {\n      return this.decrypt(result, this.sampleAes);\n    }\n    return result;\n  }\n  extractRemainingSamples(demuxResult) {\n    const {\n      audioTrack,\n      videoTrack,\n      id3Track,\n      textTrack\n    } = demuxResult;\n    const videoData = videoTrack.pesData;\n    const audioData = audioTrack.pesData;\n    const id3Data = id3Track.pesData;\n    // try to parse last PES packets\n    let pes;\n    if (videoData && (pes = parsePES(videoData, this.logger))) {\n      this.readyVideoParser(videoTrack.segmentCodec);\n      if (this.videoParser !== null) {\n        this.videoParser.parsePES(videoTrack, textTrack, pes, true);\n        videoTrack.pesData = null;\n      }\n    } else {\n      // either avcData null or PES truncated, keep it for next frag parsing\n      videoTrack.pesData = videoData;\n    }\n    if (audioData && (pes = parsePES(audioData, this.logger))) {\n      switch (audioTrack.segmentCodec) {\n        case 'aac':\n          this.parseAACPES(audioTrack, pes);\n          break;\n        case 'mp3':\n          this.parseMPEGPES(audioTrack, pes);\n          break;\n        case 'ac3':\n          {\n            this.parseAC3PES(audioTrack, pes);\n          }\n          break;\n      }\n      audioTrack.pesData = null;\n    } else {\n      if (audioData != null && audioData.size) {\n        this.logger.log('last AAC PES packet truncated,might overlap between fragments');\n      }\n\n      // either audioData null or PES truncated, keep it for next frag parsing\n      audioTrack.pesData = audioData;\n    }\n    if (id3Data && (pes = parsePES(id3Data, this.logger))) {\n      this.parseID3PES(id3Track, pes);\n      id3Track.pesData = null;\n    } else {\n      // either id3Data null or PES truncated, keep it for next frag parsing\n      id3Track.pesData = id3Data;\n    }\n  }\n  demuxSampleAes(data, keyData, timeOffset) {\n    const demuxResult = this.demux(data, timeOffset, true, !this.config.progressive);\n    const sampleAes = this.sampleAes = new SampleAesDecrypter(this.observer, this.config, keyData);\n    return this.decrypt(demuxResult, sampleAes);\n  }\n  readyVideoParser(codec) {\n    if (this.videoParser === null) {\n      if (codec === 'avc') {\n        this.videoParser = new AvcVideoParser();\n      } else if (codec === 'hevc') {\n        this.videoParser = new HevcVideoParser();\n      }\n    }\n  }\n  decrypt(demuxResult, sampleAes) {\n    return new Promise(resolve => {\n      const {\n        audioTrack,\n        videoTrack\n      } = demuxResult;\n      if (audioTrack.samples && audioTrack.segmentCodec === 'aac') {\n        sampleAes.decryptAacSamples(audioTrack.samples, 0, () => {\n          if (videoTrack.samples) {\n            sampleAes.decryptAvcSamples(videoTrack.samples, 0, 0, () => {\n              resolve(demuxResult);\n            });\n          } else {\n            resolve(demuxResult);\n          }\n        });\n      } else if (videoTrack.samples) {\n        sampleAes.decryptAvcSamples(videoTrack.samples, 0, 0, () => {\n          resolve(demuxResult);\n        });\n      }\n    });\n  }\n  destroy() {\n    if (this.observer) {\n      this.observer.removeAllListeners();\n    }\n    // @ts-ignore\n    this.config = this.logger = this.observer = null;\n    this.aacOverFlow = this.videoParser = this.remainderData = this.sampleAes = null;\n    this._videoTrack = this._audioTrack = this._id3Track = this._txtTrack = undefined;\n  }\n  parseAACPES(track, pes) {\n    let startOffset = 0;\n    const aacOverFlow = this.aacOverFlow;\n    let data = pes.data;\n    if (aacOverFlow) {\n      this.aacOverFlow = null;\n      const frameMissingBytes = aacOverFlow.missing;\n      const sampleLength = aacOverFlow.sample.unit.byteLength;\n      // logger.log(`AAC: append overflowing ${sampleLength} bytes to beginning of new PES`);\n      if (frameMissingBytes === -1) {\n        data = appendUint8Array(aacOverFlow.sample.unit, data);\n      } else {\n        const frameOverflowBytes = sampleLength - frameMissingBytes;\n        aacOverFlow.sample.unit.set(data.subarray(0, frameMissingBytes), frameOverflowBytes);\n        track.samples.push(aacOverFlow.sample);\n        startOffset = aacOverFlow.missing;\n      }\n    }\n    // look for ADTS header (0xFFFx)\n    let offset;\n    let len;\n    for (offset = startOffset, len = data.length; offset < len - 1; offset++) {\n      if (isHeader$1(data, offset)) {\n        break;\n      }\n    }\n    // if ADTS header does not start straight from the beginning of the PES payload, raise an error\n    if (offset !== startOffset) {\n      let reason;\n      const recoverable = offset < len - 1;\n      if (recoverable) {\n        reason = `AAC PES did not start with ADTS header,offset:${offset}`;\n      } else {\n        reason = 'No ADTS header found in AAC PES';\n      }\n      emitParsingError(this.observer, new Error(reason), recoverable, this.logger);\n      if (!recoverable) {\n        return;\n      }\n    }\n    initTrackConfig(track, this.observer, data, offset, this.audioCodec);\n    let pts;\n    if (pes.pts !== undefined) {\n      pts = pes.pts;\n    } else if (aacOverFlow) {\n      // if last AAC frame is overflowing, we should ensure timestamps are contiguous:\n      // first sample PTS should be equal to last sample PTS + frameDuration\n      const frameDuration = getFrameDuration(track.samplerate);\n      pts = aacOverFlow.sample.pts + frameDuration;\n    } else {\n      this.logger.warn('[tsdemuxer]: AAC PES unknown PTS');\n      return;\n    }\n\n    // scan for aac samples\n    let frameIndex = 0;\n    let frame;\n    while (offset < len) {\n      frame = appendFrame$2(track, data, offset, pts, frameIndex);\n      offset += frame.length;\n      if (!frame.missing) {\n        frameIndex++;\n        for (; offset < len - 1; offset++) {\n          if (isHeader$1(data, offset)) {\n            break;\n          }\n        }\n      } else {\n        this.aacOverFlow = frame;\n        break;\n      }\n    }\n  }\n  parseMPEGPES(track, pes) {\n    const data = pes.data;\n    const length = data.length;\n    let frameIndex = 0;\n    let offset = 0;\n    const pts = pes.pts;\n    if (pts === undefined) {\n      this.logger.warn('[tsdemuxer]: MPEG PES unknown PTS');\n      return;\n    }\n    while (offset < length) {\n      if (isHeader(data, offset)) {\n        const frame = appendFrame$1(track, data, offset, pts, frameIndex);\n        if (frame) {\n          offset += frame.length;\n          frameIndex++;\n        } else {\n          // logger.log('Unable to parse Mpeg audio frame');\n          break;\n        }\n      } else {\n        // nothing found, keep looking\n        offset++;\n      }\n    }\n  }\n  parseAC3PES(track, pes) {\n    {\n      const data = pes.data;\n      const pts = pes.pts;\n      if (pts === undefined) {\n        this.logger.warn('[tsdemuxer]: AC3 PES unknown PTS');\n        return;\n      }\n      const length = data.length;\n      let frameIndex = 0;\n      let offset = 0;\n      let parsed;\n      while (offset < length && (parsed = appendFrame(track, data, offset, pts, frameIndex++)) > 0) {\n        offset += parsed;\n      }\n    }\n  }\n  parseID3PES(id3Track, pes) {\n    if (pes.pts === undefined) {\n      this.logger.warn('[tsdemuxer]: ID3 PES unknown PTS');\n      return;\n    }\n    const id3Sample = _extends({}, pes, {\n      type: this._videoTrack ? MetadataSchema.emsg : MetadataSchema.audioId3,\n      duration: Number.POSITIVE_INFINITY\n    });\n    id3Track.samples.push(id3Sample);\n  }\n}\nfunction parsePID(data, offset) {\n  // pid is a 13-bit field starting at the last bit of TS[1]\n  return ((data[offset + 1] & 0x1f) << 8) + data[offset + 2];\n}\nfunction parsePAT(data, offset) {\n  // skip the PSI header and parse the first PMT entry\n  return (data[offset + 10] & 0x1f) << 8 | data[offset + 11];\n}\nfunction parsePMT(data, offset, typeSupported, isSampleAes, observer, logger) {\n  const result = {\n    audioPid: -1,\n    videoPid: -1,\n    id3Pid: -1,\n    segmentVideoCodec: 'avc',\n    segmentAudioCodec: 'aac'\n  };\n  const sectionLength = (data[offset + 1] & 0x0f) << 8 | data[offset + 2];\n  const tableEnd = offset + 3 + sectionLength - 4;\n  // to determine where the table is, we have to figure out how\n  // long the program info descriptors are\n  const programInfoLength = (data[offset + 10] & 0x0f) << 8 | data[offset + 11];\n  // advance the offset to the first entry in the mapping table\n  offset += 12 + programInfoLength;\n  while (offset < tableEnd) {\n    const pid = parsePID(data, offset);\n    const esInfoLength = (data[offset + 3] & 0x0f) << 8 | data[offset + 4];\n    switch (data[offset]) {\n      case 0xcf:\n        // SAMPLE-AES AAC\n        if (!isSampleAes) {\n          logEncryptedSamplesFoundInUnencryptedStream('ADTS AAC', logger);\n          break;\n        }\n      /* falls through */\n      case 0x0f:\n        // ISO/IEC 13818-7 ADTS AAC (MPEG-2 lower bit-rate audio)\n        // logger.log('AAC PID:'  + pid);\n        if (result.audioPid === -1) {\n          result.audioPid = pid;\n        }\n        break;\n\n      // Packetized metadata (ID3)\n      case 0x15:\n        // logger.log('ID3 PID:'  + pid);\n        if (result.id3Pid === -1) {\n          result.id3Pid = pid;\n        }\n        break;\n      case 0xdb:\n        // SAMPLE-AES AVC\n        if (!isSampleAes) {\n          logEncryptedSamplesFoundInUnencryptedStream('H.264', logger);\n          break;\n        }\n      /* falls through */\n      case 0x1b:\n        // ITU-T Rec. H.264 and ISO/IEC 14496-10 (lower bit-rate video)\n        // logger.log('AVC PID:'  + pid);\n        if (result.videoPid === -1) {\n          result.videoPid = pid;\n        }\n        break;\n\n      // ISO/IEC 11172-3 (MPEG-1 audio)\n      // or ISO/IEC 13818-3 (MPEG-2 halved sample rate audio)\n      case 0x03:\n      case 0x04:\n        // logger.log('MPEG PID:'  + pid);\n        if (!typeSupported.mpeg && !typeSupported.mp3) {\n          logger.log('MPEG audio found, not supported in this browser');\n        } else if (result.audioPid === -1) {\n          result.audioPid = pid;\n          result.segmentAudioCodec = 'mp3';\n        }\n        break;\n      case 0xc1:\n        // SAMPLE-AES AC3\n        if (!isSampleAes) {\n          logEncryptedSamplesFoundInUnencryptedStream('AC-3', logger);\n          break;\n        }\n      /* falls through */\n      case 0x81:\n        {\n          if (!typeSupported.ac3) {\n            logger.log('AC-3 audio found, not supported in this browser');\n          } else if (result.audioPid === -1) {\n            result.audioPid = pid;\n            result.segmentAudioCodec = 'ac3';\n          }\n        }\n        break;\n      case 0x06:\n        // stream_type 6 can mean a lot of different things in case of DVB.\n        // We need to look at the descriptors. Right now, we're only interested\n        // in AC-3 audio, so we do the descriptor parsing only when we don't have\n        // an audio PID yet.\n        if (result.audioPid === -1 && esInfoLength > 0) {\n          let parsePos = offset + 5;\n          let remaining = esInfoLength;\n          while (remaining > 2) {\n            const descriptorId = data[parsePos];\n            switch (descriptorId) {\n              case 0x6a:\n                // DVB Descriptor for AC-3\n                {\n                  if (typeSupported.ac3 !== true) {\n                    logger.log('AC-3 audio found, not supported in this browser for now');\n                  } else {\n                    result.audioPid = pid;\n                    result.segmentAudioCodec = 'ac3';\n                  }\n                }\n                break;\n            }\n            const descriptorLen = data[parsePos + 1] + 2;\n            parsePos += descriptorLen;\n            remaining -= descriptorLen;\n          }\n        }\n        break;\n      case 0xc2: // SAMPLE-AES EC3\n      /* falls through */\n      case 0x87:\n        emitParsingError(observer, new Error('Unsupported EC-3 in M2TS found'), undefined, logger);\n        return result;\n      case 0x24:\n        // ITU-T Rec. H.265 and ISO/IEC 23008-2 (HEVC)\n        {\n          if (result.videoPid === -1) {\n            result.videoPid = pid;\n            result.segmentVideoCodec = 'hevc';\n            logger.log('HEVC in M2TS found');\n          }\n        }\n        break;\n    }\n    // move to the next table entry\n    // skip past the elementary stream descriptors, if present\n    offset += esInfoLength + 5;\n  }\n  return result;\n}\nfunction emitParsingError(observer, error, levelRetry, logger) {\n  logger.warn(`parsing error: ${error.message}`);\n  observer.emit(Events.ERROR, Events.ERROR, {\n    type: ErrorTypes.MEDIA_ERROR,\n    details: ErrorDetails.FRAG_PARSING_ERROR,\n    fatal: false,\n    levelRetry,\n    error,\n    reason: error.message\n  });\n}\nfunction logEncryptedSamplesFoundInUnencryptedStream(type, logger) {\n  logger.log(`${type} with AES-128-CBC encryption found in unencrypted stream`);\n}\nfunction parsePES(stream, logger) {\n  let i = 0;\n  let frag;\n  let pesLen;\n  let pesHdrLen;\n  let pesPts;\n  let pesDts;\n  const data = stream.data;\n  // safety check\n  if (!stream || stream.size === 0) {\n    return null;\n  }\n\n  // we might need up to 19 bytes to read PES header\n  // if first chunk of data is less than 19 bytes, let's merge it with following ones until we get 19 bytes\n  // usually only one merge is needed (and this is rare ...)\n  while (data[0].length < 19 && data.length > 1) {\n    data[0] = appendUint8Array(data[0], data[1]);\n    data.splice(1, 1);\n  }\n  // retrieve PTS/DTS from first fragment\n  frag = data[0];\n  const pesPrefix = (frag[0] << 16) + (frag[1] << 8) + frag[2];\n  if (pesPrefix === 1) {\n    pesLen = (frag[4] << 8) + frag[5];\n    // if PES parsed length is not zero and greater than total received length, stop parsing. PES might be truncated\n    // minus 6 : PES header size\n    if (pesLen && pesLen > stream.size - 6) {\n      return null;\n    }\n    const pesFlags = frag[7];\n    if (pesFlags & 0xc0) {\n      /* PES header described here : http://dvd.sourceforge.net/dvdinfo/pes-hdr.html\n          as PTS / DTS is 33 bit we cannot use bitwise operator in JS,\n          as Bitwise operators treat their operands as a sequence of 32 bits */\n      pesPts = (frag[9] & 0x0e) * 536870912 +\n      // 1 << 29\n      (frag[10] & 0xff) * 4194304 +\n      // 1 << 22\n      (frag[11] & 0xfe) * 16384 +\n      // 1 << 14\n      (frag[12] & 0xff) * 128 +\n      // 1 << 7\n      (frag[13] & 0xfe) / 2;\n      if (pesFlags & 0x40) {\n        pesDts = (frag[14] & 0x0e) * 536870912 +\n        // 1 << 29\n        (frag[15] & 0xff) * 4194304 +\n        // 1 << 22\n        (frag[16] & 0xfe) * 16384 +\n        // 1 << 14\n        (frag[17] & 0xff) * 128 +\n        // 1 << 7\n        (frag[18] & 0xfe) / 2;\n        if (pesPts - pesDts > 60 * 90000) {\n          logger.warn(`${Math.round((pesPts - pesDts) / 90000)}s delta between PTS and DTS, align them`);\n          pesPts = pesDts;\n        }\n      } else {\n        pesDts = pesPts;\n      }\n    }\n    pesHdrLen = frag[8];\n    // 9 bytes : 6 bytes for PES header + 3 bytes for PES extension\n    let payloadStartOffset = pesHdrLen + 9;\n    if (stream.size <= payloadStartOffset) {\n      return null;\n    }\n    stream.size -= payloadStartOffset;\n    // reassemble PES packet\n    const pesData = new Uint8Array(stream.size);\n    for (let j = 0, dataLen = data.length; j < dataLen; j++) {\n      frag = data[j];\n      let len = frag.byteLength;\n      if (payloadStartOffset) {\n        if (payloadStartOffset > len) {\n          // trim full frag if PES header bigger than frag\n          payloadStartOffset -= len;\n          continue;\n        } else {\n          // trim partial frag if PES header smaller than frag\n          frag = frag.subarray(payloadStartOffset);\n          len -= payloadStartOffset;\n          payloadStartOffset = 0;\n        }\n      }\n      pesData.set(frag, i);\n      i += len;\n    }\n    if (pesLen) {\n      // payload size : remove PES header + PES extension\n      pesLen -= pesHdrLen + 3;\n    }\n    return {\n      data: pesData,\n      pts: pesPts,\n      dts: pesDts,\n      len: pesLen\n    };\n  }\n  return null;\n}\n\n/**\n *  AAC helper\n */\n\nclass AAC {\n  static getSilentFrame(codec, channelCount) {\n    switch (codec) {\n      case 'mp4a.40.2':\n        if (channelCount === 1) {\n          return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x23, 0x80]);\n        } else if (channelCount === 2) {\n          return new Uint8Array([0x21, 0x00, 0x49, 0x90, 0x02, 0x19, 0x00, 0x23, 0x80]);\n        } else if (channelCount === 3) {\n          return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x8e]);\n        } else if (channelCount === 4) {\n          return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x80, 0x2c, 0x80, 0x08, 0x02, 0x38]);\n        } else if (channelCount === 5) {\n          return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x82, 0x30, 0x04, 0x99, 0x00, 0x21, 0x90, 0x02, 0x38]);\n        } else if (channelCount === 6) {\n          return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x82, 0x30, 0x04, 0x99, 0x00, 0x21, 0x90, 0x02, 0x00, 0xb2, 0x00, 0x20, 0x08, 0xe0]);\n        }\n        break;\n      // handle HE-AAC below (mp4a.40.5 / mp4a.40.29)\n      default:\n        if (channelCount === 1) {\n          // ffmpeg -y -f lavfi -i \"aevalsrc=0:d=0.05\" -c:a libfdk_aac -profile:a aac_he -b:a 4k output.aac && hexdump -v -e '16/1 \"0x%x,\" \"\\n\"' -v output.aac\n          return new Uint8Array([0x1, 0x40, 0x22, 0x80, 0xa3, 0x4e, 0xe6, 0x80, 0xba, 0x8, 0x0, 0x0, 0x0, 0x1c, 0x6, 0xf1, 0xc1, 0xa, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5e]);\n        } else if (channelCount === 2) {\n          // ffmpeg -y -f lavfi -i \"aevalsrc=0|0:d=0.05\" -c:a libfdk_aac -profile:a aac_he_v2 -b:a 4k output.aac && hexdump -v -e '16/1 \"0x%x,\" \"\\n\"' -v output.aac\n          return new Uint8Array([0x1, 0x40, 0x22, 0x80, 0xa3, 0x5e, 0xe6, 0x80, 0xba, 0x8, 0x0, 0x0, 0x0, 0x0, 0x95, 0x0, 0x6, 0xf1, 0xa1, 0xa, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5e]);\n        } else if (channelCount === 3) {\n          // ffmpeg -y -f lavfi -i \"aevalsrc=0|0|0:d=0.05\" -c:a libfdk_aac -profile:a aac_he_v2 -b:a 4k output.aac && hexdump -v -e '16/1 \"0x%x,\" \"\\n\"' -v output.aac\n          return new Uint8Array([0x1, 0x40, 0x22, 0x80, 0xa3, 0x5e, 0xe6, 0x80, 0xba, 0x8, 0x0, 0x0, 0x0, 0x0, 0x95, 0x0, 0x6, 0xf1, 0xa1, 0xa, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5e]);\n        }\n        break;\n    }\n    return undefined;\n  }\n}\n\n/**\n * Generate MP4 Box\n */\n\nconst UINT32_MAX = Math.pow(2, 32) - 1;\nclass MP4 {\n  static init() {\n    MP4.types = {\n      avc1: [],\n      // codingname\n      avcC: [],\n      hvc1: [],\n      hvcC: [],\n      btrt: [],\n      dinf: [],\n      dref: [],\n      esds: [],\n      ftyp: [],\n      hdlr: [],\n      mdat: [],\n      mdhd: [],\n      mdia: [],\n      mfhd: [],\n      minf: [],\n      moof: [],\n      moov: [],\n      mp4a: [],\n      '.mp3': [],\n      dac3: [],\n      'ac-3': [],\n      mvex: [],\n      mvhd: [],\n      pasp: [],\n      sdtp: [],\n      stbl: [],\n      stco: [],\n      stsc: [],\n      stsd: [],\n      stsz: [],\n      stts: [],\n      tfdt: [],\n      tfhd: [],\n      traf: [],\n      trak: [],\n      trun: [],\n      trex: [],\n      tkhd: [],\n      vmhd: [],\n      smhd: []\n    };\n    let i;\n    for (i in MP4.types) {\n      if (MP4.types.hasOwnProperty(i)) {\n        MP4.types[i] = [i.charCodeAt(0), i.charCodeAt(1), i.charCodeAt(2), i.charCodeAt(3)];\n      }\n    }\n    const videoHdlr = new Uint8Array([0x00,\n    // version 0\n    0x00, 0x00, 0x00,\n    // flags\n    0x00, 0x00, 0x00, 0x00,\n    // pre_defined\n    0x76, 0x69, 0x64, 0x65,\n    // handler_type: 'vide'\n    0x00, 0x00, 0x00, 0x00,\n    // reserved\n    0x00, 0x00, 0x00, 0x00,\n    // reserved\n    0x00, 0x00, 0x00, 0x00,\n    // reserved\n    0x56, 0x69, 0x64, 0x65, 0x6f, 0x48, 0x61, 0x6e, 0x64, 0x6c, 0x65, 0x72, 0x00 // name: 'VideoHandler'\n    ]);\n    const audioHdlr = new Uint8Array([0x00,\n    // version 0\n    0x00, 0x00, 0x00,\n    // flags\n    0x00, 0x00, 0x00, 0x00,\n    // pre_defined\n    0x73, 0x6f, 0x75, 0x6e,\n    // handler_type: 'soun'\n    0x00, 0x00, 0x00, 0x00,\n    // reserved\n    0x00, 0x00, 0x00, 0x00,\n    // reserved\n    0x00, 0x00, 0x00, 0x00,\n    // reserved\n    0x53, 0x6f, 0x75, 0x6e, 0x64, 0x48, 0x61, 0x6e, 0x64, 0x6c, 0x65, 0x72, 0x00 // name: 'SoundHandler'\n    ]);\n    MP4.HDLR_TYPES = {\n      video: videoHdlr,\n      audio: audioHdlr\n    };\n    const dref = new Uint8Array([0x00,\n    // version 0\n    0x00, 0x00, 0x00,\n    // flags\n    0x00, 0x00, 0x00, 0x01,\n    // entry_count\n    0x00, 0x00, 0x00, 0x0c,\n    // entry_size\n    0x75, 0x72, 0x6c, 0x20,\n    // 'url' type\n    0x00,\n    // version 0\n    0x00, 0x00, 0x01 // entry_flags\n    ]);\n    const stco = new Uint8Array([0x00,\n    // version\n    0x00, 0x00, 0x00,\n    // flags\n    0x00, 0x00, 0x00, 0x00 // entry_count\n    ]);\n    MP4.STTS = MP4.STSC = MP4.STCO = stco;\n    MP4.STSZ = new Uint8Array([0x00,\n    // version\n    0x00, 0x00, 0x00,\n    // flags\n    0x00, 0x00, 0x00, 0x00,\n    // sample_size\n    0x00, 0x00, 0x00, 0x00 // sample_count\n    ]);\n    MP4.VMHD = new Uint8Array([0x00,\n    // version\n    0x00, 0x00, 0x01,\n    // flags\n    0x00, 0x00,\n    // graphicsmode\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00 // opcolor\n    ]);\n    MP4.SMHD = new Uint8Array([0x00,\n    // version\n    0x00, 0x00, 0x00,\n    // flags\n    0x00, 0x00,\n    // balance\n    0x00, 0x00 // reserved\n    ]);\n    MP4.STSD = new Uint8Array([0x00,\n    // version 0\n    0x00, 0x00, 0x00,\n    // flags\n    0x00, 0x00, 0x00, 0x01]); // entry_count\n\n    const majorBrand = new Uint8Array([105, 115, 111, 109]); // isom\n    const avc1Brand = new Uint8Array([97, 118, 99, 49]); // avc1\n    const minorVersion = new Uint8Array([0, 0, 0, 1]);\n    MP4.FTYP = MP4.box(MP4.types.ftyp, majorBrand, minorVersion, majorBrand, avc1Brand);\n    MP4.DINF = MP4.box(MP4.types.dinf, MP4.box(MP4.types.dref, dref));\n  }\n  static box(type, ...payload) {\n    let size = 8;\n    let i = payload.length;\n    const len = i;\n    // calculate the total size we need to allocate\n    while (i--) {\n      size += payload[i].byteLength;\n    }\n    const result = new Uint8Array(size);\n    result[0] = size >> 24 & 0xff;\n    result[1] = size >> 16 & 0xff;\n    result[2] = size >> 8 & 0xff;\n    result[3] = size & 0xff;\n    result.set(type, 4);\n    // copy the payload into the result\n    for (i = 0, size = 8; i < len; i++) {\n      // copy payload[i] array @ offset size\n      result.set(payload[i], size);\n      size += payload[i].byteLength;\n    }\n    return result;\n  }\n  static hdlr(type) {\n    return MP4.box(MP4.types.hdlr, MP4.HDLR_TYPES[type]);\n  }\n  static mdat(data) {\n    return MP4.box(MP4.types.mdat, data);\n  }\n  static mdhd(timescale, duration) {\n    duration *= timescale;\n    const upperWordDuration = Math.floor(duration / (UINT32_MAX + 1));\n    const lowerWordDuration = Math.floor(duration % (UINT32_MAX + 1));\n    return MP4.box(MP4.types.mdhd, new Uint8Array([0x01,\n    // version 1\n    0x00, 0x00, 0x00,\n    // flags\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02,\n    // creation_time\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x03,\n    // modification_time\n    timescale >> 24 & 0xff, timescale >> 16 & 0xff, timescale >> 8 & 0xff, timescale & 0xff,\n    // timescale\n    upperWordDuration >> 24, upperWordDuration >> 16 & 0xff, upperWordDuration >> 8 & 0xff, upperWordDuration & 0xff, lowerWordDuration >> 24, lowerWordDuration >> 16 & 0xff, lowerWordDuration >> 8 & 0xff, lowerWordDuration & 0xff, 0x55, 0xc4,\n    // 'und' language (undetermined)\n    0x00, 0x00]));\n  }\n  static mdia(track) {\n    return MP4.box(MP4.types.mdia, MP4.mdhd(track.timescale || 0, track.duration || 0), MP4.hdlr(track.type), MP4.minf(track));\n  }\n  static mfhd(sequenceNumber) {\n    return MP4.box(MP4.types.mfhd, new Uint8Array([0x00, 0x00, 0x00, 0x00,\n    // flags\n    sequenceNumber >> 24, sequenceNumber >> 16 & 0xff, sequenceNumber >> 8 & 0xff, sequenceNumber & 0xff // sequence_number\n    ]));\n  }\n  static minf(track) {\n    if (track.type === 'audio') {\n      return MP4.box(MP4.types.minf, MP4.box(MP4.types.smhd, MP4.SMHD), MP4.DINF, MP4.stbl(track));\n    } else {\n      return MP4.box(MP4.types.minf, MP4.box(MP4.types.vmhd, MP4.VMHD), MP4.DINF, MP4.stbl(track));\n    }\n  }\n  static moof(sn, baseMediaDecodeTime, track) {\n    return MP4.box(MP4.types.moof, MP4.mfhd(sn), MP4.traf(track, baseMediaDecodeTime));\n  }\n  static moov(tracks) {\n    let i = tracks.length;\n    const boxes = [];\n    while (i--) {\n      boxes[i] = MP4.trak(tracks[i]);\n    }\n    return MP4.box.apply(null, [MP4.types.moov, MP4.mvhd(tracks[0].timescale || 0, tracks[0].duration || 0)].concat(boxes).concat(MP4.mvex(tracks)));\n  }\n  static mvex(tracks) {\n    let i = tracks.length;\n    const boxes = [];\n    while (i--) {\n      boxes[i] = MP4.trex(tracks[i]);\n    }\n    return MP4.box.apply(null, [MP4.types.mvex, ...boxes]);\n  }\n  static mvhd(timescale, duration) {\n    duration *= timescale;\n    const upperWordDuration = Math.floor(duration / (UINT32_MAX + 1));\n    const lowerWordDuration = Math.floor(duration % (UINT32_MAX + 1));\n    const bytes = new Uint8Array([0x01,\n    // version 1\n    0x00, 0x00, 0x00,\n    // flags\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02,\n    // creation_time\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x03,\n    // modification_time\n    timescale >> 24 & 0xff, timescale >> 16 & 0xff, timescale >> 8 & 0xff, timescale & 0xff,\n    // timescale\n    upperWordDuration >> 24, upperWordDuration >> 16 & 0xff, upperWordDuration >> 8 & 0xff, upperWordDuration & 0xff, lowerWordDuration >> 24, lowerWordDuration >> 16 & 0xff, lowerWordDuration >> 8 & 0xff, lowerWordDuration & 0xff, 0x00, 0x01, 0x00, 0x00,\n    // 1.0 rate\n    0x01, 0x00,\n    // 1.0 volume\n    0x00, 0x00,\n    // reserved\n    0x00, 0x00, 0x00, 0x00,\n    // reserved\n    0x00, 0x00, 0x00, 0x00,\n    // reserved\n    0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00,\n    // transformation: unity matrix\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n    // pre_defined\n    0xff, 0xff, 0xff, 0xff // next_track_ID\n    ]);\n    return MP4.box(MP4.types.mvhd, bytes);\n  }\n  static sdtp(track) {\n    const samples = track.samples || [];\n    const bytes = new Uint8Array(4 + samples.length);\n    let i;\n    let flags;\n    // leave the full box header (4 bytes) all zero\n    // write the sample table\n    for (i = 0; i < samples.length; i++) {\n      flags = samples[i].flags;\n      bytes[i + 4] = flags.dependsOn << 4 | flags.isDependedOn << 2 | flags.hasRedundancy;\n    }\n    return MP4.box(MP4.types.sdtp, bytes);\n  }\n  static stbl(track) {\n    return MP4.box(MP4.types.stbl, MP4.stsd(track), MP4.box(MP4.types.stts, MP4.STTS), MP4.box(MP4.types.stsc, MP4.STSC), MP4.box(MP4.types.stsz, MP4.STSZ), MP4.box(MP4.types.stco, MP4.STCO));\n  }\n  static avc1(track) {\n    let sps = [];\n    let pps = [];\n    let i;\n    let data;\n    let len;\n    // assemble the SPSs\n\n    for (i = 0; i < track.sps.length; i++) {\n      data = track.sps[i];\n      len = data.byteLength;\n      sps.push(len >>> 8 & 0xff);\n      sps.push(len & 0xff);\n\n      // SPS\n      sps = sps.concat(Array.prototype.slice.call(data));\n    }\n\n    // assemble the PPSs\n    for (i = 0; i < track.pps.length; i++) {\n      data = track.pps[i];\n      len = data.byteLength;\n      pps.push(len >>> 8 & 0xff);\n      pps.push(len & 0xff);\n      pps = pps.concat(Array.prototype.slice.call(data));\n    }\n    const avcc = MP4.box(MP4.types.avcC, new Uint8Array([0x01,\n    // version\n    sps[3],\n    // profile\n    sps[4],\n    // profile compat\n    sps[5],\n    // level\n    0xfc | 3,\n    // lengthSizeMinusOne, hard-coded to 4 bytes\n    0xe0 | track.sps.length // 3bit reserved (111) + numOfSequenceParameterSets\n    ].concat(sps).concat([track.pps.length // numOfPictureParameterSets\n    ]).concat(pps))); // \"PPS\"\n    const width = track.width;\n    const height = track.height;\n    const hSpacing = track.pixelRatio[0];\n    const vSpacing = track.pixelRatio[1];\n    return MP4.box(MP4.types.avc1, new Uint8Array([0x00, 0x00, 0x00,\n    // reserved\n    0x00, 0x00, 0x00,\n    // reserved\n    0x00, 0x01,\n    // data_reference_index\n    0x00, 0x00,\n    // pre_defined\n    0x00, 0x00,\n    // reserved\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n    // pre_defined\n    width >> 8 & 0xff, width & 0xff,\n    // width\n    height >> 8 & 0xff, height & 0xff,\n    // height\n    0x00, 0x48, 0x00, 0x00,\n    // horizresolution\n    0x00, 0x48, 0x00, 0x00,\n    // vertresolution\n    0x00, 0x00, 0x00, 0x00,\n    // reserved\n    0x00, 0x01,\n    // frame_count\n    0x12, 0x64, 0x61, 0x69, 0x6c,\n    // dailymotion/hls.js\n    0x79, 0x6d, 0x6f, 0x74, 0x69, 0x6f, 0x6e, 0x2f, 0x68, 0x6c, 0x73, 0x2e, 0x6a, 0x73, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n    // compressorname\n    0x00, 0x18,\n    // depth = 24\n    0x11, 0x11]),\n    // pre_defined = -1\n    avcc, MP4.box(MP4.types.btrt, new Uint8Array([0x00, 0x1c, 0x9c, 0x80,\n    // bufferSizeDB\n    0x00, 0x2d, 0xc6, 0xc0,\n    // maxBitrate\n    0x00, 0x2d, 0xc6, 0xc0])),\n    // avgBitrate\n    MP4.box(MP4.types.pasp, new Uint8Array([hSpacing >> 24,\n    // hSpacing\n    hSpacing >> 16 & 0xff, hSpacing >> 8 & 0xff, hSpacing & 0xff, vSpacing >> 24,\n    // vSpacing\n    vSpacing >> 16 & 0xff, vSpacing >> 8 & 0xff, vSpacing & 0xff])));\n  }\n  static esds(track) {\n    const config = track.config;\n    return new Uint8Array([0x00,\n    // version 0\n    0x00, 0x00, 0x00,\n    // flags\n\n    0x03,\n    // descriptor_type\n    0x19,\n    // length\n\n    0x00, 0x01,\n    // es_id\n\n    0x00,\n    // stream_priority\n\n    0x04,\n    // descriptor_type\n    0x11,\n    // length\n    0x40,\n    // codec : mpeg4_audio\n    0x15,\n    // stream_type\n    0x00, 0x00, 0x00,\n    // buffer_size\n    0x00, 0x00, 0x00, 0x00,\n    // maxBitrate\n    0x00, 0x00, 0x00, 0x00,\n    // avgBitrate\n\n    0x05,\n    // descriptor_type\n    0x02,\n    // length\n    ...config, 0x06, 0x01, 0x02 // GASpecificConfig)); // length + audio config descriptor\n    ]);\n  }\n  static audioStsd(track) {\n    const samplerate = track.samplerate || 0;\n    return new Uint8Array([0x00, 0x00, 0x00,\n    // reserved\n    0x00, 0x00, 0x00,\n    // reserved\n    0x00, 0x01,\n    // data_reference_index\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n    // reserved\n    0x00, track.channelCount || 0,\n    // channelcount\n    0x00, 0x10,\n    // sampleSize:16bits\n    0x00, 0x00, 0x00, 0x00,\n    // reserved2\n    samplerate >> 8 & 0xff, samplerate & 0xff,\n    //\n    0x00, 0x00]);\n  }\n  static mp4a(track) {\n    return MP4.box(MP4.types.mp4a, MP4.audioStsd(track), MP4.box(MP4.types.esds, MP4.esds(track)));\n  }\n  static mp3(track) {\n    return MP4.box(MP4.types['.mp3'], MP4.audioStsd(track));\n  }\n  static ac3(track) {\n    return MP4.box(MP4.types['ac-3'], MP4.audioStsd(track), MP4.box(MP4.types.dac3, track.config));\n  }\n  static stsd(track) {\n    const {\n      segmentCodec\n    } = track;\n    if (track.type === 'audio') {\n      if (segmentCodec === 'aac') {\n        return MP4.box(MP4.types.stsd, MP4.STSD, MP4.mp4a(track));\n      }\n      if (segmentCodec === 'ac3' && track.config) {\n        return MP4.box(MP4.types.stsd, MP4.STSD, MP4.ac3(track));\n      }\n      if (segmentCodec === 'mp3' && track.codec === 'mp3') {\n        return MP4.box(MP4.types.stsd, MP4.STSD, MP4.mp3(track));\n      }\n    } else {\n      if (track.pps && track.sps) {\n        if (segmentCodec === 'avc') {\n          return MP4.box(MP4.types.stsd, MP4.STSD, MP4.avc1(track));\n        }\n        if (segmentCodec === 'hevc' && track.vps) {\n          return MP4.box(MP4.types.stsd, MP4.STSD, MP4.hvc1(track));\n        }\n      } else {\n        throw new Error(`video track missing pps or sps`);\n      }\n    }\n    throw new Error(`unsupported ${track.type} segment codec (${segmentCodec}/${track.codec})`);\n  }\n  static tkhd(track) {\n    const id = track.id;\n    const duration = (track.duration || 0) * (track.timescale || 0);\n    const width = track.width || 0;\n    const height = track.height || 0;\n    const upperWordDuration = Math.floor(duration / (UINT32_MAX + 1));\n    const lowerWordDuration = Math.floor(duration % (UINT32_MAX + 1));\n    return MP4.box(MP4.types.tkhd, new Uint8Array([0x01,\n    // version 1\n    0x00, 0x00, 0x07,\n    // flags\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02,\n    // creation_time\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x03,\n    // modification_time\n    id >> 24 & 0xff, id >> 16 & 0xff, id >> 8 & 0xff, id & 0xff,\n    // track_ID\n    0x00, 0x00, 0x00, 0x00,\n    // reserved\n    upperWordDuration >> 24, upperWordDuration >> 16 & 0xff, upperWordDuration >> 8 & 0xff, upperWordDuration & 0xff, lowerWordDuration >> 24, lowerWordDuration >> 16 & 0xff, lowerWordDuration >> 8 & 0xff, lowerWordDuration & 0xff, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n    // reserved\n    0x00, 0x00,\n    // layer\n    0x00, 0x00,\n    // alternate_group\n    0x00, 0x00,\n    // non-audio track volume\n    0x00, 0x00,\n    // reserved\n    0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00,\n    // transformation: unity matrix\n    width >> 8 & 0xff, width & 0xff, 0x00, 0x00,\n    // width\n    height >> 8 & 0xff, height & 0xff, 0x00, 0x00 // height\n    ]));\n  }\n  static traf(track, baseMediaDecodeTime) {\n    const sampleDependencyTable = MP4.sdtp(track);\n    const id = track.id;\n    const upperWordBaseMediaDecodeTime = Math.floor(baseMediaDecodeTime / (UINT32_MAX + 1));\n    const lowerWordBaseMediaDecodeTime = Math.floor(baseMediaDecodeTime % (UINT32_MAX + 1));\n    return MP4.box(MP4.types.traf, MP4.box(MP4.types.tfhd, new Uint8Array([0x00,\n    // version 0\n    0x00, 0x00, 0x00,\n    // flags\n    id >> 24, id >> 16 & 0xff, id >> 8 & 0xff, id & 0xff // track_ID\n    ])), MP4.box(MP4.types.tfdt, new Uint8Array([0x01,\n    // version 1\n    0x00, 0x00, 0x00,\n    // flags\n    upperWordBaseMediaDecodeTime >> 24, upperWordBaseMediaDecodeTime >> 16 & 0xff, upperWordBaseMediaDecodeTime >> 8 & 0xff, upperWordBaseMediaDecodeTime & 0xff, lowerWordBaseMediaDecodeTime >> 24, lowerWordBaseMediaDecodeTime >> 16 & 0xff, lowerWordBaseMediaDecodeTime >> 8 & 0xff, lowerWordBaseMediaDecodeTime & 0xff])), MP4.trun(track, sampleDependencyTable.length + 16 +\n    // tfhd\n    20 +\n    // tfdt\n    8 +\n    // traf header\n    16 +\n    // mfhd\n    8 +\n    // moof header\n    8),\n    // mdat header\n    sampleDependencyTable);\n  }\n\n  /**\n   * Generate a track box.\n   * @param track a track definition\n   */\n  static trak(track) {\n    track.duration = track.duration || 0xffffffff;\n    return MP4.box(MP4.types.trak, MP4.tkhd(track), MP4.mdia(track));\n  }\n  static trex(track) {\n    const id = track.id;\n    return MP4.box(MP4.types.trex, new Uint8Array([0x00,\n    // version 0\n    0x00, 0x00, 0x00,\n    // flags\n    id >> 24, id >> 16 & 0xff, id >> 8 & 0xff, id & 0xff,\n    // track_ID\n    0x00, 0x00, 0x00, 0x01,\n    // default_sample_description_index\n    0x00, 0x00, 0x00, 0x00,\n    // default_sample_duration\n    0x00, 0x00, 0x00, 0x00,\n    // default_sample_size\n    0x00, 0x01, 0x00, 0x01 // default_sample_flags\n    ]));\n  }\n  static trun(track, offset) {\n    const samples = track.samples || [];\n    const len = samples.length;\n    const arraylen = 12 + 16 * len;\n    const array = new Uint8Array(arraylen);\n    let i;\n    let sample;\n    let duration;\n    let size;\n    let flags;\n    let cts;\n    offset += 8 + arraylen;\n    array.set([track.type === 'video' ? 0x01 : 0x00,\n    // version 1 for video with signed-int sample_composition_time_offset\n    0x00, 0x0f, 0x01,\n    // flags\n    len >>> 24 & 0xff, len >>> 16 & 0xff, len >>> 8 & 0xff, len & 0xff,\n    // sample_count\n    offset >>> 24 & 0xff, offset >>> 16 & 0xff, offset >>> 8 & 0xff, offset & 0xff // data_offset\n    ], 0);\n    for (i = 0; i < len; i++) {\n      sample = samples[i];\n      duration = sample.duration;\n      size = sample.size;\n      flags = sample.flags;\n      cts = sample.cts;\n      array.set([duration >>> 24 & 0xff, duration >>> 16 & 0xff, duration >>> 8 & 0xff, duration & 0xff,\n      // sample_duration\n      size >>> 24 & 0xff, size >>> 16 & 0xff, size >>> 8 & 0xff, size & 0xff,\n      // sample_size\n      flags.isLeading << 2 | flags.dependsOn, flags.isDependedOn << 6 | flags.hasRedundancy << 4 | flags.paddingValue << 1 | flags.isNonSync, flags.degradPrio & 0xf0 << 8, flags.degradPrio & 0x0f,\n      // sample_flags\n      cts >>> 24 & 0xff, cts >>> 16 & 0xff, cts >>> 8 & 0xff, cts & 0xff // sample_composition_time_offset\n      ], 12 + 16 * i);\n    }\n    return MP4.box(MP4.types.trun, array);\n  }\n  static initSegment(tracks) {\n    if (!MP4.types) {\n      MP4.init();\n    }\n    const movie = MP4.moov(tracks);\n    const result = appendUint8Array(MP4.FTYP, movie);\n    return result;\n  }\n  static hvc1(track) {\n    const ps = track.params;\n    const units = [track.vps, track.sps, track.pps];\n    const NALuLengthSize = 4;\n    const config = new Uint8Array([0x01, ps.general_profile_space << 6 | (ps.general_tier_flag ? 32 : 0) | ps.general_profile_idc, ps.general_profile_compatibility_flags[0], ps.general_profile_compatibility_flags[1], ps.general_profile_compatibility_flags[2], ps.general_profile_compatibility_flags[3], ps.general_constraint_indicator_flags[0], ps.general_constraint_indicator_flags[1], ps.general_constraint_indicator_flags[2], ps.general_constraint_indicator_flags[3], ps.general_constraint_indicator_flags[4], ps.general_constraint_indicator_flags[5], ps.general_level_idc, 240 | ps.min_spatial_segmentation_idc >> 8, 255 & ps.min_spatial_segmentation_idc, 252 | ps.parallelismType, 252 | ps.chroma_format_idc, 248 | ps.bit_depth_luma_minus8, 248 | ps.bit_depth_chroma_minus8, 0x00, parseInt(ps.frame_rate.fps), NALuLengthSize - 1 | ps.temporal_id_nested << 2 | ps.num_temporal_layers << 3 | (ps.frame_rate.fixed ? 64 : 0), units.length]);\n\n    // compute hvcC size in bytes\n    let length = config.length;\n    for (let i = 0; i < units.length; i += 1) {\n      length += 3;\n      for (let j = 0; j < units[i].length; j += 1) {\n        length += 2 + units[i][j].length;\n      }\n    }\n    const hvcC = new Uint8Array(length);\n    hvcC.set(config, 0);\n    length = config.length;\n    // append parameter set units: one vps, one or more sps and pps\n    const iMax = units.length - 1;\n    for (let i = 0; i < units.length; i += 1) {\n      hvcC.set(new Uint8Array([32 + i | (i === iMax ? 128 : 0), 0x00, units[i].length]), length);\n      length += 3;\n      for (let j = 0; j < units[i].length; j += 1) {\n        hvcC.set(new Uint8Array([units[i][j].length >> 8, units[i][j].length & 255]), length);\n        length += 2;\n        hvcC.set(units[i][j], length);\n        length += units[i][j].length;\n      }\n    }\n    const hvcc = MP4.box(MP4.types.hvcC, hvcC);\n    const width = track.width;\n    const height = track.height;\n    const hSpacing = track.pixelRatio[0];\n    const vSpacing = track.pixelRatio[1];\n    return MP4.box(MP4.types.hvc1, new Uint8Array([0x00, 0x00, 0x00,\n    // reserved\n    0x00, 0x00, 0x00,\n    // reserved\n    0x00, 0x01,\n    // data_reference_index\n    0x00, 0x00,\n    // pre_defined\n    0x00, 0x00,\n    // reserved\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n    // pre_defined\n    width >> 8 & 0xff, width & 0xff,\n    // width\n    height >> 8 & 0xff, height & 0xff,\n    // height\n    0x00, 0x48, 0x00, 0x00,\n    // horizresolution\n    0x00, 0x48, 0x00, 0x00,\n    // vertresolution\n    0x00, 0x00, 0x00, 0x00,\n    // reserved\n    0x00, 0x01,\n    // frame_count\n    0x12, 0x64, 0x61, 0x69, 0x6c,\n    // dailymotion/hls.js\n    0x79, 0x6d, 0x6f, 0x74, 0x69, 0x6f, 0x6e, 0x2f, 0x68, 0x6c, 0x73, 0x2e, 0x6a, 0x73, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n    // compressorname\n    0x00, 0x18,\n    // depth = 24\n    0x11, 0x11]),\n    // pre_defined = -1\n    hvcc, MP4.box(MP4.types.btrt, new Uint8Array([0x00, 0x1c, 0x9c, 0x80,\n    // bufferSizeDB\n    0x00, 0x2d, 0xc6, 0xc0,\n    // maxBitrate\n    0x00, 0x2d, 0xc6, 0xc0])),\n    // avgBitrate\n    MP4.box(MP4.types.pasp, new Uint8Array([hSpacing >> 24,\n    // hSpacing\n    hSpacing >> 16 & 0xff, hSpacing >> 8 & 0xff, hSpacing & 0xff, vSpacing >> 24,\n    // vSpacing\n    vSpacing >> 16 & 0xff, vSpacing >> 8 & 0xff, vSpacing & 0xff])));\n  }\n}\nMP4.types = void 0;\nMP4.HDLR_TYPES = void 0;\nMP4.STTS = void 0;\nMP4.STSC = void 0;\nMP4.STCO = void 0;\nMP4.STSZ = void 0;\nMP4.VMHD = void 0;\nMP4.SMHD = void 0;\nMP4.STSD = void 0;\nMP4.FTYP = void 0;\nMP4.DINF = void 0;\n\nconst MPEG_TS_CLOCK_FREQ_HZ = 90000;\nfunction toTimescaleFromBase(baseTime, destScale, srcBase = 1, round = false) {\n  const result = baseTime * destScale * srcBase; // equivalent to `(value * scale) / (1 / base)`\n  return round ? Math.round(result) : result;\n}\nfunction toTimescaleFromScale(baseTime, destScale, srcScale = 1, round = false) {\n  return toTimescaleFromBase(baseTime, destScale, 1 / srcScale, round);\n}\nfunction toMsFromMpegTsClock(baseTime, round = false) {\n  return toTimescaleFromBase(baseTime, 1000, 1 / MPEG_TS_CLOCK_FREQ_HZ, round);\n}\nfunction toMpegTsClockFromTimescale(baseTime, srcScale = 1) {\n  return toTimescaleFromBase(baseTime, MPEG_TS_CLOCK_FREQ_HZ, 1 / srcScale);\n}\nfunction timestampToString(timestamp) {\n  const {\n    baseTime,\n    timescale,\n    trackId\n  } = timestamp;\n  return `${baseTime / timescale} (${baseTime}/${timescale}) trackId: ${trackId}`;\n}\n\nconst MAX_SILENT_FRAME_DURATION = 10 * 1000; // 10 seconds\nconst AAC_SAMPLES_PER_FRAME = 1024;\nconst MPEG_AUDIO_SAMPLE_PER_FRAME = 1152;\nconst AC3_SAMPLES_PER_FRAME = 1536;\nlet chromeVersion = null;\nlet safariWebkitVersion = null;\nfunction createMp4Sample(isKeyframe, duration, size, cts) {\n  return {\n    duration,\n    size,\n    cts,\n    flags: {\n      isLeading: 0,\n      isDependedOn: 0,\n      hasRedundancy: 0,\n      degradPrio: 0,\n      dependsOn: isKeyframe ? 2 : 1,\n      isNonSync: isKeyframe ? 0 : 1\n    }\n  };\n}\nclass MP4Remuxer extends Logger {\n  constructor(observer, config, typeSupported, logger) {\n    super('mp4-remuxer', logger);\n    this.observer = void 0;\n    this.config = void 0;\n    this.typeSupported = void 0;\n    this.ISGenerated = false;\n    this._initPTS = null;\n    this._initDTS = null;\n    this.nextVideoTs = null;\n    this.nextAudioTs = null;\n    this.videoSampleDuration = null;\n    this.isAudioContiguous = false;\n    this.isVideoContiguous = false;\n    this.videoTrackConfig = void 0;\n    this.observer = observer;\n    this.config = config;\n    this.typeSupported = typeSupported;\n    this.ISGenerated = false;\n    if (chromeVersion === null) {\n      const userAgent = navigator.userAgent || '';\n      const result = userAgent.match(/Chrome\\/(\\d+)/i);\n      chromeVersion = result ? parseInt(result[1]) : 0;\n    }\n    if (safariWebkitVersion === null) {\n      const result = navigator.userAgent.match(/Safari\\/(\\d+)/i);\n      safariWebkitVersion = result ? parseInt(result[1]) : 0;\n    }\n  }\n  destroy() {\n    // @ts-ignore\n    this.config = this.videoTrackConfig = this._initPTS = this._initDTS = null;\n  }\n  resetTimeStamp(defaultTimeStamp) {\n    const initPTS = this._initPTS;\n    if (!initPTS || !defaultTimeStamp || defaultTimeStamp.trackId !== initPTS.trackId || defaultTimeStamp.baseTime !== initPTS.baseTime || defaultTimeStamp.timescale !== initPTS.timescale) {\n      this.log(`Reset initPTS: ${initPTS ? timestampToString(initPTS) : initPTS} > ${defaultTimeStamp ? timestampToString(defaultTimeStamp) : defaultTimeStamp}`);\n    }\n    this._initPTS = this._initDTS = defaultTimeStamp;\n  }\n  resetNextTimestamp() {\n    this.log('reset next timestamp');\n    this.isVideoContiguous = false;\n    this.isAudioContiguous = false;\n  }\n  resetInitSegment() {\n    this.log('ISGenerated flag reset');\n    this.ISGenerated = false;\n    this.videoTrackConfig = undefined;\n  }\n  getVideoStartPts(videoSamples) {\n    // Get the minimum PTS value relative to the first sample's PTS, normalized for 33-bit wrapping\n    let rolloverDetected = false;\n    const firstPts = videoSamples[0].pts;\n    const startPTS = videoSamples.reduce((minPTS, sample) => {\n      let pts = sample.pts;\n      let delta = pts - minPTS;\n      if (delta < -4294967296) {\n        // 2^32, see PTSNormalize for reasoning, but we're hitting a rollover here, and we don't want that to impact the timeOffset calculation\n        rolloverDetected = true;\n        pts = normalizePts(pts, firstPts);\n        delta = pts - minPTS;\n      }\n      if (delta > 0) {\n        return minPTS;\n      }\n      return pts;\n    }, firstPts);\n    if (rolloverDetected) {\n      this.debug('PTS rollover detected');\n    }\n    return startPTS;\n  }\n  remux(audioTrack, videoTrack, id3Track, textTrack, timeOffset, accurateTimeOffset, flush, playlistType) {\n    let video;\n    let audio;\n    let initSegment;\n    let text;\n    let id3;\n    let independent;\n    let audioTimeOffset = timeOffset;\n    let videoTimeOffset = timeOffset;\n\n    // If we're remuxing audio and video progressively, wait until we've received enough samples for each track before proceeding.\n    // This is done to synchronize the audio and video streams. We know if the current segment will have samples if the \"pid\"\n    // parameter is greater than -1. The pid is set when the PMT is parsed, which contains the tracks list.\n    // However, if the initSegment has already been generated, or we've reached the end of a segment (flush),\n    // then we can remux one track without waiting for the other.\n    const hasAudio = audioTrack.pid > -1;\n    const hasVideo = videoTrack.pid > -1;\n    const length = videoTrack.samples.length;\n    const enoughAudioSamples = audioTrack.samples.length > 0;\n    const enoughVideoSamples = flush && length > 0 || length > 1;\n    const canRemuxAvc = (!hasAudio || enoughAudioSamples) && (!hasVideo || enoughVideoSamples) || this.ISGenerated || flush;\n    if (canRemuxAvc) {\n      if (this.ISGenerated) {\n        var _videoTrack$pixelRati, _config$pixelRatio, _videoTrack$pixelRati2, _config$pixelRatio2;\n        const config = this.videoTrackConfig;\n        if (config && (videoTrack.width !== config.width || videoTrack.height !== config.height || ((_videoTrack$pixelRati = videoTrack.pixelRatio) == null ? void 0 : _videoTrack$pixelRati[0]) !== ((_config$pixelRatio = config.pixelRatio) == null ? void 0 : _config$pixelRatio[0]) || ((_videoTrack$pixelRati2 = videoTrack.pixelRatio) == null ? void 0 : _videoTrack$pixelRati2[1]) !== ((_config$pixelRatio2 = config.pixelRatio) == null ? void 0 : _config$pixelRatio2[1])) || !config && enoughVideoSamples || this.nextAudioTs === null && enoughAudioSamples) {\n          this.resetInitSegment();\n        }\n      }\n      if (!this.ISGenerated) {\n        initSegment = this.generateIS(audioTrack, videoTrack, timeOffset, accurateTimeOffset);\n      }\n      const isVideoContiguous = this.isVideoContiguous;\n      let firstKeyFrameIndex = -1;\n      let firstKeyFramePTS;\n      if (enoughVideoSamples) {\n        firstKeyFrameIndex = findKeyframeIndex(videoTrack.samples);\n        if (!isVideoContiguous && this.config.forceKeyFrameOnDiscontinuity) {\n          independent = true;\n          if (firstKeyFrameIndex > 0) {\n            this.warn(`Dropped ${firstKeyFrameIndex} out of ${length} video samples due to a missing keyframe`);\n            const startPTS = this.getVideoStartPts(videoTrack.samples);\n            videoTrack.samples = videoTrack.samples.slice(firstKeyFrameIndex);\n            videoTrack.dropped += firstKeyFrameIndex;\n            videoTimeOffset += (videoTrack.samples[0].pts - startPTS) / videoTrack.inputTimeScale;\n            firstKeyFramePTS = videoTimeOffset;\n          } else if (firstKeyFrameIndex === -1) {\n            this.warn(`No keyframe found out of ${length} video samples`);\n            independent = false;\n          }\n        }\n      }\n      if (this.ISGenerated) {\n        if (enoughAudioSamples && enoughVideoSamples) {\n          // timeOffset is expected to be the offset of the first timestamp of this fragment (first DTS)\n          // if first audio DTS is not aligned with first video DTS then we need to take that into account\n          // when providing timeOffset to remuxAudio / remuxVideo. if we don't do that, there might be a permanent / small\n          // drift between audio and video streams\n          const startPTS = this.getVideoStartPts(videoTrack.samples);\n          const tsDelta = normalizePts(audioTrack.samples[0].pts, startPTS) - startPTS;\n          const audiovideoTimestampDelta = tsDelta / videoTrack.inputTimeScale;\n          audioTimeOffset += Math.max(0, audiovideoTimestampDelta);\n          videoTimeOffset += Math.max(0, -audiovideoTimestampDelta);\n        }\n\n        // Purposefully remuxing audio before video, so that remuxVideo can use nextAudioPts, which is calculated in remuxAudio.\n        if (enoughAudioSamples) {\n          // if initSegment was generated without audio samples, regenerate it again\n          if (!audioTrack.samplerate) {\n            this.warn('regenerate InitSegment as audio detected');\n            initSegment = this.generateIS(audioTrack, videoTrack, timeOffset, accurateTimeOffset);\n          }\n          audio = this.remuxAudio(audioTrack, audioTimeOffset, this.isAudioContiguous, accurateTimeOffset, hasVideo || enoughVideoSamples || playlistType === PlaylistLevelType.AUDIO ? videoTimeOffset : undefined);\n          if (enoughVideoSamples) {\n            const audioTrackLength = audio ? audio.endPTS - audio.startPTS : 0;\n            // if initSegment was generated without video samples, regenerate it again\n            if (!videoTrack.inputTimeScale) {\n              this.warn('regenerate InitSegment as video detected');\n              initSegment = this.generateIS(audioTrack, videoTrack, timeOffset, accurateTimeOffset);\n            }\n            video = this.remuxVideo(videoTrack, videoTimeOffset, isVideoContiguous, audioTrackLength);\n          }\n        } else if (enoughVideoSamples) {\n          video = this.remuxVideo(videoTrack, videoTimeOffset, isVideoContiguous, 0);\n        }\n        if (video) {\n          video.firstKeyFrame = firstKeyFrameIndex;\n          video.independent = firstKeyFrameIndex !== -1;\n          video.firstKeyFramePTS = firstKeyFramePTS;\n        }\n      }\n    }\n\n    // Allow ID3 and text to remux, even if more audio/video samples are required\n    if (this.ISGenerated && this._initPTS && this._initDTS) {\n      if (id3Track.samples.length) {\n        id3 = flushTextTrackMetadataCueSamples(id3Track, timeOffset, this._initPTS, this._initDTS);\n      }\n      if (textTrack.samples.length) {\n        text = flushTextTrackUserdataCueSamples(textTrack, timeOffset, this._initPTS);\n      }\n    }\n    return {\n      audio,\n      video,\n      initSegment,\n      independent,\n      text,\n      id3\n    };\n  }\n  computeInitPts(basetime, timescale, presentationTime, type) {\n    const offset = Math.round(presentationTime * timescale);\n    let timestamp = normalizePts(basetime, offset);\n    if (timestamp < offset + timescale) {\n      this.log(`Adjusting PTS for rollover in timeline near ${(offset - timestamp) / timescale} ${type}`);\n      while (timestamp < offset + timescale) {\n        timestamp += 8589934592;\n      }\n    }\n    return timestamp - offset;\n  }\n  generateIS(audioTrack, videoTrack, timeOffset, accurateTimeOffset) {\n    const audioSamples = audioTrack.samples;\n    const videoSamples = videoTrack.samples;\n    const typeSupported = this.typeSupported;\n    const tracks = {};\n    const _initPTS = this._initPTS;\n    let computePTSDTS = !_initPTS || accurateTimeOffset;\n    let container = 'audio/mp4';\n    let initPTS;\n    let initDTS;\n    let timescale;\n    let trackId = -1;\n    if (computePTSDTS) {\n      initPTS = initDTS = Infinity;\n    }\n    if (audioTrack.config && audioSamples.length) {\n      // let's use audio sampling rate as MP4 time scale.\n      // rationale is that there is a integer nb of audio frames per audio sample (1024 for AAC)\n      // using audio sampling rate here helps having an integer MP4 frame duration\n      // this avoids potential rounding issue and AV sync issue\n      audioTrack.timescale = audioTrack.samplerate;\n      switch (audioTrack.segmentCodec) {\n        case 'mp3':\n          if (typeSupported.mpeg) {\n            // Chrome and Safari\n            container = 'audio/mpeg';\n            audioTrack.codec = '';\n          } else if (typeSupported.mp3) {\n            // Firefox\n            audioTrack.codec = 'mp3';\n          }\n          break;\n        case 'ac3':\n          audioTrack.codec = 'ac-3';\n          break;\n      }\n      tracks.audio = {\n        id: 'audio',\n        container: container,\n        codec: audioTrack.codec,\n        initSegment: audioTrack.segmentCodec === 'mp3' && typeSupported.mpeg ? new Uint8Array(0) : MP4.initSegment([audioTrack]),\n        metadata: {\n          channelCount: audioTrack.channelCount\n        }\n      };\n      if (computePTSDTS) {\n        trackId = audioTrack.id;\n        timescale = audioTrack.inputTimeScale;\n        if (!_initPTS || timescale !== _initPTS.timescale) {\n          // remember first PTS of this demuxing context. for audio, PTS = DTS\n          initPTS = initDTS = this.computeInitPts(audioSamples[0].pts, timescale, timeOffset, 'audio');\n        } else {\n          computePTSDTS = false;\n        }\n      }\n    }\n    if (videoTrack.sps && videoTrack.pps && videoSamples.length) {\n      // let's use input time scale as MP4 video timescale\n      // we use input time scale straight away to avoid rounding issues on frame duration / cts computation\n      videoTrack.timescale = videoTrack.inputTimeScale;\n      tracks.video = {\n        id: 'main',\n        container: 'video/mp4',\n        codec: videoTrack.codec,\n        initSegment: MP4.initSegment([videoTrack]),\n        metadata: {\n          width: videoTrack.width,\n          height: videoTrack.height\n        }\n      };\n      if (computePTSDTS) {\n        trackId = videoTrack.id;\n        timescale = videoTrack.inputTimeScale;\n        if (!_initPTS || timescale !== _initPTS.timescale) {\n          const basePTS = this.getVideoStartPts(videoSamples);\n          const baseDTS = normalizePts(videoSamples[0].dts, basePTS);\n          const videoInitDTS = this.computeInitPts(baseDTS, timescale, timeOffset, 'video');\n          const videoInitPTS = this.computeInitPts(basePTS, timescale, timeOffset, 'video');\n          initDTS = Math.min(initDTS, videoInitDTS);\n          initPTS = Math.min(initPTS, videoInitPTS);\n        } else {\n          computePTSDTS = false;\n        }\n      }\n      this.videoTrackConfig = {\n        width: videoTrack.width,\n        height: videoTrack.height,\n        pixelRatio: videoTrack.pixelRatio\n      };\n    }\n    if (Object.keys(tracks).length) {\n      this.ISGenerated = true;\n      if (computePTSDTS) {\n        if (_initPTS) {\n          this.warn(`Timestamps at playlist time: ${accurateTimeOffset ? '' : '~'}${timeOffset} ${initPTS / timescale} != initPTS: ${_initPTS.baseTime / _initPTS.timescale} (${_initPTS.baseTime}/${_initPTS.timescale}) trackId: ${_initPTS.trackId}`);\n        }\n        this.log(`Found initPTS at playlist time: ${timeOffset} offset: ${initPTS / timescale} (${initPTS}/${timescale}) trackId: ${trackId}`);\n        this._initPTS = {\n          baseTime: initPTS,\n          timescale: timescale,\n          trackId: trackId\n        };\n        this._initDTS = {\n          baseTime: initDTS,\n          timescale: timescale,\n          trackId: trackId\n        };\n      } else {\n        initPTS = timescale = undefined;\n      }\n      return {\n        tracks,\n        initPTS,\n        timescale,\n        trackId\n      };\n    }\n  }\n  remuxVideo(track, timeOffset, contiguous, audioTrackLength) {\n    const timeScale = track.inputTimeScale;\n    const inputSamples = track.samples;\n    const outputSamples = [];\n    const nbSamples = inputSamples.length;\n    const initPTS = this._initPTS;\n    const initTime = initPTS.baseTime * timeScale / initPTS.timescale;\n    let nextVideoTs = this.nextVideoTs;\n    let offset = 8;\n    let mp4SampleDuration = this.videoSampleDuration;\n    let firstDTS;\n    let lastDTS;\n    let minPTS = Number.POSITIVE_INFINITY;\n    let maxPTS = Number.NEGATIVE_INFINITY;\n    let sortSamples = false;\n\n    // if parsed fragment is contiguous with last one, let's use last DTS value as reference\n    if (!contiguous || nextVideoTs === null) {\n      const pts = initTime + timeOffset * timeScale;\n      const cts = inputSamples[0].pts - normalizePts(inputSamples[0].dts, inputSamples[0].pts);\n      if (chromeVersion && nextVideoTs !== null && Math.abs(pts - cts - (nextVideoTs + initTime)) < 15000) {\n        // treat as contigous to adjust samples that would otherwise produce video buffer gaps in Chrome\n        contiguous = true;\n      } else {\n        // if not contiguous, let's use target timeOffset\n        nextVideoTs = pts - cts - initTime;\n      }\n    }\n\n    // PTS is coded on 33bits, and can loop from -2^32 to 2^32\n    // PTSNormalize will make PTS/DTS value monotonic, we use last known DTS value as reference value\n    const nextVideoPts = nextVideoTs + initTime;\n    for (let i = 0; i < nbSamples; i++) {\n      const sample = inputSamples[i];\n      sample.pts = normalizePts(sample.pts, nextVideoPts);\n      sample.dts = normalizePts(sample.dts, nextVideoPts);\n      if (sample.dts < inputSamples[i > 0 ? i - 1 : i].dts) {\n        sortSamples = true;\n      }\n    }\n\n    // sort video samples by DTS then PTS then demux id order\n    if (sortSamples) {\n      inputSamples.sort(function (a, b) {\n        const deltadts = a.dts - b.dts;\n        const deltapts = a.pts - b.pts;\n        return deltadts || deltapts;\n      });\n    }\n\n    // Get first/last DTS\n    firstDTS = inputSamples[0].dts;\n    lastDTS = inputSamples[inputSamples.length - 1].dts;\n\n    // Sample duration (as expected by trun MP4 boxes), should be the delta between sample DTS\n    // set this constant duration as being the avg delta between consecutive DTS.\n    const inputDuration = lastDTS - firstDTS;\n    const averageSampleDuration = inputDuration ? Math.round(inputDuration / (nbSamples - 1)) : mp4SampleDuration || track.inputTimeScale / 30;\n\n    // if fragment are contiguous, detect hole/overlapping between fragments\n    if (contiguous) {\n      // check timestamp continuity across consecutive fragments (this is to remove inter-fragment gap/hole)\n      const delta = firstDTS - nextVideoPts;\n      const foundHole = delta > averageSampleDuration;\n      const foundOverlap = delta < -1;\n      if (foundHole || foundOverlap) {\n        if (foundHole) {\n          this.warn(`${(track.segmentCodec || '').toUpperCase()}: ${toMsFromMpegTsClock(delta, true)} ms (${delta}dts) hole between fragments detected at ${timeOffset.toFixed(3)}`);\n        } else {\n          this.warn(`${(track.segmentCodec || '').toUpperCase()}: ${toMsFromMpegTsClock(-delta, true)} ms (${delta}dts) overlapping between fragments detected at ${timeOffset.toFixed(3)}`);\n        }\n        if (!foundOverlap || nextVideoPts >= inputSamples[0].pts || chromeVersion) {\n          firstDTS = nextVideoPts;\n          const firstPTS = inputSamples[0].pts - delta;\n          if (foundHole) {\n            inputSamples[0].dts = firstDTS;\n            inputSamples[0].pts = firstPTS;\n          } else {\n            let isPTSOrderRetained = true;\n            for (let i = 0; i < inputSamples.length; i++) {\n              if (inputSamples[i].dts > firstPTS && isPTSOrderRetained) {\n                break;\n              }\n              const prevPTS = inputSamples[i].pts;\n              inputSamples[i].dts -= delta;\n              inputSamples[i].pts -= delta;\n\n              // check to see if this sample's PTS order has changed\n              // relative to the next one\n              if (i < inputSamples.length - 1) {\n                const nextSamplePTS = inputSamples[i + 1].pts;\n                const currentSamplePTS = inputSamples[i].pts;\n                const currentOrder = nextSamplePTS <= currentSamplePTS;\n                const prevOrder = nextSamplePTS <= prevPTS;\n                isPTSOrderRetained = currentOrder == prevOrder;\n              }\n            }\n          }\n          this.log(`Video: Initial PTS/DTS adjusted: ${toMsFromMpegTsClock(firstPTS, true)}/${toMsFromMpegTsClock(firstDTS, true)}, delta: ${toMsFromMpegTsClock(delta, true)} ms`);\n        }\n      }\n    }\n    firstDTS = Math.max(0, firstDTS);\n    let nbNalu = 0;\n    let naluLen = 0;\n    let dtsStep = firstDTS;\n    for (let i = 0; i < nbSamples; i++) {\n      // compute total/avc sample length and nb of NAL units\n      const sample = inputSamples[i];\n      const units = sample.units;\n      const nbUnits = units.length;\n      let sampleLen = 0;\n      for (let j = 0; j < nbUnits; j++) {\n        sampleLen += units[j].data.length;\n      }\n      naluLen += sampleLen;\n      nbNalu += nbUnits;\n      sample.length = sampleLen;\n\n      // ensure sample monotonic DTS\n      if (sample.dts < dtsStep) {\n        sample.dts = dtsStep;\n        dtsStep += averageSampleDuration / 4 | 0 || 1;\n      } else {\n        dtsStep = sample.dts;\n      }\n      minPTS = Math.min(sample.pts, minPTS);\n      maxPTS = Math.max(sample.pts, maxPTS);\n    }\n    lastDTS = inputSamples[nbSamples - 1].dts;\n\n    /* concatenate the video data and construct the mdat in place\n      (need 8 more bytes to fill length and mpdat type) */\n    const mdatSize = naluLen + 4 * nbNalu + 8;\n    let mdat;\n    try {\n      mdat = new Uint8Array(mdatSize);\n    } catch (err) {\n      this.observer.emit(Events.ERROR, Events.ERROR, {\n        type: ErrorTypes.MUX_ERROR,\n        details: ErrorDetails.REMUX_ALLOC_ERROR,\n        fatal: false,\n        error: err,\n        bytes: mdatSize,\n        reason: `fail allocating video mdat ${mdatSize}`\n      });\n      return;\n    }\n    const view = new DataView(mdat.buffer);\n    view.setUint32(0, mdatSize);\n    mdat.set(MP4.types.mdat, 4);\n    let stretchedLastFrame = false;\n    let minDtsDelta = Number.POSITIVE_INFINITY;\n    let minPtsDelta = Number.POSITIVE_INFINITY;\n    let maxDtsDelta = Number.NEGATIVE_INFINITY;\n    let maxPtsDelta = Number.NEGATIVE_INFINITY;\n    for (let i = 0; i < nbSamples; i++) {\n      const VideoSample = inputSamples[i];\n      const VideoSampleUnits = VideoSample.units;\n      let mp4SampleLength = 0;\n      // convert NALU bitstream to MP4 format (prepend NALU with size field)\n      for (let j = 0, nbUnits = VideoSampleUnits.length; j < nbUnits; j++) {\n        const unit = VideoSampleUnits[j];\n        const unitData = unit.data;\n        const unitDataLen = unit.data.byteLength;\n        view.setUint32(offset, unitDataLen);\n        offset += 4;\n        mdat.set(unitData, offset);\n        offset += unitDataLen;\n        mp4SampleLength += 4 + unitDataLen;\n      }\n\n      // expected sample duration is the Decoding Timestamp diff of consecutive samples\n      let ptsDelta;\n      if (i < nbSamples - 1) {\n        mp4SampleDuration = inputSamples[i + 1].dts - VideoSample.dts;\n        ptsDelta = inputSamples[i + 1].pts - VideoSample.pts;\n      } else {\n        const config = this.config;\n        const lastFrameDuration = i > 0 ? VideoSample.dts - inputSamples[i - 1].dts : averageSampleDuration;\n        ptsDelta = i > 0 ? VideoSample.pts - inputSamples[i - 1].pts : averageSampleDuration;\n        if (config.stretchShortVideoTrack && this.nextAudioTs !== null) {\n          // In some cases, a segment's audio track duration may exceed the video track duration.\n          // Since we've already remuxed audio, and we know how long the audio track is, we look to\n          // see if the delta to the next segment is longer than maxBufferHole.\n          // If so, playback would potentially get stuck, so we artificially inflate\n          // the duration of the last frame to minimize any potential gap between segments.\n          const gapTolerance = Math.floor(config.maxBufferHole * timeScale);\n          const deltaToFrameEnd = (audioTrackLength ? minPTS + audioTrackLength * timeScale : this.nextAudioTs + initTime) - VideoSample.pts;\n          if (deltaToFrameEnd > gapTolerance) {\n            // We subtract lastFrameDuration from deltaToFrameEnd to try to prevent any video\n            // frame overlap. maxBufferHole should be >> lastFrameDuration anyway.\n            mp4SampleDuration = deltaToFrameEnd - lastFrameDuration;\n            if (mp4SampleDuration < 0) {\n              mp4SampleDuration = lastFrameDuration;\n            } else {\n              stretchedLastFrame = true;\n            }\n            this.log(`It is approximately ${deltaToFrameEnd / 90} ms to the next segment; using duration ${mp4SampleDuration / 90} ms for the last video frame.`);\n          } else {\n            mp4SampleDuration = lastFrameDuration;\n          }\n        } else {\n          mp4SampleDuration = lastFrameDuration;\n        }\n      }\n      const compositionTimeOffset = Math.round(VideoSample.pts - VideoSample.dts);\n      minDtsDelta = Math.min(minDtsDelta, mp4SampleDuration);\n      maxDtsDelta = Math.max(maxDtsDelta, mp4SampleDuration);\n      minPtsDelta = Math.min(minPtsDelta, ptsDelta);\n      maxPtsDelta = Math.max(maxPtsDelta, ptsDelta);\n      outputSamples.push(createMp4Sample(VideoSample.key, mp4SampleDuration, mp4SampleLength, compositionTimeOffset));\n    }\n    if (outputSamples.length) {\n      if (chromeVersion) {\n        if (chromeVersion < 70) {\n          // Chrome workaround, mark first sample as being a Random Access Point (keyframe) to avoid sourcebuffer append issue\n          // https://code.google.com/p/chromium/issues/detail?id=229412\n          const flags = outputSamples[0].flags;\n          flags.dependsOn = 2;\n          flags.isNonSync = 0;\n        }\n      } else if (safariWebkitVersion) {\n        // Fix for \"CNN special report, with CC\" in test-streams (Safari browser only)\n        // Ignore DTS when frame durations are irregular. Safari MSE does not handle this leading to gaps.\n        if (maxPtsDelta - minPtsDelta < maxDtsDelta - minDtsDelta && averageSampleDuration / maxDtsDelta < 0.025 && outputSamples[0].cts === 0) {\n          this.warn('Found irregular gaps in sample duration. Using PTS instead of DTS to determine MP4 sample duration.');\n          let dts = firstDTS;\n          for (let i = 0, len = outputSamples.length; i < len; i++) {\n            const nextDts = dts + outputSamples[i].duration;\n            const pts = dts + outputSamples[i].cts;\n            if (i < len - 1) {\n              const nextPts = nextDts + outputSamples[i + 1].cts;\n              outputSamples[i].duration = nextPts - pts;\n            } else {\n              outputSamples[i].duration = i ? outputSamples[i - 1].duration : averageSampleDuration;\n            }\n            outputSamples[i].cts = 0;\n            dts = nextDts;\n          }\n        }\n      }\n    }\n    // next AVC/HEVC sample DTS should be equal to last sample DTS + last sample duration (in PES timescale)\n    mp4SampleDuration = stretchedLastFrame || !mp4SampleDuration ? averageSampleDuration : mp4SampleDuration;\n    const endDTS = lastDTS + mp4SampleDuration;\n    this.nextVideoTs = nextVideoTs = endDTS - initTime;\n    this.videoSampleDuration = mp4SampleDuration;\n    this.isVideoContiguous = true;\n    const moof = MP4.moof(track.sequenceNumber++, firstDTS, _extends(track, {\n      samples: outputSamples\n    }));\n    const type = 'video';\n    const data = {\n      data1: moof,\n      data2: mdat,\n      startPTS: (minPTS - initTime) / timeScale,\n      endPTS: (maxPTS + mp4SampleDuration - initTime) / timeScale,\n      startDTS: (firstDTS - initTime) / timeScale,\n      endDTS: nextVideoTs / timeScale,\n      type,\n      hasAudio: false,\n      hasVideo: true,\n      nb: outputSamples.length,\n      dropped: track.dropped\n    };\n    track.samples = [];\n    track.dropped = 0;\n    return data;\n  }\n  getSamplesPerFrame(track) {\n    switch (track.segmentCodec) {\n      case 'mp3':\n        return MPEG_AUDIO_SAMPLE_PER_FRAME;\n      case 'ac3':\n        return AC3_SAMPLES_PER_FRAME;\n      default:\n        return AAC_SAMPLES_PER_FRAME;\n    }\n  }\n  remuxAudio(track, timeOffset, contiguous, accurateTimeOffset, videoTimeOffset) {\n    const inputTimeScale = track.inputTimeScale;\n    const mp4timeScale = track.samplerate ? track.samplerate : inputTimeScale;\n    const scaleFactor = inputTimeScale / mp4timeScale;\n    const mp4SampleDuration = this.getSamplesPerFrame(track);\n    const inputSampleDuration = mp4SampleDuration * scaleFactor;\n    const initPTS = this._initPTS;\n    const rawMPEG = track.segmentCodec === 'mp3' && this.typeSupported.mpeg;\n    const outputSamples = [];\n    const alignedWithVideo = videoTimeOffset !== undefined;\n    let inputSamples = track.samples;\n    let offset = rawMPEG ? 0 : 8;\n    let nextAudioTs = this.nextAudioTs || -1;\n\n    // window.audioSamples ? window.audioSamples.push(inputSamples.map(s => s.pts)) : (window.audioSamples = [inputSamples.map(s => s.pts)]);\n\n    // for audio samples, also consider consecutive fragments as being contiguous (even if a level switch occurs),\n    // for sake of clarity:\n    // consecutive fragments are frags with\n    //  - less than 100ms gaps between new time offset (if accurate) and next expected PTS OR\n    //  - less than 20 audio frames distance\n    // contiguous fragments are consecutive fragments from same quality level (same level, new SN = old SN + 1)\n    // this helps ensuring audio continuity\n    // and this also avoids audio glitches/cut when switching quality, or reporting wrong duration on first audio frame\n    const initTime = initPTS.baseTime * inputTimeScale / initPTS.timescale;\n    const timeOffsetMpegTS = initTime + timeOffset * inputTimeScale;\n    this.isAudioContiguous = contiguous = contiguous || inputSamples.length && nextAudioTs > 0 && (accurateTimeOffset && Math.abs(timeOffsetMpegTS - (nextAudioTs + initTime)) < 9000 || Math.abs(normalizePts(inputSamples[0].pts, timeOffsetMpegTS) - (nextAudioTs + initTime)) < 20 * inputSampleDuration);\n\n    // compute normalized PTS\n    inputSamples.forEach(function (sample) {\n      sample.pts = normalizePts(sample.pts, timeOffsetMpegTS);\n    });\n    if (!contiguous || nextAudioTs < 0) {\n      const sampleCount = inputSamples.length;\n      // filter out sample with negative PTS that are not playable anyway\n      // if we don't remove these negative samples, they will shift all audio samples forward.\n      // leading to audio overlap between current / next fragment\n      inputSamples = inputSamples.filter(sample => sample.pts >= 0);\n      if (sampleCount !== inputSamples.length) {\n        this.warn(`Removed ${inputSamples.length - sampleCount} of ${sampleCount} samples (initPTS ${initTime} / ${inputTimeScale})`);\n      }\n\n      // in case all samples have negative PTS, and have been filtered out, return now\n      if (!inputSamples.length) {\n        return;\n      }\n      if (videoTimeOffset === 0) {\n        // Set the start to match video so that start gaps larger than inputSampleDuration are filled with silence\n        nextAudioTs = 0;\n      } else if (accurateTimeOffset && !alignedWithVideo) {\n        // When not seeking, not live, and LevelDetails.PTSKnown, use fragment start as predicted next audio PTS\n        nextAudioTs = Math.max(0, timeOffsetMpegTS - initTime);\n      } else {\n        // if frags are not contiguous and if we cant trust time offset, let's use first sample PTS as next audio PTS\n        nextAudioTs = inputSamples[0].pts - initTime;\n      }\n    }\n\n    // If the audio track is missing samples, the frames seem to get \"left-shifted\" within the\n    // resulting mp4 segment, causing sync issues and leaving gaps at the end of the audio segment.\n    // In an effort to prevent this from happening, we inject frames here where there are gaps.\n    // When possible, we inject a silent frame; when that's not possible, we duplicate the last\n    // frame.\n\n    if (track.segmentCodec === 'aac') {\n      const maxAudioFramesDrift = this.config.maxAudioFramesDrift;\n      for (let i = 0, nextPts = nextAudioTs + initTime; i < inputSamples.length; i++) {\n        // First, let's see how far off this frame is from where we expect it to be\n        const sample = inputSamples[i];\n        const pts = sample.pts;\n        const delta = pts - nextPts;\n        const duration = Math.abs(1000 * delta / inputTimeScale);\n\n        // When remuxing with video, if we're overlapping by more than a duration, drop this sample to stay in sync\n        if (delta <= -maxAudioFramesDrift * inputSampleDuration && alignedWithVideo) {\n          if (i === 0) {\n            this.warn(`Audio frame @ ${(pts / inputTimeScale).toFixed(3)}s overlaps marker by ${Math.round(1000 * delta / inputTimeScale)} ms.`);\n            this.nextAudioTs = nextAudioTs = pts - initTime;\n            nextPts = pts;\n          }\n        } // eslint-disable-line brace-style\n\n        // Insert missing frames if:\n        // 1: We're more than maxAudioFramesDrift frame away\n        // 2: Not more than MAX_SILENT_FRAME_DURATION away\n        // 3: currentTime (aka nextPtsNorm) is not 0\n        // 4: remuxing with video (videoTimeOffset !== undefined)\n        else if (delta >= maxAudioFramesDrift * inputSampleDuration && duration < MAX_SILENT_FRAME_DURATION && alignedWithVideo) {\n          let missing = Math.round(delta / inputSampleDuration);\n          // Adjust nextPts so that silent samples are aligned with media pts. This will prevent media samples from\n          // later being shifted if nextPts is based on timeOffset and delta is not a multiple of inputSampleDuration.\n          nextPts = pts - missing * inputSampleDuration;\n          while (nextPts < 0 && missing && inputSampleDuration) {\n            missing--;\n            nextPts += inputSampleDuration;\n          }\n          if (i === 0) {\n            this.nextAudioTs = nextAudioTs = nextPts - initTime;\n          }\n          this.warn(`Injecting ${missing} audio frames @ ${((nextPts - initTime) / inputTimeScale).toFixed(3)}s due to ${Math.round(1000 * delta / inputTimeScale)} ms gap.`);\n          for (let j = 0; j < missing; j++) {\n            let fillFrame = AAC.getSilentFrame(track.parsedCodec || track.manifestCodec || track.codec, track.channelCount);\n            if (!fillFrame) {\n              this.log('Unable to get silent frame for given audio codec; duplicating last frame instead.');\n              fillFrame = sample.unit.subarray();\n            }\n            inputSamples.splice(i, 0, {\n              unit: fillFrame,\n              pts: nextPts\n            });\n            nextPts += inputSampleDuration;\n            i++;\n          }\n        }\n        sample.pts = nextPts;\n        nextPts += inputSampleDuration;\n      }\n    }\n    let firstPTS = null;\n    let lastPTS = null;\n    let mdat;\n    let mdatSize = 0;\n    let sampleLength = inputSamples.length;\n    while (sampleLength--) {\n      mdatSize += inputSamples[sampleLength].unit.byteLength;\n    }\n    for (let j = 0, _nbSamples = inputSamples.length; j < _nbSamples; j++) {\n      const audioSample = inputSamples[j];\n      const unit = audioSample.unit;\n      let pts = audioSample.pts;\n      if (lastPTS !== null) {\n        // If we have more than one sample, set the duration of the sample to the \"real\" duration; the PTS diff with\n        // the previous sample\n        const prevSample = outputSamples[j - 1];\n        prevSample.duration = Math.round((pts - lastPTS) / scaleFactor);\n      } else {\n        if (contiguous && track.segmentCodec === 'aac') {\n          // set PTS/DTS to expected PTS/DTS\n          pts = nextAudioTs + initTime;\n        }\n        // remember first PTS of our audioSamples\n        firstPTS = pts;\n        if (mdatSize > 0) {\n          /* concatenate the audio data and construct the mdat in place\n            (need 8 more bytes to fill length and mdat type) */\n          mdatSize += offset;\n          try {\n            mdat = new Uint8Array(mdatSize);\n          } catch (err) {\n            this.observer.emit(Events.ERROR, Events.ERROR, {\n              type: ErrorTypes.MUX_ERROR,\n              details: ErrorDetails.REMUX_ALLOC_ERROR,\n              fatal: false,\n              error: err,\n              bytes: mdatSize,\n              reason: `fail allocating audio mdat ${mdatSize}`\n            });\n            return;\n          }\n          if (!rawMPEG) {\n            const view = new DataView(mdat.buffer);\n            view.setUint32(0, mdatSize);\n            mdat.set(MP4.types.mdat, 4);\n          }\n        } else {\n          // no audio samples\n          return;\n        }\n      }\n      mdat.set(unit, offset);\n      const unitLen = unit.byteLength;\n      offset += unitLen;\n      // Default the sample's duration to the computed mp4SampleDuration, which will either be 1024 for AAC or 1152 for MPEG\n      // In the case that we have 1 sample, this will be the duration. If we have more than one sample, the duration\n      // becomes the PTS diff with the previous sample\n      outputSamples.push(createMp4Sample(true, mp4SampleDuration, unitLen, 0));\n      lastPTS = pts;\n    }\n\n    // We could end up with no audio samples if all input samples were overlapping with the previously remuxed ones\n    const nbSamples = outputSamples.length;\n    if (!nbSamples) {\n      return;\n    }\n\n    // The next audio sample PTS should be equal to last sample PTS + duration\n    const lastSample = outputSamples[outputSamples.length - 1];\n    nextAudioTs = lastPTS - initTime;\n    this.nextAudioTs = nextAudioTs + scaleFactor * lastSample.duration;\n\n    // Set the track samples from inputSamples to outputSamples before remuxing\n    const moof = rawMPEG ? new Uint8Array(0) : MP4.moof(track.sequenceNumber++, firstPTS / scaleFactor, _extends({}, track, {\n      samples: outputSamples\n    }));\n\n    // Clear the track samples. This also clears the samples array in the demuxer, since the reference is shared\n    track.samples = [];\n    const start = (firstPTS - initTime) / inputTimeScale;\n    const end = this.nextAudioTs / inputTimeScale;\n    const type = 'audio';\n    const audioData = {\n      data1: moof,\n      data2: mdat,\n      startPTS: start,\n      endPTS: end,\n      startDTS: start,\n      endDTS: end,\n      type,\n      hasAudio: true,\n      hasVideo: false,\n      nb: nbSamples\n    };\n    this.isAudioContiguous = true;\n    return audioData;\n  }\n}\nfunction normalizePts(value, reference) {\n  let offset;\n  if (reference === null) {\n    return value;\n  }\n  if (reference < value) {\n    // - 2^33\n    offset = -8589934592;\n  } else {\n    // + 2^33\n    offset = 8589934592;\n  }\n  /* PTS is 33bit (from 0 to 2^33 -1)\n    if diff between value and reference is bigger than half of the amplitude (2^32) then it means that\n    PTS looping occured. fill the gap */\n  while (Math.abs(value - reference) > 4294967296) {\n    value += offset;\n  }\n  return value;\n}\nfunction findKeyframeIndex(samples) {\n  for (let i = 0; i < samples.length; i++) {\n    if (samples[i].key) {\n      return i;\n    }\n  }\n  return -1;\n}\nfunction flushTextTrackMetadataCueSamples(track, timeOffset, initPTS, initDTS) {\n  const length = track.samples.length;\n  if (!length) {\n    return;\n  }\n  const inputTimeScale = track.inputTimeScale;\n  for (let index = 0; index < length; index++) {\n    const sample = track.samples[index];\n    // setting id3 pts, dts to relative time\n    // using this._initPTS and this._initDTS to calculate relative time\n    sample.pts = normalizePts(sample.pts - initPTS.baseTime * inputTimeScale / initPTS.timescale, timeOffset * inputTimeScale) / inputTimeScale;\n    sample.dts = normalizePts(sample.dts - initDTS.baseTime * inputTimeScale / initDTS.timescale, timeOffset * inputTimeScale) / inputTimeScale;\n  }\n  const samples = track.samples;\n  track.samples = [];\n  return {\n    samples\n  };\n}\nfunction flushTextTrackUserdataCueSamples(track, timeOffset, initPTS) {\n  const length = track.samples.length;\n  if (!length) {\n    return;\n  }\n  const inputTimeScale = track.inputTimeScale;\n  for (let index = 0; index < length; index++) {\n    const sample = track.samples[index];\n    // setting text pts, dts to relative time\n    // using this._initPTS and this._initDTS to calculate relative time\n    sample.pts = normalizePts(sample.pts - initPTS.baseTime * inputTimeScale / initPTS.timescale, timeOffset * inputTimeScale) / inputTimeScale;\n  }\n  track.samples.sort((a, b) => a.pts - b.pts);\n  const samples = track.samples;\n  track.samples = [];\n  return {\n    samples\n  };\n}\n\nclass PassThroughRemuxer extends Logger {\n  constructor(observer, config, typeSupported, logger) {\n    super('passthrough-remuxer', logger);\n    this.emitInitSegment = false;\n    this.audioCodec = void 0;\n    this.videoCodec = void 0;\n    this.initData = void 0;\n    this.initPTS = null;\n    this.initTracks = void 0;\n    this.lastEndTime = null;\n    this.isVideoContiguous = false;\n  }\n  destroy() {}\n  resetTimeStamp(defaultInitPTS) {\n    this.lastEndTime = null;\n    const initPTS = this.initPTS;\n    if (initPTS && defaultInitPTS) {\n      if (initPTS.baseTime === defaultInitPTS.baseTime && initPTS.timescale === defaultInitPTS.timescale) {\n        return;\n      }\n    }\n    this.initPTS = defaultInitPTS;\n  }\n  resetNextTimestamp() {\n    this.isVideoContiguous = false;\n    this.lastEndTime = null;\n  }\n  resetInitSegment(initSegment, audioCodec, videoCodec, decryptdata) {\n    this.audioCodec = audioCodec;\n    this.videoCodec = videoCodec;\n    this.generateInitSegment(initSegment, decryptdata);\n    this.emitInitSegment = true;\n  }\n  generateInitSegment(initSegment, decryptdata) {\n    let {\n      audioCodec,\n      videoCodec\n    } = this;\n    if (!(initSegment != null && initSegment.byteLength)) {\n      this.initTracks = undefined;\n      this.initData = undefined;\n      return;\n    }\n    const {\n      audio,\n      video\n    } = this.initData = parseInitSegment(initSegment);\n    if (decryptdata) {\n      patchEncyptionData(initSegment, decryptdata);\n    } else {\n      const eitherTrack = audio || video;\n      if (eitherTrack != null && eitherTrack.encrypted) {\n        this.warn(`Init segment with encrypted track with has no key (\"${eitherTrack.codec}\")!`);\n      }\n    }\n\n    // Get codec from initSegment\n    if (audio) {\n      audioCodec = getParsedTrackCodec(audio, ElementaryStreamTypes.AUDIO, this);\n    }\n    if (video) {\n      videoCodec = getParsedTrackCodec(video, ElementaryStreamTypes.VIDEO, this);\n    }\n    const tracks = {};\n    if (audio && video) {\n      tracks.audiovideo = {\n        container: 'video/mp4',\n        codec: audioCodec + ',' + videoCodec,\n        supplemental: video.supplemental,\n        encrypted: video.encrypted,\n        initSegment,\n        id: 'main'\n      };\n    } else if (audio) {\n      tracks.audio = {\n        container: 'audio/mp4',\n        codec: audioCodec,\n        encrypted: audio.encrypted,\n        initSegment,\n        id: 'audio'\n      };\n    } else if (video) {\n      tracks.video = {\n        container: 'video/mp4',\n        codec: videoCodec,\n        supplemental: video.supplemental,\n        encrypted: video.encrypted,\n        initSegment,\n        id: 'main'\n      };\n    } else {\n      this.warn('initSegment does not contain moov or trak boxes.');\n    }\n    this.initTracks = tracks;\n  }\n  remux(audioTrack, videoTrack, id3Track, textTrack, timeOffset, accurateTimeOffset) {\n    var _initData, _initData2;\n    let {\n      initPTS,\n      lastEndTime\n    } = this;\n    const result = {\n      audio: undefined,\n      video: undefined,\n      text: textTrack,\n      id3: id3Track,\n      initSegment: undefined\n    };\n\n    // If we haven't yet set a lastEndDTS, or it was reset, set it to the provided timeOffset. We want to use the\n    // lastEndDTS over timeOffset whenever possible; during progressive playback, the media source will not update\n    // the media duration (which is what timeOffset is provided as) before we need to process the next chunk.\n    if (!isFiniteNumber(lastEndTime)) {\n      lastEndTime = this.lastEndTime = timeOffset || 0;\n    }\n\n    // The binary segment data is added to the videoTrack in the mp4demuxer. We don't check to see if the data is only\n    // audio or video (or both); adding it to video was an arbitrary choice.\n    const data = videoTrack.samples;\n    if (!data.length) {\n      return result;\n    }\n    const initSegment = {\n      initPTS: undefined,\n      timescale: undefined,\n      trackId: undefined\n    };\n    let initData = this.initData;\n    if (!((_initData = initData) != null && _initData.length)) {\n      this.generateInitSegment(data);\n      initData = this.initData;\n    }\n    if (!((_initData2 = initData) != null && _initData2.length)) {\n      // We can't remux if the initSegment could not be generated\n      this.warn('Failed to generate initSegment.');\n      return result;\n    }\n    if (this.emitInitSegment) {\n      initSegment.tracks = this.initTracks;\n      this.emitInitSegment = false;\n    }\n    const trackSampleData = getSampleData(data, initData, this);\n    const audioSampleTimestamps = initData.audio ? trackSampleData[initData.audio.id] : null;\n    const videoSampleTimestamps = initData.video ? trackSampleData[initData.video.id] : null;\n    const videoStartTime = toStartEndOrDefault(videoSampleTimestamps, Infinity);\n    const audioStartTime = toStartEndOrDefault(audioSampleTimestamps, Infinity);\n    const videoEndTime = toStartEndOrDefault(videoSampleTimestamps, 0, true);\n    const audioEndTime = toStartEndOrDefault(audioSampleTimestamps, 0, true);\n    let decodeTime = timeOffset;\n    let duration = 0;\n    const syncOnAudio = audioSampleTimestamps && (!videoSampleTimestamps || !initPTS && audioStartTime < videoStartTime || initPTS && initPTS.trackId === initData.audio.id);\n    const baseOffsetSamples = syncOnAudio ? audioSampleTimestamps : videoSampleTimestamps;\n    if (baseOffsetSamples) {\n      const timescale = baseOffsetSamples.timescale;\n      const baseTime = baseOffsetSamples.start - timeOffset * timescale;\n      const trackId = syncOnAudio ? initData.audio.id : initData.video.id;\n      decodeTime = baseOffsetSamples.start / timescale;\n      duration = syncOnAudio ? audioEndTime - audioStartTime : videoEndTime - videoStartTime;\n      if ((accurateTimeOffset || !initPTS) && (isInvalidInitPts(initPTS, decodeTime, timeOffset, duration) || timescale !== initPTS.timescale)) {\n        if (initPTS) {\n          this.warn(`Timestamps at playlist time: ${accurateTimeOffset ? '' : '~'}${timeOffset} ${baseTime / timescale} != initPTS: ${initPTS.baseTime / initPTS.timescale} (${initPTS.baseTime}/${initPTS.timescale}) trackId: ${initPTS.trackId}`);\n        }\n        this.log(`Found initPTS at playlist time: ${timeOffset} offset: ${decodeTime - timeOffset} (${baseTime}/${timescale}) trackId: ${trackId}`);\n        initPTS = null;\n        initSegment.initPTS = baseTime;\n        initSegment.timescale = timescale;\n        initSegment.trackId = trackId;\n      }\n    } else {\n      this.warn(`No audio or video samples found for initPTS at playlist time: ${timeOffset}`);\n    }\n    if (!initPTS) {\n      if (!initSegment.timescale || initSegment.trackId === undefined || initSegment.initPTS === undefined) {\n        this.warn('Could not set initPTS');\n        initSegment.initPTS = decodeTime;\n        initSegment.timescale = 1;\n        initSegment.trackId = -1;\n      }\n      this.initPTS = initPTS = {\n        baseTime: initSegment.initPTS,\n        timescale: initSegment.timescale,\n        trackId: initSegment.trackId\n      };\n    } else {\n      initSegment.initPTS = initPTS.baseTime;\n      initSegment.timescale = initPTS.timescale;\n      initSegment.trackId = initPTS.trackId;\n    }\n    const startTime = decodeTime - initPTS.baseTime / initPTS.timescale;\n    const endTime = startTime + duration;\n    if (duration > 0) {\n      this.lastEndTime = endTime;\n    } else {\n      this.warn('Duration parsed from mp4 should be greater than zero');\n      this.resetNextTimestamp();\n    }\n    const hasAudio = !!initData.audio;\n    const hasVideo = !!initData.video;\n    let type = '';\n    if (hasAudio) {\n      type += 'audio';\n    }\n    if (hasVideo) {\n      type += 'video';\n    }\n    const encrypted = (initData.audio ? initData.audio.encrypted : false) || (initData.video ? initData.video.encrypted : false);\n    const track = {\n      data1: data,\n      startPTS: startTime,\n      startDTS: startTime,\n      endPTS: endTime,\n      endDTS: endTime,\n      type,\n      hasAudio,\n      hasVideo,\n      nb: 1,\n      dropped: 0,\n      encrypted\n    };\n    result.audio = hasAudio && !hasVideo ? track : undefined;\n    result.video = hasVideo ? track : undefined;\n    const videoSampleCount = videoSampleTimestamps == null ? void 0 : videoSampleTimestamps.sampleCount;\n    if (videoSampleCount) {\n      const firstKeyFrame = videoSampleTimestamps.keyFrameIndex;\n      const independent = firstKeyFrame !== -1;\n      track.nb = videoSampleCount;\n      track.dropped = firstKeyFrame === 0 || this.isVideoContiguous ? 0 : independent ? firstKeyFrame : videoSampleCount;\n      track.independent = independent;\n      track.firstKeyFrame = firstKeyFrame;\n      if (independent && videoSampleTimestamps.keyFrameStart) {\n        track.firstKeyFramePTS = (videoSampleTimestamps.keyFrameStart - initPTS.baseTime) / initPTS.timescale;\n      }\n      if (!this.isVideoContiguous) {\n        result.independent = independent;\n      }\n      this.isVideoContiguous || (this.isVideoContiguous = independent);\n      if (track.dropped) {\n        this.warn(`fmp4 does not start with IDR: firstIDR ${firstKeyFrame}/${videoSampleCount} dropped: ${track.dropped} start: ${track.firstKeyFramePTS || 'NA'}`);\n      }\n    }\n    result.initSegment = initSegment;\n    result.id3 = flushTextTrackMetadataCueSamples(id3Track, timeOffset, initPTS, initPTS);\n    if (textTrack.samples.length) {\n      result.text = flushTextTrackUserdataCueSamples(textTrack, timeOffset, initPTS);\n    }\n    return result;\n  }\n}\nfunction toStartEndOrDefault(trackTimes, defaultValue, end = false) {\n  return (trackTimes == null ? void 0 : trackTimes.start) !== undefined ? (trackTimes.start + (end ? trackTimes.duration : 0)) / trackTimes.timescale : defaultValue;\n}\nfunction isInvalidInitPts(initPTS, startDTS, timeOffset, duration) {\n  if (initPTS === null) {\n    return true;\n  }\n  // InitPTS is invalid when distance from program would be more than segment duration or a minimum of one second\n  const minDuration = Math.max(duration, 1);\n  const startTime = startDTS - initPTS.baseTime / initPTS.timescale;\n  return Math.abs(startTime - timeOffset) > minDuration;\n}\nfunction getParsedTrackCodec(track, type, logger) {\n  const parsedCodec = track.codec;\n  if (parsedCodec && parsedCodec.length > 4) {\n    return parsedCodec;\n  }\n  if (type === ElementaryStreamTypes.AUDIO) {\n    if (parsedCodec === 'ec-3' || parsedCodec === 'ac-3' || parsedCodec === 'alac') {\n      return parsedCodec;\n    }\n    if (parsedCodec === 'fLaC' || parsedCodec === 'Opus') {\n      // Opting not to get `preferManagedMediaSource` from player config for isSupported() check for simplicity\n      const preferManagedMediaSource = false;\n      return getCodecCompatibleName(parsedCodec, preferManagedMediaSource);\n    }\n    logger.warn(`Unhandled audio codec \"${parsedCodec}\" in mp4 MAP`);\n    return parsedCodec || 'mp4a';\n  }\n  // Provide defaults based on codec type\n  // This allows for some playback of some fmp4 playlists without CODECS defined in manifest\n  logger.warn(`Unhandled video codec \"${parsedCodec}\" in mp4 MAP`);\n  return parsedCodec || 'avc1';\n}\n\nlet now;\n// performance.now() not available on WebWorker, at least on Safari Desktop\ntry {\n  now = self.performance.now.bind(self.performance);\n} catch (err) {\n  now = Date.now;\n}\nconst muxConfig = [{\n  demux: MP4Demuxer,\n  remux: PassThroughRemuxer\n}, {\n  demux: TSDemuxer,\n  remux: MP4Remuxer\n}, {\n  demux: AACDemuxer,\n  remux: MP4Remuxer\n}, {\n  demux: MP3Demuxer,\n  remux: MP4Remuxer\n}];\n{\n  muxConfig.splice(2, 0, {\n    demux: AC3Demuxer,\n    remux: MP4Remuxer\n  });\n}\nclass Transmuxer {\n  constructor(observer, typeSupported, config, vendor, id, logger) {\n    this.asyncResult = false;\n    this.logger = void 0;\n    this.observer = void 0;\n    this.typeSupported = void 0;\n    this.config = void 0;\n    this.id = void 0;\n    this.demuxer = void 0;\n    this.remuxer = void 0;\n    this.decrypter = void 0;\n    this.probe = void 0;\n    this.decryptionPromise = null;\n    this.transmuxConfig = void 0;\n    this.currentTransmuxState = void 0;\n    this.observer = observer;\n    this.typeSupported = typeSupported;\n    this.config = config;\n    this.id = id;\n    this.logger = logger;\n  }\n  configure(transmuxConfig) {\n    this.transmuxConfig = transmuxConfig;\n    if (this.decrypter) {\n      this.decrypter.reset();\n    }\n  }\n  push(data, decryptdata, chunkMeta, state) {\n    const stats = chunkMeta.transmuxing;\n    stats.executeStart = now();\n    let uintData = new Uint8Array(data);\n    const {\n      currentTransmuxState,\n      transmuxConfig\n    } = this;\n    if (state) {\n      this.currentTransmuxState = state;\n    }\n    const {\n      contiguous,\n      discontinuity,\n      trackSwitch,\n      accurateTimeOffset,\n      timeOffset,\n      initSegmentChange\n    } = state || currentTransmuxState;\n    const {\n      audioCodec,\n      videoCodec,\n      defaultInitPts,\n      duration,\n      initSegmentData\n    } = transmuxConfig;\n    const keyData = getEncryptionType(uintData, decryptdata);\n    if (keyData && isFullSegmentEncryption(keyData.method)) {\n      const decrypter = this.getDecrypter();\n      const aesMode = getAesModeFromFullSegmentMethod(keyData.method);\n\n      // Software decryption is synchronous; webCrypto is not\n      if (decrypter.isSync()) {\n        // Software decryption is progressive. Progressive decryption may not return a result on each call. Any cached\n        // data is handled in the flush() call\n        let decryptedData = decrypter.softwareDecrypt(uintData, keyData.key.buffer, keyData.iv.buffer, aesMode);\n        // For Low-Latency HLS Parts, decrypt in place, since part parsing is expected on push progress\n        const loadingParts = chunkMeta.part > -1;\n        if (loadingParts) {\n          const _data = decrypter.flush();\n          decryptedData = _data ? _data.buffer : _data;\n        }\n        if (!decryptedData) {\n          stats.executeEnd = now();\n          return emptyResult(chunkMeta);\n        }\n        uintData = new Uint8Array(decryptedData);\n      } else {\n        this.asyncResult = true;\n        this.decryptionPromise = decrypter.webCryptoDecrypt(uintData, keyData.key.buffer, keyData.iv.buffer, aesMode).then(decryptedData => {\n          // Calling push here is important; if flush() is called while this is still resolving, this ensures that\n          // the decrypted data has been transmuxed\n          const result = this.push(decryptedData, null, chunkMeta);\n          this.decryptionPromise = null;\n          return result;\n        });\n        return this.decryptionPromise;\n      }\n    }\n    const resetMuxers = this.needsProbing(discontinuity, trackSwitch);\n    if (resetMuxers) {\n      const error = this.configureTransmuxer(uintData);\n      if (error) {\n        this.logger.warn(`[transmuxer] ${error.message}`);\n        this.observer.emit(Events.ERROR, Events.ERROR, {\n          type: ErrorTypes.MEDIA_ERROR,\n          details: ErrorDetails.FRAG_PARSING_ERROR,\n          fatal: false,\n          error,\n          reason: error.message\n        });\n        stats.executeEnd = now();\n        return emptyResult(chunkMeta);\n      }\n    }\n    if (discontinuity || trackSwitch || initSegmentChange || resetMuxers) {\n      this.resetInitSegment(initSegmentData, audioCodec, videoCodec, duration, decryptdata);\n    }\n    if (discontinuity || initSegmentChange || resetMuxers) {\n      this.resetInitialTimestamp(defaultInitPts);\n    }\n    if (!contiguous) {\n      this.resetContiguity();\n    }\n    const result = this.transmux(uintData, keyData, timeOffset, accurateTimeOffset, chunkMeta);\n    this.asyncResult = isPromise(result);\n    const currentState = this.currentTransmuxState;\n    currentState.contiguous = true;\n    currentState.discontinuity = false;\n    currentState.trackSwitch = false;\n    stats.executeEnd = now();\n    return result;\n  }\n\n  // Due to data caching, flush calls can produce more than one TransmuxerResult (hence the Array type)\n  flush(chunkMeta) {\n    const stats = chunkMeta.transmuxing;\n    stats.executeStart = now();\n    const {\n      decrypter,\n      currentTransmuxState,\n      decryptionPromise\n    } = this;\n    if (decryptionPromise) {\n      this.asyncResult = true;\n      // Upon resolution, the decryption promise calls push() and returns its TransmuxerResult up the stack. Therefore\n      // only flushing is required for async decryption\n      return decryptionPromise.then(() => {\n        return this.flush(chunkMeta);\n      });\n    }\n    const transmuxResults = [];\n    const {\n      timeOffset\n    } = currentTransmuxState;\n    if (decrypter) {\n      // The decrypter may have data cached, which needs to be demuxed. In this case we'll have two TransmuxResults\n      // This happens in the case that we receive only 1 push call for a segment (either for non-progressive downloads,\n      // or for progressive downloads with small segments)\n      const decryptedData = decrypter.flush();\n      if (decryptedData) {\n        // Push always returns a TransmuxerResult if decryptdata is null\n        transmuxResults.push(this.push(decryptedData.buffer, null, chunkMeta));\n      }\n    }\n    const {\n      demuxer,\n      remuxer\n    } = this;\n    if (!demuxer || !remuxer) {\n      // If probing failed, then Hls.js has been given content its not able to handle\n      stats.executeEnd = now();\n      const emptyResults = [emptyResult(chunkMeta)];\n      if (this.asyncResult) {\n        return Promise.resolve(emptyResults);\n      }\n      return emptyResults;\n    }\n    const demuxResultOrPromise = demuxer.flush(timeOffset);\n    if (isPromise(demuxResultOrPromise)) {\n      this.asyncResult = true;\n      // Decrypt final SAMPLE-AES samples\n      return demuxResultOrPromise.then(demuxResult => {\n        this.flushRemux(transmuxResults, demuxResult, chunkMeta);\n        return transmuxResults;\n      });\n    }\n    this.flushRemux(transmuxResults, demuxResultOrPromise, chunkMeta);\n    if (this.asyncResult) {\n      return Promise.resolve(transmuxResults);\n    }\n    return transmuxResults;\n  }\n  flushRemux(transmuxResults, demuxResult, chunkMeta) {\n    const {\n      audioTrack,\n      videoTrack,\n      id3Track,\n      textTrack\n    } = demuxResult;\n    const {\n      accurateTimeOffset,\n      timeOffset\n    } = this.currentTransmuxState;\n    this.logger.log(`[transmuxer.ts]: Flushed ${this.id} sn: ${chunkMeta.sn}${chunkMeta.part > -1 ? ' part: ' + chunkMeta.part : ''} of ${this.id === PlaylistLevelType.MAIN ? 'level' : 'track'} ${chunkMeta.level}`);\n    const remuxResult = this.remuxer.remux(audioTrack, videoTrack, id3Track, textTrack, timeOffset, accurateTimeOffset, true, this.id);\n    transmuxResults.push({\n      remuxResult,\n      chunkMeta\n    });\n    chunkMeta.transmuxing.executeEnd = now();\n  }\n  resetInitialTimestamp(defaultInitPts) {\n    const {\n      demuxer,\n      remuxer\n    } = this;\n    if (!demuxer || !remuxer) {\n      return;\n    }\n    demuxer.resetTimeStamp(defaultInitPts);\n    remuxer.resetTimeStamp(defaultInitPts);\n  }\n  resetContiguity() {\n    const {\n      demuxer,\n      remuxer\n    } = this;\n    if (!demuxer || !remuxer) {\n      return;\n    }\n    demuxer.resetContiguity();\n    remuxer.resetNextTimestamp();\n  }\n  resetInitSegment(initSegmentData, audioCodec, videoCodec, trackDuration, decryptdata) {\n    const {\n      demuxer,\n      remuxer\n    } = this;\n    if (!demuxer || !remuxer) {\n      return;\n    }\n    demuxer.resetInitSegment(initSegmentData, audioCodec, videoCodec, trackDuration);\n    remuxer.resetInitSegment(initSegmentData, audioCodec, videoCodec, decryptdata);\n  }\n  destroy() {\n    if (this.demuxer) {\n      this.demuxer.destroy();\n      this.demuxer = undefined;\n    }\n    if (this.remuxer) {\n      this.remuxer.destroy();\n      this.remuxer = undefined;\n    }\n  }\n  transmux(data, keyData, timeOffset, accurateTimeOffset, chunkMeta) {\n    let result;\n    if (keyData && keyData.method === 'SAMPLE-AES') {\n      result = this.transmuxSampleAes(data, keyData, timeOffset, accurateTimeOffset, chunkMeta);\n    } else {\n      result = this.transmuxUnencrypted(data, timeOffset, accurateTimeOffset, chunkMeta);\n    }\n    return result;\n  }\n  transmuxUnencrypted(data, timeOffset, accurateTimeOffset, chunkMeta) {\n    const {\n      audioTrack,\n      videoTrack,\n      id3Track,\n      textTrack\n    } = this.demuxer.demux(data, timeOffset, false, !this.config.progressive);\n    const remuxResult = this.remuxer.remux(audioTrack, videoTrack, id3Track, textTrack, timeOffset, accurateTimeOffset, false, this.id);\n    return {\n      remuxResult,\n      chunkMeta\n    };\n  }\n  transmuxSampleAes(data, decryptData, timeOffset, accurateTimeOffset, chunkMeta) {\n    return this.demuxer.demuxSampleAes(data, decryptData, timeOffset).then(demuxResult => {\n      const remuxResult = this.remuxer.remux(demuxResult.audioTrack, demuxResult.videoTrack, demuxResult.id3Track, demuxResult.textTrack, timeOffset, accurateTimeOffset, false, this.id);\n      return {\n        remuxResult,\n        chunkMeta\n      };\n    });\n  }\n  configureTransmuxer(data) {\n    const {\n      config,\n      observer,\n      typeSupported\n    } = this;\n    // probe for content type\n    let mux;\n    for (let i = 0, len = muxConfig.length; i < len; i++) {\n      var _muxConfig$i$demux;\n      if ((_muxConfig$i$demux = muxConfig[i].demux) != null && _muxConfig$i$demux.probe(data, this.logger)) {\n        mux = muxConfig[i];\n        break;\n      }\n    }\n    if (!mux) {\n      return new Error('Failed to find demuxer by probing fragment data');\n    }\n    // so let's check that current remuxer and demuxer are still valid\n    const demuxer = this.demuxer;\n    const remuxer = this.remuxer;\n    const Remuxer = mux.remux;\n    const Demuxer = mux.demux;\n    if (!remuxer || !(remuxer instanceof Remuxer)) {\n      this.remuxer = new Remuxer(observer, config, typeSupported, this.logger);\n    }\n    if (!demuxer || !(demuxer instanceof Demuxer)) {\n      this.demuxer = new Demuxer(observer, config, typeSupported, this.logger);\n      this.probe = Demuxer.probe;\n    }\n  }\n  needsProbing(discontinuity, trackSwitch) {\n    // in case of continuity change, or track switch\n    // we might switch from content type (AAC container to TS container, or TS to fmp4 for example)\n    return !this.demuxer || !this.remuxer || discontinuity || trackSwitch;\n  }\n  getDecrypter() {\n    let decrypter = this.decrypter;\n    if (!decrypter) {\n      decrypter = this.decrypter = new Decrypter(this.config);\n    }\n    return decrypter;\n  }\n}\nfunction getEncryptionType(data, decryptData) {\n  let encryptionType = null;\n  if (data.byteLength > 0 && (decryptData == null ? void 0 : decryptData.key) != null && decryptData.iv !== null && decryptData.method != null) {\n    encryptionType = decryptData;\n  }\n  return encryptionType;\n}\nconst emptyResult = chunkMeta => ({\n  remuxResult: {},\n  chunkMeta\n});\nfunction isPromise(p) {\n  return 'then' in p && p.then instanceof Function;\n}\nclass TransmuxConfig {\n  constructor(audioCodec, videoCodec, initSegmentData, duration, defaultInitPts) {\n    this.audioCodec = void 0;\n    this.videoCodec = void 0;\n    this.initSegmentData = void 0;\n    this.duration = void 0;\n    this.defaultInitPts = void 0;\n    this.audioCodec = audioCodec;\n    this.videoCodec = videoCodec;\n    this.initSegmentData = initSegmentData;\n    this.duration = duration;\n    this.defaultInitPts = defaultInitPts || null;\n  }\n}\nclass TransmuxState {\n  constructor(discontinuity, contiguous, accurateTimeOffset, trackSwitch, timeOffset, initSegmentChange) {\n    this.discontinuity = void 0;\n    this.contiguous = void 0;\n    this.accurateTimeOffset = void 0;\n    this.trackSwitch = void 0;\n    this.timeOffset = void 0;\n    this.initSegmentChange = void 0;\n    this.discontinuity = discontinuity;\n    this.contiguous = contiguous;\n    this.accurateTimeOffset = accurateTimeOffset;\n    this.trackSwitch = trackSwitch;\n    this.timeOffset = timeOffset;\n    this.initSegmentChange = initSegmentChange;\n  }\n}\n\nlet transmuxerInstanceCount = 0;\nclass TransmuxerInterface {\n  constructor(_hls, id, onTransmuxComplete, onFlush) {\n    this.error = null;\n    this.hls = void 0;\n    this.id = void 0;\n    this.instanceNo = transmuxerInstanceCount++;\n    this.observer = void 0;\n    this.frag = null;\n    this.part = null;\n    this.useWorker = void 0;\n    this.workerContext = null;\n    this.transmuxer = null;\n    this.onTransmuxComplete = void 0;\n    this.onFlush = void 0;\n    this.onWorkerMessage = event => {\n      const data = event.data;\n      const hls = this.hls;\n      if (!hls || !(data != null && data.event) || data.instanceNo !== this.instanceNo) {\n        return;\n      }\n      switch (data.event) {\n        case 'init':\n          {\n            var _this$workerContext;\n            const objectURL = (_this$workerContext = this.workerContext) == null ? void 0 : _this$workerContext.objectURL;\n            if (objectURL) {\n              // revoke the Object URL that was used to create transmuxer worker, so as not to leak it\n              self.URL.revokeObjectURL(objectURL);\n            }\n            break;\n          }\n        case 'transmuxComplete':\n          {\n            this.handleTransmuxComplete(data.data);\n            break;\n          }\n        case 'flush':\n          {\n            this.onFlush(data.data);\n            break;\n          }\n\n        // pass logs from the worker thread to the main logger\n        case 'workerLog':\n          {\n            if (hls.logger[data.data.logType]) {\n              hls.logger[data.data.logType](data.data.message);\n            }\n            break;\n          }\n        default:\n          {\n            data.data = data.data || {};\n            data.data.frag = this.frag;\n            data.data.part = this.part;\n            data.data.id = this.id;\n            hls.trigger(data.event, data.data);\n            break;\n          }\n      }\n    };\n    this.onWorkerError = event => {\n      if (!this.hls) {\n        return;\n      }\n      const error = new Error(`${event.message}  (${event.filename}:${event.lineno})`);\n      this.hls.config.enableWorker = false;\n      this.hls.logger.warn(`Error in \"${this.id}\" Web Worker, fallback to inline`);\n      this.hls.trigger(Events.ERROR, {\n        type: ErrorTypes.OTHER_ERROR,\n        details: ErrorDetails.INTERNAL_EXCEPTION,\n        fatal: false,\n        event: 'demuxerWorker',\n        error\n      });\n    };\n    const config = _hls.config;\n    this.hls = _hls;\n    this.id = id;\n    this.useWorker = !!config.enableWorker;\n    this.onTransmuxComplete = onTransmuxComplete;\n    this.onFlush = onFlush;\n    const forwardMessage = (ev, data) => {\n      data = data || {};\n      data.frag = this.frag || undefined;\n      if (ev === Events.ERROR) {\n        data = data;\n        data.parent = this.id;\n        data.part = this.part;\n        this.error = data.error;\n      }\n      this.hls.trigger(ev, data);\n    };\n\n    // forward events to main thread\n    this.observer = new EventEmitter();\n    this.observer.on(Events.FRAG_DECRYPTED, forwardMessage);\n    this.observer.on(Events.ERROR, forwardMessage);\n    const m2tsTypeSupported = getM2TSSupportedAudioTypes(config.preferManagedMediaSource);\n    if (this.useWorker && typeof Worker !== 'undefined') {\n      const logger = this.hls.logger;\n      const canCreateWorker = config.workerPath || hasUMDWorker();\n      if (canCreateWorker) {\n        try {\n          if (config.workerPath) {\n            logger.log(`loading Web Worker ${config.workerPath} for \"${id}\"`);\n            this.workerContext = loadWorker(config.workerPath);\n          } else {\n            logger.log(`injecting Web Worker for \"${id}\"`);\n            this.workerContext = injectWorker();\n          }\n          const {\n            worker\n          } = this.workerContext;\n          worker.addEventListener('message', this.onWorkerMessage);\n          worker.addEventListener('error', this.onWorkerError);\n          worker.postMessage({\n            instanceNo: this.instanceNo,\n            cmd: 'init',\n            typeSupported: m2tsTypeSupported,\n            id,\n            config: stringify(config)\n          });\n        } catch (err) {\n          logger.warn(`Error setting up \"${id}\" Web Worker, fallback to inline`, err);\n          this.terminateWorker();\n          this.error = null;\n          this.transmuxer = new Transmuxer(this.observer, m2tsTypeSupported, config, '', id, _hls.logger);\n        }\n        return;\n      }\n    }\n    this.transmuxer = new Transmuxer(this.observer, m2tsTypeSupported, config, '', id, _hls.logger);\n  }\n  reset() {\n    this.frag = null;\n    this.part = null;\n    if (this.workerContext) {\n      const instanceNo = this.instanceNo;\n      this.instanceNo = transmuxerInstanceCount++;\n      const config = this.hls.config;\n      const m2tsTypeSupported = getM2TSSupportedAudioTypes(config.preferManagedMediaSource);\n      this.workerContext.worker.postMessage({\n        instanceNo: this.instanceNo,\n        cmd: 'reset',\n        resetNo: instanceNo,\n        typeSupported: m2tsTypeSupported,\n        id: this.id,\n        config: stringify(config)\n      });\n    }\n  }\n  terminateWorker() {\n    if (this.workerContext) {\n      const {\n        worker\n      } = this.workerContext;\n      this.workerContext = null;\n      worker.removeEventListener('message', this.onWorkerMessage);\n      worker.removeEventListener('error', this.onWorkerError);\n      removeWorkerFromStore(this.hls.config.workerPath);\n    }\n  }\n  destroy() {\n    if (this.workerContext) {\n      this.terminateWorker();\n      // @ts-ignore\n      this.onWorkerMessage = this.onWorkerError = null;\n    } else {\n      const transmuxer = this.transmuxer;\n      if (transmuxer) {\n        transmuxer.destroy();\n        this.transmuxer = null;\n      }\n    }\n    const observer = this.observer;\n    if (observer) {\n      observer.removeAllListeners();\n    }\n    this.frag = null;\n    this.part = null;\n    // @ts-ignore\n    this.observer = null;\n    // @ts-ignore\n    this.hls = null;\n  }\n  push(data, initSegmentData, audioCodec, videoCodec, frag, part, duration, accurateTimeOffset, chunkMeta, defaultInitPTS) {\n    var _frag$initSegment, _lastFrag$initSegment;\n    chunkMeta.transmuxing.start = self.performance.now();\n    const {\n      instanceNo,\n      transmuxer\n    } = this;\n    const timeOffset = part ? part.start : frag.start;\n    // TODO: push \"clear-lead\" decrypt data for unencrypted fragments in streams with encrypted ones\n    const decryptdata = frag.decryptdata;\n    const lastFrag = this.frag;\n    const discontinuity = !(lastFrag && frag.cc === lastFrag.cc);\n    const trackSwitch = !(lastFrag && chunkMeta.level === lastFrag.level);\n    const snDiff = lastFrag ? chunkMeta.sn - lastFrag.sn : -1;\n    const partDiff = this.part ? chunkMeta.part - this.part.index : -1;\n    const progressive = snDiff === 0 && chunkMeta.id > 1 && chunkMeta.id === (lastFrag == null ? void 0 : lastFrag.stats.chunkCount);\n    const contiguous = !trackSwitch && (snDiff === 1 || snDiff === 0 && (partDiff === 1 || progressive && partDiff <= 0));\n    const now = self.performance.now();\n    if (trackSwitch || snDiff || frag.stats.parsing.start === 0) {\n      frag.stats.parsing.start = now;\n    }\n    if (part && (partDiff || !contiguous)) {\n      part.stats.parsing.start = now;\n    }\n    const initSegmentChange = !(lastFrag && ((_frag$initSegment = frag.initSegment) == null ? void 0 : _frag$initSegment.url) === ((_lastFrag$initSegment = lastFrag.initSegment) == null ? void 0 : _lastFrag$initSegment.url));\n    const state = new TransmuxState(discontinuity, contiguous, accurateTimeOffset, trackSwitch, timeOffset, initSegmentChange);\n    if (!contiguous || discontinuity || initSegmentChange) {\n      this.hls.logger.log(`[transmuxer-interface]: Starting new transmux session for ${frag.type} sn: ${chunkMeta.sn}${chunkMeta.part > -1 ? ' part: ' + chunkMeta.part : ''} ${this.id === PlaylistLevelType.MAIN ? 'level' : 'track'}: ${chunkMeta.level} id: ${chunkMeta.id}\n        discontinuity: ${discontinuity}\n        trackSwitch: ${trackSwitch}\n        contiguous: ${contiguous}\n        accurateTimeOffset: ${accurateTimeOffset}\n        timeOffset: ${timeOffset}\n        initSegmentChange: ${initSegmentChange}`);\n      const config = new TransmuxConfig(audioCodec, videoCodec, initSegmentData, duration, defaultInitPTS);\n      this.configureTransmuxer(config);\n    }\n    this.frag = frag;\n    this.part = part;\n\n    // Frags with sn of 'initSegment' are not transmuxed\n    if (this.workerContext) {\n      // post fragment payload as transferable objects for ArrayBuffer (no copy)\n      this.workerContext.worker.postMessage({\n        instanceNo,\n        cmd: 'demux',\n        data,\n        decryptdata,\n        chunkMeta,\n        state\n      }, data instanceof ArrayBuffer ? [data] : []);\n    } else if (transmuxer) {\n      const transmuxResult = transmuxer.push(data, decryptdata, chunkMeta, state);\n      if (isPromise(transmuxResult)) {\n        transmuxResult.then(data => {\n          this.handleTransmuxComplete(data);\n        }).catch(error => {\n          this.transmuxerError(error, chunkMeta, 'transmuxer-interface push error');\n        });\n      } else {\n        this.handleTransmuxComplete(transmuxResult);\n      }\n    }\n  }\n  flush(chunkMeta) {\n    chunkMeta.transmuxing.start = self.performance.now();\n    const {\n      instanceNo,\n      transmuxer\n    } = this;\n    if (this.workerContext) {\n      this.workerContext.worker.postMessage({\n        instanceNo,\n        cmd: 'flush',\n        chunkMeta\n      });\n    } else if (transmuxer) {\n      const transmuxResult = transmuxer.flush(chunkMeta);\n      if (isPromise(transmuxResult)) {\n        transmuxResult.then(data => {\n          this.handleFlushResult(data, chunkMeta);\n        }).catch(error => {\n          this.transmuxerError(error, chunkMeta, 'transmuxer-interface flush error');\n        });\n      } else {\n        this.handleFlushResult(transmuxResult, chunkMeta);\n      }\n    }\n  }\n  transmuxerError(error, chunkMeta, reason) {\n    if (!this.hls) {\n      return;\n    }\n    this.error = error;\n    this.hls.trigger(Events.ERROR, {\n      type: ErrorTypes.MEDIA_ERROR,\n      details: ErrorDetails.FRAG_PARSING_ERROR,\n      chunkMeta,\n      frag: this.frag || undefined,\n      part: this.part || undefined,\n      fatal: false,\n      error,\n      err: error,\n      reason\n    });\n  }\n  handleFlushResult(results, chunkMeta) {\n    results.forEach(result => {\n      this.handleTransmuxComplete(result);\n    });\n    this.onFlush(chunkMeta);\n  }\n  configureTransmuxer(config) {\n    const {\n      instanceNo,\n      transmuxer\n    } = this;\n    if (this.workerContext) {\n      this.workerContext.worker.postMessage({\n        instanceNo,\n        cmd: 'configure',\n        config\n      });\n    } else if (transmuxer) {\n      transmuxer.configure(config);\n    }\n  }\n  handleTransmuxComplete(result) {\n    result.chunkMeta.transmuxing.end = self.performance.now();\n    this.onTransmuxComplete(result);\n  }\n}\n\nconst TICK_INTERVAL$3 = 100; // how often to tick in ms\n\nclass AudioStreamController extends BaseStreamController {\n  constructor(hls, fragmentTracker, keyLoader) {\n    super(hls, fragmentTracker, keyLoader, 'audio-stream-controller', PlaylistLevelType.AUDIO);\n    this.mainAnchor = null;\n    this.mainFragLoading = null;\n    this.audioOnly = false;\n    this.bufferedTrack = null;\n    this.switchingTrack = null;\n    this.trackId = -1;\n    this.waitingData = null;\n    this.mainDetails = null;\n    this.flushing = false;\n    this.bufferFlushed = false;\n    this.cachedTrackLoadedData = null;\n    this.registerListeners();\n  }\n  onHandlerDestroying() {\n    this.unregisterListeners();\n    super.onHandlerDestroying();\n    this.resetItem();\n  }\n  resetItem() {\n    this.mainDetails = this.mainAnchor = this.mainFragLoading = this.bufferedTrack = this.switchingTrack = this.waitingData = this.cachedTrackLoadedData = null;\n  }\n  registerListeners() {\n    super.registerListeners();\n    const {\n      hls\n    } = this;\n    hls.on(Events.LEVEL_LOADED, this.onLevelLoaded, this);\n    hls.on(Events.AUDIO_TRACKS_UPDATED, this.onAudioTracksUpdated, this);\n    hls.on(Events.AUDIO_TRACK_SWITCHING, this.onAudioTrackSwitching, this);\n    hls.on(Events.AUDIO_TRACK_LOADED, this.onAudioTrackLoaded, this);\n    hls.on(Events.BUFFER_RESET, this.onBufferReset, this);\n    hls.on(Events.BUFFER_CREATED, this.onBufferCreated, this);\n    hls.on(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);\n    hls.on(Events.BUFFER_FLUSHED, this.onBufferFlushed, this);\n    hls.on(Events.INIT_PTS_FOUND, this.onInitPtsFound, this);\n    hls.on(Events.FRAG_LOADING, this.onFragLoading, this);\n    hls.on(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n  }\n  unregisterListeners() {\n    const {\n      hls\n    } = this;\n    if (!hls) {\n      return;\n    }\n    super.unregisterListeners();\n    hls.off(Events.LEVEL_LOADED, this.onLevelLoaded, this);\n    hls.off(Events.AUDIO_TRACKS_UPDATED, this.onAudioTracksUpdated, this);\n    hls.off(Events.AUDIO_TRACK_SWITCHING, this.onAudioTrackSwitching, this);\n    hls.off(Events.AUDIO_TRACK_LOADED, this.onAudioTrackLoaded, this);\n    hls.off(Events.BUFFER_RESET, this.onBufferReset, this);\n    hls.off(Events.BUFFER_CREATED, this.onBufferCreated, this);\n    hls.off(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);\n    hls.off(Events.BUFFER_FLUSHED, this.onBufferFlushed, this);\n    hls.off(Events.INIT_PTS_FOUND, this.onInitPtsFound, this);\n    hls.off(Events.FRAG_LOADING, this.onFragLoading, this);\n    hls.off(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n  }\n\n  // INIT_PTS_FOUND is triggered when the video track parsed in the stream-controller has a new PTS value\n  onInitPtsFound(event, {\n    frag,\n    id,\n    initPTS,\n    timescale,\n    trackId\n  }) {\n    // Always update the new INIT PTS\n    // Can change due level switch\n    if (id === PlaylistLevelType.MAIN) {\n      const cc = frag.cc;\n      const inFlightFrag = this.fragCurrent;\n      this.initPTS[cc] = {\n        baseTime: initPTS,\n        timescale,\n        trackId\n      };\n      this.log(`InitPTS for cc: ${cc} found from main: ${initPTS / timescale} (${initPTS}/${timescale}) trackId: ${trackId}`);\n      this.mainAnchor = frag;\n      // If we are waiting, tick immediately to unblock audio fragment transmuxing\n      if (this.state === State.WAITING_INIT_PTS) {\n        const waitingData = this.waitingData;\n        if (!waitingData && !this.loadingParts || waitingData && waitingData.frag.cc !== cc) {\n          this.syncWithAnchor(frag, waitingData == null ? void 0 : waitingData.frag);\n        }\n      } else if (!this.hls.hasEnoughToStart && inFlightFrag && inFlightFrag.cc !== cc) {\n        inFlightFrag.abortRequests();\n        this.syncWithAnchor(frag, inFlightFrag);\n      } else if (this.state === State.IDLE) {\n        this.tick();\n      }\n    }\n  }\n  getLoadPosition() {\n    if (!this.startFragRequested && this.nextLoadPosition >= 0) {\n      return this.nextLoadPosition;\n    }\n    return super.getLoadPosition();\n  }\n  syncWithAnchor(mainAnchor, waitingToAppend) {\n    var _this$mainFragLoading;\n    // Drop waiting fragment if videoTrackCC has changed since waitingFragment was set and initPTS was not found\n    const mainFragLoading = ((_this$mainFragLoading = this.mainFragLoading) == null ? void 0 : _this$mainFragLoading.frag) || null;\n    if (waitingToAppend) {\n      if ((mainFragLoading == null ? void 0 : mainFragLoading.cc) === waitingToAppend.cc) {\n        // Wait for loading frag to complete and INIT_PTS_FOUND\n        return;\n      }\n    }\n    const targetDiscontinuity = (mainFragLoading || mainAnchor).cc;\n    const trackDetails = this.getLevelDetails();\n    const pos = this.getLoadPosition();\n    const syncFrag = findNearestWithCC(trackDetails, targetDiscontinuity, pos);\n    // Only stop waiting for audioFrag.cc if an audio segment of the same discontinuity domain (cc) is found\n    if (syncFrag) {\n      this.log(`Syncing with main frag at ${syncFrag.start} cc ${syncFrag.cc}`);\n      this.startFragRequested = false;\n      this.nextLoadPosition = syncFrag.start;\n      this.resetLoadingState();\n      if (this.state === State.IDLE) {\n        this.doTickIdle();\n      }\n    }\n  }\n  startLoad(startPosition, skipSeekToStartPosition) {\n    if (!this.levels) {\n      this.startPosition = startPosition;\n      this.state = State.STOPPED;\n      return;\n    }\n    const lastCurrentTime = this.lastCurrentTime;\n    this.stopLoad();\n    this.setInterval(TICK_INTERVAL$3);\n    if (lastCurrentTime > 0 && startPosition === -1) {\n      this.log(`Override startPosition with lastCurrentTime @${lastCurrentTime.toFixed(3)}`);\n      startPosition = lastCurrentTime;\n      this.state = State.IDLE;\n    } else {\n      this.state = State.WAITING_TRACK;\n    }\n    this.nextLoadPosition = this.lastCurrentTime = startPosition + this.timelineOffset;\n    this.startPosition = skipSeekToStartPosition ? -1 : startPosition;\n    this.tick();\n  }\n  doTick() {\n    switch (this.state) {\n      case State.IDLE:\n        this.doTickIdle();\n        break;\n      case State.WAITING_TRACK:\n        {\n          const {\n            levels,\n            trackId\n          } = this;\n          const currenTrack = levels == null ? void 0 : levels[trackId];\n          const details = currenTrack == null ? void 0 : currenTrack.details;\n          if (details && !this.waitForLive(currenTrack)) {\n            if (this.waitForCdnTuneIn(details)) {\n              break;\n            }\n            this.state = State.WAITING_INIT_PTS;\n          }\n          break;\n        }\n      case State.FRAG_LOADING_WAITING_RETRY:\n        {\n          this.checkRetryDate();\n          break;\n        }\n      case State.WAITING_INIT_PTS:\n        {\n          // Ensure we don't get stuck in the WAITING_INIT_PTS state if the waiting frag CC doesn't match any initPTS\n          const waitingData = this.waitingData;\n          if (waitingData) {\n            const {\n              frag,\n              part,\n              cache,\n              complete\n            } = waitingData;\n            const mainAnchor = this.mainAnchor;\n            if (this.initPTS[frag.cc] !== undefined) {\n              this.waitingData = null;\n              this.state = State.FRAG_LOADING;\n              const payload = cache.flush().buffer;\n              const data = {\n                frag,\n                part,\n                payload,\n                networkDetails: null\n              };\n              this._handleFragmentLoadProgress(data);\n              if (complete) {\n                super._handleFragmentLoadComplete(data);\n              }\n            } else if (mainAnchor && mainAnchor.cc !== waitingData.frag.cc) {\n              this.syncWithAnchor(mainAnchor, waitingData.frag);\n            }\n          } else {\n            this.state = State.IDLE;\n          }\n        }\n    }\n    this.onTickEnd();\n  }\n  resetLoadingState() {\n    const waitingData = this.waitingData;\n    if (waitingData) {\n      this.fragmentTracker.removeFragment(waitingData.frag);\n      this.waitingData = null;\n    }\n    super.resetLoadingState();\n  }\n  onTickEnd() {\n    const {\n      media\n    } = this;\n    if (!(media != null && media.readyState)) {\n      // Exit early if we don't have media or if the media hasn't buffered anything yet (readyState 0)\n      return;\n    }\n    this.lastCurrentTime = media.currentTime;\n  }\n  doTickIdle() {\n    var _this$mainFragLoading2;\n    const {\n      hls,\n      levels,\n      media,\n      trackId\n    } = this;\n    const config = hls.config;\n\n    // 1. if buffering is suspended\n    // 2. if video not attached AND\n    //    start fragment already requested OR start frag prefetch not enabled\n    // 3. if tracks or track not loaded and selected\n    // then exit loop\n    // => if media not attached but start frag prefetch is enabled and start frag not requested yet, we will not exit loop\n    if (!this.buffering || !media && !this.primaryPrefetch && (this.startFragRequested || !config.startFragPrefetch) || !(levels != null && levels[trackId])) {\n      return;\n    }\n    const levelInfo = levels[trackId];\n    const trackDetails = levelInfo.details;\n    if (!trackDetails || this.waitForLive(levelInfo) || this.waitForCdnTuneIn(trackDetails)) {\n      this.state = State.WAITING_TRACK;\n      this.startFragRequested = false;\n      return;\n    }\n    const bufferable = this.mediaBuffer ? this.mediaBuffer : this.media;\n    if (this.bufferFlushed && bufferable) {\n      this.bufferFlushed = false;\n      this.afterBufferFlushed(bufferable, ElementaryStreamTypes.AUDIO, PlaylistLevelType.AUDIO);\n    }\n    const bufferInfo = this.getFwdBufferInfo(bufferable, PlaylistLevelType.AUDIO);\n    if (bufferInfo === null) {\n      return;\n    }\n    if (!this.switchingTrack && this._streamEnded(bufferInfo, trackDetails)) {\n      hls.trigger(Events.BUFFER_EOS, {\n        type: 'audio'\n      });\n      this.state = State.ENDED;\n      return;\n    }\n    const bufferLen = bufferInfo.len;\n    const maxBufLen = hls.maxBufferLength;\n    const fragments = trackDetails.fragments;\n    const start = fragments[0].start;\n    const loadPosition = this.getLoadPosition();\n    const targetBufferTime = this.flushing ? loadPosition : bufferInfo.end;\n    if (this.switchingTrack && media) {\n      const pos = loadPosition;\n      // if currentTime (pos) is less than alt audio playlist start time, it means that alt audio is ahead of currentTime\n      if (trackDetails.PTSKnown && pos < start) {\n        // if everything is buffered from pos to start or if audio buffer upfront, let's seek to start\n        if (bufferInfo.end > start || bufferInfo.nextStart) {\n          this.log('Alt audio track ahead of main track, seek to start of alt audio track');\n          media.currentTime = start + 0.05;\n        }\n      }\n    }\n\n    // if buffer length is less than maxBufLen, or near the end, find a fragment to load\n    if (bufferLen >= maxBufLen && !this.switchingTrack && targetBufferTime < fragments[fragments.length - 1].start) {\n      return;\n    }\n    let frag = this.getNextFragment(targetBufferTime, trackDetails);\n    // Avoid loop loading by using nextLoadPosition set for backtracking and skipping consecutive GAP tags\n    if (frag && this.isLoopLoading(frag, targetBufferTime)) {\n      frag = this.getNextFragmentLoopLoading(frag, trackDetails, bufferInfo, PlaylistLevelType.MAIN, maxBufLen);\n    }\n    if (!frag) {\n      this.bufferFlushed = true;\n      return;\n    }\n\n    // Request audio segments up to one fragment ahead of main stream-controller\n    let mainFragLoading = ((_this$mainFragLoading2 = this.mainFragLoading) == null ? void 0 : _this$mainFragLoading2.frag) || null;\n    if (!this.audioOnly && this.startFragRequested && mainFragLoading && isMediaFragment(frag) && !frag.endList && (!trackDetails.live || !this.loadingParts && targetBufferTime < this.hls.liveSyncPosition)) {\n      if (this.fragmentTracker.getState(mainFragLoading) === FragmentState.OK) {\n        this.mainFragLoading = mainFragLoading = null;\n      }\n      if (mainFragLoading && isMediaFragment(mainFragLoading)) {\n        if (frag.start > mainFragLoading.end) {\n          // Get buffered frag at target position from tracker (loaded out of sequence)\n          const mainFragAtPos = this.fragmentTracker.getFragAtPos(targetBufferTime, PlaylistLevelType.MAIN);\n          if (mainFragAtPos && mainFragAtPos.end > mainFragLoading.end) {\n            mainFragLoading = mainFragAtPos;\n            this.mainFragLoading = {\n              frag: mainFragAtPos,\n              targetBufferTime: null\n            };\n          }\n        }\n        const atBufferSyncLimit = frag.start > mainFragLoading.end;\n        if (atBufferSyncLimit) {\n          return;\n        }\n      }\n    }\n    this.loadFragment(frag, levelInfo, targetBufferTime);\n  }\n  onMediaDetaching(event, data) {\n    this.bufferFlushed = this.flushing = false;\n    super.onMediaDetaching(event, data);\n  }\n  onAudioTracksUpdated(event, {\n    audioTracks\n  }) {\n    // Reset tranxmuxer is essential for large context switches (Content Steering)\n    this.resetTransmuxer();\n    this.levels = audioTracks.map(mediaPlaylist => new Level(mediaPlaylist));\n  }\n  onAudioTrackSwitching(event, data) {\n    // if any URL found on new audio track, it is an alternate audio track\n    const altAudio = !!data.url;\n    this.trackId = data.id;\n    const {\n      fragCurrent\n    } = this;\n    if (fragCurrent) {\n      fragCurrent.abortRequests();\n      this.removeUnbufferedFrags(fragCurrent.start);\n    }\n    this.resetLoadingState();\n\n    // should we switch tracks ?\n    if (altAudio) {\n      this.switchingTrack = data;\n      // main audio track are handled by stream-controller, just do something if switching to alt audio track\n      this.flushAudioIfNeeded(data);\n      if (this.state !== State.STOPPED) {\n        // switching to audio track, start timer if not already started\n        this.setInterval(TICK_INTERVAL$3);\n        this.state = State.IDLE;\n        this.tick();\n      }\n    } else {\n      // destroy useless transmuxer when switching audio to main\n      this.resetTransmuxer();\n      this.switchingTrack = null;\n      this.bufferedTrack = data;\n      this.clearInterval();\n    }\n  }\n  onManifestLoading() {\n    super.onManifestLoading();\n    this.bufferFlushed = this.flushing = this.audioOnly = false;\n    this.resetItem();\n    this.trackId = -1;\n  }\n  onLevelLoaded(event, data) {\n    this.mainDetails = data.details;\n    const cachedTrackLoadedData = this.cachedTrackLoadedData;\n    if (cachedTrackLoadedData) {\n      this.cachedTrackLoadedData = null;\n      this.onAudioTrackLoaded(Events.AUDIO_TRACK_LOADED, cachedTrackLoadedData);\n    }\n  }\n  onAudioTrackLoaded(event, data) {\n    var _trackLevel$details;\n    const {\n      levels\n    } = this;\n    const {\n      details: newDetails,\n      id: trackId,\n      groupId,\n      track\n    } = data;\n    if (!levels) {\n      this.warn(`Audio tracks reset while loading track ${trackId} \"${track.name}\" of \"${groupId}\"`);\n      return;\n    }\n    const mainDetails = this.mainDetails;\n    if (!mainDetails || newDetails.endCC > mainDetails.endCC || mainDetails.expired) {\n      this.cachedTrackLoadedData = data;\n      if (this.state !== State.STOPPED) {\n        this.state = State.WAITING_TRACK;\n      }\n      return;\n    }\n    this.cachedTrackLoadedData = null;\n    this.log(`Audio track ${trackId} \"${track.name}\" of \"${groupId}\" loaded [${newDetails.startSN},${newDetails.endSN}]${newDetails.lastPartSn ? `[part-${newDetails.lastPartSn}-${newDetails.lastPartIndex}]` : ''},duration:${newDetails.totalduration}`);\n    const trackLevel = levels[trackId];\n    let sliding = 0;\n    if (newDetails.live || (_trackLevel$details = trackLevel.details) != null && _trackLevel$details.live) {\n      this.checkLiveUpdate(newDetails);\n      if (newDetails.deltaUpdateFailed) {\n        return;\n      }\n      if (trackLevel.details) {\n        var _this$levelLastLoaded;\n        sliding = this.alignPlaylists(newDetails, trackLevel.details, (_this$levelLastLoaded = this.levelLastLoaded) == null ? void 0 : _this$levelLastLoaded.details);\n      }\n      if (!newDetails.alignedSliding) {\n        // Align audio rendition with the \"main\" playlist on discontinuity change\n        // or program-date-time (PDT)\n        alignDiscontinuities(newDetails, mainDetails);\n        if (!newDetails.alignedSliding) {\n          alignMediaPlaylistByPDT(newDetails, mainDetails);\n        }\n        sliding = newDetails.fragmentStart;\n      }\n    }\n    trackLevel.details = newDetails;\n    this.levelLastLoaded = trackLevel;\n\n    // compute start position if we are aligned with the main playlist\n    if (!this.startFragRequested) {\n      this.setStartPosition(mainDetails, sliding);\n    }\n    this.hls.trigger(Events.AUDIO_TRACK_UPDATED, {\n      details: newDetails,\n      id: trackId,\n      groupId: data.groupId\n    });\n\n    // only switch back to IDLE state if we were waiting for track to start downloading a new fragment\n    if (this.state === State.WAITING_TRACK && !this.waitForCdnTuneIn(newDetails)) {\n      this.state = State.IDLE;\n    }\n\n    // trigger handler right now\n    this.tick();\n  }\n  _handleFragmentLoadProgress(data) {\n    var _frag$initSegment;\n    const frag = data.frag;\n    const {\n      part,\n      payload\n    } = data;\n    const {\n      config,\n      trackId,\n      levels\n    } = this;\n    if (!levels) {\n      this.warn(`Audio tracks were reset while fragment load was in progress. Fragment ${frag.sn} of level ${frag.level} will not be buffered`);\n      return;\n    }\n    const track = levels[trackId];\n    if (!track) {\n      this.warn('Audio track is undefined on fragment load progress');\n      return;\n    }\n    const details = track.details;\n    if (!details) {\n      this.warn('Audio track details undefined on fragment load progress');\n      this.removeUnbufferedFrags(frag.start);\n      return;\n    }\n    const audioCodec = config.defaultAudioCodec || track.audioCodec || 'mp4a.40.2';\n    let transmuxer = this.transmuxer;\n    if (!transmuxer) {\n      transmuxer = this.transmuxer = new TransmuxerInterface(this.hls, PlaylistLevelType.AUDIO, this._handleTransmuxComplete.bind(this), this._handleTransmuxerFlush.bind(this));\n    }\n\n    // Check if we have video initPTS\n    // If not we need to wait for it\n    const initPTS = this.initPTS[frag.cc];\n    const initSegmentData = (_frag$initSegment = frag.initSegment) == null ? void 0 : _frag$initSegment.data;\n    if (initPTS !== undefined) {\n      // this.log(`Transmuxing ${sn} of [${details.startSN} ,${details.endSN}],track ${trackId}`);\n      // time Offset is accurate if level PTS is known, or if playlist is not sliding (not live)\n      const accurateTimeOffset = false; // details.PTSKnown || !details.live;\n      const partIndex = part ? part.index : -1;\n      const partial = partIndex !== -1;\n      const chunkMeta = new ChunkMetadata(frag.level, frag.sn, frag.stats.chunkCount, payload.byteLength, partIndex, partial);\n      transmuxer.push(payload, initSegmentData, audioCodec, '', frag, part, details.totalduration, accurateTimeOffset, chunkMeta, initPTS);\n    } else {\n      this.log(`Unknown video PTS for cc ${frag.cc}, waiting for video PTS before demuxing audio frag ${frag.sn} of [${details.startSN} ,${details.endSN}],track ${trackId}`);\n      const {\n        cache\n      } = this.waitingData = this.waitingData || {\n        frag,\n        part,\n        cache: new ChunkCache(),\n        complete: false\n      };\n      cache.push(new Uint8Array(payload));\n      if (this.state !== State.STOPPED) {\n        this.state = State.WAITING_INIT_PTS;\n      }\n    }\n  }\n  _handleFragmentLoadComplete(fragLoadedData) {\n    if (this.waitingData) {\n      this.waitingData.complete = true;\n      return;\n    }\n    super._handleFragmentLoadComplete(fragLoadedData);\n  }\n  onBufferReset(/* event: Events.BUFFER_RESET */\n  ) {\n    // reset reference to sourcebuffers\n    this.mediaBuffer = null;\n  }\n  onBufferCreated(event, data) {\n    this.bufferFlushed = this.flushing = false;\n    const audioTrack = data.tracks.audio;\n    if (audioTrack) {\n      this.mediaBuffer = audioTrack.buffer || null;\n    }\n  }\n  onFragLoading(event, data) {\n    if (!this.audioOnly && data.frag.type === PlaylistLevelType.MAIN && isMediaFragment(data.frag)) {\n      this.mainFragLoading = data;\n      if (this.state === State.IDLE) {\n        this.tick();\n      }\n    }\n  }\n  onFragBuffered(event, data) {\n    const {\n      frag,\n      part\n    } = data;\n    if (frag.type !== PlaylistLevelType.AUDIO) {\n      if (!this.audioOnly && frag.type === PlaylistLevelType.MAIN && !frag.elementaryStreams.video && !frag.elementaryStreams.audiovideo) {\n        this.audioOnly = true;\n        this.mainFragLoading = null;\n      }\n      return;\n    }\n    if (this.fragContextChanged(frag)) {\n      // If a level switch was requested while a fragment was buffering, it will emit the FRAG_BUFFERED event upon completion\n      // Avoid setting state back to IDLE or concluding the audio switch; otherwise, the switched-to track will not buffer\n      this.warn(`Fragment ${frag.sn}${part ? ' p: ' + part.index : ''} of level ${frag.level} finished buffering, but was aborted. state: ${this.state}, audioSwitch: ${this.switchingTrack ? this.switchingTrack.name : 'false'}`);\n      return;\n    }\n    if (isMediaFragment(frag)) {\n      this.fragPrevious = frag;\n      const track = this.switchingTrack;\n      if (track) {\n        this.bufferedTrack = track;\n        this.switchingTrack = null;\n        this.hls.trigger(Events.AUDIO_TRACK_SWITCHED, _objectSpread2({}, track));\n      }\n    }\n    this.fragBufferedComplete(frag, part);\n    if (this.media) {\n      this.tick();\n    }\n  }\n  onError(event, data) {\n    var _data$context;\n    if (data.fatal) {\n      this.state = State.ERROR;\n      return;\n    }\n    switch (data.details) {\n      case ErrorDetails.FRAG_GAP:\n      case ErrorDetails.FRAG_PARSING_ERROR:\n      case ErrorDetails.FRAG_DECRYPT_ERROR:\n      case ErrorDetails.FRAG_LOAD_ERROR:\n      case ErrorDetails.FRAG_LOAD_TIMEOUT:\n      case ErrorDetails.KEY_LOAD_ERROR:\n      case ErrorDetails.KEY_LOAD_TIMEOUT:\n        this.onFragmentOrKeyLoadError(PlaylistLevelType.AUDIO, data);\n        break;\n      case ErrorDetails.AUDIO_TRACK_LOAD_ERROR:\n      case ErrorDetails.AUDIO_TRACK_LOAD_TIMEOUT:\n      case ErrorDetails.LEVEL_PARSING_ERROR:\n        // in case of non fatal error while loading track, if not retrying to load track, switch back to IDLE\n        if (!data.levelRetry && this.state === State.WAITING_TRACK && ((_data$context = data.context) == null ? void 0 : _data$context.type) === PlaylistContextType.AUDIO_TRACK) {\n          this.state = State.IDLE;\n        }\n        break;\n      case ErrorDetails.BUFFER_ADD_CODEC_ERROR:\n      case ErrorDetails.BUFFER_APPEND_ERROR:\n        if (data.parent !== 'audio') {\n          return;\n        }\n        if (!this.reduceLengthAndFlushBuffer(data)) {\n          this.resetLoadingState();\n        }\n        break;\n      case ErrorDetails.BUFFER_FULL_ERROR:\n        if (data.parent !== 'audio') {\n          return;\n        }\n        if (this.reduceLengthAndFlushBuffer(data)) {\n          this.bufferedTrack = null;\n          super.flushMainBuffer(0, Number.POSITIVE_INFINITY, 'audio');\n        }\n        break;\n      case ErrorDetails.INTERNAL_EXCEPTION:\n        this.recoverWorkerError(data);\n        break;\n    }\n  }\n  onBufferFlushing(event, {\n    type\n  }) {\n    if (type !== ElementaryStreamTypes.VIDEO) {\n      this.flushing = true;\n    }\n  }\n  onBufferFlushed(event, {\n    type\n  }) {\n    if (type !== ElementaryStreamTypes.VIDEO) {\n      this.flushing = false;\n      this.bufferFlushed = true;\n      if (this.state === State.ENDED) {\n        this.state = State.IDLE;\n      }\n      const mediaBuffer = this.mediaBuffer || this.media;\n      if (mediaBuffer) {\n        this.afterBufferFlushed(mediaBuffer, type, PlaylistLevelType.AUDIO);\n        this.tick();\n      }\n    }\n  }\n  _handleTransmuxComplete(transmuxResult) {\n    var _id3$samples;\n    const id = 'audio';\n    const {\n      hls\n    } = this;\n    const {\n      remuxResult,\n      chunkMeta\n    } = transmuxResult;\n    const context = this.getCurrentContext(chunkMeta);\n    if (!context) {\n      this.resetWhenMissingContext(chunkMeta);\n      return;\n    }\n    const {\n      frag,\n      part,\n      level\n    } = context;\n    const {\n      details\n    } = level;\n    const {\n      audio,\n      text,\n      id3,\n      initSegment\n    } = remuxResult;\n\n    // Check if the current fragment has been aborted. We check this by first seeing if we're still playing the current level.\n    // If we are, subsequently check if the currently loading fragment (fragCurrent) has changed.\n    if (this.fragContextChanged(frag) || !details) {\n      this.fragmentTracker.removeFragment(frag);\n      return;\n    }\n    this.state = State.PARSING;\n    if (this.switchingTrack && audio) {\n      this.completeAudioSwitch(this.switchingTrack);\n    }\n    if (initSegment != null && initSegment.tracks) {\n      const mapFragment = frag.initSegment || frag;\n      if (this.unhandledEncryptionError(initSegment, frag)) {\n        return;\n      }\n      this._bufferInitSegment(level, initSegment.tracks, mapFragment, chunkMeta);\n      hls.trigger(Events.FRAG_PARSING_INIT_SEGMENT, {\n        frag: mapFragment,\n        id,\n        tracks: initSegment.tracks\n      });\n      // Only flush audio from old audio tracks when PTS is known on new audio track\n    }\n    if (audio) {\n      const {\n        startPTS,\n        endPTS,\n        startDTS,\n        endDTS\n      } = audio;\n      if (part) {\n        part.elementaryStreams[ElementaryStreamTypes.AUDIO] = {\n          startPTS,\n          endPTS,\n          startDTS,\n          endDTS\n        };\n      }\n      frag.setElementaryStreamInfo(ElementaryStreamTypes.AUDIO, startPTS, endPTS, startDTS, endDTS);\n      this.bufferFragmentData(audio, frag, part, chunkMeta);\n    }\n    if (id3 != null && (_id3$samples = id3.samples) != null && _id3$samples.length) {\n      const emittedID3 = _extends({\n        id,\n        frag,\n        details\n      }, id3);\n      hls.trigger(Events.FRAG_PARSING_METADATA, emittedID3);\n    }\n    if (text) {\n      const emittedText = _extends({\n        id,\n        frag,\n        details\n      }, text);\n      hls.trigger(Events.FRAG_PARSING_USERDATA, emittedText);\n    }\n  }\n  _bufferInitSegment(currentLevel, tracks, frag, chunkMeta) {\n    if (this.state !== State.PARSING) {\n      return;\n    }\n    // delete any video track found on audio transmuxer\n    if (tracks.video) {\n      delete tracks.video;\n    }\n    if (tracks.audiovideo) {\n      delete tracks.audiovideo;\n    }\n\n    // include levelCodec in audio and video tracks\n    if (!tracks.audio) {\n      return;\n    }\n    const track = tracks.audio;\n    track.id = PlaylistLevelType.AUDIO;\n    const variantAudioCodecs = currentLevel.audioCodec;\n    this.log(`Init audio buffer, container:${track.container}, codecs[level/parsed]=[${variantAudioCodecs}/${track.codec}]`);\n    // SourceBuffer will use track.levelCodec if defined\n    if (variantAudioCodecs && variantAudioCodecs.split(',').length === 1) {\n      track.levelCodec = variantAudioCodecs;\n    }\n    this.hls.trigger(Events.BUFFER_CODECS, tracks);\n    const initSegment = track.initSegment;\n    if (initSegment != null && initSegment.byteLength) {\n      const segment = {\n        type: 'audio',\n        frag,\n        part: null,\n        chunkMeta,\n        parent: frag.type,\n        data: initSegment\n      };\n      this.hls.trigger(Events.BUFFER_APPENDING, segment);\n    }\n    // trigger handler right now\n    this.tickImmediate();\n  }\n  loadFragment(frag, track, targetBufferTime) {\n    // only load if fragment is not loaded or if in audio switch\n    const fragState = this.fragmentTracker.getState(frag);\n\n    // we force a frag loading in audio switch as fragment tracker might not have evicted previous frags in case of quick audio switch\n    if (this.switchingTrack || fragState === FragmentState.NOT_LOADED || fragState === FragmentState.PARTIAL) {\n      var _track$details;\n      if (!isMediaFragment(frag)) {\n        this._loadInitSegment(frag, track);\n      } else if ((_track$details = track.details) != null && _track$details.live && !this.initPTS[frag.cc]) {\n        this.log(`Waiting for video PTS in continuity counter ${frag.cc} of live stream before loading audio fragment ${frag.sn} of level ${this.trackId}`);\n        this.state = State.WAITING_INIT_PTS;\n        const mainDetails = this.mainDetails;\n        if (mainDetails && mainDetails.fragmentStart !== track.details.fragmentStart) {\n          alignMediaPlaylistByPDT(track.details, mainDetails);\n        }\n      } else {\n        super.loadFragment(frag, track, targetBufferTime);\n      }\n    } else {\n      this.clearTrackerIfNeeded(frag);\n    }\n  }\n  flushAudioIfNeeded(switchingTrack) {\n    if (this.media && this.bufferedTrack) {\n      const {\n        name,\n        lang,\n        assocLang,\n        characteristics,\n        audioCodec,\n        channels\n      } = this.bufferedTrack;\n      if (!matchesOption({\n        name,\n        lang,\n        assocLang,\n        characteristics,\n        audioCodec,\n        channels\n      }, switchingTrack, audioMatchPredicate)) {\n        if (useAlternateAudio(switchingTrack.url, this.hls)) {\n          this.log('Switching audio track : flushing all audio');\n          super.flushMainBuffer(0, Number.POSITIVE_INFINITY, 'audio');\n          this.bufferedTrack = null;\n        } else {\n          // Main is being buffered. Set bufferedTrack so that it is flushed when switching back to alt-audio\n          this.bufferedTrack = switchingTrack;\n        }\n      }\n    }\n  }\n  completeAudioSwitch(switchingTrack) {\n    const {\n      hls\n    } = this;\n    this.flushAudioIfNeeded(switchingTrack);\n    this.bufferedTrack = switchingTrack;\n    this.switchingTrack = null;\n    hls.trigger(Events.AUDIO_TRACK_SWITCHED, _objectSpread2({}, switchingTrack));\n  }\n}\n\nclass BasePlaylistController extends Logger {\n  constructor(hls, logPrefix) {\n    super(logPrefix, hls.logger);\n    this.hls = void 0;\n    this.canLoad = false;\n    this.timer = -1;\n    this.hls = hls;\n  }\n  destroy() {\n    this.clearTimer();\n    // @ts-ignore\n    this.hls = this.log = this.warn = null;\n  }\n  clearTimer() {\n    if (this.timer !== -1) {\n      self.clearTimeout(this.timer);\n      this.timer = -1;\n    }\n  }\n  startLoad() {\n    this.canLoad = true;\n    this.loadPlaylist();\n  }\n  stopLoad() {\n    this.canLoad = false;\n    this.clearTimer();\n  }\n  switchParams(playlistUri, previous, current) {\n    const renditionReports = previous == null ? void 0 : previous.renditionReports;\n    if (renditionReports) {\n      let foundIndex = -1;\n      for (let i = 0; i < renditionReports.length; i++) {\n        const attr = renditionReports[i];\n        let uri;\n        try {\n          uri = new self.URL(attr.URI, previous.url).href;\n        } catch (error) {\n          this.warn(`Could not construct new URL for Rendition Report: ${error}`);\n          uri = attr.URI || '';\n        }\n        // Use exact match. Otherwise, the last partial match, if any, will be used\n        // (Playlist URI includes a query string that the Rendition Report does not)\n        if (uri === playlistUri) {\n          foundIndex = i;\n          break;\n        } else if (uri === playlistUri.substring(0, uri.length)) {\n          foundIndex = i;\n        }\n      }\n      if (foundIndex !== -1) {\n        const attr = renditionReports[foundIndex];\n        const msn = parseInt(attr['LAST-MSN']) || previous.lastPartSn;\n        let part = parseInt(attr['LAST-PART']) || previous.lastPartIndex;\n        if (this.hls.config.lowLatencyMode) {\n          const currentGoal = Math.min(previous.age - previous.partTarget, previous.targetduration);\n          if (part >= 0 && currentGoal > previous.partTarget) {\n            part += 1;\n          }\n        }\n        const skip = current && getSkipValue(current);\n        return new HlsUrlParameters(msn, part >= 0 ? part : undefined, skip);\n      }\n    }\n  }\n  loadPlaylist(hlsUrlParameters) {\n    // Loading is handled by the subclasses\n    this.clearTimer();\n  }\n  loadingPlaylist(playlist, hlsUrlParameters) {\n    // Loading is handled by the subclasses\n    this.clearTimer();\n  }\n  shouldLoadPlaylist(playlist) {\n    return this.canLoad && !!playlist && !!playlist.url && (!playlist.details || playlist.details.live);\n  }\n  getUrlWithDirectives(uri, hlsUrlParameters) {\n    if (hlsUrlParameters) {\n      try {\n        return hlsUrlParameters.addDirectives(uri);\n      } catch (error) {\n        this.warn(`Could not construct new URL with HLS Delivery Directives: ${error}`);\n      }\n    }\n    return uri;\n  }\n  playlistLoaded(index, data, previousDetails) {\n    const {\n      details,\n      stats\n    } = data;\n\n    // Set last updated date-time\n    const now = self.performance.now();\n    const elapsed = stats.loading.first ? Math.max(0, now - stats.loading.first) : 0;\n    details.advancedDateTime = Date.now() - elapsed;\n\n    // shift fragment starts with timelineOffset\n    const timelineOffset = this.hls.config.timelineOffset;\n    if (timelineOffset !== details.appliedTimelineOffset) {\n      const offset = Math.max(timelineOffset || 0, 0);\n      details.appliedTimelineOffset = offset;\n      details.fragments.forEach(frag => {\n        frag.setStart(frag.playlistOffset + offset);\n      });\n    }\n\n    // if current playlist is a live playlist, arm a timer to reload it\n    if (details.live || previousDetails != null && previousDetails.live) {\n      const levelOrTrack = 'levelInfo' in data ? data.levelInfo : data.track;\n      details.reloaded(previousDetails);\n      // Merge live playlists to adjust fragment starts and fill in delta playlist skipped segments\n      if (previousDetails && details.fragments.length > 0) {\n        mergeDetails(previousDetails, details, this);\n        const error = details.playlistParsingError;\n        if (error) {\n          this.warn(error);\n          const hls = this.hls;\n          if (!hls.config.ignorePlaylistParsingErrors) {\n            var _details$fragments$;\n            const {\n              networkDetails\n            } = data;\n            hls.trigger(Events.ERROR, {\n              type: ErrorTypes.NETWORK_ERROR,\n              details: ErrorDetails.LEVEL_PARSING_ERROR,\n              fatal: false,\n              url: details.url,\n              error,\n              reason: error.message,\n              level: data.level || undefined,\n              parent: (_details$fragments$ = details.fragments[0]) == null ? void 0 : _details$fragments$.type,\n              networkDetails,\n              stats\n            });\n            return;\n          }\n          details.playlistParsingError = null;\n        }\n      }\n      if (details.requestScheduled === -1) {\n        details.requestScheduled = stats.loading.start;\n      }\n      const bufferInfo = this.hls.mainForwardBufferInfo;\n      const position = bufferInfo ? bufferInfo.end - bufferInfo.len : 0;\n      const distanceToLiveEdgeMs = (details.edge - position) * 1000;\n      const reloadInterval = computeReloadInterval(details, distanceToLiveEdgeMs);\n      if (details.requestScheduled + reloadInterval < now) {\n        details.requestScheduled = now;\n      } else {\n        details.requestScheduled += reloadInterval;\n      }\n      this.log(`live playlist ${index} ${details.advanced ? 'REFRESHED ' + details.lastPartSn + '-' + details.lastPartIndex : details.updated ? 'UPDATED' : 'MISSED'}`);\n      if (!this.canLoad || !details.live) {\n        return;\n      }\n      let deliveryDirectives;\n      let msn = undefined;\n      let part = undefined;\n      if (details.canBlockReload && details.endSN && details.advanced) {\n        // Load level with LL-HLS delivery directives\n        const lowLatencyMode = this.hls.config.lowLatencyMode;\n        const lastPartSn = details.lastPartSn;\n        const endSn = details.endSN;\n        const lastPartIndex = details.lastPartIndex;\n        const hasParts = lastPartIndex !== -1;\n        const atLastPartOfSegment = lastPartSn === endSn;\n        if (hasParts) {\n          // When low latency mode is disabled, request the last part of the next segment\n          if (atLastPartOfSegment) {\n            msn = endSn + 1;\n            part = lowLatencyMode ? 0 : lastPartIndex;\n          } else {\n            msn = lastPartSn;\n            part = lowLatencyMode ? lastPartIndex + 1 : details.maxPartIndex;\n          }\n        } else {\n          msn = endSn + 1;\n        }\n        // Low-Latency CDN Tune-in: \"age\" header and time since load indicates we're behind by more than one part\n        // Update directives to obtain the Playlist that has the estimated additional duration of media\n        const lastAdvanced = details.age;\n        const cdnAge = lastAdvanced + details.ageHeader;\n        let currentGoal = Math.min(cdnAge - details.partTarget, details.targetduration * 1.5);\n        if (currentGoal > 0) {\n          if (cdnAge > details.targetduration * 3) {\n            // Omit segment and part directives when the last response was more than 3 target durations ago,\n            this.log(`Playlist last advanced ${lastAdvanced.toFixed(2)}s ago. Omitting segment and part directives.`);\n            msn = undefined;\n            part = undefined;\n          } else if (previousDetails != null && previousDetails.tuneInGoal && cdnAge - details.partTarget > previousDetails.tuneInGoal) {\n            // If we attempted to get the next or latest playlist update, but currentGoal increased,\n            // then we either can't catchup, or the \"age\" header cannot be trusted.\n            this.warn(`CDN Tune-in goal increased from: ${previousDetails.tuneInGoal} to: ${currentGoal} with playlist age: ${details.age}`);\n            currentGoal = 0;\n          } else {\n            const segments = Math.floor(currentGoal / details.targetduration);\n            msn += segments;\n            if (part !== undefined) {\n              const parts = Math.round(currentGoal % details.targetduration / details.partTarget);\n              part += parts;\n            }\n            this.log(`CDN Tune-in age: ${details.ageHeader}s last advanced ${lastAdvanced.toFixed(2)}s goal: ${currentGoal} skip sn ${segments} to part ${part}`);\n          }\n          details.tuneInGoal = currentGoal;\n        }\n        deliveryDirectives = this.getDeliveryDirectives(details, data.deliveryDirectives, msn, part);\n        if (lowLatencyMode || !atLastPartOfSegment) {\n          details.requestScheduled = now;\n          this.loadingPlaylist(levelOrTrack, deliveryDirectives);\n          return;\n        }\n      } else if (details.canBlockReload || details.canSkipUntil) {\n        deliveryDirectives = this.getDeliveryDirectives(details, data.deliveryDirectives, msn, part);\n      }\n      if (deliveryDirectives && msn !== undefined && details.canBlockReload) {\n        details.requestScheduled = stats.loading.first + Math.max(reloadInterval - elapsed * 2, reloadInterval / 2);\n      }\n      this.scheduleLoading(levelOrTrack, deliveryDirectives, details);\n    } else {\n      this.clearTimer();\n    }\n  }\n  scheduleLoading(levelOrTrack, deliveryDirectives, updatedDetails) {\n    const details = updatedDetails || levelOrTrack.details;\n    if (!details) {\n      this.loadingPlaylist(levelOrTrack, deliveryDirectives);\n      return;\n    }\n    const now = self.performance.now();\n    const requestScheduled = details.requestScheduled;\n    if (now >= requestScheduled) {\n      this.loadingPlaylist(levelOrTrack, deliveryDirectives);\n      return;\n    }\n    const estimatedTimeUntilUpdate = requestScheduled - now;\n    this.log(`reload live playlist ${levelOrTrack.name || levelOrTrack.bitrate + 'bps'} in ${Math.round(estimatedTimeUntilUpdate)} ms`);\n    this.clearTimer();\n    this.timer = self.setTimeout(() => this.loadingPlaylist(levelOrTrack, deliveryDirectives), estimatedTimeUntilUpdate);\n  }\n  getDeliveryDirectives(details, previousDeliveryDirectives, msn, part) {\n    let skip = getSkipValue(details);\n    if (previousDeliveryDirectives != null && previousDeliveryDirectives.skip && details.deltaUpdateFailed) {\n      msn = previousDeliveryDirectives.msn;\n      part = previousDeliveryDirectives.part;\n      skip = HlsSkip.No;\n    }\n    return new HlsUrlParameters(msn, part, skip);\n  }\n  checkRetry(errorEvent) {\n    const errorDetails = errorEvent.details;\n    const isTimeout = isTimeoutError(errorEvent);\n    const errorAction = errorEvent.errorAction;\n    const {\n      action,\n      retryCount = 0,\n      retryConfig\n    } = errorAction || {};\n    const retry = !!errorAction && !!retryConfig && (action === NetworkErrorAction.RetryRequest || !errorAction.resolved && action === NetworkErrorAction.SendAlternateToPenaltyBox);\n    if (retry) {\n      var _errorEvent$context;\n      if (retryCount >= retryConfig.maxNumRetry) {\n        return false;\n      }\n      if (isTimeout && (_errorEvent$context = errorEvent.context) != null && _errorEvent$context.deliveryDirectives) {\n        // The LL-HLS request already timed out so retry immediately\n        this.warn(`Retrying playlist loading ${retryCount + 1}/${retryConfig.maxNumRetry} after \"${errorDetails}\" without delivery-directives`);\n        this.loadPlaylist();\n      } else {\n        const delay = getRetryDelay(retryConfig, retryCount);\n        // Schedule level/track reload\n        this.clearTimer();\n        this.timer = self.setTimeout(() => this.loadPlaylist(), delay);\n        this.warn(`Retrying playlist loading ${retryCount + 1}/${retryConfig.maxNumRetry} after \"${errorDetails}\" in ${delay}ms`);\n      }\n      // `levelRetry = true` used to inform other controllers that a retry is happening\n      errorEvent.levelRetry = true;\n      errorAction.resolved = true;\n    }\n    return retry;\n  }\n}\n\nfunction subtitleOptionsIdentical(trackList1, trackList2) {\n  if (trackList1.length !== trackList2.length) {\n    return false;\n  }\n  for (let i = 0; i < trackList1.length; i++) {\n    if (!mediaAttributesIdentical(trackList1[i].attrs, trackList2[i].attrs)) {\n      return false;\n    }\n  }\n  return true;\n}\nfunction mediaAttributesIdentical(attrs1, attrs2, customAttributes) {\n  // Media options with the same rendition ID must be bit identical\n  const stableRenditionId = attrs1['STABLE-RENDITION-ID'];\n  if (stableRenditionId && !customAttributes) {\n    return stableRenditionId === attrs2['STABLE-RENDITION-ID'];\n  }\n  // When rendition ID is not present, compare attributes\n  return !(customAttributes || ['LANGUAGE', 'NAME', 'CHARACTERISTICS', 'AUTOSELECT', 'DEFAULT', 'FORCED', 'ASSOC-LANGUAGE']).some(subtitleAttribute => attrs1[subtitleAttribute] !== attrs2[subtitleAttribute]);\n}\nfunction subtitleTrackMatchesTextTrack(subtitleTrack, textTrack) {\n  return textTrack.label.toLowerCase() === subtitleTrack.name.toLowerCase() && (!textTrack.language || textTrack.language.toLowerCase() === (subtitleTrack.lang || '').toLowerCase());\n}\n\nclass AudioTrackController extends BasePlaylistController {\n  constructor(hls) {\n    super(hls, 'audio-track-controller');\n    this.tracks = [];\n    this.groupIds = null;\n    this.tracksInGroup = [];\n    this.trackId = -1;\n    this.currentTrack = null;\n    this.selectDefaultTrack = true;\n    this.registerListeners();\n  }\n  registerListeners() {\n    const {\n      hls\n    } = this;\n    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.on(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n    hls.on(Events.LEVEL_LOADING, this.onLevelLoading, this);\n    hls.on(Events.LEVEL_SWITCHING, this.onLevelSwitching, this);\n    hls.on(Events.AUDIO_TRACK_LOADED, this.onAudioTrackLoaded, this);\n    hls.on(Events.ERROR, this.onError, this);\n  }\n  unregisterListeners() {\n    const {\n      hls\n    } = this;\n    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.off(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n    hls.off(Events.LEVEL_LOADING, this.onLevelLoading, this);\n    hls.off(Events.LEVEL_SWITCHING, this.onLevelSwitching, this);\n    hls.off(Events.AUDIO_TRACK_LOADED, this.onAudioTrackLoaded, this);\n    hls.off(Events.ERROR, this.onError, this);\n  }\n  destroy() {\n    this.unregisterListeners();\n    this.tracks.length = 0;\n    this.tracksInGroup.length = 0;\n    this.currentTrack = null;\n    super.destroy();\n  }\n  onManifestLoading() {\n    this.tracks = [];\n    this.tracksInGroup = [];\n    this.groupIds = null;\n    this.currentTrack = null;\n    this.trackId = -1;\n    this.selectDefaultTrack = true;\n  }\n  onManifestParsed(event, data) {\n    this.tracks = data.audioTracks || [];\n  }\n  onAudioTrackLoaded(event, data) {\n    const {\n      id,\n      groupId,\n      details\n    } = data;\n    const trackInActiveGroup = this.tracksInGroup[id];\n    if (!trackInActiveGroup || trackInActiveGroup.groupId !== groupId) {\n      this.warn(`Audio track with id:${id} and group:${groupId} not found in active group ${trackInActiveGroup == null ? void 0 : trackInActiveGroup.groupId}`);\n      return;\n    }\n    const curDetails = trackInActiveGroup.details;\n    trackInActiveGroup.details = data.details;\n    this.log(`Audio track ${id} \"${trackInActiveGroup.name}\" lang:${trackInActiveGroup.lang} group:${groupId} loaded [${details.startSN}-${details.endSN}]`);\n    if (id === this.trackId) {\n      this.playlistLoaded(id, data, curDetails);\n    }\n  }\n  onLevelLoading(event, data) {\n    this.switchLevel(data.level);\n  }\n  onLevelSwitching(event, data) {\n    this.switchLevel(data.level);\n  }\n  switchLevel(levelIndex) {\n    const levelInfo = this.hls.levels[levelIndex];\n    if (!levelInfo) {\n      return;\n    }\n    const audioGroups = levelInfo.audioGroups || null;\n    const currentGroups = this.groupIds;\n    let currentTrack = this.currentTrack;\n    if (!audioGroups || (currentGroups == null ? void 0 : currentGroups.length) !== (audioGroups == null ? void 0 : audioGroups.length) || audioGroups != null && audioGroups.some(groupId => (currentGroups == null ? void 0 : currentGroups.indexOf(groupId)) === -1)) {\n      this.groupIds = audioGroups;\n      this.trackId = -1;\n      this.currentTrack = null;\n      const audioTracks = this.tracks.filter(track => !audioGroups || audioGroups.indexOf(track.groupId) !== -1);\n      if (audioTracks.length) {\n        // Disable selectDefaultTrack if there are no default tracks\n        if (this.selectDefaultTrack && !audioTracks.some(track => track.default)) {\n          this.selectDefaultTrack = false;\n        }\n        // track.id should match hls.audioTracks index\n        audioTracks.forEach((track, i) => {\n          track.id = i;\n        });\n      } else if (!currentTrack && !this.tracksInGroup.length) {\n        // Do not dispatch AUDIO_TRACKS_UPDATED when there were and are no tracks\n        return;\n      }\n      this.tracksInGroup = audioTracks;\n\n      // Find preferred track\n      const audioPreference = this.hls.config.audioPreference;\n      if (!currentTrack && audioPreference) {\n        const groupIndex = findMatchingOption(audioPreference, audioTracks, audioMatchPredicate);\n        if (groupIndex > -1) {\n          currentTrack = audioTracks[groupIndex];\n        } else {\n          const allIndex = findMatchingOption(audioPreference, this.tracks);\n          currentTrack = this.tracks[allIndex];\n        }\n      }\n\n      // Select initial track\n      let trackId = this.findTrackId(currentTrack);\n      if (trackId === -1 && currentTrack) {\n        trackId = this.findTrackId(null);\n      }\n\n      // Dispatch events and load track if needed\n      const audioTracksUpdated = {\n        audioTracks\n      };\n      this.log(`Updating audio tracks, ${audioTracks.length} track(s) found in group(s): ${audioGroups == null ? void 0 : audioGroups.join(',')}`);\n      this.hls.trigger(Events.AUDIO_TRACKS_UPDATED, audioTracksUpdated);\n      const selectedTrackId = this.trackId;\n      if (trackId !== -1 && selectedTrackId === -1) {\n        this.setAudioTrack(trackId);\n      } else if (audioTracks.length && selectedTrackId === -1) {\n        var _this$groupIds;\n        const error = new Error(`No audio track selected for current audio group-ID(s): ${(_this$groupIds = this.groupIds) == null ? void 0 : _this$groupIds.join(',')} track count: ${audioTracks.length}`);\n        this.warn(error.message);\n        this.hls.trigger(Events.ERROR, {\n          type: ErrorTypes.MEDIA_ERROR,\n          details: ErrorDetails.AUDIO_TRACK_LOAD_ERROR,\n          fatal: true,\n          error\n        });\n      }\n    }\n  }\n  onError(event, data) {\n    if (data.fatal || !data.context) {\n      return;\n    }\n    if (data.context.type === PlaylistContextType.AUDIO_TRACK && data.context.id === this.trackId && (!this.groupIds || this.groupIds.indexOf(data.context.groupId) !== -1)) {\n      this.checkRetry(data);\n    }\n  }\n  get allAudioTracks() {\n    return this.tracks;\n  }\n  get audioTracks() {\n    return this.tracksInGroup;\n  }\n  get audioTrack() {\n    return this.trackId;\n  }\n  set audioTrack(newId) {\n    // If audio track is selected from API then don't choose from the manifest default track\n    this.selectDefaultTrack = false;\n    this.setAudioTrack(newId);\n  }\n  setAudioOption(audioOption) {\n    const hls = this.hls;\n    hls.config.audioPreference = audioOption;\n    if (audioOption) {\n      const allAudioTracks = this.allAudioTracks;\n      this.selectDefaultTrack = false;\n      if (allAudioTracks.length) {\n        // First see if current option matches (no switch op)\n        const currentTrack = this.currentTrack;\n        if (currentTrack && matchesOption(audioOption, currentTrack, audioMatchPredicate)) {\n          return currentTrack;\n        }\n        // Find option in available tracks (tracksInGroup)\n        const groupIndex = findMatchingOption(audioOption, this.tracksInGroup, audioMatchPredicate);\n        if (groupIndex > -1) {\n          const track = this.tracksInGroup[groupIndex];\n          this.setAudioTrack(groupIndex);\n          return track;\n        } else if (currentTrack) {\n          // Find option in nearest level audio group\n          let searchIndex = hls.loadLevel;\n          if (searchIndex === -1) {\n            searchIndex = hls.firstAutoLevel;\n          }\n          const switchIndex = findClosestLevelWithAudioGroup(audioOption, hls.levels, allAudioTracks, searchIndex, audioMatchPredicate);\n          if (switchIndex === -1) {\n            // could not find matching variant\n            return null;\n          }\n          // and switch level to acheive the audio group switch\n          hls.nextLoadLevel = switchIndex;\n        }\n        if (audioOption.channels || audioOption.audioCodec) {\n          // Could not find a match with codec / channels predicate\n          // Find a match without channels or codec\n          const withoutCodecAndChannelsMatch = findMatchingOption(audioOption, allAudioTracks);\n          if (withoutCodecAndChannelsMatch > -1) {\n            return allAudioTracks[withoutCodecAndChannelsMatch];\n          }\n        }\n      }\n    }\n    return null;\n  }\n  setAudioTrack(newId) {\n    const tracks = this.tracksInGroup;\n\n    // check if level idx is valid\n    if (newId < 0 || newId >= tracks.length) {\n      this.warn(`Invalid audio track id: ${newId}`);\n      return;\n    }\n    this.selectDefaultTrack = false;\n    const lastTrack = this.currentTrack;\n    const track = tracks[newId];\n    const trackLoaded = track.details && !track.details.live;\n    if (newId === this.trackId && track === lastTrack && trackLoaded) {\n      return;\n    }\n    this.log(`Switching to audio-track ${newId} \"${track.name}\" lang:${track.lang} group:${track.groupId} channels:${track.channels}`);\n    this.trackId = newId;\n    this.currentTrack = track;\n    this.hls.trigger(Events.AUDIO_TRACK_SWITCHING, _objectSpread2({}, track));\n    // Do not reload track unless live\n    if (trackLoaded) {\n      return;\n    }\n    const hlsUrlParameters = this.switchParams(track.url, lastTrack == null ? void 0 : lastTrack.details, track.details);\n    this.loadPlaylist(hlsUrlParameters);\n  }\n  findTrackId(currentTrack) {\n    const audioTracks = this.tracksInGroup;\n    for (let i = 0; i < audioTracks.length; i++) {\n      const track = audioTracks[i];\n      if (this.selectDefaultTrack && !track.default) {\n        continue;\n      }\n      if (!currentTrack || matchesOption(currentTrack, track, audioMatchPredicate)) {\n        return i;\n      }\n    }\n    if (currentTrack) {\n      const {\n        name,\n        lang,\n        assocLang,\n        characteristics,\n        audioCodec,\n        channels\n      } = currentTrack;\n      for (let i = 0; i < audioTracks.length; i++) {\n        const track = audioTracks[i];\n        if (matchesOption({\n          name,\n          lang,\n          assocLang,\n          characteristics,\n          audioCodec,\n          channels\n        }, track, audioMatchPredicate)) {\n          return i;\n        }\n      }\n      for (let i = 0; i < audioTracks.length; i++) {\n        const track = audioTracks[i];\n        if (mediaAttributesIdentical(currentTrack.attrs, track.attrs, ['LANGUAGE', 'ASSOC-LANGUAGE', 'CHARACTERISTICS'])) {\n          return i;\n        }\n      }\n      for (let i = 0; i < audioTracks.length; i++) {\n        const track = audioTracks[i];\n        if (mediaAttributesIdentical(currentTrack.attrs, track.attrs, ['LANGUAGE'])) {\n          return i;\n        }\n      }\n    }\n    return -1;\n  }\n  loadPlaylist(hlsUrlParameters) {\n    super.loadPlaylist();\n    const audioTrack = this.currentTrack;\n    if (!this.shouldLoadPlaylist(audioTrack)) {\n      return;\n    }\n    // Do not load audio rendition with URI matching main variant URI\n    if (useAlternateAudio(audioTrack.url, this.hls)) {\n      this.scheduleLoading(audioTrack, hlsUrlParameters);\n    }\n  }\n  loadingPlaylist(audioTrack, hlsUrlParameters) {\n    super.loadingPlaylist(audioTrack, hlsUrlParameters);\n    const id = audioTrack.id;\n    const groupId = audioTrack.groupId;\n    const url = this.getUrlWithDirectives(audioTrack.url, hlsUrlParameters);\n    const details = audioTrack.details;\n    const age = details == null ? void 0 : details.age;\n    this.log(`Loading audio-track ${id} \"${audioTrack.name}\" lang:${audioTrack.lang} group:${groupId}${(hlsUrlParameters == null ? void 0 : hlsUrlParameters.msn) !== undefined ? ' at sn ' + hlsUrlParameters.msn + ' part ' + hlsUrlParameters.part : ''}${age && details.live ? ' age ' + age.toFixed(1) + (details.type ? ' ' + details.type || 0 : '') : ''} ${url}`);\n    this.hls.trigger(Events.AUDIO_TRACK_LOADING, {\n      url,\n      id,\n      groupId,\n      deliveryDirectives: hlsUrlParameters || null,\n      track: audioTrack\n    });\n  }\n}\n\nclass BufferOperationQueue {\n  constructor(sourceBufferReference) {\n    this.tracks = void 0;\n    this.queues = {\n      video: [],\n      audio: [],\n      audiovideo: []\n    };\n    this.tracks = sourceBufferReference;\n  }\n  destroy() {\n    this.tracks = this.queues = null;\n  }\n  append(operation, type, pending) {\n    if (this.queues === null || this.tracks === null) {\n      return;\n    }\n    const queue = this.queues[type];\n    queue.push(operation);\n    if (queue.length === 1 && !pending) {\n      this.executeNext(type);\n    }\n  }\n  appendBlocker(type) {\n    return new Promise(resolve => {\n      const operation = {\n        label: 'async-blocker',\n        execute: resolve,\n        onStart: () => {},\n        onComplete: () => {},\n        onError: () => {}\n      };\n      this.append(operation, type);\n    });\n  }\n  prependBlocker(type) {\n    return new Promise(resolve => {\n      if (this.queues) {\n        const operation = {\n          label: 'async-blocker-prepend',\n          execute: resolve,\n          onStart: () => {},\n          onComplete: () => {},\n          onError: () => {}\n        };\n        this.queues[type].unshift(operation);\n      }\n    });\n  }\n  removeBlockers() {\n    if (this.queues === null) {\n      return;\n    }\n    [this.queues.video, this.queues.audio, this.queues.audiovideo].forEach(queue => {\n      var _queue$;\n      const label = (_queue$ = queue[0]) == null ? void 0 : _queue$.label;\n      if (label === 'async-blocker' || label === 'async-blocker-prepend') {\n        queue[0].execute();\n        queue.splice(0, 1);\n      }\n    });\n  }\n  unblockAudio(op) {\n    if (this.queues === null) {\n      return;\n    }\n    const queue = this.queues.audio;\n    if (queue[0] === op) {\n      this.shiftAndExecuteNext('audio');\n    }\n  }\n  executeNext(type) {\n    if (this.queues === null || this.tracks === null) {\n      return;\n    }\n    const queue = this.queues[type];\n    if (queue.length) {\n      const operation = queue[0];\n      try {\n        // Operations are expected to result in an 'updateend' event being fired. If not, the queue will lock. Operations\n        // which do not end with this event must call _onSBUpdateEnd manually\n        operation.execute();\n      } catch (error) {\n        var _this$tracks$type;\n        operation.onError(error);\n        if (this.queues === null || this.tracks === null) {\n          return;\n        }\n\n        // Only shift the current operation off, otherwise the updateend handler will do this for us\n        const sb = (_this$tracks$type = this.tracks[type]) == null ? void 0 : _this$tracks$type.buffer;\n        if (!(sb != null && sb.updating)) {\n          this.shiftAndExecuteNext(type);\n        }\n      }\n    }\n  }\n  shiftAndExecuteNext(type) {\n    if (this.queues === null) {\n      return;\n    }\n    this.queues[type].shift();\n    this.executeNext(type);\n  }\n  current(type) {\n    var _this$queues;\n    return ((_this$queues = this.queues) == null ? void 0 : _this$queues[type][0]) || null;\n  }\n  toString() {\n    const {\n      queues,\n      tracks\n    } = this;\n    if (queues === null || tracks === null) {\n      return `<destroyed>`;\n    }\n    return `\n${this.list('video')}\n${this.list('audio')}\n${this.list('audiovideo')}}`;\n  }\n  list(type) {\n    var _this$queues2, _this$tracks;\n    return (_this$queues2 = this.queues) != null && _this$queues2[type] || (_this$tracks = this.tracks) != null && _this$tracks[type] ? `${type}: (${this.listSbInfo(type)}) ${this.listOps(type)}` : '';\n  }\n  listSbInfo(type) {\n    var _this$tracks2;\n    const track = (_this$tracks2 = this.tracks) == null ? void 0 : _this$tracks2[type];\n    const sb = track == null ? void 0 : track.buffer;\n    if (!sb) {\n      return 'none';\n    }\n    return `SourceBuffer${sb.updating ? ' updating' : ''}${track.ended ? ' ended' : ''}${track.ending ? ' ending' : ''}`;\n  }\n  listOps(type) {\n    var _this$queues3;\n    return ((_this$queues3 = this.queues) == null ? void 0 : _this$queues3[type].map(op => op.label).join(', ')) || '';\n  }\n}\n\nconst VIDEO_CODEC_PROFILE_REPLACE = /(avc[1234]|hvc1|hev1|dvh[1e]|vp09|av01)(?:\\.[^.,]+)+/;\nconst TRACK_REMOVED_ERROR_NAME = 'HlsJsTrackRemovedError';\nclass HlsJsTrackRemovedError extends Error {\n  constructor(message) {\n    super(message);\n    this.name = TRACK_REMOVED_ERROR_NAME;\n  }\n}\nclass BufferController extends Logger {\n  constructor(hls, fragmentTracker) {\n    super('buffer-controller', hls.logger);\n    this.hls = void 0;\n    this.fragmentTracker = void 0;\n    // The level details used to determine duration, target-duration and live\n    this.details = null;\n    // cache the self generated object url to detect hijack of video tag\n    this._objectUrl = null;\n    // A queue of buffer operations which require the SourceBuffer to not be updating upon execution\n    this.operationQueue = null;\n    // The total number track codecs expected before any sourceBuffers are created (2: audio and video or 1: audiovideo | audio | video)\n    this.bufferCodecEventsTotal = 0;\n    // A reference to the attached media element\n    this.media = null;\n    // A reference to the active media source\n    this.mediaSource = null;\n    // Last MP3 audio chunk appended\n    this.lastMpegAudioChunk = null;\n    // Audio fragment blocked from appending until corresponding video appends or context changes\n    this.blockedAudioAppend = null;\n    // Keep track of video append position for unblocking audio\n    this.lastVideoAppendEnd = 0;\n    // Whether or not to use ManagedMediaSource API and append source element to media element.\n    this.appendSource = void 0;\n    // Transferred MediaSource information used to detmerine if duration end endstream may be appended\n    this.transferData = void 0;\n    // Directives used to override default MediaSource handling\n    this.overrides = void 0;\n    // Error counters\n    this.appendErrors = {\n      audio: 0,\n      video: 0,\n      audiovideo: 0\n    };\n    // Record of required or created buffers by type. SourceBuffer is stored in Track.buffer once created.\n    this.tracks = {};\n    // Array of SourceBuffer type and SourceBuffer (or null). One entry per TrackSet in this.tracks.\n    this.sourceBuffers = [[null, null], [null, null]];\n    this._onEndStreaming = event => {\n      var _this$mediaSource;\n      if (!this.hls) {\n        return;\n      }\n      if (((_this$mediaSource = this.mediaSource) == null ? void 0 : _this$mediaSource.readyState) !== 'open') {\n        return;\n      }\n      this.hls.pauseBuffering();\n    };\n    this._onStartStreaming = event => {\n      if (!this.hls) {\n        return;\n      }\n      this.hls.resumeBuffering();\n    };\n    // Keep as arrow functions so that we can directly reference these functions directly as event listeners\n    this._onMediaSourceOpen = e => {\n      const {\n        media,\n        mediaSource\n      } = this;\n      if (e) {\n        this.log('Media source opened');\n      }\n      if (!media || !mediaSource) {\n        return;\n      }\n      // once received, don't listen anymore to sourceopen event\n      mediaSource.removeEventListener('sourceopen', this._onMediaSourceOpen);\n      media.removeEventListener('emptied', this._onMediaEmptied);\n      this.updateDuration();\n      this.hls.trigger(Events.MEDIA_ATTACHED, {\n        media,\n        mediaSource: mediaSource\n      });\n      if (this.mediaSource !== null) {\n        this.checkPendingTracks();\n      }\n    };\n    this._onMediaSourceClose = () => {\n      this.log('Media source closed');\n    };\n    this._onMediaSourceEnded = () => {\n      this.log('Media source ended');\n    };\n    this._onMediaEmptied = () => {\n      const {\n        mediaSrc,\n        _objectUrl\n      } = this;\n      if (mediaSrc !== _objectUrl) {\n        this.error(`Media element src was set while attaching MediaSource (${_objectUrl} > ${mediaSrc})`);\n      }\n    };\n    this.hls = hls;\n    this.fragmentTracker = fragmentTracker;\n    this.appendSource = isManagedMediaSource(getMediaSource(hls.config.preferManagedMediaSource));\n    this.initTracks();\n    this.registerListeners();\n  }\n  hasSourceTypes() {\n    return Object.keys(this.tracks).length > 0;\n  }\n  destroy() {\n    this.unregisterListeners();\n    this.details = null;\n    this.lastMpegAudioChunk = this.blockedAudioAppend = null;\n    this.transferData = this.overrides = undefined;\n    if (this.operationQueue) {\n      this.operationQueue.destroy();\n      this.operationQueue = null;\n    }\n    // @ts-ignore\n    this.hls = this.fragmentTracker = null;\n    // @ts-ignore\n    this._onMediaSourceOpen = this._onMediaSourceClose = null;\n    // @ts-ignore\n    this._onMediaSourceEnded = null;\n    // @ts-ignore\n    this._onStartStreaming = this._onEndStreaming = null;\n  }\n  registerListeners() {\n    const {\n      hls\n    } = this;\n    hls.on(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);\n    hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.on(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n    hls.on(Events.BUFFER_RESET, this.onBufferReset, this);\n    hls.on(Events.BUFFER_APPENDING, this.onBufferAppending, this);\n    hls.on(Events.BUFFER_CODECS, this.onBufferCodecs, this);\n    hls.on(Events.BUFFER_EOS, this.onBufferEos, this);\n    hls.on(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);\n    hls.on(Events.LEVEL_UPDATED, this.onLevelUpdated, this);\n    hls.on(Events.FRAG_PARSED, this.onFragParsed, this);\n    hls.on(Events.FRAG_CHANGED, this.onFragChanged, this);\n    hls.on(Events.ERROR, this.onError, this);\n  }\n  unregisterListeners() {\n    const {\n      hls\n    } = this;\n    hls.off(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);\n    hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.off(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n    hls.off(Events.BUFFER_RESET, this.onBufferReset, this);\n    hls.off(Events.BUFFER_APPENDING, this.onBufferAppending, this);\n    hls.off(Events.BUFFER_CODECS, this.onBufferCodecs, this);\n    hls.off(Events.BUFFER_EOS, this.onBufferEos, this);\n    hls.off(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);\n    hls.off(Events.LEVEL_UPDATED, this.onLevelUpdated, this);\n    hls.off(Events.FRAG_PARSED, this.onFragParsed, this);\n    hls.off(Events.FRAG_CHANGED, this.onFragChanged, this);\n    hls.off(Events.ERROR, this.onError, this);\n  }\n  transferMedia() {\n    const {\n      media,\n      mediaSource\n    } = this;\n    if (!media) {\n      return null;\n    }\n    const tracks = {};\n    if (this.operationQueue) {\n      const updating = this.isUpdating();\n      if (!updating) {\n        this.operationQueue.removeBlockers();\n      }\n      const queued = this.isQueued();\n      if (updating || queued) {\n        this.warn(`Transfering MediaSource with${queued ? ' operations in queue' : ''}${updating ? ' updating SourceBuffer(s)' : ''} ${this.operationQueue}`);\n      }\n      this.operationQueue.destroy();\n    }\n    const transferData = this.transferData;\n    if (!this.sourceBufferCount && transferData && transferData.mediaSource === mediaSource) {\n      _extends(tracks, transferData.tracks);\n    } else {\n      this.sourceBuffers.forEach(tuple => {\n        const [type] = tuple;\n        if (type) {\n          tracks[type] = _extends({}, this.tracks[type]);\n          this.removeBuffer(type);\n        }\n        tuple[0] = tuple[1] = null;\n      });\n    }\n    return {\n      media,\n      mediaSource,\n      tracks\n    };\n  }\n  initTracks() {\n    const tracks = {};\n    this.sourceBuffers = [[null, null], [null, null]];\n    this.tracks = tracks;\n    this.resetQueue();\n    this.resetAppendErrors();\n    this.lastMpegAudioChunk = this.blockedAudioAppend = null;\n    this.lastVideoAppendEnd = 0;\n  }\n  onManifestLoading() {\n    this.bufferCodecEventsTotal = 0;\n    this.details = null;\n  }\n  onManifestParsed(event, data) {\n    var _this$transferData;\n    // in case of alt audio 2 BUFFER_CODECS events will be triggered, one per stream controller\n    // sourcebuffers will be created all at once when the expected nb of tracks will be reached\n    // in case alt audio is not used, only one BUFFER_CODEC event will be fired from main stream controller\n    // it will contain the expected nb of source buffers, no need to compute it\n    let codecEvents = 2;\n    if (data.audio && !data.video || !data.altAudio) {\n      codecEvents = 1;\n    }\n    this.bufferCodecEventsTotal = codecEvents;\n    this.log(`${codecEvents} bufferCodec event(s) expected.`);\n    if ((_this$transferData = this.transferData) != null && _this$transferData.mediaSource && this.sourceBufferCount && codecEvents) {\n      this.bufferCreated();\n    }\n  }\n  onMediaAttaching(event, data) {\n    const media = this.media = data.media;\n    this.transferData = this.overrides = undefined;\n    const MediaSource = getMediaSource(this.appendSource);\n    if (MediaSource) {\n      const transferringMedia = !!data.mediaSource;\n      if (transferringMedia || data.overrides) {\n        this.transferData = data;\n        this.overrides = data.overrides;\n      }\n      const ms = this.mediaSource = data.mediaSource || new MediaSource();\n      this.assignMediaSource(ms);\n      if (transferringMedia) {\n        this._objectUrl = media.src;\n        this.attachTransferred();\n      } else {\n        // cache the locally generated object url\n        const objectUrl = this._objectUrl = self.URL.createObjectURL(ms);\n        // link video and media Source\n        if (this.appendSource) {\n          try {\n            media.removeAttribute('src');\n            // ManagedMediaSource will not open without disableRemotePlayback set to false or source alternatives\n            const MMS = self.ManagedMediaSource;\n            media.disableRemotePlayback = media.disableRemotePlayback || MMS && ms instanceof MMS;\n            removeSourceChildren(media);\n            addSource(media, objectUrl);\n            media.load();\n          } catch (error) {\n            media.src = objectUrl;\n          }\n        } else {\n          media.src = objectUrl;\n        }\n      }\n      media.addEventListener('emptied', this._onMediaEmptied);\n    }\n  }\n  assignMediaSource(ms) {\n    var _this$transferData2, _ms$constructor;\n    this.log(`${((_this$transferData2 = this.transferData) == null ? void 0 : _this$transferData2.mediaSource) === ms ? 'transferred' : 'created'} media source: ${(_ms$constructor = ms.constructor) == null ? void 0 : _ms$constructor.name}`);\n    // MediaSource listeners are arrow functions with a lexical scope, and do not need to be bound\n    ms.addEventListener('sourceopen', this._onMediaSourceOpen);\n    ms.addEventListener('sourceended', this._onMediaSourceEnded);\n    ms.addEventListener('sourceclose', this._onMediaSourceClose);\n    if (this.appendSource) {\n      ms.addEventListener('startstreaming', this._onStartStreaming);\n      ms.addEventListener('endstreaming', this._onEndStreaming);\n    }\n  }\n  attachTransferred() {\n    const media = this.media;\n    const data = this.transferData;\n    if (!data || !media) {\n      return;\n    }\n    const requiredTracks = this.tracks;\n    const transferredTracks = data.tracks;\n    const trackNames = transferredTracks ? Object.keys(transferredTracks) : null;\n    const trackCount = trackNames ? trackNames.length : 0;\n    const mediaSourceOpenCallback = () => {\n      // eslint-disable-next-line @typescript-eslint/no-floating-promises\n      Promise.resolve().then(() => {\n        if (this.media && this.mediaSourceOpenOrEnded) {\n          this._onMediaSourceOpen();\n        }\n      });\n    };\n    if (transferredTracks && trackNames && trackCount) {\n      if (!this.tracksReady) {\n        // Wait for CODECS event(s)\n        this.hls.config.startFragPrefetch = true;\n        this.log(`attachTransferred: waiting for SourceBuffer track info`);\n        return;\n      }\n      this.log(`attachTransferred: (bufferCodecEventsTotal ${this.bufferCodecEventsTotal})\nrequired tracks: ${stringify(requiredTracks, (key, value) => key === 'initSegment' ? undefined : value)};\ntransfer tracks: ${stringify(transferredTracks, (key, value) => key === 'initSegment' ? undefined : value)}}`);\n      if (!isCompatibleTrackChange(transferredTracks, requiredTracks)) {\n        // destroy attaching media source\n        data.mediaSource = null;\n        data.tracks = undefined;\n        const currentTime = media.currentTime;\n        const details = this.details;\n        const startTime = Math.max(currentTime, (details == null ? void 0 : details.fragments[0].start) || 0);\n        if (startTime - currentTime > 1) {\n          this.log(`attachTransferred: waiting for playback to reach new tracks start time ${currentTime} -> ${startTime}`);\n          return;\n        }\n        this.warn(`attachTransferred: resetting MediaSource for incompatible tracks (\"${Object.keys(transferredTracks)}\"->\"${Object.keys(requiredTracks)}\") start time: ${startTime} currentTime: ${currentTime}`);\n        this.onMediaDetaching(Events.MEDIA_DETACHING, {});\n        this.onMediaAttaching(Events.MEDIA_ATTACHING, data);\n        media.currentTime = startTime;\n        return;\n      }\n      this.transferData = undefined;\n      trackNames.forEach(trackName => {\n        const type = trackName;\n        const track = transferredTracks[type];\n        if (track) {\n          const sb = track.buffer;\n          if (sb) {\n            // Purge fragment tracker of ejected segments for existing buffer\n            const fragmentTracker = this.fragmentTracker;\n            const playlistType = track.id;\n            if (fragmentTracker.hasFragments(playlistType) || fragmentTracker.hasParts(playlistType)) {\n              const bufferedTimeRanges = BufferHelper.getBuffered(sb);\n              fragmentTracker.detectEvictedFragments(type, bufferedTimeRanges, playlistType, null, true);\n            }\n            // Transfer SourceBuffer\n            const sbIndex = sourceBufferNameToIndex(type);\n            const sbTuple = [type, sb];\n            this.sourceBuffers[sbIndex] = sbTuple;\n            if (sb.updating && this.operationQueue) {\n              // eslint-disable-next-line @typescript-eslint/no-floating-promises\n              this.operationQueue.prependBlocker(type);\n            }\n            this.trackSourceBuffer(type, track);\n          }\n        }\n      });\n      mediaSourceOpenCallback();\n      this.bufferCreated();\n    } else {\n      this.log(`attachTransferred: MediaSource w/o SourceBuffers`);\n      mediaSourceOpenCallback();\n    }\n  }\n  get mediaSourceOpenOrEnded() {\n    var _this$mediaSource2;\n    const readyState = (_this$mediaSource2 = this.mediaSource) == null ? void 0 : _this$mediaSource2.readyState;\n    return readyState === 'open' || readyState === 'ended';\n  }\n  onMediaDetaching(event, data) {\n    const transferringMedia = !!data.transferMedia;\n    this.transferData = this.overrides = undefined;\n    const {\n      media,\n      mediaSource,\n      _objectUrl\n    } = this;\n    if (mediaSource) {\n      this.log(`media source ${transferringMedia ? 'transferring' : 'detaching'}`);\n      if (transferringMedia) {\n        // Detach SourceBuffers without removing from MediaSource\n        // and leave `tracks` (required SourceBuffers configuration)\n        this.sourceBuffers.forEach(([type]) => {\n          if (type) {\n            this.removeBuffer(type);\n          }\n        });\n        this.resetQueue();\n      } else {\n        if (this.mediaSourceOpenOrEnded) {\n          const open = mediaSource.readyState === 'open';\n          try {\n            const sourceBuffers = mediaSource.sourceBuffers;\n            for (let i = sourceBuffers.length; i--;) {\n              if (open) {\n                sourceBuffers[i].abort();\n              }\n              mediaSource.removeSourceBuffer(sourceBuffers[i]);\n            }\n            if (open) {\n              // endOfStream could trigger exception if any sourcebuffer is in updating state\n              // we don't really care about checking sourcebuffer state here,\n              // as we are anyway detaching the MediaSource\n              // let's just avoid this exception to propagate\n              mediaSource.endOfStream();\n            }\n          } catch (err) {\n            this.warn(`onMediaDetaching: ${err.message} while calling endOfStream`);\n          }\n        }\n        // Clean up the SourceBuffers by invoking onBufferReset\n        if (this.sourceBufferCount) {\n          this.onBufferReset();\n        }\n      }\n      mediaSource.removeEventListener('sourceopen', this._onMediaSourceOpen);\n      mediaSource.removeEventListener('sourceended', this._onMediaSourceEnded);\n      mediaSource.removeEventListener('sourceclose', this._onMediaSourceClose);\n      if (this.appendSource) {\n        mediaSource.removeEventListener('startstreaming', this._onStartStreaming);\n        mediaSource.removeEventListener('endstreaming', this._onEndStreaming);\n      }\n      this.mediaSource = null;\n      this._objectUrl = null;\n    }\n\n    // Detach properly the MediaSource from the HTMLMediaElement as\n    // suggested in https://github.com/w3c/media-source/issues/53.\n    if (media) {\n      media.removeEventListener('emptied', this._onMediaEmptied);\n      if (!transferringMedia) {\n        if (_objectUrl) {\n          self.URL.revokeObjectURL(_objectUrl);\n        }\n\n        // clean up video tag src only if it's our own url. some external libraries might\n        // hijack the video tag and change its 'src' without destroying the Hls instance first\n        if (this.mediaSrc === _objectUrl) {\n          media.removeAttribute('src');\n          if (this.appendSource) {\n            removeSourceChildren(media);\n          }\n          media.load();\n        } else {\n          this.warn('media|source.src was changed by a third party - skip cleanup');\n        }\n      }\n      this.media = null;\n    }\n    this.hls.trigger(Events.MEDIA_DETACHED, data);\n  }\n  onBufferReset() {\n    this.sourceBuffers.forEach(([type]) => {\n      if (type) {\n        this.resetBuffer(type);\n      }\n    });\n    this.initTracks();\n  }\n  resetBuffer(type) {\n    var _this$tracks$type;\n    const sb = (_this$tracks$type = this.tracks[type]) == null ? void 0 : _this$tracks$type.buffer;\n    this.removeBuffer(type);\n    if (sb) {\n      try {\n        var _this$mediaSource3;\n        if ((_this$mediaSource3 = this.mediaSource) != null && _this$mediaSource3.sourceBuffers.length) {\n          this.mediaSource.removeSourceBuffer(sb);\n        }\n      } catch (err) {\n        this.warn(`onBufferReset ${type}`, err);\n      }\n    }\n    delete this.tracks[type];\n  }\n  removeBuffer(type) {\n    this.removeBufferListeners(type);\n    this.sourceBuffers[sourceBufferNameToIndex(type)] = [null, null];\n    const track = this.tracks[type];\n    if (track) {\n      track.buffer = undefined;\n    }\n  }\n  resetQueue() {\n    if (this.operationQueue) {\n      this.operationQueue.destroy();\n    }\n    this.operationQueue = new BufferOperationQueue(this.tracks);\n  }\n  onBufferCodecs(event, data) {\n    var _data$audio;\n    const tracks = this.tracks;\n    const trackNames = Object.keys(data);\n    this.log(`BUFFER_CODECS: \"${trackNames}\" (current SB count ${this.sourceBufferCount})`);\n    const unmuxedToMuxed = 'audiovideo' in data && (tracks.audio || tracks.video) || tracks.audiovideo && ('audio' in data || 'video' in data);\n    const muxedToUnmuxed = !unmuxedToMuxed && this.sourceBufferCount && this.media && trackNames.some(sbName => !tracks[sbName]);\n    if (unmuxedToMuxed || muxedToUnmuxed) {\n      this.warn(`Unsupported transition between \"${Object.keys(tracks)}\" and \"${trackNames}\" SourceBuffers`);\n      // Do not add incompatible track ('audiovideo' <-> 'video'/'audio').\n      // Allow following onBufferAppending handle to trigger BUFFER_APPEND_ERROR.\n      // This will either be resolved by level switch or could be handled with recoverMediaError().\n      return;\n    }\n    trackNames.forEach(trackName => {\n      var _this$transferData3, _trackCodec;\n      const parsedTrack = data[trackName];\n      const {\n        id,\n        codec,\n        levelCodec,\n        container,\n        metadata,\n        supplemental\n      } = parsedTrack;\n      let track = tracks[trackName];\n      const transferredTrack = (_this$transferData3 = this.transferData) == null || (_this$transferData3 = _this$transferData3.tracks) == null ? void 0 : _this$transferData3[trackName];\n      const sbTrack = transferredTrack != null && transferredTrack.buffer ? transferredTrack : track;\n      const sbCodec = (sbTrack == null ? void 0 : sbTrack.pendingCodec) || (sbTrack == null ? void 0 : sbTrack.codec);\n      const trackLevelCodec = sbTrack == null ? void 0 : sbTrack.levelCodec;\n      if (!track) {\n        track = tracks[trackName] = {\n          buffer: undefined,\n          listeners: [],\n          codec,\n          supplemental,\n          container,\n          levelCodec,\n          metadata,\n          id\n        };\n      }\n      // check if SourceBuffer codec needs to change\n      const currentCodecFull = pickMostCompleteCodecName(sbCodec, trackLevelCodec);\n      const currentCodec = currentCodecFull == null ? void 0 : currentCodecFull.replace(VIDEO_CODEC_PROFILE_REPLACE, '$1');\n      let trackCodec = pickMostCompleteCodecName(codec, levelCodec);\n      const nextCodec = (_trackCodec = trackCodec) == null ? void 0 : _trackCodec.replace(VIDEO_CODEC_PROFILE_REPLACE, '$1');\n      if (trackCodec && currentCodecFull && currentCodec !== nextCodec) {\n        if (trackName.slice(0, 5) === 'audio') {\n          trackCodec = getCodecCompatibleName(trackCodec, this.appendSource);\n        }\n        this.log(`switching codec ${sbCodec} to ${trackCodec}`);\n        if (trackCodec !== (track.pendingCodec || track.codec)) {\n          track.pendingCodec = trackCodec;\n        }\n        track.container = container;\n        this.appendChangeType(trackName, container, trackCodec);\n      }\n    });\n    if (this.tracksReady || this.sourceBufferCount) {\n      data.tracks = this.sourceBufferTracks;\n    }\n\n    // if sourcebuffers already created, do nothing ...\n    if (this.sourceBufferCount) {\n      return;\n    }\n    if (this.bufferCodecEventsTotal > 1 && !this.tracks.video && !data.video && ((_data$audio = data.audio) == null ? void 0 : _data$audio.id) === 'main') {\n      // MVP is missing CODECS and only audio was found in main segment (#7524)\n      this.log(`Main audio-only`);\n      this.bufferCodecEventsTotal = 1;\n    }\n    if (this.mediaSourceOpenOrEnded) {\n      this.checkPendingTracks();\n    }\n  }\n  get sourceBufferTracks() {\n    return Object.keys(this.tracks).reduce((baseTracks, type) => {\n      const track = this.tracks[type];\n      baseTracks[type] = {\n        id: track.id,\n        container: track.container,\n        codec: track.codec,\n        levelCodec: track.levelCodec\n      };\n      return baseTracks;\n    }, {});\n  }\n  appendChangeType(type, container, codec) {\n    const mimeType = `${container};codecs=${codec}`;\n    const operation = {\n      label: `change-type=${mimeType}`,\n      execute: () => {\n        const track = this.tracks[type];\n        if (track) {\n          const sb = track.buffer;\n          if (sb != null && sb.changeType) {\n            this.log(`changing ${type} sourceBuffer type to ${mimeType}`);\n            sb.changeType(mimeType);\n            track.codec = codec;\n            track.container = container;\n          }\n        }\n        this.shiftAndExecuteNext(type);\n      },\n      onStart: () => {},\n      onComplete: () => {},\n      onError: error => {\n        this.warn(`Failed to change ${type} SourceBuffer type`, error);\n      }\n    };\n    this.append(operation, type, this.isPending(this.tracks[type]));\n  }\n  blockAudio(partOrFrag) {\n    var _this$fragmentTracker;\n    const pStart = partOrFrag.start;\n    const pTime = pStart + partOrFrag.duration * 0.05;\n    const atGap = ((_this$fragmentTracker = this.fragmentTracker.getAppendedFrag(pStart, PlaylistLevelType.MAIN)) == null ? void 0 : _this$fragmentTracker.gap) === true;\n    if (atGap) {\n      return;\n    }\n    const op = {\n      label: 'block-audio',\n      execute: () => {\n        var _this$fragmentTracker2;\n        const videoTrack = this.tracks.video;\n        if (this.lastVideoAppendEnd > pTime || videoTrack != null && videoTrack.buffer && BufferHelper.isBuffered(videoTrack.buffer, pTime) || ((_this$fragmentTracker2 = this.fragmentTracker.getAppendedFrag(pTime, PlaylistLevelType.MAIN)) == null ? void 0 : _this$fragmentTracker2.gap) === true) {\n          this.blockedAudioAppend = null;\n          this.shiftAndExecuteNext('audio');\n        }\n      },\n      onStart: () => {},\n      onComplete: () => {},\n      onError: error => {\n        this.warn('Error executing block-audio operation', error);\n      }\n    };\n    this.blockedAudioAppend = {\n      op,\n      frag: partOrFrag\n    };\n    this.append(op, 'audio', true);\n  }\n  unblockAudio() {\n    const {\n      blockedAudioAppend,\n      operationQueue\n    } = this;\n    if (blockedAudioAppend && operationQueue) {\n      this.blockedAudioAppend = null;\n      operationQueue.unblockAudio(blockedAudioAppend.op);\n    }\n  }\n  onBufferAppending(event, eventData) {\n    const {\n      tracks\n    } = this;\n    const {\n      data,\n      type,\n      parent,\n      frag,\n      part,\n      chunkMeta,\n      offset\n    } = eventData;\n    const chunkStats = chunkMeta.buffering[type];\n    const {\n      sn,\n      cc\n    } = frag;\n    const bufferAppendingStart = self.performance.now();\n    chunkStats.start = bufferAppendingStart;\n    const fragBuffering = frag.stats.buffering;\n    const partBuffering = part ? part.stats.buffering : null;\n    if (fragBuffering.start === 0) {\n      fragBuffering.start = bufferAppendingStart;\n    }\n    if (partBuffering && partBuffering.start === 0) {\n      partBuffering.start = bufferAppendingStart;\n    }\n\n    // TODO: Only update timestampOffset when audio/mpeg fragment or part is not contiguous with previously appended\n    // Adjusting `SourceBuffer.timestampOffset` (desired point in the timeline where the next frames should be appended)\n    // in Chrome browser when we detect MPEG audio container and time delta between level PTS and `SourceBuffer.timestampOffset`\n    // is greater than 100ms (this is enough to handle seek for VOD or level change for LIVE videos).\n    // More info here: https://github.com/video-dev/hls.js/issues/332#issuecomment-257986486\n    const audioTrack = tracks.audio;\n    let checkTimestampOffset = false;\n    if (type === 'audio' && (audioTrack == null ? void 0 : audioTrack.container) === 'audio/mpeg') {\n      checkTimestampOffset = !this.lastMpegAudioChunk || chunkMeta.id === 1 || this.lastMpegAudioChunk.sn !== chunkMeta.sn;\n      this.lastMpegAudioChunk = chunkMeta;\n    }\n\n    // Block audio append until overlapping video append\n    const videoTrack = tracks.video;\n    const videoSb = videoTrack == null ? void 0 : videoTrack.buffer;\n    if (videoSb && sn !== 'initSegment') {\n      const partOrFrag = part || frag;\n      const blockedAudioAppend = this.blockedAudioAppend;\n      if (type === 'audio' && parent !== 'main' && !this.blockedAudioAppend && !(videoTrack.ending || videoTrack.ended)) {\n        const pStart = partOrFrag.start;\n        const pTime = pStart + partOrFrag.duration * 0.05;\n        const vbuffered = videoSb.buffered;\n        const vappending = this.currentOp('video');\n        if (!vbuffered.length && !vappending) {\n          // wait for video before appending audio\n          this.blockAudio(partOrFrag);\n        } else if (!vappending && !BufferHelper.isBuffered(videoSb, pTime) && this.lastVideoAppendEnd < pTime) {\n          // audio is ahead of video\n          this.blockAudio(partOrFrag);\n        }\n      } else if (type === 'video') {\n        const videoAppendEnd = partOrFrag.end;\n        if (blockedAudioAppend) {\n          const audioStart = blockedAudioAppend.frag.start;\n          if (videoAppendEnd > audioStart || videoAppendEnd < this.lastVideoAppendEnd || BufferHelper.isBuffered(videoSb, audioStart)) {\n            this.unblockAudio();\n          }\n        }\n        this.lastVideoAppendEnd = videoAppendEnd;\n      }\n    }\n    const fragStart = (part || frag).start;\n    const operation = {\n      label: `append-${type}`,\n      execute: () => {\n        var _this$tracks$type2;\n        chunkStats.executeStart = self.performance.now();\n        const sb = (_this$tracks$type2 = this.tracks[type]) == null ? void 0 : _this$tracks$type2.buffer;\n        if (sb) {\n          if (checkTimestampOffset) {\n            this.updateTimestampOffset(sb, fragStart, 0.1, type, sn, cc);\n          } else if (offset !== undefined && isFiniteNumber(offset)) {\n            this.updateTimestampOffset(sb, offset, 0.000001, type, sn, cc);\n          }\n        }\n        this.appendExecutor(data, type);\n      },\n      onStart: () => {\n        // logger.debug(`[buffer-controller]: ${type} SourceBuffer updatestart`);\n      },\n      onComplete: () => {\n        // logger.debug(`[buffer-controller]: ${type} SourceBuffer updateend`);\n        const end = self.performance.now();\n        chunkStats.executeEnd = chunkStats.end = end;\n        if (fragBuffering.first === 0) {\n          fragBuffering.first = end;\n        }\n        if (partBuffering && partBuffering.first === 0) {\n          partBuffering.first = end;\n        }\n        const timeRanges = {};\n        this.sourceBuffers.forEach(([type, sb]) => {\n          if (type) {\n            timeRanges[type] = BufferHelper.getBuffered(sb);\n          }\n        });\n        this.appendErrors[type] = 0;\n        if (type === 'audio' || type === 'video') {\n          this.appendErrors.audiovideo = 0;\n        } else {\n          this.appendErrors.audio = 0;\n          this.appendErrors.video = 0;\n        }\n        this.hls.trigger(Events.BUFFER_APPENDED, {\n          type,\n          frag,\n          part,\n          chunkMeta,\n          parent: frag.type,\n          timeRanges\n        });\n      },\n      onError: error => {\n        var _this$media;\n        // in case any error occured while appending, put back segment in segments table\n        const event = {\n          type: ErrorTypes.MEDIA_ERROR,\n          parent: frag.type,\n          details: ErrorDetails.BUFFER_APPEND_ERROR,\n          sourceBufferName: type,\n          frag,\n          part,\n          chunkMeta,\n          error,\n          err: error,\n          fatal: false\n        };\n        const mediaError = (_this$media = this.media) == null ? void 0 : _this$media.error;\n        if (error.code === DOMException.QUOTA_EXCEEDED_ERR || error.name == 'QuotaExceededError' || `quota` in error) {\n          // QuotaExceededError: http://www.w3.org/TR/html5/infrastructure.html#quotaexceedederror\n          // let's stop appending any segments, and report BUFFER_FULL_ERROR error\n          event.details = ErrorDetails.BUFFER_FULL_ERROR;\n        } else if (error.code === DOMException.INVALID_STATE_ERR && this.mediaSourceOpenOrEnded && !mediaError) {\n          // Allow retry for \"Failed to execute 'appendBuffer' on 'SourceBuffer': This SourceBuffer is still processing\" errors\n          event.errorAction = createDoNothingErrorAction(true);\n        } else if (error.name === TRACK_REMOVED_ERROR_NAME && this.sourceBufferCount === 0) {\n          // Do nothing if sourceBuffers were removed (media is detached and append was not aborted)\n          event.errorAction = createDoNothingErrorAction(true);\n        } else {\n          const appendErrorCount = ++this.appendErrors[type];\n          /* with UHD content, we could get loop of quota exceeded error until\n            browser is able to evict some data from sourcebuffer. Retrying can help recover.\n          */\n          this.warn(`Failed ${appendErrorCount}/${this.hls.config.appendErrorMaxRetry} times to append segment in \"${type}\" sourceBuffer (${mediaError ? mediaError : 'no media error'})`);\n          if (appendErrorCount >= this.hls.config.appendErrorMaxRetry || !!mediaError) {\n            event.fatal = true;\n          }\n        }\n        this.hls.trigger(Events.ERROR, event);\n      }\n    };\n    this.log(`queuing \"${type}\" append sn: ${sn}${part ? ' p: ' + part.index : ''} of ${frag.type === PlaylistLevelType.MAIN ? 'level' : 'track'} ${frag.level} cc: ${cc}`);\n    this.append(operation, type, this.isPending(this.tracks[type]));\n  }\n  getFlushOp(type, start, end) {\n    this.log(`queuing \"${type}\" remove ${start}-${end}`);\n    return {\n      label: 'remove',\n      execute: () => {\n        this.removeExecutor(type, start, end);\n      },\n      onStart: () => {\n        // logger.debug(`[buffer-controller]: Started flushing ${data.startOffset} -> ${data.endOffset} for ${type} Source Buffer`);\n      },\n      onComplete: () => {\n        // logger.debug(`[buffer-controller]: Finished flushing ${data.startOffset} -> ${data.endOffset} for ${type} Source Buffer`);\n        this.hls.trigger(Events.BUFFER_FLUSHED, {\n          type\n        });\n      },\n      onError: error => {\n        this.warn(`Failed to remove ${start}-${end} from \"${type}\" SourceBuffer`, error);\n      }\n    };\n  }\n  onBufferFlushing(event, data) {\n    const {\n      type,\n      startOffset,\n      endOffset\n    } = data;\n    if (type) {\n      this.append(this.getFlushOp(type, startOffset, endOffset), type);\n    } else {\n      this.sourceBuffers.forEach(([type]) => {\n        if (type) {\n          this.append(this.getFlushOp(type, startOffset, endOffset), type);\n        }\n      });\n    }\n  }\n  onFragParsed(event, data) {\n    const {\n      frag,\n      part\n    } = data;\n    const buffersAppendedTo = [];\n    const elementaryStreams = part ? part.elementaryStreams : frag.elementaryStreams;\n    if (elementaryStreams[ElementaryStreamTypes.AUDIOVIDEO]) {\n      buffersAppendedTo.push('audiovideo');\n    } else {\n      if (elementaryStreams[ElementaryStreamTypes.AUDIO]) {\n        buffersAppendedTo.push('audio');\n      }\n      if (elementaryStreams[ElementaryStreamTypes.VIDEO]) {\n        buffersAppendedTo.push('video');\n      }\n    }\n    const onUnblocked = () => {\n      const now = self.performance.now();\n      frag.stats.buffering.end = now;\n      if (part) {\n        part.stats.buffering.end = now;\n      }\n      const stats = part ? part.stats : frag.stats;\n      this.hls.trigger(Events.FRAG_BUFFERED, {\n        frag,\n        part,\n        stats,\n        id: frag.type\n      });\n    };\n    if (buffersAppendedTo.length === 0) {\n      this.warn(`Fragments must have at least one ElementaryStreamType set. type: ${frag.type} level: ${frag.level} sn: ${frag.sn}`);\n    }\n    this.blockBuffers(onUnblocked, buffersAppendedTo).catch(error => {\n      this.warn(`Fragment buffered callback ${error}`);\n      this.stepOperationQueue(this.sourceBufferTypes);\n    });\n  }\n  onFragChanged(event, data) {\n    this.trimBuffers();\n  }\n  get bufferedToEnd() {\n    return this.sourceBufferCount > 0 && !this.sourceBuffers.some(([type]) => {\n      if (type) {\n        const track = this.tracks[type];\n        if (track) {\n          return !track.ended || track.ending;\n        }\n      }\n      return false;\n    });\n  }\n\n  // on BUFFER_EOS mark matching sourcebuffer(s) as \"ending\" and \"ended\" and queue endOfStream after remaining operations(s)\n  // an undefined data.type will mark all buffers as EOS.\n  onBufferEos(event, data) {\n    var _this$overrides;\n    this.sourceBuffers.forEach(([type]) => {\n      if (type) {\n        const track = this.tracks[type];\n        if (!data.type || data.type === type) {\n          track.ending = true;\n          if (!track.ended) {\n            track.ended = true;\n            this.log(`${type} buffer reached EOS`);\n          }\n        }\n      }\n    });\n    const allowEndOfStream = ((_this$overrides = this.overrides) == null ? void 0 : _this$overrides.endOfStream) !== false;\n    const allTracksEnding = this.sourceBufferCount > 0 && !this.sourceBuffers.some(([type]) => {\n      var _this$tracks$type3;\n      return type && !((_this$tracks$type3 = this.tracks[type]) != null && _this$tracks$type3.ended);\n    });\n    if (allTracksEnding) {\n      if (allowEndOfStream) {\n        this.log(`Queueing EOS`);\n        this.blockUntilOpen(() => {\n          this.tracksEnded();\n          const {\n            mediaSource\n          } = this;\n          if (!mediaSource || mediaSource.readyState !== 'open') {\n            if (mediaSource) {\n              this.log(`Could not call mediaSource.endOfStream(). mediaSource.readyState: ${mediaSource.readyState}`);\n            }\n            return;\n          }\n          this.log(`Calling mediaSource.endOfStream()`);\n          // Allow this to throw and be caught by the enqueueing function\n          mediaSource.endOfStream();\n          this.hls.trigger(Events.BUFFERED_TO_END, undefined);\n        });\n      } else {\n        this.tracksEnded();\n        this.hls.trigger(Events.BUFFERED_TO_END, undefined);\n      }\n    } else if (data.type === 'video') {\n      // Make sure pending audio appends are unblocked when video reaches end\n      this.unblockAudio();\n    }\n  }\n  tracksEnded() {\n    this.sourceBuffers.forEach(([type]) => {\n      if (type !== null) {\n        const track = this.tracks[type];\n        if (track) {\n          track.ending = false;\n        }\n      }\n    });\n  }\n  onLevelUpdated(event, {\n    details\n  }) {\n    if (!details.fragments.length) {\n      return;\n    }\n    this.details = details;\n    this.updateDuration();\n  }\n  updateDuration() {\n    this.blockUntilOpen(() => {\n      const durationAndRange = this.getDurationAndRange();\n      if (!durationAndRange) {\n        return;\n      }\n      this.updateMediaSource(durationAndRange);\n    });\n  }\n  onError(event, data) {\n    if (data.details === ErrorDetails.BUFFER_APPEND_ERROR && data.frag) {\n      var _data$errorAction;\n      const nextAutoLevel = (_data$errorAction = data.errorAction) == null ? void 0 : _data$errorAction.nextAutoLevel;\n      if (isFiniteNumber(nextAutoLevel) && nextAutoLevel !== data.frag.level) {\n        this.resetAppendErrors();\n      }\n    }\n  }\n  resetAppendErrors() {\n    this.appendErrors = {\n      audio: 0,\n      video: 0,\n      audiovideo: 0\n    };\n  }\n  trimBuffers() {\n    const {\n      hls,\n      details,\n      media\n    } = this;\n    if (!media || details === null) {\n      return;\n    }\n    if (!this.sourceBufferCount) {\n      return;\n    }\n    const config = hls.config;\n    const currentTime = media.currentTime;\n    const targetDuration = details.levelTargetDuration;\n\n    // Support for deprecated liveBackBufferLength\n    const backBufferLength = details.live && config.liveBackBufferLength !== null ? config.liveBackBufferLength : config.backBufferLength;\n    if (isFiniteNumber(backBufferLength) && backBufferLength >= 0) {\n      const maxBackBufferLength = Math.max(backBufferLength, targetDuration);\n      const targetBackBufferPosition = Math.floor(currentTime / targetDuration) * targetDuration - maxBackBufferLength;\n      this.flushBackBuffer(currentTime, targetDuration, targetBackBufferPosition);\n    }\n    const frontBufferFlushThreshold = config.frontBufferFlushThreshold;\n    if (isFiniteNumber(frontBufferFlushThreshold) && frontBufferFlushThreshold > 0) {\n      const frontBufferLength = Math.max(config.maxBufferLength, frontBufferFlushThreshold);\n      const maxFrontBufferLength = Math.max(frontBufferLength, targetDuration);\n      const targetFrontBufferPosition = Math.floor(currentTime / targetDuration) * targetDuration + maxFrontBufferLength;\n      this.flushFrontBuffer(currentTime, targetDuration, targetFrontBufferPosition);\n    }\n  }\n  flushBackBuffer(currentTime, targetDuration, targetBackBufferPosition) {\n    this.sourceBuffers.forEach(([type, sb]) => {\n      if (sb) {\n        const buffered = BufferHelper.getBuffered(sb);\n        // when target buffer start exceeds actual buffer start\n        if (buffered.length > 0 && targetBackBufferPosition > buffered.start(0)) {\n          var _this$details;\n          this.hls.trigger(Events.BACK_BUFFER_REACHED, {\n            bufferEnd: targetBackBufferPosition\n          });\n\n          // Support for deprecated event:\n          const track = this.tracks[type];\n          if ((_this$details = this.details) != null && _this$details.live) {\n            this.hls.trigger(Events.LIVE_BACK_BUFFER_REACHED, {\n              bufferEnd: targetBackBufferPosition\n            });\n          } else if (track != null && track.ended) {\n            this.log(`Cannot flush ${type} back buffer while SourceBuffer is in ended state`);\n            return;\n          }\n          this.hls.trigger(Events.BUFFER_FLUSHING, {\n            startOffset: 0,\n            endOffset: targetBackBufferPosition,\n            type\n          });\n        }\n      }\n    });\n  }\n  flushFrontBuffer(currentTime, targetDuration, targetFrontBufferPosition) {\n    this.sourceBuffers.forEach(([type, sb]) => {\n      if (sb) {\n        const buffered = BufferHelper.getBuffered(sb);\n        const numBufferedRanges = buffered.length;\n        // The buffer is either empty or contiguous\n        if (numBufferedRanges < 2) {\n          return;\n        }\n        const bufferStart = buffered.start(numBufferedRanges - 1);\n        const bufferEnd = buffered.end(numBufferedRanges - 1);\n        // No flush if we can tolerate the current buffer length or the current buffer range we would flush is contiguous with current position\n        if (targetFrontBufferPosition > bufferStart || currentTime >= bufferStart && currentTime <= bufferEnd) {\n          return;\n        }\n        this.hls.trigger(Events.BUFFER_FLUSHING, {\n          startOffset: bufferStart,\n          endOffset: Infinity,\n          type\n        });\n      }\n    });\n  }\n\n  /**\n   * Update Media Source duration to current level duration or override to Infinity if configuration parameter\n   * 'liveDurationInfinity` is set to `true`\n   * More details: https://github.com/video-dev/hls.js/issues/355\n   */\n  getDurationAndRange() {\n    var _this$overrides2;\n    const {\n      details,\n      mediaSource\n    } = this;\n    if (!details || !this.media || (mediaSource == null ? void 0 : mediaSource.readyState) !== 'open') {\n      return null;\n    }\n    const playlistEnd = details.edge;\n    if (details.live && this.hls.config.liveDurationInfinity) {\n      const len = details.fragments.length;\n      if (len && !!mediaSource.setLiveSeekableRange) {\n        const start = Math.max(0, details.fragmentStart);\n        const end = Math.max(start, playlistEnd);\n        return {\n          duration: Infinity,\n          start,\n          end\n        };\n      }\n      return {\n        duration: Infinity\n      };\n    }\n    const overrideDuration = (_this$overrides2 = this.overrides) == null ? void 0 : _this$overrides2.duration;\n    if (overrideDuration) {\n      if (!isFiniteNumber(overrideDuration)) {\n        return null;\n      }\n      return {\n        duration: overrideDuration\n      };\n    }\n    const mediaDuration = this.media.duration;\n    const msDuration = isFiniteNumber(mediaSource.duration) ? mediaSource.duration : 0;\n    if (playlistEnd > msDuration && playlistEnd > mediaDuration || !isFiniteNumber(mediaDuration)) {\n      return {\n        duration: playlistEnd\n      };\n    }\n    return null;\n  }\n  updateMediaSource({\n    duration,\n    start,\n    end\n  }) {\n    const mediaSource = this.mediaSource;\n    if (!this.media || !mediaSource || mediaSource.readyState !== 'open') {\n      return;\n    }\n    if (mediaSource.duration !== duration) {\n      if (isFiniteNumber(duration)) {\n        this.log(`Updating MediaSource duration to ${duration.toFixed(3)}`);\n      }\n      mediaSource.duration = duration;\n    }\n    if (start !== undefined && end !== undefined) {\n      this.log(`MediaSource duration is set to ${mediaSource.duration}. Setting seekable range to ${start}-${end}.`);\n      mediaSource.setLiveSeekableRange(start, end);\n    }\n  }\n  get tracksReady() {\n    const pendingTrackCount = this.pendingTrackCount;\n    return pendingTrackCount > 0 && (pendingTrackCount >= this.bufferCodecEventsTotal || this.isPending(this.tracks.audiovideo));\n  }\n  checkPendingTracks() {\n    const {\n      bufferCodecEventsTotal,\n      pendingTrackCount,\n      tracks\n    } = this;\n    this.log(`checkPendingTracks (pending: ${pendingTrackCount} codec events expected: ${bufferCodecEventsTotal}) ${stringify(tracks)}`);\n    // Check if we've received all of the expected bufferCodec events. When none remain, create all the sourceBuffers at once.\n    // This is important because the MSE spec allows implementations to throw QuotaExceededErrors if creating new sourceBuffers after\n    // data has been appended to existing ones.\n    // 2 tracks is the max (one for audio, one for video). If we've reach this max go ahead and create the buffers.\n    if (this.tracksReady) {\n      var _this$transferData4;\n      const transferredTracks = (_this$transferData4 = this.transferData) == null ? void 0 : _this$transferData4.tracks;\n      if (transferredTracks && Object.keys(transferredTracks).length) {\n        this.attachTransferred();\n      } else {\n        // ok, let's create them now !\n        this.createSourceBuffers();\n      }\n    }\n  }\n  bufferCreated() {\n    if (this.sourceBufferCount) {\n      const tracks = {};\n      this.sourceBuffers.forEach(([type, buffer]) => {\n        if (type) {\n          const track = this.tracks[type];\n          tracks[type] = {\n            buffer,\n            container: track.container,\n            codec: track.codec,\n            supplemental: track.supplemental,\n            levelCodec: track.levelCodec,\n            id: track.id,\n            metadata: track.metadata\n          };\n        }\n      });\n      this.hls.trigger(Events.BUFFER_CREATED, {\n        tracks\n      });\n      this.log(`SourceBuffers created. Running queue: ${this.operationQueue}`);\n      this.sourceBuffers.forEach(([type]) => {\n        this.executeNext(type);\n      });\n    } else {\n      const error = new Error('could not create source buffer for media codec(s)');\n      this.hls.trigger(Events.ERROR, {\n        type: ErrorTypes.MEDIA_ERROR,\n        details: ErrorDetails.BUFFER_INCOMPATIBLE_CODECS_ERROR,\n        fatal: true,\n        error,\n        reason: error.message\n      });\n    }\n  }\n  createSourceBuffers() {\n    const {\n      tracks,\n      sourceBuffers,\n      mediaSource\n    } = this;\n    if (!mediaSource) {\n      throw new Error('createSourceBuffers called when mediaSource was null');\n    }\n    for (const trackName in tracks) {\n      const type = trackName;\n      const track = tracks[type];\n      if (this.isPending(track)) {\n        const codec = this.getTrackCodec(track, type);\n        const mimeType = `${track.container};codecs=${codec}`;\n        track.codec = codec;\n        this.log(`creating sourceBuffer(${mimeType})${this.currentOp(type) ? ' Queued' : ''} ${stringify(track)}`);\n        try {\n          const sb = mediaSource.addSourceBuffer(mimeType);\n          const sbIndex = sourceBufferNameToIndex(type);\n          const sbTuple = [type, sb];\n          sourceBuffers[sbIndex] = sbTuple;\n          track.buffer = sb;\n        } catch (error) {\n          var _this$operationQueue;\n          this.error(`error while trying to add sourceBuffer: ${error.message}`);\n          // remove init segment from queue and delete track info\n          this.shiftAndExecuteNext(type);\n          (_this$operationQueue = this.operationQueue) == null || _this$operationQueue.removeBlockers();\n          delete this.tracks[type];\n          this.hls.trigger(Events.ERROR, {\n            type: ErrorTypes.MEDIA_ERROR,\n            details: ErrorDetails.BUFFER_ADD_CODEC_ERROR,\n            fatal: false,\n            error,\n            sourceBufferName: type,\n            mimeType: mimeType,\n            parent: track.id\n          });\n          return;\n        }\n        this.trackSourceBuffer(type, track);\n      }\n    }\n    this.bufferCreated();\n  }\n  getTrackCodec(track, trackName) {\n    // Use supplemental video codec when supported when adding SourceBuffer (#5558)\n    const supplementalCodec = track.supplemental;\n    let trackCodec = track.codec;\n    if (supplementalCodec && (trackName === 'video' || trackName === 'audiovideo') && areCodecsMediaSourceSupported(supplementalCodec, 'video')) {\n      trackCodec = replaceVideoCodec(trackCodec, supplementalCodec);\n    }\n    const codec = pickMostCompleteCodecName(trackCodec, track.levelCodec);\n    if (codec) {\n      if (trackName.slice(0, 5) === 'audio') {\n        return getCodecCompatibleName(codec, this.appendSource);\n      }\n      return codec;\n    }\n    return '';\n  }\n  trackSourceBuffer(type, track) {\n    const buffer = track.buffer;\n    if (!buffer) {\n      return;\n    }\n    const codec = this.getTrackCodec(track, type);\n    this.tracks[type] = {\n      buffer,\n      codec,\n      container: track.container,\n      levelCodec: track.levelCodec,\n      supplemental: track.supplemental,\n      metadata: track.metadata,\n      id: track.id,\n      listeners: []\n    };\n    this.removeBufferListeners(type);\n    this.addBufferListener(type, 'updatestart', this.onSBUpdateStart);\n    this.addBufferListener(type, 'updateend', this.onSBUpdateEnd);\n    this.addBufferListener(type, 'error', this.onSBUpdateError);\n    // ManagedSourceBuffer bufferedchange event\n    if (this.appendSource) {\n      this.addBufferListener(type, 'bufferedchange', (type, event) => {\n        // If media was ejected check for a change. Added ranges are redundant with changes on 'updateend' event.\n        const removedRanges = event.removedRanges;\n        if (removedRanges != null && removedRanges.length) {\n          this.hls.trigger(Events.BUFFER_FLUSHED, {\n            type: type\n          });\n        }\n      });\n    }\n  }\n  get mediaSrc() {\n    var _this$media2, _this$media2$querySel;\n    const media = ((_this$media2 = this.media) == null || (_this$media2$querySel = _this$media2.querySelector) == null ? void 0 : _this$media2$querySel.call(_this$media2, 'source')) || this.media;\n    return media == null ? void 0 : media.src;\n  }\n  onSBUpdateStart(type) {\n    const operation = this.currentOp(type);\n    if (!operation) {\n      return;\n    }\n    operation.onStart();\n  }\n  onSBUpdateEnd(type) {\n    var _this$mediaSource4;\n    if (((_this$mediaSource4 = this.mediaSource) == null ? void 0 : _this$mediaSource4.readyState) === 'closed') {\n      this.resetBuffer(type);\n      return;\n    }\n    const operation = this.currentOp(type);\n    if (!operation) {\n      return;\n    }\n    operation.onComplete();\n    this.shiftAndExecuteNext(type);\n  }\n  onSBUpdateError(type, event) {\n    var _this$mediaSource5;\n    const error = new Error(`${type} SourceBuffer error. MediaSource readyState: ${(_this$mediaSource5 = this.mediaSource) == null ? void 0 : _this$mediaSource5.readyState}`);\n    this.error(`${error}`, event);\n    // according to http://www.w3.org/TR/media-source/#sourcebuffer-append-error\n    // SourceBuffer errors are not necessarily fatal; if so, the HTMLMediaElement will fire an error event\n    this.hls.trigger(Events.ERROR, {\n      type: ErrorTypes.MEDIA_ERROR,\n      details: ErrorDetails.BUFFER_APPENDING_ERROR,\n      sourceBufferName: type,\n      error,\n      fatal: false\n    });\n    // updateend is always fired after error, so we'll allow that to shift the current operation off of the queue\n    const operation = this.currentOp(type);\n    if (operation) {\n      operation.onError(error);\n    }\n  }\n  updateTimestampOffset(sb, timestampOffset, tolerance, type, sn, cc) {\n    const delta = timestampOffset - sb.timestampOffset;\n    if (Math.abs(delta) >= tolerance) {\n      this.log(`Updating ${type} SourceBuffer timestampOffset to ${timestampOffset} (sn: ${sn} cc: ${cc})`);\n      sb.timestampOffset = timestampOffset;\n    }\n  }\n\n  // This method must result in an updateend event; if remove is not called, onSBUpdateEnd must be called manually\n  removeExecutor(type, startOffset, endOffset) {\n    const {\n      media,\n      mediaSource\n    } = this;\n    const track = this.tracks[type];\n    const sb = track == null ? void 0 : track.buffer;\n    if (!media || !mediaSource || !sb) {\n      this.warn(`Attempting to remove from the ${type} SourceBuffer, but it does not exist`);\n      this.shiftAndExecuteNext(type);\n      return;\n    }\n    const mediaDuration = isFiniteNumber(media.duration) ? media.duration : Infinity;\n    const msDuration = isFiniteNumber(mediaSource.duration) ? mediaSource.duration : Infinity;\n    const removeStart = Math.max(0, startOffset);\n    const removeEnd = Math.min(endOffset, mediaDuration, msDuration);\n    if (removeEnd > removeStart && (!track.ending || track.ended)) {\n      track.ended = false;\n      this.log(`Removing [${removeStart},${removeEnd}] from the ${type} SourceBuffer`);\n      sb.remove(removeStart, removeEnd);\n    } else {\n      // Cycle the queue\n      this.shiftAndExecuteNext(type);\n    }\n  }\n\n  // This method must result in an updateend event; if append is not called, onSBUpdateEnd must be called manually\n  appendExecutor(data, type) {\n    const track = this.tracks[type];\n    const sb = track == null ? void 0 : track.buffer;\n    if (!sb) {\n      throw new HlsJsTrackRemovedError(`Attempting to append to the ${type} SourceBuffer, but it does not exist`);\n    }\n    track.ending = false;\n    track.ended = false;\n    sb.appendBuffer(data);\n  }\n  blockUntilOpen(callback) {\n    if (this.isUpdating() || this.isQueued()) {\n      this.blockBuffers(callback).catch(error => {\n        this.warn(`SourceBuffer blocked callback ${error}`);\n        this.stepOperationQueue(this.sourceBufferTypes);\n      });\n    } else {\n      try {\n        callback();\n      } catch (error) {\n        this.warn(`Callback run without blocking ${this.operationQueue} ${error}`);\n      }\n    }\n  }\n  isUpdating() {\n    return this.sourceBuffers.some(([type, sb]) => type && sb.updating);\n  }\n  isQueued() {\n    return this.sourceBuffers.some(([type]) => type && !!this.currentOp(type));\n  }\n  isPending(track) {\n    return !!track && !track.buffer;\n  }\n\n  // Enqueues an operation to each SourceBuffer queue which, upon execution, resolves a promise. When all promises\n  // resolve, the onUnblocked function is executed. Functions calling this method do not need to unblock the queue\n  // upon completion, since we already do it here\n  blockBuffers(onUnblocked, bufferNames = this.sourceBufferTypes) {\n    if (!bufferNames.length) {\n      this.log('Blocking operation requested, but no SourceBuffers exist');\n      return Promise.resolve().then(onUnblocked);\n    }\n    const {\n      operationQueue\n    } = this;\n\n    // logger.debug(`[buffer-controller]: Blocking ${buffers} SourceBuffer`);\n    const blockingOperations = bufferNames.map(type => this.appendBlocker(type));\n    const audioBlocked = bufferNames.length > 1 && !!this.blockedAudioAppend;\n    if (audioBlocked) {\n      this.unblockAudio();\n    }\n    return Promise.all(blockingOperations).then(result => {\n      if (operationQueue !== this.operationQueue) {\n        return;\n      }\n      // logger.debug(`[buffer-controller]: Blocking operation resolved; unblocking ${buffers} SourceBuffer`);\n      onUnblocked();\n      this.stepOperationQueue(this.sourceBufferTypes);\n    });\n  }\n  stepOperationQueue(bufferNames) {\n    bufferNames.forEach(type => {\n      var _this$tracks$type4;\n      const sb = (_this$tracks$type4 = this.tracks[type]) == null ? void 0 : _this$tracks$type4.buffer;\n      // Only cycle the queue if the SB is not updating. There's a bug in Chrome which sets the SB updating flag to\n      // true when changing the MediaSource duration (https://bugs.chromium.org/p/chromium/issues/detail?id=959359&can=2&q=mediasource%20duration)\n      // While this is a workaround, it's probably useful to have around\n      if (!sb || sb.updating) {\n        return;\n      }\n      this.shiftAndExecuteNext(type);\n    });\n  }\n  append(operation, type, pending) {\n    if (this.operationQueue) {\n      this.operationQueue.append(operation, type, pending);\n    }\n  }\n  appendBlocker(type) {\n    if (this.operationQueue) {\n      return this.operationQueue.appendBlocker(type);\n    }\n  }\n  currentOp(type) {\n    if (this.operationQueue) {\n      return this.operationQueue.current(type);\n    }\n    return null;\n  }\n  executeNext(type) {\n    if (type && this.operationQueue) {\n      this.operationQueue.executeNext(type);\n    }\n  }\n  shiftAndExecuteNext(type) {\n    if (this.operationQueue) {\n      this.operationQueue.shiftAndExecuteNext(type);\n    }\n  }\n  get pendingTrackCount() {\n    return Object.keys(this.tracks).reduce((acc, type) => acc + (this.isPending(this.tracks[type]) ? 1 : 0), 0);\n  }\n  get sourceBufferCount() {\n    return this.sourceBuffers.reduce((acc, [type]) => acc + (type ? 1 : 0), 0);\n  }\n  get sourceBufferTypes() {\n    return this.sourceBuffers.map(([type]) => type).filter(type => !!type);\n  }\n  addBufferListener(type, event, fn) {\n    const track = this.tracks[type];\n    if (!track) {\n      return;\n    }\n    const buffer = track.buffer;\n    if (!buffer) {\n      return;\n    }\n    const listener = fn.bind(this, type);\n    track.listeners.push({\n      event,\n      listener\n    });\n    buffer.addEventListener(event, listener);\n  }\n  removeBufferListeners(type) {\n    const track = this.tracks[type];\n    if (!track) {\n      return;\n    }\n    const buffer = track.buffer;\n    if (!buffer) {\n      return;\n    }\n    track.listeners.forEach(l => {\n      buffer.removeEventListener(l.event, l.listener);\n    });\n    track.listeners.length = 0;\n  }\n}\nfunction removeSourceChildren(node) {\n  const sourceChildren = node.querySelectorAll('source');\n  [].slice.call(sourceChildren).forEach(source => {\n    node.removeChild(source);\n  });\n}\nfunction addSource(media, url) {\n  const source = self.document.createElement('source');\n  source.type = 'video/mp4';\n  source.src = url;\n  media.appendChild(source);\n}\nfunction sourceBufferNameToIndex(type) {\n  return type === 'audio' ? 1 : 0;\n}\n\nclass CapLevelController {\n  constructor(hls) {\n    this.hls = void 0;\n    this.autoLevelCapping = void 0;\n    this.firstLevel = void 0;\n    this.media = void 0;\n    this.restrictedLevels = void 0;\n    this.timer = void 0;\n    this.clientRect = void 0;\n    this.streamController = void 0;\n    this.hls = hls;\n    this.autoLevelCapping = Number.POSITIVE_INFINITY;\n    this.firstLevel = -1;\n    this.media = null;\n    this.restrictedLevels = [];\n    this.timer = undefined;\n    this.clientRect = null;\n    this.registerListeners();\n  }\n  setStreamController(streamController) {\n    this.streamController = streamController;\n  }\n  destroy() {\n    if (this.hls) {\n      this.unregisterListener();\n    }\n    if (this.timer) {\n      this.stopCapping();\n    }\n    this.media = null;\n    this.clientRect = null;\n    // @ts-ignore\n    this.hls = this.streamController = null;\n  }\n  registerListeners() {\n    const {\n      hls\n    } = this;\n    hls.on(Events.FPS_DROP_LEVEL_CAPPING, this.onFpsDropLevelCapping, this);\n    hls.on(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);\n    hls.on(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n    hls.on(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);\n    hls.on(Events.BUFFER_CODECS, this.onBufferCodecs, this);\n    hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n  }\n  unregisterListener() {\n    const {\n      hls\n    } = this;\n    hls.off(Events.FPS_DROP_LEVEL_CAPPING, this.onFpsDropLevelCapping, this);\n    hls.off(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);\n    hls.off(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n    hls.off(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);\n    hls.off(Events.BUFFER_CODECS, this.onBufferCodecs, this);\n    hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n  }\n  onFpsDropLevelCapping(event, data) {\n    // Don't add a restricted level more than once\n    const level = this.hls.levels[data.droppedLevel];\n    if (this.isLevelAllowed(level)) {\n      this.restrictedLevels.push({\n        bitrate: level.bitrate,\n        height: level.height,\n        width: level.width\n      });\n    }\n  }\n  onMediaAttaching(event, data) {\n    this.media = data.media instanceof HTMLVideoElement ? data.media : null;\n    this.clientRect = null;\n    if (this.timer && this.hls.levels.length) {\n      this.detectPlayerSize();\n    }\n  }\n  onManifestParsed(event, data) {\n    const hls = this.hls;\n    this.restrictedLevels = [];\n    this.firstLevel = data.firstLevel;\n    if (hls.config.capLevelToPlayerSize && data.video) {\n      // Start capping immediately if the manifest has signaled video codecs\n      this.startCapping();\n    }\n  }\n  onLevelsUpdated(event, data) {\n    if (this.timer && isFiniteNumber(this.autoLevelCapping)) {\n      this.detectPlayerSize();\n    }\n  }\n\n  // Only activate capping when playing a video stream; otherwise, multi-bitrate audio-only streams will be restricted\n  // to the first level\n  onBufferCodecs(event, data) {\n    const hls = this.hls;\n    if (hls.config.capLevelToPlayerSize && data.video) {\n      // If the manifest did not signal a video codec capping has been deferred until we're certain video is present\n      this.startCapping();\n    }\n  }\n  onMediaDetaching() {\n    this.stopCapping();\n    this.media = null;\n  }\n  detectPlayerSize() {\n    if (this.media) {\n      if (this.mediaHeight <= 0 || this.mediaWidth <= 0) {\n        this.clientRect = null;\n        return;\n      }\n      const levels = this.hls.levels;\n      if (levels.length) {\n        const hls = this.hls;\n        const maxLevel = this.getMaxLevel(levels.length - 1);\n        if (maxLevel !== this.autoLevelCapping) {\n          hls.logger.log(`Setting autoLevelCapping to ${maxLevel}: ${levels[maxLevel].height}p@${levels[maxLevel].bitrate} for media ${this.mediaWidth}x${this.mediaHeight}`);\n        }\n        hls.autoLevelCapping = maxLevel;\n        if (hls.autoLevelEnabled && hls.autoLevelCapping > this.autoLevelCapping && this.streamController) {\n          // if auto level capping has a higher value for the previous one, flush the buffer using nextLevelSwitch\n          // usually happen when the user go to the fullscreen mode.\n          this.streamController.nextLevelSwitch();\n        }\n        this.autoLevelCapping = hls.autoLevelCapping;\n      }\n    }\n  }\n\n  /*\n   * returns level should be the one with the dimensions equal or greater than the media (player) dimensions (so the video will be downscaled)\n   */\n  getMaxLevel(capLevelIndex) {\n    const levels = this.hls.levels;\n    if (!levels.length) {\n      return -1;\n    }\n    const validLevels = levels.filter((level, index) => this.isLevelAllowed(level) && index <= capLevelIndex);\n    this.clientRect = null;\n    return CapLevelController.getMaxLevelByMediaSize(validLevels, this.mediaWidth, this.mediaHeight);\n  }\n  startCapping() {\n    if (this.timer) {\n      // Don't reset capping if started twice; this can happen if the manifest signals a video codec\n      return;\n    }\n    this.autoLevelCapping = Number.POSITIVE_INFINITY;\n    self.clearInterval(this.timer);\n    this.timer = self.setInterval(this.detectPlayerSize.bind(this), 1000);\n    this.detectPlayerSize();\n  }\n  stopCapping() {\n    this.restrictedLevels = [];\n    this.firstLevel = -1;\n    this.autoLevelCapping = Number.POSITIVE_INFINITY;\n    if (this.timer) {\n      self.clearInterval(this.timer);\n      this.timer = undefined;\n    }\n  }\n  getDimensions() {\n    if (this.clientRect) {\n      return this.clientRect;\n    }\n    const media = this.media;\n    const boundsRect = {\n      width: 0,\n      height: 0\n    };\n    if (media) {\n      const clientRect = media.getBoundingClientRect();\n      boundsRect.width = clientRect.width;\n      boundsRect.height = clientRect.height;\n      if (!boundsRect.width && !boundsRect.height) {\n        // When the media element has no width or height (equivalent to not being in the DOM),\n        // then use its width and height attributes (media.width, media.height)\n        boundsRect.width = clientRect.right - clientRect.left || media.width || 0;\n        boundsRect.height = clientRect.bottom - clientRect.top || media.height || 0;\n      }\n    }\n    this.clientRect = boundsRect;\n    return boundsRect;\n  }\n  get mediaWidth() {\n    return this.getDimensions().width * this.contentScaleFactor;\n  }\n  get mediaHeight() {\n    return this.getDimensions().height * this.contentScaleFactor;\n  }\n  get contentScaleFactor() {\n    let pixelRatio = 1;\n    if (!this.hls.config.ignoreDevicePixelRatio) {\n      try {\n        pixelRatio = self.devicePixelRatio;\n      } catch (e) {\n        /* no-op */\n      }\n    }\n    return Math.min(pixelRatio, this.hls.config.maxDevicePixelRatio);\n  }\n  isLevelAllowed(level) {\n    const restrictedLevels = this.restrictedLevels;\n    return !restrictedLevels.some(restrictedLevel => {\n      return level.bitrate === restrictedLevel.bitrate && level.width === restrictedLevel.width && level.height === restrictedLevel.height;\n    });\n  }\n  static getMaxLevelByMediaSize(levels, width, height) {\n    if (!(levels != null && levels.length)) {\n      return -1;\n    }\n\n    // Levels can have the same dimensions but differing bandwidths - since levels are ordered, we can look to the next\n    // to determine whether we've chosen the greatest bandwidth for the media's dimensions\n    const atGreatestBandwidth = (curLevel, nextLevel) => {\n      if (!nextLevel) {\n        return true;\n      }\n      return curLevel.width !== nextLevel.width || curLevel.height !== nextLevel.height;\n    };\n\n    // If we run through the loop without breaking, the media's dimensions are greater than every level, so default to\n    // the max level\n    let maxLevelIndex = levels.length - 1;\n    // Prevent changes in aspect-ratio from causing capping to toggle back and forth\n    const squareSize = Math.max(width, height);\n    for (let i = 0; i < levels.length; i += 1) {\n      const level = levels[i];\n      if ((level.width >= squareSize || level.height >= squareSize) && atGreatestBandwidth(level, levels[i + 1])) {\n        maxLevelIndex = i;\n        break;\n      }\n    }\n    return maxLevelIndex;\n  }\n}\n\n/**\n * Common Media Object Type\n *\n * @internal\n */\nconst CmObjectType = {\n  /**\n   * text file, such as a manifest or playlist\n   */\n  MANIFEST: 'm',\n  /**\n   * audio only\n   */\n  AUDIO: 'a',\n  /**\n   * video only\n   */\n  VIDEO: 'v',\n  /**\n   * muxed audio and video\n   */\n  MUXED: 'av',\n  /**\n   * init segment\n   */\n  INIT: 'i',\n  /**\n   * caption or subtitle\n   */\n  CAPTION: 'c',\n  /**\n   * ISOBMFF timed text track\n   */\n  TIMED_TEXT: 'tt',\n  /**\n   * cryptographic key, license or certificate.\n   */\n  KEY: 'k',\n  /**\n   * other\n   */\n  OTHER: 'o'\n};\n\n/**\n * Common Media Client Data Object Type\n *\n * @group CMCD\n *\n * @beta\n *\n * @enum\n */\nconst CmcdObjectType = CmObjectType;\n\n/**\n * Common Media Streaming Format\n *\n * @internal\n */\nconst CmStreamingFormat = {\n  /**\n   * HTTP Live Streaming (HLS)\n   */\n  HLS: 'h'};\n\n/**\n * Common Media Client Data Streaming Format\n *\n * @group CMCD\n *\n * @enum\n *\n * @beta\n */\nconst CmcdStreamingFormat = CmStreamingFormat;\n\n/**\n * Structured Field Item\n *\n * @group Structured Field\n *\n * @beta\n */\nclass SfItem {\n  constructor(value, params) {\n    if (Array.isArray(value)) {\n      value = value.map(v => v instanceof SfItem ? v : new SfItem(v));\n    }\n    this.value = value;\n    this.params = params;\n  }\n}\n\nconst DICT = 'Dict';\n\nfunction format(value) {\n  if (Array.isArray(value)) {\n    return JSON.stringify(value);\n  }\n  if (value instanceof Map) {\n    return 'Map{}';\n  }\n  if (value instanceof Set) {\n    return 'Set{}';\n  }\n  if (typeof value === 'object') {\n    return JSON.stringify(value);\n  }\n  return String(value);\n}\nfunction throwError(action, src, type, cause) {\n  return new Error(`failed to ${action} \"${format(src)}\" as ${type}`, {\n    cause\n  });\n}\n\nfunction serializeError(src, type, cause) {\n  return throwError('serialize', src, type, cause);\n}\n\n/**\n * A class to represent structured field tokens when `Symbol` is not available.\n *\n * @group Structured Field\n *\n * @beta\n */\nclass SfToken {\n  constructor(description) {\n    this.description = description;\n  }\n}\n\nconst BARE_ITEM = 'Bare Item';\n\nconst BOOLEAN = 'Boolean';\n\n// 4.1.9.  Serializing a Boolean\n//\n// Given a Boolean as input_boolean, return an ASCII string suitable for\n// use in a HTTP field value.\n//\n// 1.  If input_boolean is not a boolean, fail serialization.\n//\n// 2.  Let output be an empty string.\n//\n// 3.  Append \"?\" to output.\n//\n// 4.  If input_boolean is true, append \"1\" to output.\n//\n// 5.  If input_boolean is false, append \"0\" to output.\n//\n// 6.  Return output.\nfunction serializeBoolean(value) {\n  if (typeof value !== 'boolean') {\n    throw serializeError(value, BOOLEAN);\n  }\n  return value ? '?1' : '?0';\n}\n\n/**\n * Encodes binary data to base64\n *\n * @param binary - The binary data to encode\n * @returns The base64 encoded string\n *\n * @group Utils\n *\n * @beta\n */\nfunction encodeBase64(binary) {\n  return btoa(String.fromCharCode(...binary));\n}\n\nconst BYTES = 'Byte Sequence';\n\n// 4.1.8.  Serializing a Byte Sequence\n//\n// Given a Byte Sequence as input_bytes, return an ASCII string suitable\n// for use in a HTTP field value.\n//\n// 1.  If input_bytes is not a sequence of bytes, fail serialization.\n//\n// 2.  Let output be an empty string.\n//\n// 3.  Append \":\" to output.\n//\n// 4.  Append the result of base64-encoding input_bytes as per\n//     [RFC4648], Section 4, taking account of the requirements below.\n//\n// 5.  Append \":\" to output.\n//\n// 6.  Return output.\n//\n// The encoded data is required to be padded with \"=\", as per [RFC4648],\n// Section 3.2.\n//\n// Likewise, encoded data SHOULD have pad bits set to zero, as per\n// [RFC4648], Section 3.5, unless it is not possible to do so due to\n// implementation constraints.\nfunction serializeByteSequence(value) {\n  if (ArrayBuffer.isView(value) === false) {\n    throw serializeError(value, BYTES);\n  }\n  return `:${encodeBase64(value)}:`;\n}\n\nconst INTEGER = 'Integer';\n\nfunction isInvalidInt(value) {\n  return value < -999999999999999 || 999999999999999 < value;\n}\n\n// 4.1.4.  Serializing an Integer\n//\n// Given an Integer as input_integer, return an ASCII string suitable\n// for use in a HTTP field value.\n//\n// 1.  If input_integer is not an integer in the range of\n//     -999,999,999,999,999 to 999,999,999,999,999 inclusive, fail\n//     serialization.\n//\n// 2.  Let output be an empty string.\n//\n// 3.  If input_integer is less than (but not equal to) 0, append \"-\" to\n//     output.\n//\n// 4.  Append input_integer's numeric value represented in base 10 using\n//     only decimal digits to output.\n//\n// 5.  Return output.\nfunction serializeInteger(value) {\n  if (isInvalidInt(value)) {\n    throw serializeError(value, INTEGER);\n  }\n  return value.toString();\n}\n\n// 4.1.10.  Serializing a Date\n//\n// Given a Date as input_integer, return an ASCII string suitable for\n// use in an HTTP field value.\n// 1.  Let output be \"@\".\n// 2.  Append to output the result of running Serializing an Integer\n//     with input_date (Section 4.1.4).\n// 3.  Return output.\nfunction serializeDate(value) {\n  return `@${serializeInteger(value.getTime() / 1000)}`;\n}\n\n/**\n * This implements the rounding procedure described in step 2 of the \"Serializing a Decimal\" specification.\n * This rounding style is known as \"even rounding\", \"banker's rounding\", or \"commercial rounding\".\n *\n * @param value - The value to round\n * @param precision - The number of decimal places to round to\n * @returns The rounded value\n *\n * @group Utils\n *\n * @beta\n */\nfunction roundToEven(value, precision) {\n  if (value < 0) {\n    return -roundToEven(-value, precision);\n  }\n  const decimalShift = Math.pow(10, precision);\n  const isEquidistant = Math.abs(value * decimalShift % 1 - 0.5) < Number.EPSILON;\n  if (isEquidistant) {\n    // If the tail of the decimal place is 'equidistant' we round to the nearest even value\n    const flooredValue = Math.floor(value * decimalShift);\n    return (flooredValue % 2 === 0 ? flooredValue : flooredValue + 1) / decimalShift;\n  } else {\n    // Otherwise, proceed as normal\n    return Math.round(value * decimalShift) / decimalShift;\n  }\n}\n\nconst DECIMAL = 'Decimal';\n\n// 4.1.5.  Serializing a Decimal\n//\n// Given a decimal number as input_decimal, return an ASCII string\n// suitable for use in a HTTP field value.\n//\n// 1.   If input_decimal is not a decimal number, fail serialization.\n//\n// 2.   If input_decimal has more than three significant digits to the\n//      right of the decimal point, round it to three decimal places,\n//      rounding the final digit to the nearest value, or to the even\n//      value if it is equidistant.\n//\n// 3.   If input_decimal has more than 12 significant digits to the left\n//      of the decimal point after rounding, fail serialization.\n//\n// 4.   Let output be an empty string.\n//\n// 5.   If input_decimal is less than (but not equal to) 0, append \"-\"\n//      to output.\n//\n// 6.   Append input_decimal's integer component represented in base 10\n//      (using only decimal digits) to output; if it is zero, append\n//      \"0\".\n//\n// 7.   Append \".\" to output.\n//\n// 8.   If input_decimal's fractional component is zero, append \"0\" to\n//      output.\n//\n// 9.   Otherwise, append the significant digits of input_decimal's\n//      fractional component represented in base 10 (using only decimal\n//      digits) to output.\n//\n// 10.  Return output.\nfunction serializeDecimal(value) {\n  const roundedValue = roundToEven(value, 3); // round to 3 decimal places\n  if (Math.floor(Math.abs(roundedValue)).toString().length > 12) {\n    throw serializeError(value, DECIMAL);\n  }\n  const stringValue = roundedValue.toString();\n  return stringValue.includes('.') ? stringValue : `${stringValue}.0`;\n}\n\nconst STRING = 'String';\n\nconst STRING_REGEX = /[\\x00-\\x1f\\x7f]+/;\n\n// 4.1.6.  Serializing a String\n//\n// Given a String as input_string, return an ASCII string suitable for\n// use in a HTTP field value.\n//\n// 1.  Convert input_string into a sequence of ASCII characters; if\n//     conversion fails, fail serialization.\n//\n// 2.  If input_string contains characters in the range %x00-1f or %x7f\n//     (i.e., not in VCHAR or SP), fail serialization.\n//\n// 3.  Let output be the string DQUOTE.\n//\n// 4.  For each character char in input_string:\n//\n//     1.  If char is \"\\\" or DQUOTE:\n//\n//         1.  Append \"\\\" to output.\n//\n//     2.  Append char to output.\n//\n// 5.  Append DQUOTE to output.\n//\n// 6.  Return output.\nfunction serializeString(value) {\n  if (STRING_REGEX.test(value)) {\n    throw serializeError(value, STRING);\n  }\n  return `\"${value.replace(/\\\\/g, `\\\\\\\\`).replace(/\"/g, `\\\\\"`)}\"`;\n}\n\n/**\n * Converts a symbol to a string.\n *\n * @param symbol - The symbol to convert.\n *\n * @returns The string representation of the symbol.\n *\n * @internal\n */\nfunction symbolToStr(symbol) {\n  return symbol.description || symbol.toString().slice(7, -1);\n}\n\nconst TOKEN = 'Token';\n\nfunction serializeToken(token) {\n  const value = symbolToStr(token);\n  if (/^([a-zA-Z*])([!#$%&'*+\\-.^_`|~\\w:/]*)$/.test(value) === false) {\n    throw serializeError(value, TOKEN);\n  }\n  return value;\n}\n\n// 4.1.3.1.  Serializing a Bare Item\n//\n// Given an Item as input_item, return an ASCII string suitable for use\n// in a HTTP field value.\n//\n// 1.  If input_item is an Integer, return the result of running\n//     Serializing an Integer (Section 4.1.4) with input_item.\n//\n// 2.  If input_item is a Decimal, return the result of running\n//     Serializing a Decimal (Section 4.1.5) with input_item.\n//\n// 3.  If input_item is a String, return the result of running\n//     Serializing a String (Section 4.1.6) with input_item.\n//\n// 4.  If input_item is a Token, return the result of running\n//     Serializing a Token (Section 4.1.7) with input_item.\n//\n// 5.  If input_item is a Boolean, return the result of running\n//     Serializing a Boolean (Section 4.1.9) with input_item.\n//\n// 6.  If input_item is a Byte Sequence, return the result of running\n//     Serializing a Byte Sequence (Section 4.1.8) with input_item.\n//\n// 7.  If input_item is a Date, return the result of running Serializing\n//     a Date (Section 4.1.10) with input_item.\n//\n// 8.  Otherwise, fail serialization.\nfunction serializeBareItem(value) {\n  switch (typeof value) {\n    case 'number':\n      if (!isFiniteNumber(value)) {\n        throw serializeError(value, BARE_ITEM);\n      }\n      if (Number.isInteger(value)) {\n        return serializeInteger(value);\n      }\n      return serializeDecimal(value);\n    case 'string':\n      return serializeString(value);\n    case 'symbol':\n      return serializeToken(value);\n    case 'boolean':\n      return serializeBoolean(value);\n    case 'object':\n      if (value instanceof Date) {\n        return serializeDate(value);\n      }\n      if (value instanceof Uint8Array) {\n        return serializeByteSequence(value);\n      }\n      if (value instanceof SfToken) {\n        return serializeToken(value);\n      }\n    default:\n      // fail\n      throw serializeError(value, BARE_ITEM);\n  }\n}\n\nconst KEY = 'Key';\n\n// 4.1.1.3.  Serializing a Key\n//\n// Given a key as input_key, return an ASCII string suitable for use in\n// a HTTP field value.\n//\n// 1.  Convert input_key into a sequence of ASCII characters; if\n//     conversion fails, fail serialization.\n//\n// 2.  If input_key contains characters not in lcalpha, DIGIT, \"_\", \"-\",\n//     \".\", or \"*\" fail serialization.\n//\n// 3.  If the first character of input_key is not lcalpha or \"*\", fail\n//     serialization.\n//\n// 4.  Let output be an empty string.\n//\n// 5.  Append input_key to output.\n//\n// 6.  Return output.\nfunction serializeKey(value) {\n  if (/^[a-z*][a-z0-9\\-_.*]*$/.test(value) === false) {\n    throw serializeError(value, KEY);\n  }\n  return value;\n}\n\n// 4.1.1.2.  Serializing Parameters\n//\n// Given an ordered Dictionary as input_parameters (each member having a\n// param_name and a param_value), return an ASCII string suitable for\n// use in a HTTP field value.\n//\n// 1.  Let output be an empty string.\n//\n// 2.  For each param_name with a value of param_value in\n//     input_parameters:\n//\n//     1.  Append \";\" to output.\n//\n//     2.  Append the result of running Serializing a Key\n//         (Section 4.1.1.3) with param_name to output.\n//\n//     3.  If param_value is not Boolean true:\n//\n//         1.  Append \"=\" to output.\n//\n//         2.  Append the result of running Serializing a bare Item\n//             (Section 4.1.3.1) with param_value to output.\n//\n// 3.  Return output.\nfunction serializeParams(params) {\n  if (params == null) {\n    return '';\n  }\n  return Object.entries(params).map(([key, value]) => {\n    if (value === true) {\n      return `;${serializeKey(key)}`; // omit true\n    }\n    return `;${serializeKey(key)}=${serializeBareItem(value)}`;\n  }).join('');\n}\n\n// 4.1.3.  Serializing an Item\n//\n// Given an Item as bare_item and Parameters as item_parameters, return\n// an ASCII string suitable for use in a HTTP field value.\n//\n// 1.  Let output be an empty string.\n//\n// 2.  Append the result of running Serializing a Bare Item\n//     Section 4.1.3.1 with bare_item to output.\n//\n// 3.  Append the result of running Serializing Parameters\n//     Section 4.1.1.2 with item_parameters to output.\n//\n// 4.  Return output.\nfunction serializeItem(value) {\n  if (value instanceof SfItem) {\n    return `${serializeBareItem(value.value)}${serializeParams(value.params)}`;\n  } else {\n    return serializeBareItem(value);\n  }\n}\n\n// 4.1.1.1.  Serializing an Inner List\n//\n// Given an array of (member_value, parameters) tuples as inner_list,\n// and parameters as list_parameters, return an ASCII string suitable\n// for use in a HTTP field value.\n//\n// 1.  Let output be the string \"(\".\n//\n// 2.  For each (member_value, parameters) of inner_list:\n//\n//     1.  Append the result of running Serializing an Item\n//         (Section 4.1.3) with (member_value, parameters) to output.\n//\n//     2.  If more values remain in inner_list, append a single SP to\n//         output.\n//\n// 3.  Append \")\" to output.\n//\n// 4.  Append the result of running Serializing Parameters\n//     (Section 4.1.1.2) with list_parameters to output.\n//\n// 5.  Return output.\nfunction serializeInnerList(value) {\n  return `(${value.value.map(serializeItem).join(' ')})${serializeParams(value.params)}`;\n}\n\n// 4.1.2.  Serializing a Dictionary\n//\n// Given an ordered Dictionary as input_dictionary (each member having a\n// member_name and a tuple value of (member_value, parameters)), return\n// an ASCII string suitable for use in a HTTP field value.\n//\n// 1.  Let output be an empty string.\n//\n// 2.  For each member_name with a value of (member_value, parameters)\n//     in input_dictionary:\n//\n//     1.  Append the result of running Serializing a Key\n//         (Section 4.1.1.3) with member's member_name to output.\n//\n//     2.  If member_value is Boolean true:\n//\n//         1.  Append the result of running Serializing Parameters\n//             (Section 4.1.1.2) with parameters to output.\n//\n//     3.  Otherwise:\n//\n//         1.  Append \"=\" to output.\n//\n//         2.  If member_value is an array, append the result of running\n//             Serializing an Inner List (Section 4.1.1.1) with\n//             (member_value, parameters) to output.\n//\n//         3.  Otherwise, append the result of running Serializing an\n//             Item (Section 4.1.3) with (member_value, parameters) to\n//             output.\n//\n//     4.  If more members remain in input_dictionary:\n//\n//         1.  Append \",\" to output.\n//\n//         2.  Append a single SP to output.\n//\n// 3.  Return output.\nfunction serializeDict(dict, options = {\n  whitespace: true\n}) {\n  if (typeof dict !== 'object' || dict == null) {\n    throw serializeError(dict, DICT);\n  }\n  const entries = dict instanceof Map ? dict.entries() : Object.entries(dict);\n  const optionalWhiteSpace = (options === null || options === void 0 ? void 0 : options.whitespace) ? ' ' : '';\n  return Array.from(entries).map(([key, item]) => {\n    if (item instanceof SfItem === false) {\n      item = new SfItem(item);\n    }\n    let output = serializeKey(key);\n    if (item.value === true) {\n      output += serializeParams(item.params);\n    } else {\n      output += '=';\n      if (Array.isArray(item.value)) {\n        output += serializeInnerList(item);\n      } else {\n        output += serializeItem(item);\n      }\n    }\n    return output;\n  }).join(`,${optionalWhiteSpace}`);\n}\n\n/**\n * Encode an object into a structured field dictionary\n *\n * @param value - The structured field dictionary to encode\n * @param options - Encoding options\n *\n * @returns The structured field string\n *\n * @group Structured Field\n *\n * @beta\n */\nfunction encodeSfDict(value, options) {\n  return serializeDict(value, options);\n}\n\n/**\n * CMCD object header name.\n *\n * @group CMCD\n *\n * @beta\n */\nconst CMCD_OBJECT = 'CMCD-Object';\n\n/**\n * CMCD request header name.\n *\n * @group CMCD\n *\n * @beta\n */\nconst CMCD_REQUEST = 'CMCD-Request';\n\n/**\n * CMCD session header name.\n *\n * @group CMCD\n *\n * @beta\n */\nconst CMCD_SESSION = 'CMCD-Session';\n\n/**\n * CMCD status header name.\n *\n * @group CMCD\n *\n * @beta\n */\nconst CMCD_STATUS = 'CMCD-Status';\n\n/**\n * The map of CMCD keys to their appropriate header shard.\n *\n * @group CMCD\n *\n * @internal\n */\nconst CMCD_HEADER_MAP = {\n  // Object\n  br: CMCD_OBJECT,\n  ab: CMCD_OBJECT,\n  d: CMCD_OBJECT,\n  ot: CMCD_OBJECT,\n  tb: CMCD_OBJECT,\n  tpb: CMCD_OBJECT,\n  lb: CMCD_OBJECT,\n  tab: CMCD_OBJECT,\n  lab: CMCD_OBJECT,\n  url: CMCD_OBJECT,\n  // Request\n  pb: CMCD_REQUEST,\n  bl: CMCD_REQUEST,\n  tbl: CMCD_REQUEST,\n  dl: CMCD_REQUEST,\n  ltc: CMCD_REQUEST,\n  mtp: CMCD_REQUEST,\n  nor: CMCD_REQUEST,\n  nrr: CMCD_REQUEST,\n  rc: CMCD_REQUEST,\n  sn: CMCD_REQUEST,\n  sta: CMCD_REQUEST,\n  su: CMCD_REQUEST,\n  ttfb: CMCD_REQUEST,\n  ttfbb: CMCD_REQUEST,\n  ttlb: CMCD_REQUEST,\n  cmsdd: CMCD_REQUEST,\n  cmsds: CMCD_REQUEST,\n  smrt: CMCD_REQUEST,\n  df: CMCD_REQUEST,\n  cs: CMCD_REQUEST,\n  // TODO: Which header to put the `ts` field is not defined yet.\n  ts: CMCD_REQUEST,\n  // Session\n  cid: CMCD_SESSION,\n  pr: CMCD_SESSION,\n  sf: CMCD_SESSION,\n  sid: CMCD_SESSION,\n  st: CMCD_SESSION,\n  v: CMCD_SESSION,\n  msd: CMCD_SESSION,\n  // Status\n  bs: CMCD_STATUS,\n  bsd: CMCD_STATUS,\n  cdn: CMCD_STATUS,\n  rtp: CMCD_STATUS,\n  bg: CMCD_STATUS,\n  pt: CMCD_STATUS,\n  ec: CMCD_STATUS,\n  e: CMCD_STATUS\n};\n\n/**\n * CMCD header fields.\n *\n * @group CMCD\n *\n * @enum\n *\n * @beta\n */\nconst CmcdHeaderField = {\n  /**\n   * keys whose values vary with each request.\n   */\n  REQUEST: CMCD_REQUEST};\n\nfunction createHeaderMap(headerMap) {\n  return Object.keys(headerMap).reduce((acc, field) => {\n    var _a;\n    (_a = headerMap[field]) === null || _a === void 0 ? void 0 : _a.forEach(key => acc[key] = field);\n    return acc;\n  }, {});\n}\n/**\n * Group a CMCD data object into header shards\n *\n * @param cmcd - The CMCD data object to convert.\n * @param customHeaderMap - A map of CMCD header fields to custom CMCD keys.\n *\n * @returns The CMCD header shards.\n *\n * @group CMCD\n *\n * @beta\n */\nfunction groupCmcdHeaders(cmcd, customHeaderMap) {\n  const result = {};\n  if (!cmcd) {\n    return result;\n  }\n  const keys = Object.keys(cmcd);\n  const custom = customHeaderMap ? createHeaderMap(customHeaderMap) : {};\n  return keys.reduce((acc, key) => {\n    var _a;\n    const field = CMCD_HEADER_MAP[key] || custom[key] || CmcdHeaderField.REQUEST;\n    const data = (_a = acc[field]) !== null && _a !== void 0 ? _a : acc[field] = {};\n    data[key] = cmcd[key];\n    return acc;\n  }, result);\n}\n\n/**\n * Checks if the given key is a token field.\n *\n * @param key - The key to check.\n *\n * @returns `true` if the key is a token field.\n *\n * @internal\n */\nfunction isTokenField(key) {\n  return ['ot', 'sf', 'st', 'e', 'sta'].includes(key);\n}\n\n/**\n * Checks if the given value is valid\n *\n * @param value - The value to check.\n *\n * @returns `true` if the key is a value is valid.\n *\n * @internal\n */\nfunction isValid(value) {\n  if (typeof value === 'number') {\n    return isFiniteNumber(value);\n  }\n  return value != null && value !== '' && value !== false;\n}\n\n/**\n * CMCD event mode variable name.\n *\n * @group CMCD\n *\n * @beta\n */\nconst CMCD_EVENT_MODE = 'event';\n\n/**\n * Constructs a relative path from a URL.\n *\n * @param url - The destination URL\n * @param base - The base URL\n * @returns The relative path\n *\n * @group Utils\n *\n * @beta\n */\nfunction urlToRelativePath(url, base) {\n  const to = new URL(url);\n  const from = new URL(base);\n  if (to.origin !== from.origin) {\n    return url;\n  }\n  const toPath = to.pathname.split('/').slice(1);\n  const fromPath = from.pathname.split('/').slice(1, -1);\n  // remove common parents\n  while (toPath[0] === fromPath[0]) {\n    toPath.shift();\n    fromPath.shift();\n  }\n  // add back paths\n  while (fromPath.length) {\n    fromPath.shift();\n    toPath.unshift('..');\n  }\n  const relativePath = toPath.join('/');\n  // preserve query parameters and hash of the destination url\n  return relativePath + to.search + to.hash;\n}\n\nconst toRounded = value => Math.round(value);\nconst toUrlSafe = (value, options) => {\n  if (Array.isArray(value)) {\n    return value.map(item => toUrlSafe(item, options));\n  }\n  if (value instanceof SfItem && typeof value.value === 'string') {\n    return new SfItem(toUrlSafe(value.value, options), value.params);\n  } else {\n    if (options.baseUrl) {\n      value = urlToRelativePath(value, options.baseUrl);\n    }\n    return options.version === 1 ? encodeURIComponent(value) : value;\n  }\n};\nconst toHundred = value => toRounded(value / 100) * 100;\nconst nor = (value, options) => {\n  let norValue = value;\n  if (options.version >= 2) {\n    if (value instanceof SfItem && typeof value.value === 'string') {\n      norValue = new SfItem([value]);\n    } else if (typeof value === 'string') {\n      norValue = [value];\n    }\n  }\n  return toUrlSafe(norValue, options);\n};\n/**\n * The default formatters for CMCD values.\n *\n * @group CMCD\n *\n * @beta\n */\nconst CMCD_FORMATTER_MAP = {\n  /**\n   * Bitrate (kbps) rounded integer\n   */\n  br: toRounded,\n  /**\n   * Duration (milliseconds) rounded integer\n   */\n  d: toRounded,\n  /**\n   * Buffer Length (milliseconds) rounded nearest 100ms\n   */\n  bl: toHundred,\n  /**\n   * Deadline (milliseconds) rounded nearest 100ms\n   */\n  dl: toHundred,\n  /**\n   * Measured Throughput (kbps) rounded nearest 100kbps\n   */\n  mtp: toHundred,\n  /**\n   * Next Object Request URL encoded\n   */\n  nor,\n  /**\n   * Requested maximum throughput (kbps) rounded nearest 100kbps\n   */\n  rtp: toHundred,\n  /**\n   * Top Bitrate (kbps) rounded integer\n   */\n  tb: toRounded\n};\n\n/**\n * CMCD request mode variable name.\n *\n * @group CMCD\n *\n * @beta\n */\nconst CMCD_REQUEST_MODE = 'request';\n\n/**\n * CMCD response mode variable name.\n *\n * @group CMCD\n *\n * @beta\n */\nconst CMCD_RESPONSE_MODE = 'response';\n\n/**\n * Defines the common keys for CMCD (Common Media Client Data) version 2.\n *\n * @group CMCD\n *\n * @beta\n */\nconst CMCD_COMMON_KEYS = ['ab', 'bg', 'bl', 'br', 'bs', 'bsd', 'cdn', 'cid', 'cs', 'df', 'ec', 'lab', 'lb', 'ltc', 'msd', 'mtp', 'pb', 'pr', 'pt', 'sf', 'sid', 'sn', 'st', 'sta', 'tab', 'tb', 'tbl', 'tpb', 'ts', 'v'];\n\n/**\n * Defines the event-specific keys for CMCD (Common Media Client Data) version 2.\n *\n * @group CMCD\n *\n * @beta\n */\nconst CMCD_EVENT_KEYS = ['e'];\n\nconst CUSTOM_KEY_REGEX = /^[a-zA-Z0-9-.]+-[a-zA-Z0-9-.]+$/;\n/**\n * Check if a key is a custom key.\n *\n * @param key - The key to check.\n *\n * @returns `true` if the key is a custom key, `false` otherwise.\n *\n * @group CMCD\n *\n * @beta\n */\nfunction isCmcdCustomKey(key) {\n  return CUSTOM_KEY_REGEX.test(key);\n}\n\n/**\n * Check if a key is a valid CMCD event key.\n *\n * @param key - The key to check.\n *\n * @returns `true` if the key is a valid CMCD event key, `false` otherwise.\n *\n * @group CMCD\n *\n * @beta\n *\n * @example\n * {@includeCode ../../test/cmcd/isCmcdEventKey.test.ts#example}\n */\nfunction isCmcdEventKey(key) {\n  return CMCD_COMMON_KEYS.includes(key) || CMCD_EVENT_KEYS.includes(key) || isCmcdCustomKey(key);\n}\n\n/**\n * Defines the request-specific keys for CMCD (Common Media Client Data) version 2.\n *\n * @group CMCD\n *\n * @beta\n */\nconst CMCD_REQUEST_KEYS = ['d', 'dl', 'nor', 'ot', 'rtp', 'su'];\n\n/**\n * Check if a key is a valid CMCD request key.\n *\n * @param key - The key to check.\n *\n * @returns `true` if the key is a valid CMCD request key, `false` otherwise.\n *\n * @group CMCD\n *\n * @beta\n *\n * @example\n * {@includeCode ../../test/cmcd/isCmcdRequestKey.test.ts#example}\n */\nfunction isCmcdRequestKey(key) {\n  return CMCD_COMMON_KEYS.includes(key) || CMCD_REQUEST_KEYS.includes(key) || isCmcdCustomKey(key);\n}\n\n/**\n * CMCD v2 - Response-only and timing keys.\n *\n * @group CMCD\n *\n * @beta\n */\nconst CMCD_RESPONSE_KEYS = ['cmsdd', 'cmsds', 'rc', 'smrt', 'ttfb', 'ttfbb', 'ttlb', 'url'];\n\n/**\n * Check if a key is a valid CMCD response key.\n *\n * @param key - The key to check.\n *\n * @returns `true` if the key is a valid CMCD request key, `false` otherwise.\n *\n * @group CMCD\n *\n * @beta\n *\n * @example\n * {@includeCode ../../test/cmcd/isCmcdResponseKey.test.ts#example}\n */\nfunction isCmcdResponseKey(key) {\n  return CMCD_COMMON_KEYS.includes(key) || CMCD_REQUEST_KEYS.includes(key) || CMCD_RESPONSE_KEYS.includes(key) || isCmcdCustomKey(key);\n}\n\n/**\n * Defines the keys for CMCD (Common Media Client Data) version 1.\n *\n * @group CMCD\n *\n * @beta\n */\nconst CMCD_V1_KEYS = ['bl', 'br', 'bs', 'cid', 'd', 'dl', 'mtp', 'nor', 'nrr', 'ot', 'pr', 'rtp', 'sf', 'sid', 'st', 'su', 'tb', 'v'];\n\n/**\n * Filter function for CMCD v1 keys.\n *\n * @param key - The CMCD key to filter.\n *\n * @returns `true` if the key should be included, `false` otherwise.\n *\n * @group CMCD\n *\n * @beta\n *\n * @example\n * {@includeCode ../../test/cmcd/isCmcdV1Key.test.ts#example}\n */\nfunction isCmcdV1Key(key) {\n  return CMCD_V1_KEYS.includes(key) || isCmcdCustomKey(key);\n}\n\nconst filterMap = {\n  [CMCD_RESPONSE_MODE]: isCmcdResponseKey,\n  [CMCD_EVENT_MODE]: isCmcdEventKey,\n  [CMCD_REQUEST_MODE]: isCmcdRequestKey\n};\n/**\n * Convert a generic object to CMCD data.\n *\n * @param obj - The CMCD object to process.\n * @param options - Options for encoding.\n *\n * @group CMCD\n *\n * @beta\n */\nfunction prepareCmcdData(obj, options = {}) {\n  const results = {};\n  if (obj == null || typeof obj !== 'object') {\n    return results;\n  }\n  const version = options.version || obj['v'] || 1;\n  const reportingMode = options.reportingMode || CMCD_REQUEST_MODE;\n  const keyFilter = version === 1 ? isCmcdV1Key : filterMap[reportingMode];\n  // Filter keys based on the version, reporting mode and options\n  let keys = Object.keys(obj).filter(keyFilter);\n  const filter = options.filter;\n  if (typeof filter === 'function') {\n    keys = keys.filter(filter);\n  }\n  // Ensure all required keys are present before sorting\n  const needsTimestamp = reportingMode === CMCD_RESPONSE_MODE || reportingMode === CMCD_EVENT_MODE;\n  if (needsTimestamp && !keys.includes('ts')) {\n    keys.push('ts');\n  }\n  if (version > 1 && !keys.includes('v')) {\n    keys.push('v');\n  }\n  const formatters = _extends({}, CMCD_FORMATTER_MAP, options.formatters);\n  const formatterOptions = {\n    version,\n    reportingMode,\n    baseUrl: options.baseUrl\n  };\n  keys.sort().forEach(key => {\n    let value = obj[key];\n    const formatter = formatters[key];\n    if (typeof formatter === 'function') {\n      value = formatter(value, formatterOptions);\n    }\n    // Version should only be reported if not equal to 1.\n    if (key === 'v') {\n      if (version === 1) {\n        return;\n      } else {\n        value = version;\n      }\n    }\n    // Playback rate should only be sent if not equal to 1.\n    if (key == 'pr' && value === 1) {\n      return;\n    }\n    // Ensure a timestamp is set for response and event modes\n    if (needsTimestamp && key === 'ts' && !isFiniteNumber(value)) {\n      value = Date.now();\n    }\n    // ignore invalid values\n    if (!isValid(value)) {\n      return;\n    }\n    if (isTokenField(key) && typeof value === 'string') {\n      value = new SfToken(value);\n    }\n    results[key] = value;\n  });\n  return results;\n}\n\n/**\n * Convert a CMCD data object to request headers\n *\n * @param cmcd - The CMCD data object to convert.\n * @param options - Options for encoding the CMCD object.\n *\n * @returns The CMCD header shards.\n *\n * @group CMCD\n *\n * @beta\n *\n * @example\n * {@includeCode ../../test/cmcd/toCmcdHeaders.test.ts#example}\n */\nfunction toCmcdHeaders(cmcd, options = {}) {\n  const result = {};\n  if (!cmcd) {\n    return result;\n  }\n  const data = prepareCmcdData(cmcd, options);\n  const shards = groupCmcdHeaders(data, options === null || options === void 0 ? void 0 : options.customHeaderMap);\n  return Object.entries(shards).reduce((acc, [field, value]) => {\n    const shard = encodeSfDict(value, {\n      whitespace: false\n    });\n    if (shard) {\n      acc[field] = shard;\n    }\n    return acc;\n  }, result);\n}\n\n/**\n * Append CMCD query args to a header object.\n *\n * @param headers - The headers to append to.\n * @param cmcd - The CMCD object to append.\n * @param options - Encode options.\n *\n * @returns The headers with the CMCD header shards appended.\n *\n * @group CMCD\n *\n * @beta\n *\n * @example\n * {@includeCode ../../test/cmcd/appendCmcdHeaders.test.ts#example}\n */\nfunction appendCmcdHeaders(headers, cmcd, options) {\n  return _extends(headers, toCmcdHeaders(cmcd, options));\n}\n\n/**\n * CMCD parameter name.\n *\n * @group CMCD\n *\n * @beta\n */\nconst CMCD_PARAM = 'CMCD';\n\n/**\n * Encode a CMCD object to a string.\n *\n * @param cmcd - The CMCD object to encode.\n * @param options - Options for encoding.\n *\n * @returns The encoded CMCD string.\n *\n * @group CMCD\n *\n * @beta\n *\n * @example\n * {@includeCode ../../test/cmcd/encodeCmcd.test.ts#example}\n */\nfunction encodeCmcd(cmcd, options = {}) {\n  if (!cmcd) {\n    return '';\n  }\n  return encodeSfDict(prepareCmcdData(cmcd, options), {\n    whitespace: false\n  });\n}\n\n/**\n * Convert a CMCD data object to a URL encoded string.\n *\n * @param cmcd - The CMCD object to convert.\n * @param options - Options for encoding the CMCD object.\n *\n * @returns The URL encoded CMCD data.\n *\n * @group CMCD\n *\n * @beta\n */\nfunction toCmcdUrl(cmcd, options = {}) {\n  if (!cmcd) {\n    return '';\n  }\n  const params = encodeCmcd(cmcd, options);\n  return encodeURIComponent(params);\n}\n\n/**\n * Convert a CMCD data object to a query arg.\n *\n * @param cmcd - The CMCD object to convert.\n * @param options - Options for encoding the CMCD object.\n *\n * @returns The CMCD query arg.\n *\n * @group CMCD\n *\n * @beta\n *\n * @example\n * {@includeCode ../../test/cmcd/toCmcdQuery.test.ts#example}\n */\nfunction toCmcdQuery(cmcd, options = {}) {\n  if (!cmcd) {\n    return '';\n  }\n  const value = toCmcdUrl(cmcd, options);\n  return `${CMCD_PARAM}=${value}`;\n}\n\nconst REGEX = /CMCD=[^&#]+/;\n/**\n * Append CMCD query args to a URL.\n *\n * @param url - The URL to append to.\n * @param cmcd - The CMCD object to append.\n * @param options - Options for encoding the CMCD object.\n *\n * @returns The URL with the CMCD query args appended.\n *\n * @group CMCD\n *\n * @beta\n *\n * @example\n * {@includeCode ../../test/cmcd/appendCmcdQuery.test.ts#example}\n */\nfunction appendCmcdQuery(url, cmcd, options) {\n  // TODO: Replace with URLSearchParams once we drop Safari < 10.1 & Chrome < 49 support.\n  // https://developer.mozilla.org/en-US/docs/Web/API/URLSearchParams\n  const query = toCmcdQuery(cmcd, options);\n  if (!query) {\n    return url;\n  }\n  if (REGEX.test(url)) {\n    return url.replace(REGEX, query);\n  }\n  const separator = url.includes('?') ? '&' : '?';\n  return `${url}${separator}${query}`;\n}\n\n/**\n * Controller to deal with Common Media Client Data (CMCD)\n * @see https://cdn.cta.tech/cta/media/media/resources/standards/pdfs/cta-5004-final.pdf\n */\nclass CMCDController {\n  constructor(hls) {\n    this.hls = void 0;\n    this.config = void 0;\n    this.media = void 0;\n    this.sid = void 0;\n    this.cid = void 0;\n    this.useHeaders = false;\n    this.includeKeys = void 0;\n    this.initialized = false;\n    this.starved = false;\n    this.buffering = true;\n    this.audioBuffer = void 0;\n    this.videoBuffer = void 0;\n    this.onWaiting = () => {\n      if (this.initialized) {\n        this.starved = true;\n      }\n      this.buffering = true;\n    };\n    this.onPlaying = () => {\n      if (!this.initialized) {\n        this.initialized = true;\n      }\n      this.buffering = false;\n    };\n    /**\n     * Apply CMCD data to a manifest request.\n     */\n    this.applyPlaylistData = context => {\n      try {\n        this.apply(context, {\n          ot: CmcdObjectType.MANIFEST,\n          su: !this.initialized\n        });\n      } catch (error) {\n        this.hls.logger.warn('Could not generate manifest CMCD data.', error);\n      }\n    };\n    /**\n     * Apply CMCD data to a segment request\n     */\n    this.applyFragmentData = context => {\n      try {\n        const {\n          frag,\n          part\n        } = context;\n        const level = this.hls.levels[frag.level];\n        const ot = this.getObjectType(frag);\n        const data = {\n          d: (part || frag).duration * 1000,\n          ot\n        };\n        if (ot === CmcdObjectType.VIDEO || ot === CmcdObjectType.AUDIO || ot == CmcdObjectType.MUXED) {\n          data.br = level.bitrate / 1000;\n          data.tb = this.getTopBandwidth(ot) / 1000;\n          data.bl = this.getBufferLength(ot);\n        }\n        const next = part ? this.getNextPart(part) : this.getNextFrag(frag);\n        if (next != null && next.url && next.url !== frag.url) {\n          data.nor = next.url;\n        }\n        this.apply(context, data);\n      } catch (error) {\n        this.hls.logger.warn('Could not generate segment CMCD data.', error);\n      }\n    };\n    this.hls = hls;\n    const config = this.config = hls.config;\n    const {\n      cmcd\n    } = config;\n    if (cmcd != null) {\n      config.pLoader = this.createPlaylistLoader();\n      config.fLoader = this.createFragmentLoader();\n      this.sid = cmcd.sessionId || hls.sessionId;\n      this.cid = cmcd.contentId;\n      this.useHeaders = cmcd.useHeaders === true;\n      this.includeKeys = cmcd.includeKeys;\n      this.registerListeners();\n    }\n  }\n  registerListeners() {\n    const hls = this.hls;\n    hls.on(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n    hls.on(Events.MEDIA_DETACHED, this.onMediaDetached, this);\n    hls.on(Events.BUFFER_CREATED, this.onBufferCreated, this);\n  }\n  unregisterListeners() {\n    const hls = this.hls;\n    hls.off(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n    hls.off(Events.MEDIA_DETACHED, this.onMediaDetached, this);\n    hls.off(Events.BUFFER_CREATED, this.onBufferCreated, this);\n  }\n  destroy() {\n    this.unregisterListeners();\n    this.onMediaDetached();\n\n    // @ts-ignore\n    this.hls = this.config = this.audioBuffer = this.videoBuffer = null;\n    // @ts-ignore\n    this.onWaiting = this.onPlaying = this.media = null;\n  }\n  onMediaAttached(event, data) {\n    this.media = data.media;\n    this.media.addEventListener('waiting', this.onWaiting);\n    this.media.addEventListener('playing', this.onPlaying);\n  }\n  onMediaDetached() {\n    if (!this.media) {\n      return;\n    }\n    this.media.removeEventListener('waiting', this.onWaiting);\n    this.media.removeEventListener('playing', this.onPlaying);\n\n    // @ts-ignore\n    this.media = null;\n  }\n  onBufferCreated(event, data) {\n    var _data$tracks$audio, _data$tracks$video;\n    this.audioBuffer = (_data$tracks$audio = data.tracks.audio) == null ? void 0 : _data$tracks$audio.buffer;\n    this.videoBuffer = (_data$tracks$video = data.tracks.video) == null ? void 0 : _data$tracks$video.buffer;\n  }\n  /**\n   * Create baseline CMCD data\n   */\n  createData() {\n    var _this$media;\n    return {\n      v: 1,\n      sf: CmcdStreamingFormat.HLS,\n      sid: this.sid,\n      cid: this.cid,\n      pr: (_this$media = this.media) == null ? void 0 : _this$media.playbackRate,\n      mtp: this.hls.bandwidthEstimate / 1000\n    };\n  }\n\n  /**\n   * Apply CMCD data to a request.\n   */\n  apply(context, data = {}) {\n    // apply baseline data\n    _extends(data, this.createData());\n    const isVideo = data.ot === CmcdObjectType.INIT || data.ot === CmcdObjectType.VIDEO || data.ot === CmcdObjectType.MUXED;\n    if (this.starved && isVideo) {\n      data.bs = true;\n      data.su = true;\n      this.starved = false;\n    }\n    if (data.su == null) {\n      data.su = this.buffering;\n    }\n\n    // TODO: Implement rtp, nrr, dl\n\n    const {\n      includeKeys\n    } = this;\n    if (includeKeys) {\n      data = Object.keys(data).reduce((acc, key) => {\n        includeKeys.includes(key) && (acc[key] = data[key]);\n        return acc;\n      }, {});\n    }\n    const options = {\n      baseUrl: context.url\n    };\n    if (this.useHeaders) {\n      if (!context.headers) {\n        context.headers = {};\n      }\n      appendCmcdHeaders(context.headers, data, options);\n    } else {\n      context.url = appendCmcdQuery(context.url, data, options);\n    }\n  }\n  getNextFrag(fragment) {\n    var _this$hls$levels$frag;\n    const levelDetails = (_this$hls$levels$frag = this.hls.levels[fragment.level]) == null ? void 0 : _this$hls$levels$frag.details;\n    if (levelDetails) {\n      const index = fragment.sn - levelDetails.startSN;\n      return levelDetails.fragments[index + 1];\n    }\n    return undefined;\n  }\n  getNextPart(part) {\n    var _this$hls$levels$frag2;\n    const {\n      index,\n      fragment\n    } = part;\n    const partList = (_this$hls$levels$frag2 = this.hls.levels[fragment.level]) == null || (_this$hls$levels$frag2 = _this$hls$levels$frag2.details) == null ? void 0 : _this$hls$levels$frag2.partList;\n    if (partList) {\n      const {\n        sn\n      } = fragment;\n      for (let i = partList.length - 1; i >= 0; i--) {\n        const p = partList[i];\n        if (p.index === index && p.fragment.sn === sn) {\n          return partList[i + 1];\n        }\n      }\n    }\n    return undefined;\n  }\n\n  /**\n   * The CMCD object type.\n   */\n  getObjectType(fragment) {\n    const {\n      type\n    } = fragment;\n    if (type === 'subtitle') {\n      return CmcdObjectType.TIMED_TEXT;\n    }\n    if (fragment.sn === 'initSegment') {\n      return CmcdObjectType.INIT;\n    }\n    if (type === 'audio') {\n      return CmcdObjectType.AUDIO;\n    }\n    if (type === 'main') {\n      if (!this.hls.audioTracks.length) {\n        return CmcdObjectType.MUXED;\n      }\n      return CmcdObjectType.VIDEO;\n    }\n    return undefined;\n  }\n\n  /**\n   * Get the highest bitrate.\n   */\n  getTopBandwidth(type) {\n    let bitrate = 0;\n    let levels;\n    const hls = this.hls;\n    if (type === CmcdObjectType.AUDIO) {\n      levels = hls.audioTracks;\n    } else {\n      const max = hls.maxAutoLevel;\n      const len = max > -1 ? max + 1 : hls.levels.length;\n      levels = hls.levels.slice(0, len);\n    }\n    levels.forEach(level => {\n      if (level.bitrate > bitrate) {\n        bitrate = level.bitrate;\n      }\n    });\n    return bitrate > 0 ? bitrate : NaN;\n  }\n\n  /**\n   * Get the buffer length for a media type in milliseconds\n   */\n  getBufferLength(type) {\n    const media = this.media;\n    const buffer = type === CmcdObjectType.AUDIO ? this.audioBuffer : this.videoBuffer;\n    if (!buffer || !media) {\n      return NaN;\n    }\n    const info = BufferHelper.bufferInfo(buffer, media.currentTime, this.config.maxBufferHole);\n    return info.len * 1000;\n  }\n\n  /**\n   * Create a playlist loader\n   */\n  createPlaylistLoader() {\n    const {\n      pLoader\n    } = this.config;\n    const apply = this.applyPlaylistData;\n    const Ctor = pLoader || this.config.loader;\n    return class CmcdPlaylistLoader {\n      constructor(config) {\n        this.loader = void 0;\n        this.loader = new Ctor(config);\n      }\n      get stats() {\n        return this.loader.stats;\n      }\n      get context() {\n        return this.loader.context;\n      }\n      destroy() {\n        this.loader.destroy();\n      }\n      abort() {\n        this.loader.abort();\n      }\n      load(context, config, callbacks) {\n        apply(context);\n        this.loader.load(context, config, callbacks);\n      }\n    };\n  }\n\n  /**\n   * Create a playlist loader\n   */\n  createFragmentLoader() {\n    const {\n      fLoader\n    } = this.config;\n    const apply = this.applyFragmentData;\n    const Ctor = fLoader || this.config.loader;\n    return class CmcdFragmentLoader {\n      constructor(config) {\n        this.loader = void 0;\n        this.loader = new Ctor(config);\n      }\n      get stats() {\n        return this.loader.stats;\n      }\n      get context() {\n        return this.loader.context;\n      }\n      destroy() {\n        this.loader.destroy();\n      }\n      abort() {\n        this.loader.abort();\n      }\n      load(context, config, callbacks) {\n        apply(context);\n        this.loader.load(context, config, callbacks);\n      }\n    };\n  }\n}\n\nconst PATHWAY_PENALTY_DURATION_MS = 300000;\nclass ContentSteeringController extends Logger {\n  constructor(hls) {\n    super('content-steering', hls.logger);\n    this.hls = void 0;\n    this.loader = null;\n    this.uri = null;\n    this.pathwayId = '.';\n    this._pathwayPriority = null;\n    this.timeToLoad = 300;\n    this.reloadTimer = -1;\n    this.updated = 0;\n    this.started = false;\n    this.enabled = true;\n    this.levels = null;\n    this.audioTracks = null;\n    this.subtitleTracks = null;\n    this.penalizedPathways = {};\n    this.hls = hls;\n    this.registerListeners();\n  }\n  registerListeners() {\n    const hls = this.hls;\n    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.on(Events.MANIFEST_LOADED, this.onManifestLoaded, this);\n    hls.on(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n    hls.on(Events.ERROR, this.onError, this);\n  }\n  unregisterListeners() {\n    const hls = this.hls;\n    if (!hls) {\n      return;\n    }\n    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.off(Events.MANIFEST_LOADED, this.onManifestLoaded, this);\n    hls.off(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n    hls.off(Events.ERROR, this.onError, this);\n  }\n  pathways() {\n    return (this.levels || []).reduce((pathways, level) => {\n      if (pathways.indexOf(level.pathwayId) === -1) {\n        pathways.push(level.pathwayId);\n      }\n      return pathways;\n    }, []);\n  }\n  get pathwayPriority() {\n    return this._pathwayPriority;\n  }\n  set pathwayPriority(pathwayPriority) {\n    this.updatePathwayPriority(pathwayPriority);\n  }\n  startLoad() {\n    this.started = true;\n    this.clearTimeout();\n    if (this.enabled && this.uri) {\n      if (this.updated) {\n        const ttl = this.timeToLoad * 1000 - (performance.now() - this.updated);\n        if (ttl > 0) {\n          this.scheduleRefresh(this.uri, ttl);\n          return;\n        }\n      }\n      this.loadSteeringManifest(this.uri);\n    }\n  }\n  stopLoad() {\n    this.started = false;\n    if (this.loader) {\n      this.loader.destroy();\n      this.loader = null;\n    }\n    this.clearTimeout();\n  }\n  clearTimeout() {\n    if (this.reloadTimer !== -1) {\n      self.clearTimeout(this.reloadTimer);\n      this.reloadTimer = -1;\n    }\n  }\n  destroy() {\n    this.unregisterListeners();\n    this.stopLoad();\n    // @ts-ignore\n    this.hls = null;\n    this.levels = this.audioTracks = this.subtitleTracks = null;\n  }\n  removeLevel(levelToRemove) {\n    const levels = this.levels;\n    if (levels) {\n      this.levels = levels.filter(level => level !== levelToRemove);\n    }\n  }\n  onManifestLoading() {\n    this.stopLoad();\n    this.enabled = true;\n    this.timeToLoad = 300;\n    this.updated = 0;\n    this.uri = null;\n    this.pathwayId = '.';\n    this.levels = this.audioTracks = this.subtitleTracks = null;\n  }\n  onManifestLoaded(event, data) {\n    const {\n      contentSteering\n    } = data;\n    if (contentSteering === null) {\n      return;\n    }\n    this.pathwayId = contentSteering.pathwayId;\n    this.uri = contentSteering.uri;\n    if (this.started) {\n      this.startLoad();\n    }\n  }\n  onManifestParsed(event, data) {\n    this.audioTracks = data.audioTracks;\n    this.subtitleTracks = data.subtitleTracks;\n  }\n  onError(event, data) {\n    const {\n      errorAction\n    } = data;\n    if ((errorAction == null ? void 0 : errorAction.action) === NetworkErrorAction.SendAlternateToPenaltyBox && errorAction.flags === ErrorActionFlags.MoveAllAlternatesMatchingHost) {\n      const levels = this.levels;\n      let pathwayPriority = this._pathwayPriority;\n      let errorPathway = this.pathwayId;\n      if (data.context) {\n        const {\n          groupId,\n          pathwayId,\n          type\n        } = data.context;\n        if (groupId && levels) {\n          errorPathway = this.getPathwayForGroupId(groupId, type, errorPathway);\n        } else if (pathwayId) {\n          errorPathway = pathwayId;\n        }\n      }\n      if (!(errorPathway in this.penalizedPathways)) {\n        this.penalizedPathways[errorPathway] = performance.now();\n      }\n      if (!pathwayPriority && levels) {\n        // If PATHWAY-PRIORITY was not provided, list pathways for error handling\n        pathwayPriority = this.pathways();\n      }\n      if (pathwayPriority && pathwayPriority.length > 1) {\n        this.updatePathwayPriority(pathwayPriority);\n        errorAction.resolved = this.pathwayId !== errorPathway;\n      }\n      if (data.details === ErrorDetails.BUFFER_APPEND_ERROR && !data.fatal) {\n        // Error will become fatal in buffer-controller when reaching `appendErrorMaxRetry`\n        // Stream-controllers are expected to reduce buffer length even if this is not deemed a QuotaExceededError\n        errorAction.resolved = true;\n      } else if (!errorAction.resolved) {\n        this.warn(`Could not resolve ${data.details} (\"${data.error.message}\") with content-steering for Pathway: ${errorPathway} levels: ${levels ? levels.length : levels} priorities: ${stringify(pathwayPriority)} penalized: ${stringify(this.penalizedPathways)}`);\n      }\n    }\n  }\n  filterParsedLevels(levels) {\n    // Filter levels to only include those that are in the initial pathway\n    this.levels = levels;\n    let pathwayLevels = this.getLevelsForPathway(this.pathwayId);\n    if (pathwayLevels.length === 0) {\n      const pathwayId = levels[0].pathwayId;\n      this.log(`No levels found in Pathway ${this.pathwayId}. Setting initial Pathway to \"${pathwayId}\"`);\n      pathwayLevels = this.getLevelsForPathway(pathwayId);\n      this.pathwayId = pathwayId;\n    }\n    if (pathwayLevels.length !== levels.length) {\n      this.log(`Found ${pathwayLevels.length}/${levels.length} levels in Pathway \"${this.pathwayId}\"`);\n    }\n    return pathwayLevels;\n  }\n  getLevelsForPathway(pathwayId) {\n    if (this.levels === null) {\n      return [];\n    }\n    return this.levels.filter(level => pathwayId === level.pathwayId);\n  }\n  updatePathwayPriority(pathwayPriority) {\n    this._pathwayPriority = pathwayPriority;\n    let levels;\n\n    // Evaluate if we should remove the pathway from the penalized list\n    const penalizedPathways = this.penalizedPathways;\n    const now = performance.now();\n    Object.keys(penalizedPathways).forEach(pathwayId => {\n      if (now - penalizedPathways[pathwayId] > PATHWAY_PENALTY_DURATION_MS) {\n        delete penalizedPathways[pathwayId];\n      }\n    });\n    for (let i = 0; i < pathwayPriority.length; i++) {\n      const pathwayId = pathwayPriority[i];\n      if (pathwayId in penalizedPathways) {\n        continue;\n      }\n      if (pathwayId === this.pathwayId) {\n        return;\n      }\n      const selectedIndex = this.hls.nextLoadLevel;\n      const selectedLevel = this.hls.levels[selectedIndex];\n      levels = this.getLevelsForPathway(pathwayId);\n      if (levels.length > 0) {\n        this.log(`Setting Pathway to \"${pathwayId}\"`);\n        this.pathwayId = pathwayId;\n        reassignFragmentLevelIndexes(levels);\n        this.hls.trigger(Events.LEVELS_UPDATED, {\n          levels\n        });\n        // Set LevelController's level to trigger LEVEL_SWITCHING which loads playlist if needed\n        const levelAfterChange = this.hls.levels[selectedIndex];\n        if (selectedLevel && levelAfterChange && this.levels) {\n          if (levelAfterChange.attrs['STABLE-VARIANT-ID'] !== selectedLevel.attrs['STABLE-VARIANT-ID'] && levelAfterChange.bitrate !== selectedLevel.bitrate) {\n            this.log(`Unstable Pathways change from bitrate ${selectedLevel.bitrate} to ${levelAfterChange.bitrate}`);\n          }\n          this.hls.nextLoadLevel = selectedIndex;\n        }\n        break;\n      }\n    }\n  }\n  getPathwayForGroupId(groupId, type, defaultPathway) {\n    const levels = this.getLevelsForPathway(defaultPathway).concat(this.levels || []);\n    for (let i = 0; i < levels.length; i++) {\n      if (type === PlaylistContextType.AUDIO_TRACK && levels[i].hasAudioGroup(groupId) || type === PlaylistContextType.SUBTITLE_TRACK && levels[i].hasSubtitleGroup(groupId)) {\n        return levels[i].pathwayId;\n      }\n    }\n    return defaultPathway;\n  }\n  clonePathways(pathwayClones) {\n    const levels = this.levels;\n    if (!levels) {\n      return;\n    }\n    const audioGroupCloneMap = {};\n    const subtitleGroupCloneMap = {};\n    pathwayClones.forEach(pathwayClone => {\n      const {\n        ID: cloneId,\n        'BASE-ID': baseId,\n        'URI-REPLACEMENT': uriReplacement\n      } = pathwayClone;\n      if (levels.some(level => level.pathwayId === cloneId)) {\n        return;\n      }\n      const clonedVariants = this.getLevelsForPathway(baseId).map(baseLevel => {\n        const attributes = new AttrList(baseLevel.attrs);\n        attributes['PATHWAY-ID'] = cloneId;\n        const clonedAudioGroupId = attributes.AUDIO && `${attributes.AUDIO}_clone_${cloneId}`;\n        const clonedSubtitleGroupId = attributes.SUBTITLES && `${attributes.SUBTITLES}_clone_${cloneId}`;\n        if (clonedAudioGroupId) {\n          audioGroupCloneMap[attributes.AUDIO] = clonedAudioGroupId;\n          attributes.AUDIO = clonedAudioGroupId;\n        }\n        if (clonedSubtitleGroupId) {\n          subtitleGroupCloneMap[attributes.SUBTITLES] = clonedSubtitleGroupId;\n          attributes.SUBTITLES = clonedSubtitleGroupId;\n        }\n        const url = performUriReplacement(baseLevel.uri, attributes['STABLE-VARIANT-ID'], 'PER-VARIANT-URIS', uriReplacement);\n        const clonedLevel = new Level({\n          attrs: attributes,\n          audioCodec: baseLevel.audioCodec,\n          bitrate: baseLevel.bitrate,\n          height: baseLevel.height,\n          name: baseLevel.name,\n          url,\n          videoCodec: baseLevel.videoCodec,\n          width: baseLevel.width\n        });\n        if (baseLevel.audioGroups) {\n          for (let i = 1; i < baseLevel.audioGroups.length; i++) {\n            clonedLevel.addGroupId('audio', `${baseLevel.audioGroups[i]}_clone_${cloneId}`);\n          }\n        }\n        if (baseLevel.subtitleGroups) {\n          for (let i = 1; i < baseLevel.subtitleGroups.length; i++) {\n            clonedLevel.addGroupId('text', `${baseLevel.subtitleGroups[i]}_clone_${cloneId}`);\n          }\n        }\n        return clonedLevel;\n      });\n      levels.push(...clonedVariants);\n      cloneRenditionGroups(this.audioTracks, audioGroupCloneMap, uriReplacement, cloneId);\n      cloneRenditionGroups(this.subtitleTracks, subtitleGroupCloneMap, uriReplacement, cloneId);\n    });\n  }\n  loadSteeringManifest(uri) {\n    const config = this.hls.config;\n    const Loader = config.loader;\n    if (this.loader) {\n      this.loader.destroy();\n    }\n    this.loader = new Loader(config);\n    let url;\n    try {\n      url = new self.URL(uri);\n    } catch (error) {\n      this.enabled = false;\n      this.log(`Failed to parse Steering Manifest URI: ${uri}`);\n      return;\n    }\n    if (url.protocol !== 'data:') {\n      const throughput = (this.hls.bandwidthEstimate || config.abrEwmaDefaultEstimate) | 0;\n      url.searchParams.set('_HLS_pathway', this.pathwayId);\n      url.searchParams.set('_HLS_throughput', '' + throughput);\n    }\n    const context = {\n      responseType: 'json',\n      url: url.href\n    };\n    const loadPolicy = config.steeringManifestLoadPolicy.default;\n    const legacyRetryCompatibility = loadPolicy.errorRetry || loadPolicy.timeoutRetry || {};\n    const loaderConfig = {\n      loadPolicy,\n      timeout: loadPolicy.maxLoadTimeMs,\n      maxRetry: legacyRetryCompatibility.maxNumRetry || 0,\n      retryDelay: legacyRetryCompatibility.retryDelayMs || 0,\n      maxRetryDelay: legacyRetryCompatibility.maxRetryDelayMs || 0\n    };\n    const callbacks = {\n      onSuccess: (response, stats, context, networkDetails) => {\n        this.log(`Loaded steering manifest: \"${url}\"`);\n        const steeringData = response.data;\n        if ((steeringData == null ? void 0 : steeringData.VERSION) !== 1) {\n          this.log(`Steering VERSION ${steeringData.VERSION} not supported!`);\n          return;\n        }\n        this.updated = performance.now();\n        this.timeToLoad = steeringData.TTL;\n        const {\n          'RELOAD-URI': reloadUri,\n          'PATHWAY-CLONES': pathwayClones,\n          'PATHWAY-PRIORITY': pathwayPriority\n        } = steeringData;\n        if (reloadUri) {\n          try {\n            this.uri = new self.URL(reloadUri, url).href;\n          } catch (error) {\n            this.enabled = false;\n            this.log(`Failed to parse Steering Manifest RELOAD-URI: ${reloadUri}`);\n            return;\n          }\n        }\n        this.scheduleRefresh(this.uri || context.url);\n        if (pathwayClones) {\n          this.clonePathways(pathwayClones);\n        }\n        const loadedSteeringData = {\n          steeringManifest: steeringData,\n          url: url.toString()\n        };\n        this.hls.trigger(Events.STEERING_MANIFEST_LOADED, loadedSteeringData);\n        if (pathwayPriority) {\n          this.updatePathwayPriority(pathwayPriority);\n        }\n      },\n      onError: (error, context, networkDetails, stats) => {\n        this.log(`Error loading steering manifest: ${error.code} ${error.text} (${context.url})`);\n        this.stopLoad();\n        if (error.code === 410) {\n          this.enabled = false;\n          this.log(`Steering manifest ${context.url} no longer available`);\n          return;\n        }\n        let ttl = this.timeToLoad * 1000;\n        if (error.code === 429) {\n          const loader = this.loader;\n          if (typeof (loader == null ? void 0 : loader.getResponseHeader) === 'function') {\n            const retryAfter = loader.getResponseHeader('Retry-After');\n            if (retryAfter) {\n              ttl = parseFloat(retryAfter) * 1000;\n            }\n          }\n          this.log(`Steering manifest ${context.url} rate limited`);\n          return;\n        }\n        this.scheduleRefresh(this.uri || context.url, ttl);\n      },\n      onTimeout: (stats, context, networkDetails) => {\n        this.log(`Timeout loading steering manifest (${context.url})`);\n        this.scheduleRefresh(this.uri || context.url);\n      }\n    };\n    this.log(`Requesting steering manifest: ${url}`);\n    this.loader.load(context, loaderConfig, callbacks);\n  }\n  scheduleRefresh(uri, ttlMs = this.timeToLoad * 1000) {\n    this.clearTimeout();\n    this.reloadTimer = self.setTimeout(() => {\n      var _this$hls;\n      const media = (_this$hls = this.hls) == null ? void 0 : _this$hls.media;\n      if (media && !media.ended) {\n        this.loadSteeringManifest(uri);\n        return;\n      }\n      this.scheduleRefresh(uri, this.timeToLoad * 1000);\n    }, ttlMs);\n  }\n}\nfunction cloneRenditionGroups(tracks, groupCloneMap, uriReplacement, cloneId) {\n  if (!tracks) {\n    return;\n  }\n  Object.keys(groupCloneMap).forEach(audioGroupId => {\n    const clonedTracks = tracks.filter(track => track.groupId === audioGroupId).map(track => {\n      const clonedTrack = _extends({}, track);\n      clonedTrack.details = undefined;\n      clonedTrack.attrs = new AttrList(clonedTrack.attrs);\n      clonedTrack.url = clonedTrack.attrs.URI = performUriReplacement(track.url, track.attrs['STABLE-RENDITION-ID'], 'PER-RENDITION-URIS', uriReplacement);\n      clonedTrack.groupId = clonedTrack.attrs['GROUP-ID'] = groupCloneMap[audioGroupId];\n      clonedTrack.attrs['PATHWAY-ID'] = cloneId;\n      return clonedTrack;\n    });\n    tracks.push(...clonedTracks);\n  });\n}\nfunction performUriReplacement(uri, stableId, perOptionKey, uriReplacement) {\n  const {\n    HOST: host,\n    PARAMS: params,\n    [perOptionKey]: perOptionUris\n  } = uriReplacement;\n  let perVariantUri;\n  if (stableId) {\n    perVariantUri = perOptionUris == null ? void 0 : perOptionUris[stableId];\n    if (perVariantUri) {\n      uri = perVariantUri;\n    }\n  }\n  const url = new self.URL(uri);\n  if (host && !perVariantUri) {\n    url.host = host;\n  }\n  if (params) {\n    Object.keys(params).sort().forEach(key => {\n      if (key) {\n        url.searchParams.set(key, params[key]);\n      }\n    });\n  }\n  return url.href;\n}\n\n/**\n * Controller to deal with encrypted media extensions (EME)\n * @see https://developer.mozilla.org/en-US/docs/Web/API/Encrypted_Media_Extensions_API\n *\n * @class\n * @constructor\n */\nclass EMEController extends Logger {\n  constructor(hls) {\n    super('eme', hls.logger);\n    this.hls = void 0;\n    this.config = void 0;\n    this.media = null;\n    this.mediaResolved = void 0;\n    this.keyFormatPromise = null;\n    this.keySystemAccessPromises = {};\n    this._requestLicenseFailureCount = 0;\n    this.mediaKeySessions = [];\n    this.keyIdToKeySessionPromise = {};\n    this.mediaKeys = null;\n    this.setMediaKeysQueue = EMEController.CDMCleanupPromise ? [EMEController.CDMCleanupPromise] : [];\n    this.bannedKeyIds = {};\n    this.onMediaEncrypted = event => {\n      const {\n        initDataType,\n        initData\n      } = event;\n      const logMessage = `\"${event.type}\" event: init data type: \"${initDataType}\"`;\n      this.debug(logMessage);\n\n      // Ignore event when initData is null\n      if (initData === null) {\n        return;\n      }\n      if (!this.keyFormatPromise) {\n        let keySystems = Object.keys(this.keySystemAccessPromises);\n        if (!keySystems.length) {\n          keySystems = getKeySystemsForConfig(this.config);\n        }\n        const keyFormats = keySystems.map(keySystemDomainToKeySystemFormat).filter(k => !!k);\n        this.keyFormatPromise = this.getKeyFormatPromise(keyFormats);\n      }\n      this.keyFormatPromise.then(keySystemFormat => {\n        const keySystem = keySystemFormatToKeySystemDomain(keySystemFormat);\n        if (initDataType !== 'sinf' || keySystem !== KeySystems.FAIRPLAY) {\n          this.log(`Ignoring \"${event.type}\" event with init data type: \"${initDataType}\" for selected key-system ${keySystem}`);\n          return;\n        }\n\n        // Match sinf keyId to playlist skd://keyId=\n        let keyId;\n        try {\n          const json = bin2str(new Uint8Array(initData));\n          const sinf = base64Decode(JSON.parse(json).sinf);\n          const tenc = parseSinf(sinf);\n          if (!tenc) {\n            throw new Error(`'schm' box missing or not cbcs/cenc with schi > tenc`);\n          }\n          keyId = new Uint8Array(tenc.subarray(8, 24));\n        } catch (error) {\n          this.warn(`${logMessage} Failed to parse sinf: ${error}`);\n          return;\n        }\n        const keyIdHex = arrayToHex(keyId);\n        const {\n          keyIdToKeySessionPromise,\n          mediaKeySessions\n        } = this;\n        let keySessionContextPromise = keyIdToKeySessionPromise[keyIdHex];\n        for (let i = 0; i < mediaKeySessions.length; i++) {\n          // Match playlist key\n          const keyContext = mediaKeySessions[i];\n          const decryptdata = keyContext.decryptdata;\n          if (!decryptdata.keyId) {\n            continue;\n          }\n          const oldKeyIdHex = arrayToHex(decryptdata.keyId);\n          if (arrayValuesMatch(keyId, decryptdata.keyId) || decryptdata.uri.replace(/-/g, '').indexOf(keyIdHex) !== -1) {\n            keySessionContextPromise = keyIdToKeySessionPromise[oldKeyIdHex];\n            if (!keySessionContextPromise) {\n              continue;\n            }\n            if (decryptdata.pssh) {\n              break;\n            }\n            delete keyIdToKeySessionPromise[oldKeyIdHex];\n            decryptdata.pssh = new Uint8Array(initData);\n            decryptdata.keyId = keyId;\n            keySessionContextPromise = keyIdToKeySessionPromise[keyIdHex] = keySessionContextPromise.then(() => {\n              return this.generateRequestWithPreferredKeySession(keyContext, initDataType, initData, 'encrypted-event-key-match');\n            });\n            keySessionContextPromise.catch(error => this.handleError(error));\n            break;\n          }\n        }\n        if (!keySessionContextPromise) {\n          this.handleError(new Error(`Key ID ${keyIdHex} not encountered in playlist. Key-system sessions ${mediaKeySessions.length}.`));\n        }\n      }).catch(error => this.handleError(error));\n    };\n    this.onWaitingForKey = event => {\n      this.log(`\"${event.type}\" event`);\n    };\n    this.hls = hls;\n    this.config = hls.config;\n    this.registerListeners();\n  }\n  destroy() {\n    this.onDestroying();\n    this.onMediaDetached();\n    // Remove any references that could be held in config options or callbacks\n    const config = this.config;\n    config.requestMediaKeySystemAccessFunc = null;\n    config.licenseXhrSetup = config.licenseResponseCallback = undefined;\n    config.drmSystems = config.drmSystemOptions = {};\n    // @ts-ignore\n    this.hls = this.config = this.keyIdToKeySessionPromise = null;\n    // @ts-ignore\n    this.onMediaEncrypted = this.onWaitingForKey = null;\n  }\n  registerListeners() {\n    this.hls.on(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n    this.hls.on(Events.MEDIA_DETACHED, this.onMediaDetached, this);\n    this.hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    this.hls.on(Events.MANIFEST_LOADED, this.onManifestLoaded, this);\n    this.hls.on(Events.DESTROYING, this.onDestroying, this);\n  }\n  unregisterListeners() {\n    this.hls.off(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n    this.hls.off(Events.MEDIA_DETACHED, this.onMediaDetached, this);\n    this.hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    this.hls.off(Events.MANIFEST_LOADED, this.onManifestLoaded, this);\n    this.hls.off(Events.DESTROYING, this.onDestroying, this);\n  }\n  getLicenseServerUrl(keySystem) {\n    const {\n      drmSystems,\n      widevineLicenseUrl\n    } = this.config;\n    const keySystemConfiguration = drmSystems == null ? void 0 : drmSystems[keySystem];\n    if (keySystemConfiguration) {\n      return keySystemConfiguration.licenseUrl;\n    }\n\n    // For backward compatibility\n    if (keySystem === KeySystems.WIDEVINE && widevineLicenseUrl) {\n      return widevineLicenseUrl;\n    }\n  }\n  getLicenseServerUrlOrThrow(keySystem) {\n    const url = this.getLicenseServerUrl(keySystem);\n    if (url === undefined) {\n      throw new Error(`no license server URL configured for key-system \"${keySystem}\"`);\n    }\n    return url;\n  }\n  getServerCertificateUrl(keySystem) {\n    const {\n      drmSystems\n    } = this.config;\n    const keySystemConfiguration = drmSystems == null ? void 0 : drmSystems[keySystem];\n    if (keySystemConfiguration) {\n      return keySystemConfiguration.serverCertificateUrl;\n    } else {\n      this.log(`No Server Certificate in config.drmSystems[\"${keySystem}\"]`);\n    }\n  }\n  attemptKeySystemAccess(keySystemsToAttempt) {\n    const levels = this.hls.levels;\n    const uniqueCodec = (value, i, a) => !!value && a.indexOf(value) === i;\n    const audioCodecs = levels.map(level => level.audioCodec).filter(uniqueCodec);\n    const videoCodecs = levels.map(level => level.videoCodec).filter(uniqueCodec);\n    if (audioCodecs.length + videoCodecs.length === 0) {\n      videoCodecs.push('avc1.42e01e');\n    }\n    return new Promise((resolve, reject) => {\n      const attempt = keySystems => {\n        const keySystem = keySystems.shift();\n        this.getMediaKeysPromise(keySystem, audioCodecs, videoCodecs).then(mediaKeys => resolve({\n          keySystem,\n          mediaKeys\n        })).catch(error => {\n          if (keySystems.length) {\n            attempt(keySystems);\n          } else if (error instanceof EMEKeyError) {\n            reject(error);\n          } else {\n            reject(new EMEKeyError({\n              type: ErrorTypes.KEY_SYSTEM_ERROR,\n              details: ErrorDetails.KEY_SYSTEM_NO_ACCESS,\n              error,\n              fatal: true\n            }, error.message));\n          }\n        });\n      };\n      attempt(keySystemsToAttempt);\n    });\n  }\n  requestMediaKeySystemAccess(keySystem, supportedConfigurations) {\n    const {\n      requestMediaKeySystemAccessFunc\n    } = this.config;\n    if (!(typeof requestMediaKeySystemAccessFunc === 'function')) {\n      let errMessage = `Configured requestMediaKeySystemAccess is not a function ${requestMediaKeySystemAccessFunc}`;\n      if (requestMediaKeySystemAccess === null && self.location.protocol === 'http:') {\n        errMessage = `navigator.requestMediaKeySystemAccess is not available over insecure protocol ${location.protocol}`;\n      }\n      return Promise.reject(new Error(errMessage));\n    }\n    return requestMediaKeySystemAccessFunc(keySystem, supportedConfigurations);\n  }\n  getMediaKeysPromise(keySystem, audioCodecs, videoCodecs) {\n    var _keySystemAccessPromi;\n    // This can throw, but is caught in event handler callpath\n    const mediaKeySystemConfigs = getSupportedMediaKeySystemConfigurations(keySystem, audioCodecs, videoCodecs, this.config.drmSystemOptions || {});\n    let keySystemAccessPromises = this.keySystemAccessPromises[keySystem];\n    let keySystemAccess = (_keySystemAccessPromi = keySystemAccessPromises) == null ? void 0 : _keySystemAccessPromi.keySystemAccess;\n    if (!keySystemAccess) {\n      this.log(`Requesting encrypted media \"${keySystem}\" key-system access with config: ${stringify(mediaKeySystemConfigs)}`);\n      keySystemAccess = this.requestMediaKeySystemAccess(keySystem, mediaKeySystemConfigs);\n      const keySystemAccessPromisesNew = keySystemAccessPromises = this.keySystemAccessPromises[keySystem] = {\n        keySystemAccess\n      };\n      keySystemAccess.catch(error => {\n        this.log(`Failed to obtain access to key-system \"${keySystem}\": ${error}`);\n      });\n      return keySystemAccess.then(mediaKeySystemAccess => {\n        this.log(`Access for key-system \"${mediaKeySystemAccess.keySystem}\" obtained`);\n        const certificateRequest = this.fetchServerCertificate(keySystem);\n        this.log(`Create media-keys for \"${keySystem}\"`);\n        const mediaKeys = keySystemAccessPromisesNew.mediaKeys = mediaKeySystemAccess.createMediaKeys().then(mediaKeys => {\n          this.log(`Media-keys created for \"${keySystem}\"`);\n          keySystemAccessPromisesNew.hasMediaKeys = true;\n          return certificateRequest.then(certificate => {\n            if (certificate) {\n              return this.setMediaKeysServerCertificate(mediaKeys, keySystem, certificate);\n            }\n            return mediaKeys;\n          });\n        });\n        mediaKeys.catch(error => {\n          this.error(`Failed to create media-keys for \"${keySystem}\"}: ${error}`);\n        });\n        return mediaKeys;\n      });\n    }\n    return keySystemAccess.then(() => keySystemAccessPromises.mediaKeys);\n  }\n  createMediaKeySessionContext({\n    decryptdata,\n    keySystem,\n    mediaKeys\n  }) {\n    this.log(`Creating key-system session \"${keySystem}\" keyId: ${arrayToHex(decryptdata.keyId || [])} keyUri: ${decryptdata.uri}`);\n    const mediaKeysSession = mediaKeys.createSession();\n    const mediaKeySessionContext = {\n      decryptdata,\n      keySystem,\n      mediaKeys,\n      mediaKeysSession,\n      keyStatus: 'status-pending'\n    };\n    this.mediaKeySessions.push(mediaKeySessionContext);\n    return mediaKeySessionContext;\n  }\n  renewKeySession(mediaKeySessionContext) {\n    const decryptdata = mediaKeySessionContext.decryptdata;\n    if (decryptdata.pssh) {\n      const keySessionContext = this.createMediaKeySessionContext(mediaKeySessionContext);\n      const keyId = getKeyIdString(decryptdata);\n      const scheme = 'cenc';\n      this.keyIdToKeySessionPromise[keyId] = this.generateRequestWithPreferredKeySession(keySessionContext, scheme, decryptdata.pssh.buffer, 'expired');\n    } else {\n      this.warn(`Could not renew expired session. Missing pssh initData.`);\n    }\n    // eslint-disable-next-line @typescript-eslint/no-floating-promises\n    this.removeSession(mediaKeySessionContext);\n  }\n  updateKeySession(mediaKeySessionContext, data) {\n    const keySession = mediaKeySessionContext.mediaKeysSession;\n    this.log(`Updating key-session \"${keySession.sessionId}\" for keyId ${arrayToHex(mediaKeySessionContext.decryptdata.keyId || [])}\n      } (data length: ${data.byteLength})`);\n    return keySession.update(data);\n  }\n  getSelectedKeySystemFormats() {\n    return Object.keys(this.keySystemAccessPromises).map(keySystem => ({\n      keySystem,\n      hasMediaKeys: this.keySystemAccessPromises[keySystem].hasMediaKeys\n    })).filter(({\n      hasMediaKeys\n    }) => !!hasMediaKeys).map(({\n      keySystem\n    }) => keySystemDomainToKeySystemFormat(keySystem)).filter(keySystem => !!keySystem);\n  }\n  getKeySystemAccess(keySystemsToAttempt) {\n    return this.getKeySystemSelectionPromise(keySystemsToAttempt).then(({\n      keySystem,\n      mediaKeys\n    }) => {\n      return this.attemptSetMediaKeys(keySystem, mediaKeys);\n    });\n  }\n  selectKeySystem(keySystemsToAttempt) {\n    return new Promise((resolve, reject) => {\n      this.getKeySystemSelectionPromise(keySystemsToAttempt).then(({\n        keySystem\n      }) => {\n        const keySystemFormat = keySystemDomainToKeySystemFormat(keySystem);\n        if (keySystemFormat) {\n          resolve(keySystemFormat);\n        } else {\n          reject(new Error(`Unable to find format for key-system \"${keySystem}\"`));\n        }\n      }).catch(reject);\n    });\n  }\n  selectKeySystemFormat(frag) {\n    const keyFormats = Object.keys(frag.levelkeys || {});\n    if (!this.keyFormatPromise) {\n      this.log(`Selecting key-system from fragment (sn: ${frag.sn} ${frag.type}: ${frag.level}) key formats ${keyFormats.join(', ')}`);\n      this.keyFormatPromise = this.getKeyFormatPromise(keyFormats);\n    }\n    return this.keyFormatPromise;\n  }\n  getKeyFormatPromise(keyFormats) {\n    const keySystemsInConfig = getKeySystemsForConfig(this.config);\n    const keySystemsToAttempt = keyFormats.map(keySystemFormatToKeySystemDomain).filter(value => !!value && keySystemsInConfig.indexOf(value) !== -1);\n    return this.selectKeySystem(keySystemsToAttempt);\n  }\n  getKeyStatus(decryptdata) {\n    const {\n      mediaKeySessions\n    } = this;\n    for (let i = 0; i < mediaKeySessions.length; i++) {\n      const status = getKeyStatus(decryptdata, mediaKeySessions[i]);\n      if (status) {\n        return status;\n      }\n    }\n    return undefined;\n  }\n  loadKey(data) {\n    const decryptdata = data.keyInfo.decryptdata;\n    const keyId = getKeyIdString(decryptdata);\n    const badStatus = this.bannedKeyIds[keyId];\n    if (badStatus || this.getKeyStatus(decryptdata) === 'internal-error') {\n      const error = getKeyStatusError(badStatus || 'internal-error', decryptdata);\n      this.handleError(error, data.frag);\n      return Promise.reject(error);\n    }\n    const keyDetails = `(keyId: ${keyId} format: \"${decryptdata.keyFormat}\" method: ${decryptdata.method} uri: ${decryptdata.uri})`;\n    this.log(`Starting session for key ${keyDetails}`);\n    const keyContextPromise = this.keyIdToKeySessionPromise[keyId];\n    if (!keyContextPromise) {\n      const keySessionContextPromise = this.getKeySystemForKeyPromise(decryptdata).then(({\n        keySystem,\n        mediaKeys\n      }) => {\n        this.throwIfDestroyed();\n        this.log(`Handle encrypted media sn: ${data.frag.sn} ${data.frag.type}: ${data.frag.level} using key ${keyDetails}`);\n        return this.attemptSetMediaKeys(keySystem, mediaKeys).then(() => {\n          this.throwIfDestroyed();\n          return this.createMediaKeySessionContext({\n            keySystem,\n            mediaKeys,\n            decryptdata\n          });\n        });\n      }).then(keySessionContext => {\n        const scheme = 'cenc';\n        const initData = decryptdata.pssh ? decryptdata.pssh.buffer : null;\n        return this.generateRequestWithPreferredKeySession(keySessionContext, scheme, initData, 'playlist-key');\n      });\n      keySessionContextPromise.catch(error => this.handleError(error, data.frag));\n      this.keyIdToKeySessionPromise[keyId] = keySessionContextPromise;\n      return keySessionContextPromise;\n    }\n\n    // Re-emit error for playlist key loading\n    keyContextPromise.catch(error => {\n      if (error instanceof EMEKeyError) {\n        const errorData = _objectSpread2({}, error.data);\n        if (this.getKeyStatus(decryptdata) === 'internal-error') {\n          errorData.decryptdata = decryptdata;\n        }\n        const clonedError = new EMEKeyError(errorData, error.message);\n        this.handleError(clonedError, data.frag);\n      }\n    });\n    return keyContextPromise;\n  }\n  throwIfDestroyed(message = 'Invalid state') {\n    if (!this.hls) {\n      throw new Error('invalid state');\n    }\n  }\n  handleError(error, frag) {\n    if (!this.hls) {\n      return;\n    }\n    if (error instanceof EMEKeyError) {\n      if (frag) {\n        error.data.frag = frag;\n      }\n      const levelKey = error.data.decryptdata;\n      this.error(`${error.message}${levelKey ? ` (${arrayToHex(levelKey.keyId || [])})` : ''}`);\n      this.hls.trigger(Events.ERROR, error.data);\n    } else {\n      this.error(error.message);\n      this.hls.trigger(Events.ERROR, {\n        type: ErrorTypes.KEY_SYSTEM_ERROR,\n        details: ErrorDetails.KEY_SYSTEM_NO_KEYS,\n        error,\n        fatal: true\n      });\n    }\n  }\n  getKeySystemForKeyPromise(decryptdata) {\n    const keyId = getKeyIdString(decryptdata);\n    const mediaKeySessionContext = this.keyIdToKeySessionPromise[keyId];\n    if (!mediaKeySessionContext) {\n      const keySystem = keySystemFormatToKeySystemDomain(decryptdata.keyFormat);\n      const keySystemsToAttempt = keySystem ? [keySystem] : getKeySystemsForConfig(this.config);\n      return this.attemptKeySystemAccess(keySystemsToAttempt);\n    }\n    return mediaKeySessionContext;\n  }\n  getKeySystemSelectionPromise(keySystemsToAttempt) {\n    if (!keySystemsToAttempt.length) {\n      keySystemsToAttempt = getKeySystemsForConfig(this.config);\n    }\n    if (keySystemsToAttempt.length === 0) {\n      throw new EMEKeyError({\n        type: ErrorTypes.KEY_SYSTEM_ERROR,\n        details: ErrorDetails.KEY_SYSTEM_NO_CONFIGURED_LICENSE,\n        fatal: true\n      }, `Missing key-system license configuration options ${stringify({\n        drmSystems: this.config.drmSystems\n      })}`);\n    }\n    return this.attemptKeySystemAccess(keySystemsToAttempt);\n  }\n  attemptSetMediaKeys(keySystem, mediaKeys) {\n    this.mediaResolved = undefined;\n    if (this.mediaKeys === mediaKeys) {\n      return Promise.resolve();\n    }\n    const queue = this.setMediaKeysQueue.slice();\n    this.log(`Setting media-keys for \"${keySystem}\"`);\n    // Only one setMediaKeys() can run at one time, and multiple setMediaKeys() operations\n    // can be queued for execution for multiple key sessions.\n    const setMediaKeysPromise = Promise.all(queue).then(() => {\n      if (!this.media) {\n        return new Promise((resolve, reject) => {\n          this.mediaResolved = () => {\n            this.mediaResolved = undefined;\n            if (!this.media) {\n              return reject(new Error('Attempted to set mediaKeys without media element attached'));\n            }\n            this.mediaKeys = mediaKeys;\n            this.media.setMediaKeys(mediaKeys).then(resolve).catch(reject);\n          };\n        });\n      }\n      return this.media.setMediaKeys(mediaKeys);\n    });\n    this.mediaKeys = mediaKeys;\n    this.setMediaKeysQueue.push(setMediaKeysPromise);\n    return setMediaKeysPromise.then(() => {\n      this.log(`Media-keys set for \"${keySystem}\"`);\n      queue.push(setMediaKeysPromise);\n      this.setMediaKeysQueue = this.setMediaKeysQueue.filter(p => queue.indexOf(p) === -1);\n    });\n  }\n  generateRequestWithPreferredKeySession(context, initDataType, initData, reason) {\n    var _this$config$drmSyste;\n    const generateRequestFilter = (_this$config$drmSyste = this.config.drmSystems) == null || (_this$config$drmSyste = _this$config$drmSyste[context.keySystem]) == null ? void 0 : _this$config$drmSyste.generateRequest;\n    if (generateRequestFilter) {\n      try {\n        const mappedInitData = generateRequestFilter.call(this.hls, initDataType, initData, context);\n        if (!mappedInitData) {\n          throw new Error('Invalid response from configured generateRequest filter');\n        }\n        initDataType = mappedInitData.initDataType;\n        initData = mappedInitData.initData ? mappedInitData.initData : null;\n        context.decryptdata.pssh = initData ? new Uint8Array(initData) : null;\n      } catch (error) {\n        this.warn(error.message);\n        if (this.hls && this.hls.config.debug) {\n          throw error;\n        }\n      }\n    }\n    if (initData === null) {\n      this.log(`Skipping key-session request for \"${reason}\" (no initData)`);\n      return Promise.resolve(context);\n    }\n    const keyId = getKeyIdString(context.decryptdata);\n    const keyUri = context.decryptdata.uri;\n    this.log(`Generating key-session request for \"${reason}\" keyId: ${keyId} URI: ${keyUri} (init data type: ${initDataType} length: ${initData.byteLength})`);\n    const licenseStatus = new EventEmitter();\n    const onmessage = context._onmessage = event => {\n      const keySession = context.mediaKeysSession;\n      if (!keySession) {\n        licenseStatus.emit('error', new Error('invalid state'));\n        return;\n      }\n      const {\n        messageType,\n        message\n      } = event;\n      this.log(`\"${messageType}\" message event for session \"${keySession.sessionId}\" message size: ${message.byteLength}`);\n      if (messageType === 'license-request' || messageType === 'license-renewal') {\n        this.renewLicense(context, message).catch(error => {\n          if (licenseStatus.eventNames().length) {\n            licenseStatus.emit('error', error);\n          } else {\n            this.handleError(error);\n          }\n        });\n      } else if (messageType === 'license-release') {\n        if (context.keySystem === KeySystems.FAIRPLAY) {\n          this.updateKeySession(context, strToUtf8array('acknowledged')).then(() => this.removeSession(context)).catch(error => this.handleError(error));\n        }\n      } else {\n        this.warn(`unhandled media key message type \"${messageType}\"`);\n      }\n    };\n    const handleKeyStatus = (keyStatus, context) => {\n      context.keyStatus = keyStatus;\n      let keyError;\n      if (keyStatus.startsWith('usable')) {\n        licenseStatus.emit('resolved');\n      } else if (keyStatus === 'internal-error' || keyStatus === 'output-restricted' || keyStatus === 'output-downscaled') {\n        keyError = getKeyStatusError(keyStatus, context.decryptdata);\n      } else if (keyStatus === 'expired') {\n        keyError = new Error(`key expired (keyId: ${keyId})`);\n      } else if (keyStatus === 'released') {\n        keyError = new Error(`key released`);\n      } else if (keyStatus === 'status-pending') ; else {\n        this.warn(`unhandled key status change \"${keyStatus}\" (keyId: ${keyId})`);\n      }\n      if (keyError) {\n        if (licenseStatus.eventNames().length) {\n          licenseStatus.emit('error', keyError);\n        } else {\n          this.handleError(keyError);\n        }\n      }\n    };\n    const onkeystatuseschange = context._onkeystatuseschange = event => {\n      const keySession = context.mediaKeysSession;\n      if (!keySession) {\n        licenseStatus.emit('error', new Error('invalid state'));\n        return;\n      }\n      const keyStatuses = this.getKeyStatuses(context);\n      const keyIds = Object.keys(keyStatuses);\n\n      // exit if all keys are status-pending\n      if (!keyIds.some(id => keyStatuses[id] !== 'status-pending')) {\n        return;\n      }\n\n      // renew when a key status for a levelKey comes back expired\n      if (keyStatuses[keyId] === 'expired') {\n        // renew when a key status comes back expired\n        this.log(`Expired key ${stringify(keyStatuses)} in key-session \"${context.mediaKeysSession.sessionId}\"`);\n        this.renewKeySession(context);\n        return;\n      }\n      let keyStatus = keyStatuses[keyId];\n      if (keyStatus) {\n        // handle status of current key\n        handleKeyStatus(keyStatus, context);\n      } else {\n        var _context$keyStatusTim;\n        // Timeout key-status\n        const timeout = 1000;\n        context.keyStatusTimeouts || (context.keyStatusTimeouts = {});\n        (_context$keyStatusTim = context.keyStatusTimeouts)[keyId] || (_context$keyStatusTim[keyId] = self.setTimeout(() => {\n          if (!context.mediaKeysSession || !this.mediaKeys) {\n            return;\n          }\n\n          // Find key status in another session if missing (PlayReady #7519 no key-status \"single-key\" setup with shared key)\n          const sessionKeyStatus = this.getKeyStatus(context.decryptdata);\n          if (sessionKeyStatus && sessionKeyStatus !== 'status-pending') {\n            this.log(`No status for keyId ${keyId} in key-session \"${context.mediaKeysSession.sessionId}\". Using session key-status ${sessionKeyStatus} from other session.`);\n            return handleKeyStatus(sessionKeyStatus, context);\n          }\n\n          // Timeout key with internal-error\n          this.log(`key status for ${keyId} in key-session \"${context.mediaKeysSession.sessionId}\" timed out after ${timeout}ms`);\n          keyStatus = 'internal-error';\n          handleKeyStatus(keyStatus, context);\n        }, timeout));\n        this.log(`No status for keyId ${keyId} (${stringify(keyStatuses)}).`);\n      }\n    };\n    addEventListener(context.mediaKeysSession, 'message', onmessage);\n    addEventListener(context.mediaKeysSession, 'keystatuseschange', onkeystatuseschange);\n    const keyUsablePromise = new Promise((resolve, reject) => {\n      licenseStatus.on('error', reject);\n      licenseStatus.on('resolved', resolve);\n    });\n    return context.mediaKeysSession.generateRequest(initDataType, initData).then(() => {\n      this.log(`Request generated for key-session \"${context.mediaKeysSession.sessionId}\" keyId: ${keyId} URI: ${keyUri}`);\n    }).catch(error => {\n      throw new EMEKeyError({\n        type: ErrorTypes.KEY_SYSTEM_ERROR,\n        details: ErrorDetails.KEY_SYSTEM_NO_SESSION,\n        error,\n        decryptdata: context.decryptdata,\n        fatal: false\n      }, `Error generating key-session request: ${error}`);\n    }).then(() => keyUsablePromise).catch(error => {\n      licenseStatus.removeAllListeners();\n      return this.removeSession(context).then(() => {\n        throw error;\n      });\n    }).then(() => {\n      licenseStatus.removeAllListeners();\n      return context;\n    });\n  }\n  getKeyStatuses(mediaKeySessionContext) {\n    const keyStatuses = {};\n    mediaKeySessionContext.mediaKeysSession.keyStatuses.forEach((status, keyId) => {\n      // keyStatuses.forEach is not standard API so the callback value looks weird on xboxone\n      // xboxone callback(keyId, status) so we need to exchange them\n      if (typeof keyId === 'string' && typeof status === 'object') {\n        const temp = keyId;\n        keyId = status;\n        status = temp;\n      }\n      const keyIdArray = 'buffer' in keyId ? new Uint8Array(keyId.buffer, keyId.byteOffset, keyId.byteLength) : new Uint8Array(keyId);\n      if (mediaKeySessionContext.keySystem === KeySystems.PLAYREADY && keyIdArray.length === 16) {\n        // On some devices, the key ID has already been converted for endianness.\n        // In such cases, this key ID is the one we need to cache.\n        const originKeyIdWithStatusChange = arrayToHex(keyIdArray);\n        // Cache the original key IDs to ensure compatibility across all cases.\n        keyStatuses[originKeyIdWithStatusChange] = status;\n        changeEndianness(keyIdArray);\n      }\n      const keyIdWithStatusChange = arrayToHex(keyIdArray);\n      // Add to banned keys to prevent playlist usage and license requests\n      if (status === 'internal-error') {\n        this.bannedKeyIds[keyIdWithStatusChange] = status;\n      }\n      this.log(`key status change \"${status}\" for keyStatuses keyId: ${keyIdWithStatusChange} key-session \"${mediaKeySessionContext.mediaKeysSession.sessionId}\"`);\n      keyStatuses[keyIdWithStatusChange] = status;\n    });\n    return keyStatuses;\n  }\n  fetchServerCertificate(keySystem) {\n    const config = this.config;\n    const Loader = config.loader;\n    const certLoader = new Loader(config);\n    const url = this.getServerCertificateUrl(keySystem);\n    if (!url) {\n      return Promise.resolve();\n    }\n    this.log(`Fetching server certificate for \"${keySystem}\"`);\n    return new Promise((resolve, reject) => {\n      const loaderContext = {\n        responseType: 'arraybuffer',\n        url\n      };\n      const loadPolicy = config.certLoadPolicy.default;\n      const loaderConfig = {\n        loadPolicy,\n        timeout: loadPolicy.maxLoadTimeMs,\n        maxRetry: 0,\n        retryDelay: 0,\n        maxRetryDelay: 0\n      };\n      const loaderCallbacks = {\n        onSuccess: (response, stats, context, networkDetails) => {\n          resolve(response.data);\n        },\n        onError: (response, contex, networkDetails, stats) => {\n          reject(new EMEKeyError({\n            type: ErrorTypes.KEY_SYSTEM_ERROR,\n            details: ErrorDetails.KEY_SYSTEM_SERVER_CERTIFICATE_REQUEST_FAILED,\n            fatal: true,\n            networkDetails,\n            response: _objectSpread2({\n              url: loaderContext.url,\n              data: undefined\n            }, response)\n          }, `\"${keySystem}\" certificate request failed (${url}). Status: ${response.code} (${response.text})`));\n        },\n        onTimeout: (stats, context, networkDetails) => {\n          reject(new EMEKeyError({\n            type: ErrorTypes.KEY_SYSTEM_ERROR,\n            details: ErrorDetails.KEY_SYSTEM_SERVER_CERTIFICATE_REQUEST_FAILED,\n            fatal: true,\n            networkDetails,\n            response: {\n              url: loaderContext.url,\n              data: undefined\n            }\n          }, `\"${keySystem}\" certificate request timed out (${url})`));\n        },\n        onAbort: (stats, context, networkDetails) => {\n          reject(new Error('aborted'));\n        }\n      };\n      certLoader.load(loaderContext, loaderConfig, loaderCallbacks);\n    });\n  }\n  setMediaKeysServerCertificate(mediaKeys, keySystem, cert) {\n    return new Promise((resolve, reject) => {\n      mediaKeys.setServerCertificate(cert).then(success => {\n        this.log(`setServerCertificate ${success ? 'success' : 'not supported by CDM'} (${cert.byteLength}) on \"${keySystem}\"`);\n        resolve(mediaKeys);\n      }).catch(error => {\n        reject(new EMEKeyError({\n          type: ErrorTypes.KEY_SYSTEM_ERROR,\n          details: ErrorDetails.KEY_SYSTEM_SERVER_CERTIFICATE_UPDATE_FAILED,\n          error,\n          fatal: true\n        }, error.message));\n      });\n    });\n  }\n  renewLicense(context, keyMessage) {\n    return this.requestLicense(context, new Uint8Array(keyMessage)).then(data => {\n      return this.updateKeySession(context, new Uint8Array(data)).catch(error => {\n        throw new EMEKeyError({\n          type: ErrorTypes.KEY_SYSTEM_ERROR,\n          details: ErrorDetails.KEY_SYSTEM_SESSION_UPDATE_FAILED,\n          decryptdata: context.decryptdata,\n          error,\n          fatal: false\n        }, error.message);\n      });\n    });\n  }\n  unpackPlayReadyKeyMessage(xhr, licenseChallenge) {\n    // On Edge, the raw license message is UTF-16-encoded XML.  We need\n    // to unpack the Challenge element (base64-encoded string containing the\n    // actual license request) and any HttpHeader elements (sent as request\n    // headers).\n    // For PlayReady CDMs, we need to dig the Challenge out of the XML.\n    const xmlString = String.fromCharCode.apply(null, new Uint16Array(licenseChallenge.buffer));\n    if (!xmlString.includes('PlayReadyKeyMessage')) {\n      // This does not appear to be a wrapped message as on Edge.  Some\n      // clients do not need this unwrapping, so we will assume this is one of\n      // them.  Note that \"xml\" at this point probably looks like random\n      // garbage, since we interpreted UTF-8 as UTF-16.\n      xhr.setRequestHeader('Content-Type', 'text/xml; charset=utf-8');\n      return licenseChallenge;\n    }\n    const keyMessageXml = new DOMParser().parseFromString(xmlString, 'application/xml');\n    // Set request headers.\n    const headers = keyMessageXml.querySelectorAll('HttpHeader');\n    if (headers.length > 0) {\n      let header;\n      for (let i = 0, len = headers.length; i < len; i++) {\n        var _header$querySelector, _header$querySelector2;\n        header = headers[i];\n        const name = (_header$querySelector = header.querySelector('name')) == null ? void 0 : _header$querySelector.textContent;\n        const value = (_header$querySelector2 = header.querySelector('value')) == null ? void 0 : _header$querySelector2.textContent;\n        if (name && value) {\n          xhr.setRequestHeader(name, value);\n        }\n      }\n    }\n    const challengeElement = keyMessageXml.querySelector('Challenge');\n    const challengeText = challengeElement == null ? void 0 : challengeElement.textContent;\n    if (!challengeText) {\n      throw new Error(`Cannot find <Challenge> in key message`);\n    }\n    return strToUtf8array(atob(challengeText));\n  }\n  setupLicenseXHR(xhr, url, keysListItem, licenseChallenge) {\n    const licenseXhrSetup = this.config.licenseXhrSetup;\n    if (!licenseXhrSetup) {\n      xhr.open('POST', url, true);\n      return Promise.resolve({\n        xhr,\n        licenseChallenge\n      });\n    }\n    return Promise.resolve().then(() => {\n      if (!keysListItem.decryptdata) {\n        throw new Error('Key removed');\n      }\n      return licenseXhrSetup.call(this.hls, xhr, url, keysListItem, licenseChallenge);\n    }).catch(error => {\n      if (!keysListItem.decryptdata) {\n        // Key session removed. Cancel license request.\n        throw error;\n      }\n      // let's try to open before running setup\n      xhr.open('POST', url, true);\n      return licenseXhrSetup.call(this.hls, xhr, url, keysListItem, licenseChallenge);\n    }).then(licenseXhrSetupResult => {\n      // if licenseXhrSetup did not yet call open, let's do it now\n      if (!xhr.readyState) {\n        xhr.open('POST', url, true);\n      }\n      const finalLicenseChallenge = licenseXhrSetupResult ? licenseXhrSetupResult : licenseChallenge;\n      return {\n        xhr,\n        licenseChallenge: finalLicenseChallenge\n      };\n    });\n  }\n  requestLicense(keySessionContext, licenseChallenge) {\n    const keyLoadPolicy = this.config.keyLoadPolicy.default;\n    return new Promise((resolve, reject) => {\n      const url = this.getLicenseServerUrlOrThrow(keySessionContext.keySystem);\n      this.log(`Sending license request to URL: ${url}`);\n      const xhr = new XMLHttpRequest();\n      xhr.responseType = 'arraybuffer';\n      xhr.onreadystatechange = () => {\n        if (!this.hls || !keySessionContext.mediaKeysSession) {\n          return reject(new Error('invalid state'));\n        }\n        if (xhr.readyState === 4) {\n          if (xhr.status === 200) {\n            this._requestLicenseFailureCount = 0;\n            let data = xhr.response;\n            this.log(`License received ${data instanceof ArrayBuffer ? data.byteLength : data}`);\n            const licenseResponseCallback = this.config.licenseResponseCallback;\n            if (licenseResponseCallback) {\n              try {\n                data = licenseResponseCallback.call(this.hls, xhr, url, keySessionContext);\n              } catch (error) {\n                this.error(error);\n              }\n            }\n            resolve(data);\n          } else {\n            const retryConfig = keyLoadPolicy.errorRetry;\n            const maxNumRetry = retryConfig ? retryConfig.maxNumRetry : 0;\n            this._requestLicenseFailureCount++;\n            if (this._requestLicenseFailureCount > maxNumRetry || xhr.status >= 400 && xhr.status < 500) {\n              reject(new EMEKeyError({\n                type: ErrorTypes.KEY_SYSTEM_ERROR,\n                details: ErrorDetails.KEY_SYSTEM_LICENSE_REQUEST_FAILED,\n                decryptdata: keySessionContext.decryptdata,\n                fatal: true,\n                networkDetails: xhr,\n                response: {\n                  url,\n                  data: undefined,\n                  code: xhr.status,\n                  text: xhr.statusText\n                }\n              }, `License Request XHR failed (${url}). Status: ${xhr.status} (${xhr.statusText})`));\n            } else {\n              const attemptsLeft = maxNumRetry - this._requestLicenseFailureCount + 1;\n              this.warn(`Retrying license request, ${attemptsLeft} attempts left`);\n              this.requestLicense(keySessionContext, licenseChallenge).then(resolve, reject);\n            }\n          }\n        }\n      };\n      if (keySessionContext.licenseXhr && keySessionContext.licenseXhr.readyState !== XMLHttpRequest.DONE) {\n        keySessionContext.licenseXhr.abort();\n      }\n      keySessionContext.licenseXhr = xhr;\n      this.setupLicenseXHR(xhr, url, keySessionContext, licenseChallenge).then(({\n        xhr,\n        licenseChallenge\n      }) => {\n        if (keySessionContext.keySystem == KeySystems.PLAYREADY) {\n          licenseChallenge = this.unpackPlayReadyKeyMessage(xhr, licenseChallenge);\n        }\n        xhr.send(licenseChallenge);\n      }).catch(reject);\n    });\n  }\n  onDestroying() {\n    this.unregisterListeners();\n    this._clear();\n  }\n  onMediaAttached(event, data) {\n    if (!this.config.emeEnabled) {\n      return;\n    }\n    const media = data.media;\n\n    // keep reference of media\n    this.media = media;\n    addEventListener(media, 'encrypted', this.onMediaEncrypted);\n    addEventListener(media, 'waitingforkey', this.onWaitingForKey);\n    const mediaResolved = this.mediaResolved;\n    if (mediaResolved) {\n      mediaResolved();\n    } else {\n      this.mediaKeys = media.mediaKeys;\n    }\n  }\n  onMediaDetached() {\n    const media = this.media;\n    if (media) {\n      removeEventListener(media, 'encrypted', this.onMediaEncrypted);\n      removeEventListener(media, 'waitingforkey', this.onWaitingForKey);\n      this.media = null;\n      this.mediaKeys = null;\n    }\n  }\n  _clear() {\n    var _media$setMediaKeys;\n    this._requestLicenseFailureCount = 0;\n    this.keyIdToKeySessionPromise = {};\n    this.bannedKeyIds = {};\n    const mediaResolved = this.mediaResolved;\n    if (mediaResolved) {\n      mediaResolved();\n    }\n    if (!this.mediaKeys && !this.mediaKeySessions.length) {\n      return;\n    }\n    const media = this.media;\n    const mediaKeysList = this.mediaKeySessions.slice();\n    this.mediaKeySessions = [];\n    this.mediaKeys = null;\n    LevelKey.clearKeyUriToKeyIdMap();\n\n    // Close all sessions and remove media keys from the video element.\n    const keySessionCount = mediaKeysList.length;\n    EMEController.CDMCleanupPromise = Promise.all(mediaKeysList.map(mediaKeySessionContext => this.removeSession(mediaKeySessionContext)).concat((media == null || (_media$setMediaKeys = media.setMediaKeys(null)) == null ? void 0 : _media$setMediaKeys.catch(error => {\n      this.log(`Could not clear media keys: ${error}`);\n      if (!this.hls) return;\n      this.hls.trigger(Events.ERROR, {\n        type: ErrorTypes.OTHER_ERROR,\n        details: ErrorDetails.KEY_SYSTEM_DESTROY_MEDIA_KEYS_ERROR,\n        fatal: false,\n        error: new Error(`Could not clear media keys: ${error}`)\n      });\n    })) || Promise.resolve())).catch(error => {\n      this.log(`Could not close sessions and clear media keys: ${error}`);\n      if (!this.hls) return;\n      this.hls.trigger(Events.ERROR, {\n        type: ErrorTypes.OTHER_ERROR,\n        details: ErrorDetails.KEY_SYSTEM_DESTROY_CLOSE_SESSION_ERROR,\n        fatal: false,\n        error: new Error(`Could not close sessions and clear media keys: ${error}`)\n      });\n    }).then(() => {\n      if (keySessionCount) {\n        this.log('finished closing key sessions and clearing media keys');\n      }\n    });\n  }\n  onManifestLoading() {\n    this._clear();\n  }\n  onManifestLoaded(event, {\n    sessionKeys\n  }) {\n    if (!sessionKeys || !this.config.emeEnabled) {\n      return;\n    }\n    if (!this.keyFormatPromise) {\n      const keyFormats = sessionKeys.reduce((formats, sessionKey) => {\n        if (formats.indexOf(sessionKey.keyFormat) === -1) {\n          formats.push(sessionKey.keyFormat);\n        }\n        return formats;\n      }, []);\n      this.log(`Selecting key-system from session-keys ${keyFormats.join(', ')}`);\n      this.keyFormatPromise = this.getKeyFormatPromise(keyFormats);\n    }\n  }\n  removeSession(mediaKeySessionContext) {\n    const {\n      mediaKeysSession,\n      licenseXhr,\n      decryptdata\n    } = mediaKeySessionContext;\n    if (mediaKeysSession) {\n      this.log(`Remove licenses and keys and close session \"${mediaKeysSession.sessionId}\" keyId: ${arrayToHex((decryptdata == null ? void 0 : decryptdata.keyId) || [])}`);\n      if (mediaKeySessionContext._onmessage) {\n        mediaKeysSession.removeEventListener('message', mediaKeySessionContext._onmessage);\n        mediaKeySessionContext._onmessage = undefined;\n      }\n      if (mediaKeySessionContext._onkeystatuseschange) {\n        mediaKeysSession.removeEventListener('keystatuseschange', mediaKeySessionContext._onkeystatuseschange);\n        mediaKeySessionContext._onkeystatuseschange = undefined;\n      }\n      if (licenseXhr && licenseXhr.readyState !== XMLHttpRequest.DONE) {\n        licenseXhr.abort();\n      }\n      mediaKeySessionContext.mediaKeysSession = mediaKeySessionContext.decryptdata = mediaKeySessionContext.licenseXhr = undefined;\n      const index = this.mediaKeySessions.indexOf(mediaKeySessionContext);\n      if (index > -1) {\n        this.mediaKeySessions.splice(index, 1);\n      }\n      const {\n        keyStatusTimeouts\n      } = mediaKeySessionContext;\n      if (keyStatusTimeouts) {\n        Object.keys(keyStatusTimeouts).forEach(keyId => self.clearTimeout(keyStatusTimeouts[keyId]));\n      }\n      const {\n        drmSystemOptions\n      } = this.config;\n      const removePromise = isPersistentSessionType(drmSystemOptions) ? new Promise((resolve, reject) => {\n        self.setTimeout(() => reject(new Error(`MediaKeySession.remove() timeout`)), 8000);\n        mediaKeysSession.remove().then(resolve).catch(reject);\n      }) : Promise.resolve();\n      return removePromise.catch(error => {\n        this.log(`Could not remove session: ${error}`);\n        if (!this.hls) return;\n        this.hls.trigger(Events.ERROR, {\n          type: ErrorTypes.OTHER_ERROR,\n          details: ErrorDetails.KEY_SYSTEM_DESTROY_REMOVE_SESSION_ERROR,\n          fatal: false,\n          error: new Error(`Could not remove session: ${error}`)\n        });\n      }).then(() => {\n        return mediaKeysSession.close();\n      }).catch(error => {\n        this.log(`Could not close session: ${error}`);\n        if (!this.hls) return;\n        this.hls.trigger(Events.ERROR, {\n          type: ErrorTypes.OTHER_ERROR,\n          details: ErrorDetails.KEY_SYSTEM_DESTROY_CLOSE_SESSION_ERROR,\n          fatal: false,\n          error: new Error(`Could not close session: ${error}`)\n        });\n      });\n    }\n    return Promise.resolve();\n  }\n}\nEMEController.CDMCleanupPromise = void 0;\nfunction getKeyIdString(decryptdata) {\n  if (!decryptdata) {\n    throw new Error('Could not read keyId of undefined decryptdata');\n  }\n  if (decryptdata.keyId === null) {\n    throw new Error('keyId is null');\n  }\n  return arrayToHex(decryptdata.keyId);\n}\nfunction getKeyStatus(decryptdata, keyContext) {\n  if (decryptdata.keyId && keyContext.mediaKeysSession.keyStatuses.has(decryptdata.keyId)) {\n    return keyContext.mediaKeysSession.keyStatuses.get(decryptdata.keyId);\n  }\n  if (decryptdata.matches(keyContext.decryptdata)) {\n    return keyContext.keyStatus;\n  }\n  return undefined;\n}\nclass EMEKeyError extends Error {\n  constructor(data, message) {\n    super(message);\n    this.data = void 0;\n    data.error || (data.error = new Error(message));\n    this.data = data;\n    data.err = data.error;\n  }\n}\nfunction getKeyStatusError(keyStatus, decryptdata) {\n  const outputRestricted = keyStatus === 'output-restricted';\n  const details = outputRestricted ? ErrorDetails.KEY_SYSTEM_STATUS_OUTPUT_RESTRICTED : ErrorDetails.KEY_SYSTEM_STATUS_INTERNAL_ERROR;\n  return new EMEKeyError({\n    type: ErrorTypes.KEY_SYSTEM_ERROR,\n    details,\n    fatal: false,\n    decryptdata\n  }, outputRestricted ? 'HDCP level output restricted' : `key status changed to \"${keyStatus}\"`);\n}\n\nclass FPSController {\n  constructor(hls) {\n    this.hls = void 0;\n    this.isVideoPlaybackQualityAvailable = false;\n    this.timer = void 0;\n    this.media = null;\n    this.lastTime = void 0;\n    this.lastDroppedFrames = 0;\n    this.lastDecodedFrames = 0;\n    // stream controller must be provided as a dependency!\n    this.streamController = void 0;\n    this.hls = hls;\n    this.registerListeners();\n  }\n  setStreamController(streamController) {\n    this.streamController = streamController;\n  }\n  registerListeners() {\n    this.hls.on(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);\n    this.hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n  }\n  unregisterListeners() {\n    this.hls.off(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);\n    this.hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n  }\n  destroy() {\n    if (this.timer) {\n      clearInterval(this.timer);\n    }\n    this.unregisterListeners();\n    this.isVideoPlaybackQualityAvailable = false;\n    this.media = null;\n  }\n  onMediaAttaching(event, data) {\n    const config = this.hls.config;\n    if (config.capLevelOnFPSDrop) {\n      const media = data.media instanceof self.HTMLVideoElement ? data.media : null;\n      this.media = media;\n      if (media && typeof media.getVideoPlaybackQuality === 'function') {\n        this.isVideoPlaybackQualityAvailable = true;\n      }\n      self.clearInterval(this.timer);\n      this.timer = self.setInterval(this.checkFPSInterval.bind(this), config.fpsDroppedMonitoringPeriod);\n    }\n  }\n  onMediaDetaching() {\n    this.media = null;\n  }\n  checkFPS(video, decodedFrames, droppedFrames) {\n    const currentTime = performance.now();\n    if (decodedFrames) {\n      if (this.lastTime) {\n        const currentPeriod = currentTime - this.lastTime;\n        const currentDropped = droppedFrames - this.lastDroppedFrames;\n        const currentDecoded = decodedFrames - this.lastDecodedFrames;\n        const droppedFPS = 1000 * currentDropped / currentPeriod;\n        const hls = this.hls;\n        hls.trigger(Events.FPS_DROP, {\n          currentDropped: currentDropped,\n          currentDecoded: currentDecoded,\n          totalDroppedFrames: droppedFrames\n        });\n        if (droppedFPS > 0) {\n          // hls.logger.log('checkFPS : droppedFPS/decodedFPS:' + droppedFPS/(1000 * currentDecoded / currentPeriod));\n          if (currentDropped > hls.config.fpsDroppedMonitoringThreshold * currentDecoded) {\n            let currentLevel = hls.currentLevel;\n            hls.logger.warn('drop FPS ratio greater than max allowed value for currentLevel: ' + currentLevel);\n            if (currentLevel > 0 && (hls.autoLevelCapping === -1 || hls.autoLevelCapping >= currentLevel)) {\n              currentLevel = currentLevel - 1;\n              hls.trigger(Events.FPS_DROP_LEVEL_CAPPING, {\n                level: currentLevel,\n                droppedLevel: hls.currentLevel\n              });\n              hls.autoLevelCapping = currentLevel;\n              this.streamController.nextLevelSwitch();\n            }\n          }\n        }\n      }\n      this.lastTime = currentTime;\n      this.lastDroppedFrames = droppedFrames;\n      this.lastDecodedFrames = decodedFrames;\n    }\n  }\n  checkFPSInterval() {\n    const video = this.media;\n    if (video) {\n      if (this.isVideoPlaybackQualityAvailable) {\n        const videoPlaybackQuality = video.getVideoPlaybackQuality();\n        this.checkFPS(video, videoPlaybackQuality.totalVideoFrames, videoPlaybackQuality.droppedVideoFrames);\n      } else {\n        // HTMLVideoElement doesn't include the webkit types\n        this.checkFPS(video, video.webkitDecodedFrameCount, video.webkitDroppedFrameCount);\n      }\n    }\n  }\n}\n\nfunction sendAddTrackEvent(track, videoEl) {\n  let event;\n  try {\n    event = new Event('addtrack');\n  } catch (err) {\n    // for IE11\n    event = document.createEvent('Event');\n    event.initEvent('addtrack', false, false);\n  }\n  event.track = track;\n  videoEl.dispatchEvent(event);\n}\nfunction addCueToTrack(track, cue) {\n  // Sometimes there are cue overlaps on segmented vtts so the same\n  // cue can appear more than once in different vtt files.\n  // This avoid showing duplicated cues with same timecode and text.\n  const mode = track.mode;\n  if (mode === 'disabled') {\n    track.mode = 'hidden';\n  }\n  if (track.cues && !track.cues.getCueById(cue.id)) {\n    try {\n      track.addCue(cue);\n      if (!track.cues.getCueById(cue.id)) {\n        throw new Error(`addCue is failed for: ${cue}`);\n      }\n    } catch (err) {\n      logger.debug(`[texttrack-utils]: ${err}`);\n      try {\n        const textTrackCue = new self.TextTrackCue(cue.startTime, cue.endTime, cue.text);\n        textTrackCue.id = cue.id;\n        track.addCue(textTrackCue);\n      } catch (err2) {\n        logger.debug(`[texttrack-utils]: Legacy TextTrackCue fallback failed: ${err2}`);\n      }\n    }\n  }\n  if (mode === 'disabled') {\n    track.mode = mode;\n  }\n}\nfunction clearCurrentCues(track, enterHandler) {\n  // When track.mode is disabled, track.cues will be null.\n  // To guarantee the removal of cues, we need to temporarily\n  // change the mode to hidden\n  const mode = track.mode;\n  if (mode === 'disabled') {\n    track.mode = 'hidden';\n  }\n  if (track.cues) {\n    for (let i = track.cues.length; i--;) {\n      if (enterHandler) {\n        track.cues[i].removeEventListener('enter', enterHandler);\n      }\n      track.removeCue(track.cues[i]);\n    }\n  }\n  if (mode === 'disabled') {\n    track.mode = mode;\n  }\n}\nfunction removeCuesInRange(track, start, end, predicate) {\n  const mode = track.mode;\n  if (mode === 'disabled') {\n    track.mode = 'hidden';\n  }\n  if (track.cues && track.cues.length > 0) {\n    const cues = getCuesInRange(track.cues, start, end);\n    for (let i = 0; i < cues.length; i++) {\n      if (!predicate || predicate(cues[i])) {\n        track.removeCue(cues[i]);\n      }\n    }\n  }\n  if (mode === 'disabled') {\n    track.mode = mode;\n  }\n}\n\n// Find first cue starting at or after given time.\n// Modified version of binary search O(log(n)).\nfunction getFirstCueIndexFromTime(cues, time) {\n  // If first cue starts at or after time, start there\n  if (time <= cues[0].startTime) {\n    return 0;\n  }\n  // If the last cue ends before time there is no overlap\n  const len = cues.length - 1;\n  if (time > cues[len].endTime) {\n    return -1;\n  }\n  let left = 0;\n  let right = len;\n  let mid;\n  while (left <= right) {\n    mid = Math.floor((right + left) / 2);\n    if (time < cues[mid].startTime) {\n      right = mid - 1;\n    } else if (time > cues[mid].startTime && left < len) {\n      left = mid + 1;\n    } else {\n      // If it's not lower or higher, it must be equal.\n      return mid;\n    }\n  }\n  // At this point, left and right have swapped.\n  // No direct match was found, left or right element must be the closest. Check which one has the smallest diff.\n  return cues[left].startTime - time < time - cues[right].startTime ? left : right;\n}\nfunction getCuesInRange(cues, start, end) {\n  const cuesFound = [];\n  const firstCueInRange = getFirstCueIndexFromTime(cues, start);\n  if (firstCueInRange > -1) {\n    for (let i = firstCueInRange, len = cues.length; i < len; i++) {\n      const cue = cues[i];\n      if (cue.startTime >= start && cue.endTime <= end) {\n        cuesFound.push(cue);\n      } else if (cue.startTime > end) {\n        return cuesFound;\n      }\n    }\n  }\n  return cuesFound;\n}\nfunction filterSubtitleTracks(textTrackList) {\n  const tracks = [];\n  for (let i = 0; i < textTrackList.length; i++) {\n    const track = textTrackList[i];\n    // Edge adds a track without a label; we don't want to use it\n    if ((track.kind === 'subtitles' || track.kind === 'captions') && track.label) {\n      tracks.push(textTrackList[i]);\n    }\n  }\n  return tracks;\n}\n\nclass SubtitleTrackController extends BasePlaylistController {\n  constructor(hls) {\n    super(hls, 'subtitle-track-controller');\n    this.media = null;\n    this.tracks = [];\n    this.groupIds = null;\n    this.tracksInGroup = [];\n    this.trackId = -1;\n    this.currentTrack = null;\n    this.selectDefaultTrack = true;\n    this.queuedDefaultTrack = -1;\n    this.useTextTrackPolling = false;\n    this.subtitlePollingInterval = -1;\n    this._subtitleDisplay = true;\n    this.asyncPollTrackChange = () => this.pollTrackChange(0);\n    this.onTextTracksChanged = () => {\n      if (!this.useTextTrackPolling) {\n        self.clearInterval(this.subtitlePollingInterval);\n      }\n      // Media is undefined when switching streams via loadSource()\n      if (!this.media || !this.hls.config.renderTextTracksNatively) {\n        return;\n      }\n      let textTrack = null;\n      const tracks = filterSubtitleTracks(this.media.textTracks);\n      for (let i = 0; i < tracks.length; i++) {\n        if (tracks[i].mode === 'hidden') {\n          // Do not break in case there is a following track with showing.\n          textTrack = tracks[i];\n        } else if (tracks[i].mode === 'showing') {\n          textTrack = tracks[i];\n          break;\n        }\n      }\n\n      // Find internal track index for TextTrack\n      const trackId = this.findTrackForTextTrack(textTrack);\n      if (this.subtitleTrack !== trackId) {\n        this.setSubtitleTrack(trackId);\n      }\n    };\n    this.registerListeners();\n  }\n  destroy() {\n    this.unregisterListeners();\n    this.tracks.length = 0;\n    this.tracksInGroup.length = 0;\n    this.currentTrack = null;\n    // @ts-ignore\n    this.onTextTracksChanged = this.asyncPollTrackChange = null;\n    super.destroy();\n  }\n  get subtitleDisplay() {\n    return this._subtitleDisplay;\n  }\n  set subtitleDisplay(value) {\n    this._subtitleDisplay = value;\n    if (this.trackId > -1) {\n      this.toggleTrackModes();\n    }\n  }\n  registerListeners() {\n    const {\n      hls\n    } = this;\n    hls.on(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n    hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.on(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n    hls.on(Events.LEVEL_LOADING, this.onLevelLoading, this);\n    hls.on(Events.LEVEL_SWITCHING, this.onLevelSwitching, this);\n    hls.on(Events.SUBTITLE_TRACK_LOADED, this.onSubtitleTrackLoaded, this);\n    hls.on(Events.ERROR, this.onError, this);\n  }\n  unregisterListeners() {\n    const {\n      hls\n    } = this;\n    hls.off(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n    hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.off(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n    hls.off(Events.LEVEL_LOADING, this.onLevelLoading, this);\n    hls.off(Events.LEVEL_SWITCHING, this.onLevelSwitching, this);\n    hls.off(Events.SUBTITLE_TRACK_LOADED, this.onSubtitleTrackLoaded, this);\n    hls.off(Events.ERROR, this.onError, this);\n  }\n\n  // Listen for subtitle track change, then extract the current track ID.\n  onMediaAttached(event, data) {\n    this.media = data.media;\n    if (!this.media) {\n      return;\n    }\n    if (this.queuedDefaultTrack > -1) {\n      this.subtitleTrack = this.queuedDefaultTrack;\n      this.queuedDefaultTrack = -1;\n    }\n    this.useTextTrackPolling = !(this.media.textTracks && 'onchange' in this.media.textTracks);\n    if (this.useTextTrackPolling) {\n      this.pollTrackChange(500);\n    } else {\n      this.media.textTracks.addEventListener('change', this.asyncPollTrackChange);\n    }\n  }\n  pollTrackChange(timeout) {\n    self.clearInterval(this.subtitlePollingInterval);\n    this.subtitlePollingInterval = self.setInterval(this.onTextTracksChanged, timeout);\n  }\n  onMediaDetaching(event, data) {\n    const media = this.media;\n    if (!media) {\n      return;\n    }\n    const transferringMedia = !!data.transferMedia;\n    self.clearInterval(this.subtitlePollingInterval);\n    if (!this.useTextTrackPolling) {\n      media.textTracks.removeEventListener('change', this.asyncPollTrackChange);\n    }\n    if (this.trackId > -1) {\n      this.queuedDefaultTrack = this.trackId;\n    }\n\n    // Disable all subtitle tracks before detachment so when reattached only tracks in that content are enabled.\n    this.subtitleTrack = -1;\n    this.media = null;\n    if (transferringMedia) {\n      return;\n    }\n    const textTracks = filterSubtitleTracks(media.textTracks);\n    // Clear loaded cues on media detachment from tracks\n    textTracks.forEach(track => {\n      clearCurrentCues(track);\n    });\n  }\n  onManifestLoading() {\n    this.tracks = [];\n    this.groupIds = null;\n    this.tracksInGroup = [];\n    this.trackId = -1;\n    this.currentTrack = null;\n    this.selectDefaultTrack = true;\n  }\n\n  // Fired whenever a new manifest is loaded.\n  onManifestParsed(event, data) {\n    this.tracks = data.subtitleTracks;\n  }\n  onSubtitleTrackLoaded(event, data) {\n    const {\n      id,\n      groupId,\n      details\n    } = data;\n    const trackInActiveGroup = this.tracksInGroup[id];\n    if (!trackInActiveGroup || trackInActiveGroup.groupId !== groupId) {\n      this.warn(`Subtitle track with id:${id} and group:${groupId} not found in active group ${trackInActiveGroup == null ? void 0 : trackInActiveGroup.groupId}`);\n      return;\n    }\n    const curDetails = trackInActiveGroup.details;\n    trackInActiveGroup.details = data.details;\n    this.log(`Subtitle track ${id} \"${trackInActiveGroup.name}\" lang:${trackInActiveGroup.lang} group:${groupId} loaded [${details.startSN}-${details.endSN}]`);\n    if (id === this.trackId) {\n      this.playlistLoaded(id, data, curDetails);\n    }\n  }\n  onLevelLoading(event, data) {\n    this.switchLevel(data.level);\n  }\n  onLevelSwitching(event, data) {\n    this.switchLevel(data.level);\n  }\n  switchLevel(levelIndex) {\n    const levelInfo = this.hls.levels[levelIndex];\n    if (!levelInfo) {\n      return;\n    }\n    const subtitleGroups = levelInfo.subtitleGroups || null;\n    const currentGroups = this.groupIds;\n    let currentTrack = this.currentTrack;\n    if (!subtitleGroups || (currentGroups == null ? void 0 : currentGroups.length) !== (subtitleGroups == null ? void 0 : subtitleGroups.length) || subtitleGroups != null && subtitleGroups.some(groupId => (currentGroups == null ? void 0 : currentGroups.indexOf(groupId)) === -1)) {\n      this.groupIds = subtitleGroups;\n      this.trackId = -1;\n      this.currentTrack = null;\n      const subtitleTracks = this.tracks.filter(track => !subtitleGroups || subtitleGroups.indexOf(track.groupId) !== -1);\n      if (subtitleTracks.length) {\n        // Disable selectDefaultTrack if there are no default tracks\n        if (this.selectDefaultTrack && !subtitleTracks.some(track => track.default)) {\n          this.selectDefaultTrack = false;\n        }\n        // track.id should match hls.audioTracks index\n        subtitleTracks.forEach((track, i) => {\n          track.id = i;\n        });\n      } else if (!currentTrack && !this.tracksInGroup.length) {\n        // Do not dispatch SUBTITLE_TRACKS_UPDATED when there were and are no tracks\n        return;\n      }\n      this.tracksInGroup = subtitleTracks;\n\n      // Find preferred track\n      const subtitlePreference = this.hls.config.subtitlePreference;\n      if (!currentTrack && subtitlePreference) {\n        this.selectDefaultTrack = false;\n        const groupIndex = findMatchingOption(subtitlePreference, subtitleTracks);\n        if (groupIndex > -1) {\n          currentTrack = subtitleTracks[groupIndex];\n        } else {\n          const allIndex = findMatchingOption(subtitlePreference, this.tracks);\n          currentTrack = this.tracks[allIndex];\n        }\n      }\n\n      // Select initial track\n      let trackId = this.findTrackId(currentTrack);\n      if (trackId === -1 && currentTrack) {\n        trackId = this.findTrackId(null);\n      }\n\n      // Dispatch events and load track if needed\n      const subtitleTracksUpdated = {\n        subtitleTracks\n      };\n      this.log(`Updating subtitle tracks, ${subtitleTracks.length} track(s) found in \"${subtitleGroups == null ? void 0 : subtitleGroups.join(',')}\" group-id`);\n      this.hls.trigger(Events.SUBTITLE_TRACKS_UPDATED, subtitleTracksUpdated);\n      if (trackId !== -1 && this.trackId === -1) {\n        this.setSubtitleTrack(trackId);\n      }\n    }\n  }\n  findTrackId(currentTrack) {\n    const tracks = this.tracksInGroup;\n    const selectDefault = this.selectDefaultTrack;\n    for (let i = 0; i < tracks.length; i++) {\n      const track = tracks[i];\n      if (selectDefault && !track.default || !selectDefault && !currentTrack) {\n        continue;\n      }\n      if (!currentTrack || matchesOption(track, currentTrack)) {\n        return i;\n      }\n    }\n    if (currentTrack) {\n      for (let i = 0; i < tracks.length; i++) {\n        const track = tracks[i];\n        if (mediaAttributesIdentical(currentTrack.attrs, track.attrs, ['LANGUAGE', 'ASSOC-LANGUAGE', 'CHARACTERISTICS'])) {\n          return i;\n        }\n      }\n      for (let i = 0; i < tracks.length; i++) {\n        const track = tracks[i];\n        if (mediaAttributesIdentical(currentTrack.attrs, track.attrs, ['LANGUAGE'])) {\n          return i;\n        }\n      }\n    }\n    return -1;\n  }\n  findTrackForTextTrack(textTrack) {\n    if (textTrack) {\n      const tracks = this.tracksInGroup;\n      for (let i = 0; i < tracks.length; i++) {\n        const track = tracks[i];\n        if (subtitleTrackMatchesTextTrack(track, textTrack)) {\n          return i;\n        }\n      }\n    }\n    return -1;\n  }\n  onError(event, data) {\n    if (data.fatal || !data.context) {\n      return;\n    }\n    if (data.context.type === PlaylistContextType.SUBTITLE_TRACK && data.context.id === this.trackId && (!this.groupIds || this.groupIds.indexOf(data.context.groupId) !== -1)) {\n      this.checkRetry(data);\n    }\n  }\n  get allSubtitleTracks() {\n    return this.tracks;\n  }\n\n  /** get alternate subtitle tracks list from playlist **/\n  get subtitleTracks() {\n    return this.tracksInGroup;\n  }\n\n  /** get/set index of the selected subtitle track (based on index in subtitle track lists) **/\n  get subtitleTrack() {\n    return this.trackId;\n  }\n  set subtitleTrack(newId) {\n    this.selectDefaultTrack = false;\n    this.setSubtitleTrack(newId);\n  }\n  setSubtitleOption(subtitleOption) {\n    this.hls.config.subtitlePreference = subtitleOption;\n    if (subtitleOption) {\n      if (subtitleOption.id === -1) {\n        this.setSubtitleTrack(-1);\n        return null;\n      }\n      const allSubtitleTracks = this.allSubtitleTracks;\n      this.selectDefaultTrack = false;\n      if (allSubtitleTracks.length) {\n        // First see if current option matches (no switch op)\n        const currentTrack = this.currentTrack;\n        if (currentTrack && matchesOption(subtitleOption, currentTrack)) {\n          return currentTrack;\n        }\n        // Find option in current group\n        const groupIndex = findMatchingOption(subtitleOption, this.tracksInGroup);\n        if (groupIndex > -1) {\n          const track = this.tracksInGroup[groupIndex];\n          this.setSubtitleTrack(groupIndex);\n          return track;\n        } else if (currentTrack) {\n          // If this is not the initial selection return null\n          // option should have matched one in active group\n          return null;\n        } else {\n          // Find the option in all tracks for initial selection\n          const allIndex = findMatchingOption(subtitleOption, allSubtitleTracks);\n          if (allIndex > -1) {\n            return allSubtitleTracks[allIndex];\n          }\n        }\n      }\n    }\n    return null;\n  }\n  loadPlaylist(hlsUrlParameters) {\n    super.loadPlaylist();\n    if (this.shouldLoadPlaylist(this.currentTrack)) {\n      this.scheduleLoading(this.currentTrack, hlsUrlParameters);\n    }\n  }\n  loadingPlaylist(currentTrack, hlsUrlParameters) {\n    super.loadingPlaylist(currentTrack, hlsUrlParameters);\n    const id = currentTrack.id;\n    const groupId = currentTrack.groupId;\n    const url = this.getUrlWithDirectives(currentTrack.url, hlsUrlParameters);\n    const details = currentTrack.details;\n    const age = details == null ? void 0 : details.age;\n    this.log(`Loading subtitle ${id} \"${currentTrack.name}\" lang:${currentTrack.lang} group:${groupId}${(hlsUrlParameters == null ? void 0 : hlsUrlParameters.msn) !== undefined ? ' at sn ' + hlsUrlParameters.msn + ' part ' + hlsUrlParameters.part : ''}${age && details.live ? ' age ' + age.toFixed(1) + (details.type ? ' ' + details.type || 0 : '') : ''} ${url}`);\n    this.hls.trigger(Events.SUBTITLE_TRACK_LOADING, {\n      url,\n      id,\n      groupId,\n      deliveryDirectives: hlsUrlParameters || null,\n      track: currentTrack\n    });\n  }\n\n  /**\n   * Disables the old subtitleTrack and sets current mode on the next subtitleTrack.\n   * This operates on the DOM textTracks.\n   * A value of -1 will disable all subtitle tracks.\n   */\n  toggleTrackModes() {\n    const {\n      media\n    } = this;\n    if (!media) {\n      return;\n    }\n    const textTracks = filterSubtitleTracks(media.textTracks);\n    const currentTrack = this.currentTrack;\n    let nextTrack;\n    if (currentTrack) {\n      nextTrack = textTracks.filter(textTrack => subtitleTrackMatchesTextTrack(currentTrack, textTrack))[0];\n      if (!nextTrack) {\n        this.warn(`Unable to find subtitle TextTrack with name \"${currentTrack.name}\" and language \"${currentTrack.lang}\"`);\n      }\n    }\n    [].slice.call(textTracks).forEach(track => {\n      if (track.mode !== 'disabled' && track !== nextTrack) {\n        track.mode = 'disabled';\n      }\n    });\n    if (nextTrack) {\n      const mode = this.subtitleDisplay ? 'showing' : 'hidden';\n      if (nextTrack.mode !== mode) {\n        nextTrack.mode = mode;\n      }\n    }\n  }\n\n  /**\n   * This method is responsible for validating the subtitle index and periodically reloading if live.\n   * Dispatches the SUBTITLE_TRACK_SWITCH event, which instructs the subtitle-stream-controller to load the selected track.\n   */\n  setSubtitleTrack(newId) {\n    const tracks = this.tracksInGroup;\n\n    // setting this.subtitleTrack will trigger internal logic\n    // if media has not been attached yet, it will fail\n    // we keep a reference to the default track id\n    // and we'll set subtitleTrack when onMediaAttached is triggered\n    if (!this.media) {\n      this.queuedDefaultTrack = newId;\n      return;\n    }\n\n    // exit if track id as already set or invalid\n    if (newId < -1 || newId >= tracks.length || !isFiniteNumber(newId)) {\n      this.warn(`Invalid subtitle track id: ${newId}`);\n      return;\n    }\n    this.selectDefaultTrack = false;\n    const lastTrack = this.currentTrack;\n    const track = tracks[newId] || null;\n    this.trackId = newId;\n    this.currentTrack = track;\n    this.toggleTrackModes();\n    if (!track) {\n      // switch to -1\n      this.hls.trigger(Events.SUBTITLE_TRACK_SWITCH, {\n        id: newId\n      });\n      return;\n    }\n    const trackLoaded = !!track.details && !track.details.live;\n    if (newId === this.trackId && track === lastTrack && trackLoaded) {\n      return;\n    }\n    this.log(`Switching to subtitle-track ${newId}` + (track ? ` \"${track.name}\" lang:${track.lang} group:${track.groupId}` : ''));\n    const {\n      id,\n      groupId = '',\n      name,\n      type,\n      url\n    } = track;\n    this.hls.trigger(Events.SUBTITLE_TRACK_SWITCH, {\n      id,\n      groupId,\n      name,\n      type,\n      url\n    });\n    const hlsUrlParameters = this.switchParams(track.url, lastTrack == null ? void 0 : lastTrack.details, track.details);\n    this.loadPlaylist(hlsUrlParameters);\n  }\n}\n\n/**\n * Generate a random v4 UUID\n *\n * @returns A random v4 UUID\n *\n * @group Utils\n *\n * @beta\n */\nfunction uuid() {\n  try {\n    return crypto.randomUUID();\n  } catch (error) {\n    try {\n      const url = URL.createObjectURL(new Blob());\n      const uuid = url.toString();\n      URL.revokeObjectURL(url);\n      return uuid.slice(uuid.lastIndexOf('/') + 1);\n    } catch (error) {\n      let dt = new Date().getTime();\n      const uuid = 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, c => {\n        const r = (dt + Math.random() * 16) % 16 | 0;\n        dt = Math.floor(dt / 16);\n        return (c == 'x' ? r : r & 0x3 | 0x8).toString(16);\n      });\n      return uuid;\n    }\n  }\n}\n\n// From https://github.com/darkskyapp/string-hash\nfunction hash(text) {\n  let hash = 5381;\n  let i = text.length;\n  while (i) {\n    hash = hash * 33 ^ text.charCodeAt(--i);\n  }\n  return (hash >>> 0).toString();\n}\n\nconst ALIGNED_END_THRESHOLD_SECONDS = 0.025;\nlet TimelineOccupancy = /*#__PURE__*/function (TimelineOccupancy) {\n  TimelineOccupancy[TimelineOccupancy[\"Point\"] = 0] = \"Point\";\n  TimelineOccupancy[TimelineOccupancy[\"Range\"] = 1] = \"Range\";\n  return TimelineOccupancy;\n}({});\nfunction generateAssetIdentifier(interstitial, uri, assetListIndex) {\n  return `${interstitial.identifier}-${assetListIndex + 1}-${hash(uri)}`;\n}\nclass InterstitialEvent {\n  constructor(dateRange, base) {\n    this.base = void 0;\n    this._duration = null;\n    this._timelineStart = null;\n    this.appendInPlaceDisabled = void 0;\n    this.appendInPlaceStarted = void 0;\n    this.dateRange = void 0;\n    this.hasPlayed = false;\n    this.cumulativeDuration = 0;\n    this.resumeOffset = NaN;\n    this.playoutLimit = NaN;\n    this.restrictions = {\n      skip: false,\n      jump: false\n    };\n    this.snapOptions = {\n      out: false,\n      in: false\n    };\n    this.assetList = [];\n    this.assetListLoader = void 0;\n    this.assetListResponse = null;\n    this.resumeAnchor = void 0;\n    this.error = void 0;\n    this.resetOnResume = void 0;\n    this.base = base;\n    this.dateRange = dateRange;\n    this.setDateRange(dateRange);\n  }\n  setDateRange(dateRange) {\n    this.dateRange = dateRange;\n    this.resumeOffset = dateRange.attr.optionalFloat('X-RESUME-OFFSET', this.resumeOffset);\n    this.playoutLimit = dateRange.attr.optionalFloat('X-PLAYOUT-LIMIT', this.playoutLimit);\n    this.restrictions = dateRange.attr.enumeratedStringList('X-RESTRICT', this.restrictions);\n    this.snapOptions = dateRange.attr.enumeratedStringList('X-SNAP', this.snapOptions);\n  }\n  reset() {\n    var _this$assetListLoader;\n    this.appendInPlaceStarted = false;\n    (_this$assetListLoader = this.assetListLoader) == null || _this$assetListLoader.destroy();\n    this.assetListLoader = undefined;\n    if (!this.supplementsPrimary) {\n      this.assetListResponse = null;\n      this.assetList = [];\n      this._duration = null;\n    }\n    // `error?` is reset when seeking back over interstitial `startOffset`\n    //  using `schedule.resetErrorsInRange(start, end)`.\n  }\n  isAssetPastPlayoutLimit(assetIndex) {\n    var _this$assetList$asset;\n    if (assetIndex > 0 && assetIndex >= this.assetList.length) {\n      return true;\n    }\n    const playoutLimit = this.playoutLimit;\n    if (assetIndex <= 0 || isNaN(playoutLimit)) {\n      return false;\n    }\n    if (playoutLimit === 0) {\n      return true;\n    }\n    const assetOffset = ((_this$assetList$asset = this.assetList[assetIndex]) == null ? void 0 : _this$assetList$asset.startOffset) || 0;\n    return assetOffset > playoutLimit;\n  }\n  findAssetIndex(asset) {\n    const index = this.assetList.indexOf(asset);\n    return index;\n  }\n  get identifier() {\n    return this.dateRange.id;\n  }\n  get startDate() {\n    return this.dateRange.startDate;\n  }\n  get startTime() {\n    // Primary media timeline start time\n    const startTime = this.dateRange.startTime;\n    if (this.snapOptions.out) {\n      const frag = this.dateRange.tagAnchor;\n      if (frag) {\n        return getSnapToFragmentTime(startTime, frag);\n      }\n    }\n    return startTime;\n  }\n  get startOffset() {\n    return this.cue.pre ? 0 : this.startTime;\n  }\n  get startIsAligned() {\n    if (this.startTime === 0 || this.snapOptions.out) {\n      return true;\n    }\n    const frag = this.dateRange.tagAnchor;\n    if (frag) {\n      const startTime = this.dateRange.startTime;\n      const snappedStart = getSnapToFragmentTime(startTime, frag);\n      return startTime - snappedStart < 0.1;\n    }\n    return false;\n  }\n  get resumptionOffset() {\n    const resumeOffset = this.resumeOffset;\n    const offset = isFiniteNumber(resumeOffset) ? resumeOffset : this.duration;\n    return this.cumulativeDuration + offset;\n  }\n  get resumeTime() {\n    // Primary media timeline resumption time\n    const resumeTime = this.startOffset + this.resumptionOffset;\n    if (this.snapOptions.in) {\n      const frag = this.resumeAnchor;\n      if (frag) {\n        return getSnapToFragmentTime(resumeTime, frag);\n      }\n    }\n    return resumeTime;\n  }\n  get appendInPlace() {\n    if (this.appendInPlaceStarted) {\n      return true;\n    }\n    if (this.appendInPlaceDisabled) {\n      return false;\n    }\n    if (!this.cue.once && !this.cue.pre &&\n    // preroll starts at startPosition before startPosition is known (live)\n    this.startIsAligned && (isNaN(this.playoutLimit) && isNaN(this.resumeOffset) || this.resumeOffset && this.duration && Math.abs(this.resumeOffset - this.duration) < ALIGNED_END_THRESHOLD_SECONDS)) {\n      return true;\n    }\n    return false;\n  }\n  set appendInPlace(value) {\n    if (this.appendInPlaceStarted) {\n      this.resetOnResume = !value;\n      return;\n    }\n    this.appendInPlaceDisabled = !value;\n  }\n\n  // Extended timeline start time\n  get timelineStart() {\n    if (this._timelineStart !== null) {\n      return this._timelineStart;\n    }\n    return this.startTime;\n  }\n  set timelineStart(value) {\n    this._timelineStart = value;\n  }\n  get duration() {\n    const playoutLimit = this.playoutLimit;\n    let duration;\n    if (this._duration !== null) {\n      duration = this._duration;\n    } else if (this.dateRange.duration) {\n      duration = this.dateRange.duration;\n    } else {\n      duration = this.dateRange.plannedDuration || 0;\n    }\n    if (!isNaN(playoutLimit) && playoutLimit < duration) {\n      duration = playoutLimit;\n    }\n    return duration;\n  }\n  set duration(value) {\n    this._duration = value;\n  }\n  get cue() {\n    return this.dateRange.cue;\n  }\n  get timelineOccupancy() {\n    if (this.dateRange.attr['X-TIMELINE-OCCUPIES'] === 'RANGE') {\n      return TimelineOccupancy.Range;\n    }\n    return TimelineOccupancy.Point;\n  }\n  get supplementsPrimary() {\n    return this.dateRange.attr['X-TIMELINE-STYLE'] === 'PRIMARY';\n  }\n  get contentMayVary() {\n    return this.dateRange.attr['X-CONTENT-MAY-VARY'] !== 'NO';\n  }\n  get assetUrl() {\n    return this.dateRange.attr['X-ASSET-URI'];\n  }\n  get assetListUrl() {\n    return this.dateRange.attr['X-ASSET-LIST'];\n  }\n  get baseUrl() {\n    return this.base.url;\n  }\n  get assetListLoaded() {\n    return this.assetList.length > 0 || this.assetListResponse !== null;\n  }\n  toString() {\n    return eventToString(this);\n  }\n}\nfunction getSnapToFragmentTime(time, frag) {\n  return time - frag.start < frag.duration / 2 && !(Math.abs(time - (frag.start + frag.duration)) < ALIGNED_END_THRESHOLD_SECONDS) ? frag.start : frag.start + frag.duration;\n}\nfunction getInterstitialUrl(uri, sessionId, baseUrl) {\n  const url = new self.URL(uri, baseUrl);\n  if (url.protocol !== 'data:') {\n    url.searchParams.set('_HLS_primary_id', sessionId);\n  }\n  return url;\n}\nfunction getNextAssetIndex(interstitial, assetListIndex) {\n  while ((_interstitial$assetLi = interstitial.assetList[++assetListIndex]) != null && _interstitial$assetLi.error) {\n    var _interstitial$assetLi;\n  } /* no-op */\n  return assetListIndex;\n}\nfunction eventToString(interstitial) {\n  return `[\"${interstitial.identifier}\" ${interstitial.cue.pre ? '<pre>' : interstitial.cue.post ? '<post>' : ''}${interstitial.timelineStart.toFixed(2)}-${interstitial.resumeTime.toFixed(2)}]`;\n}\nfunction eventAssetToString(asset) {\n  const start = asset.timelineStart;\n  const duration = asset.duration || 0;\n  return `[\"${asset.identifier}\" ${start.toFixed(2)}-${(start + duration).toFixed(2)}]`;\n}\n\nclass HlsAssetPlayer {\n  constructor(HlsPlayerClass, userConfig, interstitial, assetItem) {\n    this.hls = void 0;\n    this.interstitial = void 0;\n    this.assetItem = void 0;\n    this.tracks = null;\n    this.hasDetails = false;\n    this.mediaAttached = null;\n    this._currentTime = void 0;\n    this._bufferedEosTime = void 0;\n    this.checkPlayout = () => {\n      if (this.reachedPlayout(this.currentTime) && this.hls) {\n        this.hls.trigger(Events.PLAYOUT_LIMIT_REACHED, {});\n      }\n    };\n    const hls = this.hls = new HlsPlayerClass(userConfig);\n    this.interstitial = interstitial;\n    this.assetItem = assetItem;\n    const detailsLoaded = () => {\n      this.hasDetails = true;\n    };\n    hls.once(Events.LEVEL_LOADED, detailsLoaded);\n    hls.once(Events.AUDIO_TRACK_LOADED, detailsLoaded);\n    hls.once(Events.SUBTITLE_TRACK_LOADED, detailsLoaded);\n    hls.on(Events.MEDIA_ATTACHING, (name, {\n      media\n    }) => {\n      this.removeMediaListeners();\n      this.mediaAttached = media;\n      const event = this.interstitial;\n      if (event.playoutLimit) {\n        media.addEventListener('timeupdate', this.checkPlayout);\n        if (this.appendInPlace) {\n          hls.on(Events.BUFFER_APPENDED, () => {\n            const bufferedEnd = this.bufferedEnd;\n            if (this.reachedPlayout(bufferedEnd)) {\n              this._bufferedEosTime = bufferedEnd;\n              hls.trigger(Events.BUFFERED_TO_END, undefined);\n            }\n          });\n        }\n      }\n    });\n  }\n  get appendInPlace() {\n    return this.interstitial.appendInPlace;\n  }\n  loadSource() {\n    const hls = this.hls;\n    if (!hls) {\n      return;\n    }\n    if (!hls.url) {\n      let uri = this.assetItem.uri;\n      try {\n        uri = getInterstitialUrl(uri, hls.config.primarySessionId || '').href;\n      } catch (error) {\n        // Ignore error parsing ASSET_URI or adding _HLS_primary_id to it. The\n        // issue should surface as an INTERSTITIAL_ASSET_ERROR loading the asset.\n      }\n      hls.loadSource(uri);\n    } else if (hls.levels.length && !hls.started) {\n      hls.startLoad(-1, true);\n    }\n  }\n  bufferedInPlaceToEnd(media) {\n    var _this$hls;\n    if (!this.appendInPlace) {\n      return false;\n    }\n    if ((_this$hls = this.hls) != null && _this$hls.bufferedToEnd) {\n      return true;\n    }\n    if (!media) {\n      return false;\n    }\n    const duration = Math.min(this._bufferedEosTime || Infinity, this.duration);\n    const start = this.timelineOffset;\n    const bufferInfo = BufferHelper.bufferInfo(media, start, 0);\n    const bufferedEnd = this.getAssetTime(bufferInfo.end);\n    return bufferedEnd >= duration - 0.02;\n  }\n  reachedPlayout(time) {\n    const interstitial = this.interstitial;\n    const playoutLimit = interstitial.playoutLimit;\n    return this.startOffset + time >= playoutLimit;\n  }\n  get destroyed() {\n    var _this$hls2;\n    return !((_this$hls2 = this.hls) != null && _this$hls2.userConfig);\n  }\n  get assetId() {\n    return this.assetItem.identifier;\n  }\n  get interstitialId() {\n    return this.assetItem.parentIdentifier;\n  }\n  get media() {\n    var _this$hls3;\n    return ((_this$hls3 = this.hls) == null ? void 0 : _this$hls3.media) || null;\n  }\n  get bufferedEnd() {\n    const media = this.media || this.mediaAttached;\n    if (!media) {\n      if (this._bufferedEosTime) {\n        return this._bufferedEosTime;\n      }\n      return this.currentTime;\n    }\n    const bufferInfo = BufferHelper.bufferInfo(media, media.currentTime, 0.001);\n    return this.getAssetTime(bufferInfo.end);\n  }\n  get currentTime() {\n    const media = this.media || this.mediaAttached;\n    if (!media) {\n      return this._currentTime || 0;\n    }\n    return this.getAssetTime(media.currentTime);\n  }\n  get duration() {\n    const duration = this.assetItem.duration;\n    if (!duration) {\n      return 0;\n    }\n    const playoutLimit = this.interstitial.playoutLimit;\n    if (playoutLimit) {\n      const assetPlayout = playoutLimit - this.startOffset;\n      if (assetPlayout > 0 && assetPlayout < duration) {\n        return assetPlayout;\n      }\n    }\n    return duration;\n  }\n  get remaining() {\n    const duration = this.duration;\n    if (!duration) {\n      return 0;\n    }\n    return Math.max(0, duration - this.currentTime);\n  }\n  get startOffset() {\n    return this.assetItem.startOffset;\n  }\n  get timelineOffset() {\n    var _this$hls4;\n    return ((_this$hls4 = this.hls) == null ? void 0 : _this$hls4.config.timelineOffset) || 0;\n  }\n  set timelineOffset(value) {\n    const timelineOffset = this.timelineOffset;\n    if (value !== timelineOffset) {\n      const diff = value - timelineOffset;\n      if (Math.abs(diff) > 1 / 90000 && this.hls) {\n        if (this.hasDetails) {\n          throw new Error(`Cannot set timelineOffset after playlists are loaded`);\n        }\n        this.hls.config.timelineOffset = value;\n      }\n    }\n  }\n  getAssetTime(time) {\n    const timelineOffset = this.timelineOffset;\n    const duration = this.duration;\n    return Math.min(Math.max(0, time - timelineOffset), duration);\n  }\n  removeMediaListeners() {\n    const media = this.mediaAttached;\n    if (media) {\n      this._currentTime = media.currentTime;\n      this.bufferSnapShot();\n      media.removeEventListener('timeupdate', this.checkPlayout);\n    }\n  }\n  bufferSnapShot() {\n    if (this.mediaAttached) {\n      var _this$hls5;\n      if ((_this$hls5 = this.hls) != null && _this$hls5.bufferedToEnd) {\n        this._bufferedEosTime = this.bufferedEnd;\n      }\n    }\n  }\n  destroy() {\n    this.removeMediaListeners();\n    if (this.hls) {\n      this.hls.destroy();\n    }\n    this.hls = null;\n    // @ts-ignore\n    this.tracks = this.mediaAttached = this.checkPlayout = null;\n  }\n  attachMedia(data) {\n    var _this$hls6;\n    this.loadSource();\n    (_this$hls6 = this.hls) == null || _this$hls6.attachMedia(data);\n  }\n  detachMedia() {\n    var _this$hls7;\n    this.removeMediaListeners();\n    this.mediaAttached = null;\n    (_this$hls7 = this.hls) == null || _this$hls7.detachMedia();\n  }\n  resumeBuffering() {\n    var _this$hls8;\n    (_this$hls8 = this.hls) == null || _this$hls8.resumeBuffering();\n  }\n  pauseBuffering() {\n    var _this$hls9;\n    (_this$hls9 = this.hls) == null || _this$hls9.pauseBuffering();\n  }\n  transferMedia() {\n    var _this$hls0;\n    this.bufferSnapShot();\n    return ((_this$hls0 = this.hls) == null ? void 0 : _this$hls0.transferMedia()) || null;\n  }\n  resetDetails() {\n    const hls = this.hls;\n    if (hls && this.hasDetails) {\n      hls.stopLoad();\n      const deleteDetails = obj => delete obj.details;\n      hls.levels.forEach(deleteDetails);\n      hls.allAudioTracks.forEach(deleteDetails);\n      hls.allSubtitleTracks.forEach(deleteDetails);\n      this.hasDetails = false;\n    }\n  }\n  on(event, listener, context) {\n    var _this$hls1;\n    (_this$hls1 = this.hls) == null || _this$hls1.on(event, listener);\n  }\n  once(event, listener, context) {\n    var _this$hls10;\n    (_this$hls10 = this.hls) == null || _this$hls10.once(event, listener);\n  }\n  off(event, listener, context) {\n    var _this$hls11;\n    (_this$hls11 = this.hls) == null || _this$hls11.off(event, listener);\n  }\n  toString() {\n    var _this$hls12;\n    return `HlsAssetPlayer: ${eventAssetToString(this.assetItem)} ${(_this$hls12 = this.hls) == null ? void 0 : _this$hls12.sessionId} ${this.appendInPlace ? 'append-in-place' : ''}`;\n  }\n}\n\nconst ABUTTING_THRESHOLD_SECONDS = 0.033;\nclass InterstitialsSchedule extends Logger {\n  constructor(onScheduleUpdate, logger) {\n    super('interstitials-sched', logger);\n    this.onScheduleUpdate = void 0;\n    this.eventMap = {};\n    this.events = null;\n    this.items = null;\n    this.durations = {\n      primary: 0,\n      playout: 0,\n      integrated: 0\n    };\n    this.onScheduleUpdate = onScheduleUpdate;\n  }\n  destroy() {\n    this.reset();\n    // @ts-ignore\n    this.onScheduleUpdate = null;\n  }\n  reset() {\n    this.eventMap = {};\n    this.setDurations(0, 0, 0);\n    if (this.events) {\n      this.events.forEach(interstitial => interstitial.reset());\n    }\n    this.events = this.items = null;\n  }\n  resetErrorsInRange(start, end) {\n    if (this.events) {\n      return this.events.reduce((count, interstitial) => {\n        if (start <= interstitial.startOffset && end > interstitial.startOffset) {\n          delete interstitial.error;\n          return count + 1;\n        }\n        return count;\n      }, 0);\n    }\n    return 0;\n  }\n  get duration() {\n    const items = this.items;\n    return items ? items[items.length - 1].end : 0;\n  }\n  get length() {\n    return this.items ? this.items.length : 0;\n  }\n  getEvent(identifier) {\n    return identifier ? this.eventMap[identifier] || null : null;\n  }\n  hasEvent(identifier) {\n    return identifier in this.eventMap;\n  }\n  findItemIndex(item, time) {\n    if (item.event) {\n      // Find Event Item\n      return this.findEventIndex(item.event.identifier);\n    }\n    // Find Primary Item\n    let index = -1;\n    if (item.nextEvent) {\n      index = this.findEventIndex(item.nextEvent.identifier) - 1;\n    } else if (item.previousEvent) {\n      index = this.findEventIndex(item.previousEvent.identifier) + 1;\n    }\n    const items = this.items;\n    if (items) {\n      if (!items[index]) {\n        if (time === undefined) {\n          time = item.start;\n        }\n        index = this.findItemIndexAtTime(time);\n      }\n      // Only return index of a Primary Item\n      while (index >= 0 && (_items$index = items[index]) != null && _items$index.event) {\n        var _items$index;\n        // If index found is an interstitial it is not a valid result as it should have been matched up top\n        // decrement until result is negative (not found) or a primary segment\n        index--;\n      }\n    }\n    return index;\n  }\n  findItemIndexAtTime(timelinePos, timelineType) {\n    const items = this.items;\n    if (items) {\n      for (let i = 0; i < items.length; i++) {\n        let timeRange = items[i];\n        if (timelineType && timelineType !== 'primary') {\n          timeRange = timeRange[timelineType];\n        }\n        if (timelinePos === timeRange.start || timelinePos > timeRange.start && timelinePos < timeRange.end) {\n          return i;\n        }\n      }\n    }\n    return -1;\n  }\n  findJumpRestrictedIndex(startIndex, endIndex) {\n    const items = this.items;\n    if (items) {\n      for (let i = startIndex; i <= endIndex; i++) {\n        if (!items[i]) {\n          break;\n        }\n        const event = items[i].event;\n        if (event != null && event.restrictions.jump && !event.appendInPlace) {\n          return i;\n        }\n      }\n    }\n    return -1;\n  }\n  findEventIndex(identifier) {\n    const items = this.items;\n    if (items) {\n      for (let i = items.length; i--;) {\n        var _items$i$event;\n        if (((_items$i$event = items[i].event) == null ? void 0 : _items$i$event.identifier) === identifier) {\n          return i;\n        }\n      }\n    }\n    return -1;\n  }\n  findAssetIndex(event, timelinePos) {\n    const assetList = event.assetList;\n    const length = assetList.length;\n    if (length > 1) {\n      for (let i = 0; i < length; i++) {\n        const asset = assetList[i];\n        if (!asset.error) {\n          const timelineStart = asset.timelineStart;\n          if (timelinePos === timelineStart || timelinePos > timelineStart && (timelinePos < timelineStart + (asset.duration || 0) || i === length - 1)) {\n            return i;\n          }\n        }\n      }\n    }\n    return 0;\n  }\n  get assetIdAtEnd() {\n    var _this$items;\n    const interstitialAtEnd = (_this$items = this.items) == null || (_this$items = _this$items[this.length - 1]) == null ? void 0 : _this$items.event;\n    if (interstitialAtEnd) {\n      const assetList = interstitialAtEnd.assetList;\n      const assetAtEnd = assetList[assetList.length - 1];\n      if (assetAtEnd) {\n        return assetAtEnd.identifier;\n      }\n    }\n    return null;\n  }\n  parseInterstitialDateRanges(mediaSelection, enableAppendInPlace) {\n    const details = mediaSelection.main.details;\n    const {\n      dateRanges\n    } = details;\n    const previousInterstitialEvents = this.events;\n    const interstitialEvents = this.parseDateRanges(dateRanges, {\n      url: details.url\n    }, enableAppendInPlace);\n    const ids = Object.keys(dateRanges);\n    const removedInterstitials = previousInterstitialEvents ? previousInterstitialEvents.filter(event => !ids.includes(event.identifier)) : [];\n    if (interstitialEvents.length) {\n      // pre-rolls, post-rolls, and events with the same start time are played in playlist tag order\n      // all other events are ordered by start time\n      interstitialEvents.sort((a, b) => {\n        const aPre = a.cue.pre;\n        const aPost = a.cue.post;\n        const bPre = b.cue.pre;\n        const bPost = b.cue.post;\n        if (aPre && !bPre) {\n          return -1;\n        }\n        if (bPre && !aPre) {\n          return 1;\n        }\n        if (aPost && !bPost) {\n          return 1;\n        }\n        if (bPost && !aPost) {\n          return -1;\n        }\n        if (!aPre && !bPre && !aPost && !bPost) {\n          const startA = a.startTime;\n          const startB = b.startTime;\n          if (startA !== startB) {\n            return startA - startB;\n          }\n        }\n        return a.dateRange.tagOrder - b.dateRange.tagOrder;\n      });\n    }\n    this.events = interstitialEvents;\n\n    // Clear removed DateRanges from buffered list (kills playback of active Interstitials)\n    removedInterstitials.forEach(interstitial => {\n      this.removeEvent(interstitial);\n    });\n    this.updateSchedule(mediaSelection, removedInterstitials);\n  }\n  updateSchedule(mediaSelection, removedInterstitials = [], forceUpdate = false) {\n    const events = this.events || [];\n    if (events.length || removedInterstitials.length || this.length < 2) {\n      const currentItems = this.items;\n      const updatedItems = this.parseSchedule(events, mediaSelection);\n      const updated = forceUpdate || removedInterstitials.length || (currentItems == null ? void 0 : currentItems.length) !== updatedItems.length || updatedItems.some((item, i) => {\n        return Math.abs(item.playout.start - currentItems[i].playout.start) > 0.005 || Math.abs(item.playout.end - currentItems[i].playout.end) > 0.005;\n      });\n      if (updated) {\n        this.items = updatedItems;\n        // call interstitials-controller onScheduleUpdated()\n        this.onScheduleUpdate(removedInterstitials, currentItems);\n      }\n    }\n  }\n  parseDateRanges(dateRanges, baseData, enableAppendInPlace) {\n    const interstitialEvents = [];\n    const ids = Object.keys(dateRanges);\n    for (let i = 0; i < ids.length; i++) {\n      const id = ids[i];\n      const dateRange = dateRanges[id];\n      if (dateRange.isInterstitial) {\n        let interstitial = this.eventMap[id];\n        if (interstitial) {\n          // Update InterstitialEvent already parsed and mapped\n          // This retains already loaded duration and loaded asset list info\n          interstitial.setDateRange(dateRange);\n        } else {\n          interstitial = new InterstitialEvent(dateRange, baseData);\n          this.eventMap[id] = interstitial;\n          if (enableAppendInPlace === false) {\n            interstitial.appendInPlace = enableAppendInPlace;\n          }\n        }\n        interstitialEvents.push(interstitial);\n      }\n    }\n    return interstitialEvents;\n  }\n  parseSchedule(interstitialEvents, mediaSelection) {\n    const schedule = [];\n    const details = mediaSelection.main.details;\n    const primaryDuration = details.live ? Infinity : details.edge;\n    let playoutDuration = 0;\n\n    // Filter events that have errored from the schedule (Primary fallback)\n    interstitialEvents = interstitialEvents.filter(event => !event.error && !(event.cue.once && event.hasPlayed));\n    if (interstitialEvents.length) {\n      // Update Schedule\n      this.resolveOffsets(interstitialEvents, mediaSelection);\n\n      // Populate Schedule with Interstitial Event and Primary Segment Items\n      let primaryPosition = 0;\n      let integratedTime = 0;\n      interstitialEvents.forEach((interstitial, i) => {\n        const preroll = interstitial.cue.pre;\n        const postroll = interstitial.cue.post;\n        const previousEvent = interstitialEvents[i - 1] || null;\n        const appendInPlace = interstitial.appendInPlace;\n        const eventStart = postroll ? primaryDuration : interstitial.startOffset;\n        const interstitialDuration = interstitial.duration;\n        const timelineDuration = interstitial.timelineOccupancy === TimelineOccupancy.Range ? interstitialDuration : 0;\n        const resumptionOffset = interstitial.resumptionOffset;\n        const inSameStartTimeSequence = (previousEvent == null ? void 0 : previousEvent.startTime) === eventStart;\n        const start = eventStart + interstitial.cumulativeDuration;\n        let end = appendInPlace ? start + interstitialDuration : eventStart + resumptionOffset;\n        if (preroll || !postroll && eventStart <= 0) {\n          // preroll or in-progress midroll\n          const integratedStart = integratedTime;\n          integratedTime += timelineDuration;\n          interstitial.timelineStart = start;\n          const playoutStart = playoutDuration;\n          playoutDuration += interstitialDuration;\n          schedule.push({\n            event: interstitial,\n            start,\n            end,\n            playout: {\n              start: playoutStart,\n              end: playoutDuration\n            },\n            integrated: {\n              start: integratedStart,\n              end: integratedTime\n            }\n          });\n        } else if (eventStart <= primaryDuration) {\n          if (!inSameStartTimeSequence) {\n            const segmentDuration = eventStart - primaryPosition;\n            // Do not schedule a primary segment if interstitials are abutting by less than ABUTTING_THRESHOLD_SECONDS\n            if (segmentDuration > ABUTTING_THRESHOLD_SECONDS) {\n              // primary segment\n              const timelineStart = primaryPosition;\n              const _integratedStart = integratedTime;\n              integratedTime += segmentDuration;\n              const _playoutStart = playoutDuration;\n              playoutDuration += segmentDuration;\n              const primarySegment = {\n                previousEvent: interstitialEvents[i - 1] || null,\n                nextEvent: interstitial,\n                start: timelineStart,\n                end: timelineStart + segmentDuration,\n                playout: {\n                  start: _playoutStart,\n                  end: playoutDuration\n                },\n                integrated: {\n                  start: _integratedStart,\n                  end: integratedTime\n                }\n              };\n              schedule.push(primarySegment);\n            } else if (segmentDuration > 0 && previousEvent) {\n              // Add previous event `resumeTime` (based on duration or resumeOffset) so that it ends aligned with this one\n              previousEvent.cumulativeDuration += segmentDuration;\n              schedule[schedule.length - 1].end = eventStart;\n            }\n          }\n          // midroll / postroll\n          if (postroll) {\n            end = start;\n          }\n          interstitial.timelineStart = start;\n          const integratedStart = integratedTime;\n          integratedTime += timelineDuration;\n          const playoutStart = playoutDuration;\n          playoutDuration += interstitialDuration;\n          schedule.push({\n            event: interstitial,\n            start,\n            end,\n            playout: {\n              start: playoutStart,\n              end: playoutDuration\n            },\n            integrated: {\n              start: integratedStart,\n              end: integratedTime\n            }\n          });\n        } else {\n          // Interstitial starts after end of primary VOD - not included in schedule\n          return;\n        }\n        const resumeTime = interstitial.resumeTime;\n        if (postroll || resumeTime > primaryDuration) {\n          primaryPosition = primaryDuration;\n        } else {\n          primaryPosition = resumeTime;\n        }\n      });\n      if (primaryPosition < primaryDuration) {\n        var _schedule;\n        // last primary segment\n        const timelineStart = primaryPosition;\n        const integratedStart = integratedTime;\n        const segmentDuration = primaryDuration - primaryPosition;\n        integratedTime += segmentDuration;\n        const playoutStart = playoutDuration;\n        playoutDuration += segmentDuration;\n        schedule.push({\n          previousEvent: ((_schedule = schedule[schedule.length - 1]) == null ? void 0 : _schedule.event) || null,\n          nextEvent: null,\n          start: primaryPosition,\n          end: timelineStart + segmentDuration,\n          playout: {\n            start: playoutStart,\n            end: playoutDuration\n          },\n          integrated: {\n            start: integratedStart,\n            end: integratedTime\n          }\n        });\n      }\n      this.setDurations(primaryDuration, playoutDuration, integratedTime);\n    } else {\n      // no interstials - schedule is one primary segment\n      const start = 0;\n      schedule.push({\n        previousEvent: null,\n        nextEvent: null,\n        start,\n        end: primaryDuration,\n        playout: {\n          start,\n          end: primaryDuration\n        },\n        integrated: {\n          start,\n          end: primaryDuration\n        }\n      });\n      this.setDurations(primaryDuration, primaryDuration, primaryDuration);\n    }\n    return schedule;\n  }\n  setDurations(primary, playout, integrated) {\n    this.durations = {\n      primary,\n      playout,\n      integrated\n    };\n  }\n  resolveOffsets(interstitialEvents, mediaSelection) {\n    const details = mediaSelection.main.details;\n    const primaryDuration = details.live ? Infinity : details.edge;\n\n    // First resolve cumulative resumption offsets for Interstitials that start at the same DateTime\n    let cumulativeDuration = 0;\n    let lastScheduledStart = -1;\n    interstitialEvents.forEach((interstitial, i) => {\n      const preroll = interstitial.cue.pre;\n      const postroll = interstitial.cue.post;\n      const eventStart = preroll ? 0 : postroll ? primaryDuration : interstitial.startTime;\n      this.updateAssetDurations(interstitial);\n\n      // X-RESUME-OFFSET values of interstitials scheduled at the same time are cumulative\n      const inSameStartTimeSequence = lastScheduledStart === eventStart;\n      if (inSameStartTimeSequence) {\n        interstitial.cumulativeDuration = cumulativeDuration;\n      } else {\n        cumulativeDuration = 0;\n        lastScheduledStart = eventStart;\n      }\n      if (!postroll && interstitial.snapOptions.in) {\n        // FIXME: Include audio playlist in snapping\n        interstitial.resumeAnchor = findFragmentByPTS(null, details.fragments, interstitial.startOffset + interstitial.resumptionOffset, 0, 0) || undefined;\n      }\n      // Check if primary fragments align with resumption offset and disable appendInPlace if they do not\n      if (interstitial.appendInPlace && !interstitial.appendInPlaceStarted) {\n        const alignedSegmentStart = this.primaryCanResumeInPlaceAt(interstitial, mediaSelection);\n        if (!alignedSegmentStart) {\n          interstitial.appendInPlace = false;\n        }\n      }\n      if (!interstitial.appendInPlace && i + 1 < interstitialEvents.length) {\n        // abutting Interstitials must use the same MediaSource strategy, this applies to all whether or not they are back to back:\n        const timeBetween = interstitialEvents[i + 1].startTime - interstitialEvents[i].resumeTime;\n        if (timeBetween < ABUTTING_THRESHOLD_SECONDS) {\n          interstitialEvents[i + 1].appendInPlace = false;\n          if (interstitialEvents[i + 1].appendInPlace) {\n            this.warn(`Could not change append strategy for abutting event ${interstitial}`);\n          }\n        }\n      }\n      // Update cumulativeDuration for next abutting interstitial with the same start date\n      const resumeOffset = isFiniteNumber(interstitial.resumeOffset) ? interstitial.resumeOffset : interstitial.duration;\n      cumulativeDuration += resumeOffset;\n    });\n  }\n  primaryCanResumeInPlaceAt(interstitial, mediaSelection) {\n    const resumeTime = interstitial.resumeTime;\n    const resumesInPlaceAt = interstitial.startTime + interstitial.resumptionOffset;\n    if (Math.abs(resumeTime - resumesInPlaceAt) > ALIGNED_END_THRESHOLD_SECONDS) {\n      this.log(`\"${interstitial.identifier}\" resumption ${resumeTime} not aligned with estimated timeline end ${resumesInPlaceAt}`);\n      return false;\n    }\n    const playlists = Object.keys(mediaSelection);\n    return !playlists.some(playlistType => {\n      const details = mediaSelection[playlistType].details;\n      const playlistEnd = details.edge;\n      if (resumeTime >= playlistEnd) {\n        // Live playback - resumption segments are not yet available\n        this.log(`\"${interstitial.identifier}\" resumption ${resumeTime} past ${playlistType} playlist end ${playlistEnd}`);\n        // Assume alignment is possible (or reset can take place)\n        return false;\n      }\n      const startFragment = findFragmentByPTS(null, details.fragments, resumeTime);\n      if (!startFragment) {\n        this.log(`\"${interstitial.identifier}\" resumption ${resumeTime} does not align with any fragments in ${playlistType} playlist (${details.fragStart}-${details.fragmentEnd})`);\n        return true;\n      }\n      const allowance = playlistType === 'audio' ? 0.175 : 0;\n      const alignedWithSegment = Math.abs(startFragment.start - resumeTime) < ALIGNED_END_THRESHOLD_SECONDS + allowance || Math.abs(startFragment.end - resumeTime) < ALIGNED_END_THRESHOLD_SECONDS + allowance;\n      if (!alignedWithSegment) {\n        this.log(`\"${interstitial.identifier}\" resumption ${resumeTime} not aligned with ${playlistType} fragment bounds (${startFragment.start}-${startFragment.end} sn: ${startFragment.sn} cc: ${startFragment.cc})`);\n        return true;\n      }\n      return false;\n    });\n  }\n  updateAssetDurations(interstitial) {\n    if (!interstitial.assetListLoaded) {\n      return;\n    }\n    const eventStart = interstitial.timelineStart;\n    let sumDuration = 0;\n    let hasUnknownDuration = false;\n    let hasErrors = false;\n    for (let i = 0; i < interstitial.assetList.length; i++) {\n      const asset = interstitial.assetList[i];\n      const timelineStart = eventStart + sumDuration;\n      asset.startOffset = sumDuration;\n      asset.timelineStart = timelineStart;\n      hasUnknownDuration || (hasUnknownDuration = asset.duration === null);\n      hasErrors || (hasErrors = !!asset.error);\n      const duration = asset.error ? 0 : asset.duration || 0;\n      sumDuration += duration;\n    }\n    // Use the sum of known durations when it is greater than the stated duration\n    if (hasUnknownDuration && !hasErrors) {\n      interstitial.duration = Math.max(sumDuration, interstitial.duration);\n    } else {\n      interstitial.duration = sumDuration;\n    }\n  }\n  removeEvent(interstitial) {\n    interstitial.reset();\n    delete this.eventMap[interstitial.identifier];\n  }\n}\nfunction segmentToString(segment) {\n  return `[${segment.event ? '\"' + segment.event.identifier + '\"' : 'primary'}: ${segment.start.toFixed(2)}-${segment.end.toFixed(2)}]`;\n}\n\nclass AssetListLoader {\n  constructor(hls) {\n    this.hls = void 0;\n    this.hls = hls;\n  }\n  destroy() {\n    // @ts-ignore\n    this.hls = null;\n  }\n  loadAssetList(interstitial, hlsStartOffset) {\n    const assetListUrl = interstitial.assetListUrl;\n    let url;\n    try {\n      url = getInterstitialUrl(assetListUrl, this.hls.sessionId, interstitial.baseUrl);\n    } catch (error) {\n      const errorData = this.assignAssetListError(interstitial, ErrorDetails.ASSET_LIST_LOAD_ERROR, error, assetListUrl);\n      this.hls.trigger(Events.ERROR, errorData);\n      return;\n    }\n    if (hlsStartOffset && url.protocol !== 'data:') {\n      url.searchParams.set('_HLS_start_offset', '' + hlsStartOffset);\n    }\n    const config = this.hls.config;\n    const Loader = config.loader;\n    const loader = new Loader(config);\n    const context = {\n      responseType: 'json',\n      url: url.href\n    };\n    const loadPolicy = config.interstitialAssetListLoadPolicy.default;\n    const loaderConfig = {\n      loadPolicy,\n      timeout: loadPolicy.maxLoadTimeMs,\n      maxRetry: 0,\n      retryDelay: 0,\n      maxRetryDelay: 0\n    };\n    const callbacks = {\n      onSuccess: (response, stats, context, networkDetails) => {\n        const assetListResponse = response.data;\n        const assets = assetListResponse == null ? void 0 : assetListResponse.ASSETS;\n        if (!Array.isArray(assets)) {\n          const errorData = this.assignAssetListError(interstitial, ErrorDetails.ASSET_LIST_PARSING_ERROR, new Error(`Invalid interstitial asset list`), context.url, stats, networkDetails);\n          this.hls.trigger(Events.ERROR, errorData);\n          return;\n        }\n        interstitial.assetListResponse = assetListResponse;\n        this.hls.trigger(Events.ASSET_LIST_LOADED, {\n          event: interstitial,\n          assetListResponse,\n          networkDetails\n        });\n      },\n      onError: (error, context, networkDetails, stats) => {\n        const errorData = this.assignAssetListError(interstitial, ErrorDetails.ASSET_LIST_LOAD_ERROR, new Error(`Error loading X-ASSET-LIST: HTTP status ${error.code} ${error.text} (${context.url})`), context.url, stats, networkDetails);\n        this.hls.trigger(Events.ERROR, errorData);\n      },\n      onTimeout: (stats, context, networkDetails) => {\n        const errorData = this.assignAssetListError(interstitial, ErrorDetails.ASSET_LIST_LOAD_TIMEOUT, new Error(`Timeout loading X-ASSET-LIST (${context.url})`), context.url, stats, networkDetails);\n        this.hls.trigger(Events.ERROR, errorData);\n      }\n    };\n    loader.load(context, loaderConfig, callbacks);\n    this.hls.trigger(Events.ASSET_LIST_LOADING, {\n      event: interstitial\n    });\n    return loader;\n  }\n  assignAssetListError(interstitial, details, error, url, stats, networkDetails) {\n    interstitial.error = error;\n    return {\n      type: ErrorTypes.NETWORK_ERROR,\n      details,\n      fatal: false,\n      interstitial,\n      url,\n      error,\n      networkDetails,\n      stats\n    };\n  }\n}\n\nfunction playWithCatch(media) {\n  var _media$play;\n  media == null || (_media$play = media.play()) == null || _media$play.catch(() => {\n    /* no-op */\n  });\n}\nfunction timelineMessage(label, time) {\n  return `[${label}] Advancing timeline position to ${time}`;\n}\nclass InterstitialsController extends Logger {\n  constructor(hls, HlsPlayerClass) {\n    super('interstitials', hls.logger);\n    this.HlsPlayerClass = void 0;\n    this.hls = void 0;\n    this.assetListLoader = void 0;\n    // Last updated LevelDetails\n    this.mediaSelection = null;\n    this.altSelection = null;\n    // Media and MediaSource/SourceBuffers\n    this.media = null;\n    this.detachedData = null;\n    this.requiredTracks = null;\n    // Public Interface for Interstitial playback state and control\n    this.manager = null;\n    // Interstitial Asset Players\n    this.playerQueue = [];\n    // Timeline position tracking\n    this.bufferedPos = -1;\n    this.timelinePos = -1;\n    // Schedule\n    this.schedule = void 0;\n    // Schedule playback and buffering state\n    this.playingItem = null;\n    this.bufferingItem = null;\n    this.waitingItem = null;\n    this.endedItem = null;\n    this.playingAsset = null;\n    this.endedAsset = null;\n    this.bufferingAsset = null;\n    this.shouldPlay = false;\n    this.onPlay = () => {\n      this.shouldPlay = true;\n    };\n    this.onPause = () => {\n      this.shouldPlay = false;\n    };\n    this.onSeeking = () => {\n      const currentTime = this.currentTime;\n      if (currentTime === undefined || this.playbackDisabled || !this.schedule) {\n        return;\n      }\n      const diff = currentTime - this.timelinePos;\n      const roundingError = Math.abs(diff) < 1 / 705600000; // one flick\n      if (roundingError) {\n        return;\n      }\n      const backwardSeek = diff <= -0.01;\n      this.timelinePos = currentTime;\n      this.bufferedPos = currentTime;\n\n      // Check if seeking out of an item\n      const playingItem = this.playingItem;\n      if (!playingItem) {\n        this.checkBuffer();\n        return;\n      }\n      if (backwardSeek) {\n        const resetCount = this.schedule.resetErrorsInRange(currentTime, currentTime - diff);\n        if (resetCount) {\n          this.updateSchedule(true);\n        }\n      }\n      this.checkBuffer();\n      if (backwardSeek && currentTime < playingItem.start || currentTime >= playingItem.end) {\n        var _this$media;\n        const playingIndex = this.findItemIndex(playingItem);\n        let scheduleIndex = this.schedule.findItemIndexAtTime(currentTime);\n        if (scheduleIndex === -1) {\n          scheduleIndex = playingIndex + (backwardSeek ? -1 : 1);\n          this.log(`seeked ${backwardSeek ? 'back ' : ''}to position not covered by schedule ${currentTime} (resolving from ${playingIndex} to ${scheduleIndex})`);\n        }\n        if (!this.isInterstitial(playingItem) && (_this$media = this.media) != null && _this$media.paused) {\n          this.shouldPlay = false;\n        }\n        if (!backwardSeek) {\n          // check if an Interstitial between the current item and target item has an X-RESTRICT JUMP restriction\n          if (scheduleIndex > playingIndex) {\n            const jumpIndex = this.schedule.findJumpRestrictedIndex(playingIndex + 1, scheduleIndex);\n            if (jumpIndex > playingIndex) {\n              this.setSchedulePosition(jumpIndex);\n              return;\n            }\n          }\n        }\n        this.setSchedulePosition(scheduleIndex);\n        return;\n      }\n      // Check if seeking out of an asset (assumes same item following above check)\n      const playingAsset = this.playingAsset;\n      if (!playingAsset) {\n        // restart Interstitial at end\n        if (this.playingLastItem && this.isInterstitial(playingItem)) {\n          const restartAsset = playingItem.event.assetList[0];\n          // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition\n          if (restartAsset) {\n            this.endedItem = this.playingItem;\n            this.playingItem = null;\n            this.setScheduleToAssetAtTime(currentTime, restartAsset);\n          }\n        }\n        return;\n      }\n      const start = playingAsset.timelineStart;\n      const duration = playingAsset.duration || 0;\n      if (backwardSeek && currentTime < start || currentTime >= start + duration) {\n        var _playingItem$event;\n        if ((_playingItem$event = playingItem.event) != null && _playingItem$event.appendInPlace) {\n          // Return SourceBuffer(s) to primary player and flush\n          this.clearAssetPlayers(playingItem.event, playingItem);\n          this.flushFrontBuffer(currentTime);\n        }\n        this.setScheduleToAssetAtTime(currentTime, playingAsset);\n      }\n    };\n    this.onTimeupdate = () => {\n      const currentTime = this.currentTime;\n      if (currentTime === undefined || this.playbackDisabled) {\n        return;\n      }\n\n      // Only allow timeupdate to advance primary position, seeking is used for jumping back\n      // this prevents primaryPos from being reset to 0 after re-attach\n      if (currentTime > this.timelinePos) {\n        this.timelinePos = currentTime;\n        if (currentTime > this.bufferedPos) {\n          this.checkBuffer();\n        }\n      } else {\n        return;\n      }\n\n      // Check if playback has entered the next item\n      const playingItem = this.playingItem;\n      if (!playingItem || this.playingLastItem) {\n        return;\n      }\n      if (currentTime >= playingItem.end) {\n        this.timelinePos = playingItem.end;\n        const playingIndex = this.findItemIndex(playingItem);\n        this.setSchedulePosition(playingIndex + 1);\n      }\n      // Check if playback has entered the next asset\n      const playingAsset = this.playingAsset;\n      if (!playingAsset) {\n        return;\n      }\n      const end = playingAsset.timelineStart + (playingAsset.duration || 0);\n      if (currentTime >= end) {\n        this.setScheduleToAssetAtTime(currentTime, playingAsset);\n      }\n    };\n    // Schedule update callback\n    this.onScheduleUpdate = (removedInterstitials, previousItems) => {\n      const schedule = this.schedule;\n      if (!schedule) {\n        return;\n      }\n      const playingItem = this.playingItem;\n      const interstitialEvents = schedule.events || [];\n      const scheduleItems = schedule.items || [];\n      const durations = schedule.durations;\n      const removedIds = removedInterstitials.map(interstitial => interstitial.identifier);\n      const interstitialsUpdated = !!(interstitialEvents.length || removedIds.length);\n      if (interstitialsUpdated || previousItems) {\n        this.log(`INTERSTITIALS_UPDATED (${interstitialEvents.length}): ${interstitialEvents}\nSchedule: ${scheduleItems.map(seg => segmentToString(seg))} pos: ${this.timelinePos}`);\n      }\n      if (removedIds.length) {\n        this.log(`Removed events ${removedIds}`);\n      }\n\n      // Update schedule item references\n      // Do not replace Interstitial playingItem without a match - used for INTERSTITIAL_ASSET_ENDED and INTERSTITIAL_ENDED\n      let updatedPlayingItem = null;\n      let updatedBufferingItem = null;\n      if (playingItem) {\n        updatedPlayingItem = this.updateItem(playingItem, this.timelinePos);\n        if (this.itemsMatch(playingItem, updatedPlayingItem)) {\n          this.playingItem = updatedPlayingItem;\n        } else {\n          this.waitingItem = this.endedItem = null;\n        }\n      }\n      // Clear waitingItem if it has been removed from the schedule\n      this.waitingItem = this.updateItem(this.waitingItem);\n      this.endedItem = this.updateItem(this.endedItem);\n      // Do not replace Interstitial bufferingItem without a match - used for transfering media element or source\n      const bufferingItem = this.bufferingItem;\n      if (bufferingItem) {\n        updatedBufferingItem = this.updateItem(bufferingItem, this.bufferedPos);\n        if (this.itemsMatch(bufferingItem, updatedBufferingItem)) {\n          this.bufferingItem = updatedBufferingItem;\n        } else if (bufferingItem.event) {\n          // Interstitial removed from schedule (Live -> VOD or other scenario where Start Date is outside the range of VOD Playlist)\n          this.bufferingItem = this.playingItem;\n          this.clearInterstitial(bufferingItem.event, null);\n        }\n      }\n      removedInterstitials.forEach(interstitial => {\n        interstitial.assetList.forEach(asset => {\n          this.clearAssetPlayer(asset.identifier, null);\n        });\n      });\n      this.playerQueue.forEach(player => {\n        if (player.interstitial.appendInPlace) {\n          const timelineStart = player.assetItem.timelineStart;\n          const diff = player.timelineOffset - timelineStart;\n          if (diff) {\n            try {\n              player.timelineOffset = timelineStart;\n            } catch (e) {\n              if (Math.abs(diff) > ALIGNED_END_THRESHOLD_SECONDS) {\n                this.warn(`${e} (\"${player.assetId}\" ${player.timelineOffset}->${timelineStart})`);\n              }\n            }\n          }\n        }\n      });\n      if (interstitialsUpdated || previousItems) {\n        this.hls.trigger(Events.INTERSTITIALS_UPDATED, {\n          events: interstitialEvents.slice(0),\n          schedule: scheduleItems.slice(0),\n          durations,\n          removedIds\n        });\n        if (this.isInterstitial(playingItem) && removedIds.includes(playingItem.event.identifier)) {\n          this.warn(`Interstitial \"${playingItem.event.identifier}\" removed while playing`);\n          this.primaryFallback(playingItem.event);\n          return;\n        }\n        if (playingItem) {\n          this.trimInPlace(updatedPlayingItem, playingItem);\n        }\n        if (bufferingItem && updatedBufferingItem !== updatedPlayingItem) {\n          this.trimInPlace(updatedBufferingItem, bufferingItem);\n        }\n\n        // Check if buffered to new Interstitial event boundary\n        // (Live update publishes Interstitial with new segment)\n        this.checkBuffer();\n      }\n    };\n    this.hls = hls;\n    this.HlsPlayerClass = HlsPlayerClass;\n    this.assetListLoader = new AssetListLoader(hls);\n    this.schedule = new InterstitialsSchedule(this.onScheduleUpdate, hls.logger);\n    this.registerListeners();\n  }\n  registerListeners() {\n    const hls = this.hls;\n    // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition\n    if (hls) {\n      hls.on(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);\n      hls.on(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n      hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n      hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      hls.on(Events.LEVEL_UPDATED, this.onLevelUpdated, this);\n      hls.on(Events.AUDIO_TRACK_SWITCHING, this.onAudioTrackSwitching, this);\n      hls.on(Events.AUDIO_TRACK_UPDATED, this.onAudioTrackUpdated, this);\n      hls.on(Events.SUBTITLE_TRACK_SWITCH, this.onSubtitleTrackSwitch, this);\n      hls.on(Events.SUBTITLE_TRACK_UPDATED, this.onSubtitleTrackUpdated, this);\n      hls.on(Events.EVENT_CUE_ENTER, this.onInterstitialCueEnter, this);\n      hls.on(Events.ASSET_LIST_LOADED, this.onAssetListLoaded, this);\n      hls.on(Events.BUFFER_APPENDED, this.onBufferAppended, this);\n      hls.on(Events.BUFFER_FLUSHED, this.onBufferFlushed, this);\n      hls.on(Events.BUFFERED_TO_END, this.onBufferedToEnd, this);\n      hls.on(Events.MEDIA_ENDED, this.onMediaEnded, this);\n      hls.on(Events.ERROR, this.onError, this);\n      hls.on(Events.DESTROYING, this.onDestroying, this);\n    }\n  }\n  unregisterListeners() {\n    const hls = this.hls;\n    // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition\n    if (hls) {\n      hls.off(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);\n      hls.off(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n      hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n      hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      hls.off(Events.LEVEL_UPDATED, this.onLevelUpdated, this);\n      hls.off(Events.AUDIO_TRACK_SWITCHING, this.onAudioTrackSwitching, this);\n      hls.off(Events.AUDIO_TRACK_UPDATED, this.onAudioTrackUpdated, this);\n      hls.off(Events.SUBTITLE_TRACK_SWITCH, this.onSubtitleTrackSwitch, this);\n      hls.off(Events.SUBTITLE_TRACK_UPDATED, this.onSubtitleTrackUpdated, this);\n      hls.off(Events.EVENT_CUE_ENTER, this.onInterstitialCueEnter, this);\n      hls.off(Events.ASSET_LIST_LOADED, this.onAssetListLoaded, this);\n      hls.off(Events.BUFFER_CODECS, this.onBufferCodecs, this);\n      hls.off(Events.BUFFER_APPENDED, this.onBufferAppended, this);\n      hls.off(Events.BUFFER_FLUSHED, this.onBufferFlushed, this);\n      hls.off(Events.BUFFERED_TO_END, this.onBufferedToEnd, this);\n      hls.off(Events.MEDIA_ENDED, this.onMediaEnded, this);\n      hls.off(Events.ERROR, this.onError, this);\n      hls.off(Events.DESTROYING, this.onDestroying, this);\n    }\n  }\n  startLoad() {\n    // TODO: startLoad - check for waitingItem and retry by resetting schedule\n    this.resumeBuffering();\n  }\n  stopLoad() {\n    // TODO: stopLoad - stop all scheule.events[].assetListLoader?.abort() then delete the loaders\n    this.pauseBuffering();\n  }\n  resumeBuffering() {\n    var _this$getBufferingPla;\n    (_this$getBufferingPla = this.getBufferingPlayer()) == null || _this$getBufferingPla.resumeBuffering();\n  }\n  pauseBuffering() {\n    var _this$getBufferingPla2;\n    (_this$getBufferingPla2 = this.getBufferingPlayer()) == null || _this$getBufferingPla2.pauseBuffering();\n  }\n  destroy() {\n    this.unregisterListeners();\n    this.stopLoad();\n    // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition\n    if (this.assetListLoader) {\n      this.assetListLoader.destroy();\n    }\n    this.emptyPlayerQueue();\n    this.clearScheduleState();\n    if (this.schedule) {\n      this.schedule.destroy();\n    }\n    this.media = this.detachedData = this.mediaSelection = this.requiredTracks = this.altSelection = this.schedule = this.manager = null;\n    // @ts-ignore\n    this.hls = this.HlsPlayerClass = this.log = null;\n    // @ts-ignore\n    this.assetListLoader = null;\n    // @ts-ignore\n    this.onPlay = this.onPause = this.onSeeking = this.onTimeupdate = null;\n    // @ts-ignore\n    this.onScheduleUpdate = null;\n  }\n  onDestroying() {\n    const media = this.primaryMedia || this.media;\n    if (media) {\n      this.removeMediaListeners(media);\n    }\n  }\n  removeMediaListeners(media) {\n    removeEventListener(media, 'play', this.onPlay);\n    removeEventListener(media, 'pause', this.onPause);\n    removeEventListener(media, 'seeking', this.onSeeking);\n    removeEventListener(media, 'timeupdate', this.onTimeupdate);\n  }\n  onMediaAttaching(event, data) {\n    const media = this.media = data.media;\n    addEventListener(media, 'seeking', this.onSeeking);\n    addEventListener(media, 'timeupdate', this.onTimeupdate);\n    addEventListener(media, 'play', this.onPlay);\n    addEventListener(media, 'pause', this.onPause);\n  }\n  onMediaAttached(event, data) {\n    const playingItem = this.effectivePlayingItem;\n    const detachedMedia = this.detachedData;\n    this.detachedData = null;\n    if (playingItem === null) {\n      this.checkStart();\n    } else if (!detachedMedia) {\n      // Resume schedule after detached externally\n      this.clearScheduleState();\n      const playingIndex = this.findItemIndex(playingItem);\n      this.setSchedulePosition(playingIndex);\n    }\n  }\n  clearScheduleState() {\n    this.log(`clear schedule state`);\n    this.playingItem = this.bufferingItem = this.waitingItem = this.endedItem = this.playingAsset = this.endedAsset = this.bufferingAsset = null;\n  }\n  onMediaDetaching(event, data) {\n    const transferringMedia = !!data.transferMedia;\n    const media = this.media;\n    this.media = null;\n    if (transferringMedia) {\n      return;\n    }\n    if (media) {\n      this.removeMediaListeners(media);\n    }\n    // If detachMedia is called while in an Interstitial, detach the asset player as well and reset the schedule position\n    if (this.detachedData) {\n      const player = this.getBufferingPlayer();\n      if (player) {\n        this.log(`Removing schedule state for detachedData and ${player}`);\n        this.playingAsset = this.endedAsset = this.bufferingAsset = this.bufferingItem = this.waitingItem = this.detachedData = null;\n        player.detachMedia();\n      }\n      this.shouldPlay = false;\n    }\n  }\n  get interstitialsManager() {\n    // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition\n    if (!this.hls) {\n      return null;\n    }\n    if (this.manager) {\n      return this.manager;\n    }\n    const c = this;\n    const effectiveBufferingItem = () => c.bufferingItem || c.waitingItem;\n    const getAssetPlayer = asset => asset ? c.getAssetPlayer(asset.identifier) : asset;\n    const getMappedTime = (item, timelineType, asset, controllerField, assetPlayerField) => {\n      if (item) {\n        let time = item[timelineType].start;\n        const interstitial = item.event;\n        if (interstitial) {\n          if (timelineType === 'playout' || interstitial.timelineOccupancy !== TimelineOccupancy.Point) {\n            const assetPlayer = getAssetPlayer(asset);\n            if ((assetPlayer == null ? void 0 : assetPlayer.interstitial) === interstitial) {\n              time += assetPlayer.assetItem.startOffset + assetPlayer[assetPlayerField];\n            }\n          }\n        } else {\n          const value = controllerField === 'bufferedPos' ? getBufferedEnd() : c[controllerField];\n          time += value - item.start;\n        }\n        return time;\n      }\n      return 0;\n    };\n    const findMappedTime = (primaryTime, timelineType) => {\n      var _c$schedule;\n      if (primaryTime !== 0 && timelineType !== 'primary' && (_c$schedule = c.schedule) != null && _c$schedule.length) {\n        var _c$schedule$items;\n        const index = c.schedule.findItemIndexAtTime(primaryTime);\n        const item = (_c$schedule$items = c.schedule.items) == null ? void 0 : _c$schedule$items[index];\n        if (item) {\n          const diff = item[timelineType].start - item.start;\n          return primaryTime + diff;\n        }\n      }\n      return primaryTime;\n    };\n    const getBufferedEnd = () => {\n      const value = c.bufferedPos;\n      if (value === Number.MAX_VALUE) {\n        return getMappedDuration('primary');\n      }\n      return Math.max(value, 0);\n    };\n    const getMappedDuration = timelineType => {\n      var _c$primaryDetails, _c$schedule2;\n      if ((_c$primaryDetails = c.primaryDetails) != null && _c$primaryDetails.live) {\n        // return end of last event item or playlist\n        return c.primaryDetails.edge;\n      }\n      return ((_c$schedule2 = c.schedule) == null ? void 0 : _c$schedule2.durations[timelineType]) || 0;\n    };\n    const seekTo = (time, timelineType) => {\n      var _item$event, _c$schedule$items2;\n      const item = c.effectivePlayingItem;\n      if (item != null && (_item$event = item.event) != null && _item$event.restrictions.skip || !c.schedule) {\n        return;\n      }\n      c.log(`seek to ${time} \"${timelineType}\"`);\n      const playingItem = c.effectivePlayingItem;\n      const targetIndex = c.schedule.findItemIndexAtTime(time, timelineType);\n      const targetItem = (_c$schedule$items2 = c.schedule.items) == null ? void 0 : _c$schedule$items2[targetIndex];\n      const bufferingPlayer = c.getBufferingPlayer();\n      const bufferingInterstitial = bufferingPlayer == null ? void 0 : bufferingPlayer.interstitial;\n      const appendInPlace = bufferingInterstitial == null ? void 0 : bufferingInterstitial.appendInPlace;\n      const seekInItem = playingItem && c.itemsMatch(playingItem, targetItem);\n      if (playingItem && (appendInPlace || seekInItem)) {\n        // seek in asset player or primary media (appendInPlace)\n        const assetPlayer = getAssetPlayer(c.playingAsset);\n        const media = (assetPlayer == null ? void 0 : assetPlayer.media) || c.primaryMedia;\n        if (media) {\n          const currentTime = timelineType === 'primary' ? media.currentTime : getMappedTime(playingItem, timelineType, c.playingAsset, 'timelinePos', 'currentTime');\n          const diff = time - currentTime;\n          const seekToTime = (appendInPlace ? currentTime : media.currentTime) + diff;\n          if (seekToTime >= 0 && (!assetPlayer || appendInPlace || seekToTime <= assetPlayer.duration)) {\n            media.currentTime = seekToTime;\n            return;\n          }\n        }\n      }\n      // seek out of item or asset\n      if (targetItem) {\n        let seekToTime = time;\n        if (timelineType !== 'primary') {\n          const primarySegmentStart = targetItem[timelineType].start;\n          const diff = time - primarySegmentStart;\n          seekToTime = targetItem.start + diff;\n        }\n        const targetIsPrimary = !c.isInterstitial(targetItem);\n        if ((!c.isInterstitial(playingItem) || playingItem.event.appendInPlace) && (targetIsPrimary || targetItem.event.appendInPlace)) {\n          const media = c.media || (appendInPlace ? bufferingPlayer == null ? void 0 : bufferingPlayer.media : null);\n          if (media) {\n            media.currentTime = seekToTime;\n          }\n        } else if (playingItem) {\n          // check if an Interstitial between the current item and target item has an X-RESTRICT JUMP restriction\n          const playingIndex = c.findItemIndex(playingItem);\n          if (targetIndex > playingIndex) {\n            const jumpIndex = c.schedule.findJumpRestrictedIndex(playingIndex + 1, targetIndex);\n            if (jumpIndex > playingIndex) {\n              c.setSchedulePosition(jumpIndex);\n              return;\n            }\n          }\n          let assetIndex = 0;\n          if (targetIsPrimary) {\n            c.timelinePos = seekToTime;\n            c.checkBuffer();\n          } else {\n            const assetList = targetItem.event.assetList;\n            const eventTime = time - (targetItem[timelineType] || targetItem).start;\n            for (let i = assetList.length; i--;) {\n              const asset = assetList[i];\n              if (asset.duration && eventTime >= asset.startOffset && eventTime < asset.startOffset + asset.duration) {\n                assetIndex = i;\n                break;\n              }\n            }\n          }\n          c.setSchedulePosition(targetIndex, assetIndex);\n        }\n      }\n    };\n    const getActiveInterstitial = () => {\n      const playingItem = c.effectivePlayingItem;\n      if (c.isInterstitial(playingItem)) {\n        return playingItem;\n      }\n      const bufferingItem = effectiveBufferingItem();\n      if (c.isInterstitial(bufferingItem)) {\n        return bufferingItem;\n      }\n      return null;\n    };\n    const interstitialPlayer = {\n      get bufferedEnd() {\n        const interstitialItem = effectiveBufferingItem();\n        const bufferingItem = c.bufferingItem;\n        if (bufferingItem && bufferingItem === interstitialItem) {\n          var _c$bufferingAsset;\n          return getMappedTime(bufferingItem, 'playout', c.bufferingAsset, 'bufferedPos', 'bufferedEnd') - bufferingItem.playout.start || ((_c$bufferingAsset = c.bufferingAsset) == null ? void 0 : _c$bufferingAsset.startOffset) || 0;\n        }\n        return 0;\n      },\n      get currentTime() {\n        const interstitialItem = getActiveInterstitial();\n        const playingItem = c.effectivePlayingItem;\n        if (playingItem && playingItem === interstitialItem) {\n          return getMappedTime(playingItem, 'playout', c.effectivePlayingAsset, 'timelinePos', 'currentTime') - playingItem.playout.start;\n        }\n        return 0;\n      },\n      set currentTime(time) {\n        const interstitialItem = getActiveInterstitial();\n        const playingItem = c.effectivePlayingItem;\n        if (playingItem && playingItem === interstitialItem) {\n          seekTo(time + playingItem.playout.start, 'playout');\n        }\n      },\n      get duration() {\n        const interstitialItem = getActiveInterstitial();\n        if (interstitialItem) {\n          return interstitialItem.playout.end - interstitialItem.playout.start;\n        }\n        return 0;\n      },\n      get assetPlayers() {\n        var _getActiveInterstitia;\n        const assetList = (_getActiveInterstitia = getActiveInterstitial()) == null ? void 0 : _getActiveInterstitia.event.assetList;\n        if (assetList) {\n          return assetList.map(asset => c.getAssetPlayer(asset.identifier));\n        }\n        return [];\n      },\n      get playingIndex() {\n        var _getActiveInterstitia2;\n        const interstitial = (_getActiveInterstitia2 = getActiveInterstitial()) == null ? void 0 : _getActiveInterstitia2.event;\n        if (interstitial && c.effectivePlayingAsset) {\n          return interstitial.findAssetIndex(c.effectivePlayingAsset);\n        }\n        return -1;\n      },\n      get scheduleItem() {\n        return getActiveInterstitial();\n      }\n    };\n    return this.manager = {\n      get events() {\n        var _c$schedule3;\n        // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition\n        return ((_c$schedule3 = c.schedule) == null || (_c$schedule3 = _c$schedule3.events) == null ? void 0 : _c$schedule3.slice(0)) || [];\n      },\n      get schedule() {\n        var _c$schedule4;\n        // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition\n        return ((_c$schedule4 = c.schedule) == null || (_c$schedule4 = _c$schedule4.items) == null ? void 0 : _c$schedule4.slice(0)) || [];\n      },\n      get interstitialPlayer() {\n        if (getActiveInterstitial()) {\n          return interstitialPlayer;\n        }\n        return null;\n      },\n      get playerQueue() {\n        return c.playerQueue.slice(0);\n      },\n      get bufferingAsset() {\n        return c.bufferingAsset;\n      },\n      get bufferingItem() {\n        return effectiveBufferingItem();\n      },\n      get bufferingIndex() {\n        const item = effectiveBufferingItem();\n        return c.findItemIndex(item);\n      },\n      get playingAsset() {\n        return c.effectivePlayingAsset;\n      },\n      get playingItem() {\n        return c.effectivePlayingItem;\n      },\n      get playingIndex() {\n        const item = c.effectivePlayingItem;\n        return c.findItemIndex(item);\n      },\n      primary: {\n        get bufferedEnd() {\n          return getBufferedEnd();\n        },\n        get currentTime() {\n          const timelinePos = c.timelinePos;\n          return timelinePos > 0 ? timelinePos : 0;\n        },\n        set currentTime(time) {\n          seekTo(time, 'primary');\n        },\n        get duration() {\n          return getMappedDuration('primary');\n        },\n        get seekableStart() {\n          var _c$primaryDetails2;\n          return ((_c$primaryDetails2 = c.primaryDetails) == null ? void 0 : _c$primaryDetails2.fragmentStart) || 0;\n        }\n      },\n      integrated: {\n        get bufferedEnd() {\n          return getMappedTime(effectiveBufferingItem(), 'integrated', c.bufferingAsset, 'bufferedPos', 'bufferedEnd');\n        },\n        get currentTime() {\n          return getMappedTime(c.effectivePlayingItem, 'integrated', c.effectivePlayingAsset, 'timelinePos', 'currentTime');\n        },\n        set currentTime(time) {\n          seekTo(time, 'integrated');\n        },\n        get duration() {\n          return getMappedDuration('integrated');\n        },\n        get seekableStart() {\n          var _c$primaryDetails3;\n          return findMappedTime(((_c$primaryDetails3 = c.primaryDetails) == null ? void 0 : _c$primaryDetails3.fragmentStart) || 0, 'integrated');\n        }\n      },\n      skip: () => {\n        const item = c.effectivePlayingItem;\n        const event = item == null ? void 0 : item.event;\n        if (event && !event.restrictions.skip) {\n          const index = c.findItemIndex(item);\n          if (event.appendInPlace) {\n            const time = item.playout.start + item.event.duration;\n            seekTo(time + 0.001, 'playout');\n          } else {\n            c.advanceAfterAssetEnded(event, index, Infinity);\n          }\n        }\n      }\n    };\n  }\n\n  // Schedule getters\n  get effectivePlayingItem() {\n    return this.waitingItem || this.playingItem || this.endedItem;\n  }\n  get effectivePlayingAsset() {\n    return this.playingAsset || this.endedAsset;\n  }\n  get playingLastItem() {\n    var _this$schedule;\n    const playingItem = this.playingItem;\n    const items = (_this$schedule = this.schedule) == null ? void 0 : _this$schedule.items;\n    if (!this.playbackStarted || !playingItem || !items) {\n      return false;\n    }\n    return this.findItemIndex(playingItem) === items.length - 1;\n  }\n  get playbackStarted() {\n    return this.effectivePlayingItem !== null;\n  }\n\n  // Media getters and event callbacks\n  get currentTime() {\n    var _this$bufferingItem, _media;\n    if (this.mediaSelection === null) {\n      // Do not advance before schedule is known\n      return undefined;\n    }\n    // Ignore currentTime when detached for Interstitial playback with source reset\n    const queuedForPlayback = this.waitingItem || this.playingItem;\n    if (this.isInterstitial(queuedForPlayback) && !queuedForPlayback.event.appendInPlace) {\n      return undefined;\n    }\n    let media = this.media;\n    if (!media && (_this$bufferingItem = this.bufferingItem) != null && (_this$bufferingItem = _this$bufferingItem.event) != null && _this$bufferingItem.appendInPlace) {\n      // Observe detached media currentTime when appending in place\n      media = this.primaryMedia;\n    }\n    const currentTime = (_media = media) == null ? void 0 : _media.currentTime;\n    if (currentTime === undefined || !isFiniteNumber(currentTime)) {\n      return undefined;\n    }\n    return currentTime;\n  }\n  get primaryMedia() {\n    var _this$detachedData;\n    return this.media || ((_this$detachedData = this.detachedData) == null ? void 0 : _this$detachedData.media) || null;\n  }\n  isInterstitial(item) {\n    return !!(item != null && item.event);\n  }\n  retreiveMediaSource(assetId, toSegment) {\n    const player = this.getAssetPlayer(assetId);\n    if (player) {\n      this.transferMediaFromPlayer(player, toSegment);\n    }\n  }\n  transferMediaFromPlayer(player, toSegment) {\n    const appendInPlace = player.interstitial.appendInPlace;\n    const playerMedia = player.media;\n    if (appendInPlace && playerMedia === this.primaryMedia) {\n      this.bufferingAsset = null;\n      if (!toSegment || this.isInterstitial(toSegment) && !toSegment.event.appendInPlace) {\n        // MediaSource cannot be transfered back to an Interstitial that requires a source reset\n        // no-op when toSegment is undefined\n        if (toSegment && playerMedia) {\n          this.detachedData = {\n            media: playerMedia\n          };\n          return;\n        }\n      }\n      const attachMediaSourceData = player.transferMedia();\n      this.log(`transfer MediaSource from ${player} ${stringify(attachMediaSourceData)}`);\n      this.detachedData = attachMediaSourceData;\n    } else if (toSegment && playerMedia) {\n      this.shouldPlay || (this.shouldPlay = !playerMedia.paused);\n    }\n  }\n  transferMediaTo(player, media) {\n    var _this$detachedData2, _attachMediaSourceDat;\n    if (player.media === media) {\n      return;\n    }\n    let attachMediaSourceData = null;\n    const primaryPlayer = this.hls;\n    const isAssetPlayer = player !== primaryPlayer;\n    const appendInPlace = isAssetPlayer && player.interstitial.appendInPlace;\n    const detachedMediaSource = (_this$detachedData2 = this.detachedData) == null ? void 0 : _this$detachedData2.mediaSource;\n    let logFromSource;\n    if (primaryPlayer.media) {\n      if (appendInPlace) {\n        attachMediaSourceData = primaryPlayer.transferMedia();\n        this.detachedData = attachMediaSourceData;\n      }\n      logFromSource = `Primary`;\n    } else if (detachedMediaSource) {\n      const bufferingPlayer = this.getBufferingPlayer();\n      if (bufferingPlayer) {\n        attachMediaSourceData = bufferingPlayer.transferMedia();\n        logFromSource = `${bufferingPlayer}`;\n      } else {\n        logFromSource = `detached MediaSource`;\n      }\n    } else {\n      logFromSource = `detached media`;\n    }\n    if (!attachMediaSourceData) {\n      if (detachedMediaSource) {\n        attachMediaSourceData = this.detachedData;\n        this.log(`using detachedData: MediaSource ${stringify(attachMediaSourceData)}`);\n      } else if (!this.detachedData || primaryPlayer.media === media) {\n        // Keep interstitial media transition consistent\n        const playerQueue = this.playerQueue;\n        if (playerQueue.length > 1) {\n          playerQueue.forEach(queuedPlayer => {\n            if (isAssetPlayer && queuedPlayer.interstitial.appendInPlace !== appendInPlace) {\n              const interstitial = queuedPlayer.interstitial;\n              this.clearInterstitial(queuedPlayer.interstitial, null);\n              interstitial.appendInPlace = false; // setter may be a no-op;\n              // `appendInPlace` getter may still return `true` after insterstitial streaming has begun in that mode.\n              if (interstitial.appendInPlace) {\n                this.warn(`Could not change append strategy for queued assets ${interstitial}`);\n              }\n            }\n          });\n        }\n        this.hls.detachMedia();\n        this.detachedData = {\n          media\n        };\n      }\n    }\n    const transferring = attachMediaSourceData && 'mediaSource' in attachMediaSourceData && ((_attachMediaSourceDat = attachMediaSourceData.mediaSource) == null ? void 0 : _attachMediaSourceDat.readyState) !== 'closed';\n    const dataToAttach = transferring && attachMediaSourceData ? attachMediaSourceData : media;\n    this.log(`${transferring ? 'transfering MediaSource' : 'attaching media'} to ${isAssetPlayer ? player : 'Primary'} from ${logFromSource} (media.currentTime: ${media.currentTime})`);\n    const schedule = this.schedule;\n    if (dataToAttach === attachMediaSourceData && schedule) {\n      const isAssetAtEndOfSchedule = isAssetPlayer && player.assetId === schedule.assetIdAtEnd;\n      // Prevent asset players from marking EoS on transferred MediaSource\n      dataToAttach.overrides = {\n        duration: schedule.duration,\n        endOfStream: !isAssetPlayer || isAssetAtEndOfSchedule,\n        cueRemoval: !isAssetPlayer\n      };\n    }\n    player.attachMedia(dataToAttach);\n  }\n  onInterstitialCueEnter() {\n    this.onTimeupdate();\n  }\n  // Scheduling methods\n  checkStart() {\n    const schedule = this.schedule;\n    const interstitialEvents = schedule == null ? void 0 : schedule.events;\n    if (!interstitialEvents || this.playbackDisabled || !this.media) {\n      return;\n    }\n    // Check buffered to pre-roll\n    if (this.bufferedPos === -1) {\n      this.bufferedPos = 0;\n    }\n    // Start stepping through schedule when playback begins for the first time and we have a pre-roll\n    const timelinePos = this.timelinePos;\n    const effectivePlayingItem = this.effectivePlayingItem;\n    if (timelinePos === -1) {\n      const startPosition = this.hls.startPosition;\n      this.log(timelineMessage('checkStart', startPosition));\n      this.timelinePos = startPosition;\n      if (interstitialEvents.length && interstitialEvents[0].cue.pre) {\n        const index = schedule.findEventIndex(interstitialEvents[0].identifier);\n        this.setSchedulePosition(index);\n      } else if (startPosition >= 0 || !this.primaryLive) {\n        const start = this.timelinePos = startPosition > 0 ? startPosition : 0;\n        const index = schedule.findItemIndexAtTime(start);\n        this.setSchedulePosition(index);\n      }\n    } else if (effectivePlayingItem && !this.playingItem) {\n      const index = schedule.findItemIndex(effectivePlayingItem);\n      this.setSchedulePosition(index);\n    }\n  }\n  advanceAssetBuffering(item, assetItem) {\n    const interstitial = item.event;\n    const assetListIndex = interstitial.findAssetIndex(assetItem);\n    const nextAssetIndex = getNextAssetIndex(interstitial, assetListIndex);\n    if (!interstitial.isAssetPastPlayoutLimit(nextAssetIndex)) {\n      this.bufferedToEvent(item, nextAssetIndex);\n    } else if (this.schedule) {\n      var _this$schedule$items;\n      const nextItem = (_this$schedule$items = this.schedule.items) == null ? void 0 : _this$schedule$items[this.findItemIndex(item) + 1];\n      if (nextItem) {\n        this.bufferedToItem(nextItem);\n      }\n    }\n  }\n  advanceAfterAssetEnded(interstitial, index, assetListIndex) {\n    const nextAssetIndex = getNextAssetIndex(interstitial, assetListIndex);\n    if (!interstitial.isAssetPastPlayoutLimit(nextAssetIndex)) {\n      // Advance to next asset list item\n      if (interstitial.appendInPlace) {\n        const assetItem = interstitial.assetList[nextAssetIndex];\n        if (assetItem) {\n          this.advanceInPlace(assetItem.timelineStart);\n        }\n      }\n      this.setSchedulePosition(index, nextAssetIndex);\n    } else if (this.schedule) {\n      // Advance to next schedule segment\n      // check if we've reached the end of the program\n      const scheduleItems = this.schedule.items;\n      if (scheduleItems) {\n        const nextIndex = index + 1;\n        const scheduleLength = scheduleItems.length;\n        if (nextIndex >= scheduleLength) {\n          this.setSchedulePosition(-1);\n          return;\n        }\n        const resumptionTime = interstitial.resumeTime;\n        if (this.timelinePos < resumptionTime) {\n          this.log(timelineMessage('advanceAfterAssetEnded', resumptionTime));\n          this.timelinePos = resumptionTime;\n          if (interstitial.appendInPlace) {\n            this.advanceInPlace(resumptionTime);\n          }\n          this.checkBuffer(this.bufferedPos < resumptionTime);\n        }\n        this.setSchedulePosition(nextIndex);\n      }\n    }\n  }\n  setScheduleToAssetAtTime(time, playingAsset) {\n    const schedule = this.schedule;\n    if (!schedule) {\n      return;\n    }\n    const parentIdentifier = playingAsset.parentIdentifier;\n    const interstitial = schedule.getEvent(parentIdentifier);\n    if (interstitial) {\n      const itemIndex = schedule.findEventIndex(parentIdentifier);\n      const assetListIndex = schedule.findAssetIndex(interstitial, time);\n      this.advanceAfterAssetEnded(interstitial, itemIndex, assetListIndex - 1);\n    }\n  }\n  setSchedulePosition(index, assetListIndex) {\n    var _this$schedule2;\n    const scheduleItems = (_this$schedule2 = this.schedule) == null ? void 0 : _this$schedule2.items;\n    if (!scheduleItems || this.playbackDisabled) {\n      return;\n    }\n    const scheduledItem = index >= 0 ? scheduleItems[index] : null;\n    this.log(`setSchedulePosition ${index}, ${assetListIndex} (${scheduledItem ? segmentToString(scheduledItem) : scheduledItem}) pos: ${this.timelinePos}`);\n    // Cleanup current item / asset\n    const currentItem = this.waitingItem || this.playingItem;\n    const playingLastItem = this.playingLastItem;\n    if (this.isInterstitial(currentItem)) {\n      const interstitial = currentItem.event;\n      const playingAsset = this.playingAsset;\n      const assetId = playingAsset == null ? void 0 : playingAsset.identifier;\n      const player = assetId ? this.getAssetPlayer(assetId) : null;\n      if (player && assetId && (!this.eventItemsMatch(currentItem, scheduledItem) || assetListIndex !== undefined && assetId !== interstitial.assetList[assetListIndex].identifier)) {\n        var _this$detachedData3;\n        const playingAssetListIndex = interstitial.findAssetIndex(playingAsset);\n        this.log(`INTERSTITIAL_ASSET_ENDED ${playingAssetListIndex + 1}/${interstitial.assetList.length} ${eventAssetToString(playingAsset)}`);\n        this.endedAsset = playingAsset;\n        this.playingAsset = null;\n        this.hls.trigger(Events.INTERSTITIAL_ASSET_ENDED, {\n          asset: playingAsset,\n          assetListIndex: playingAssetListIndex,\n          event: interstitial,\n          schedule: scheduleItems.slice(0),\n          scheduleIndex: index,\n          player\n        });\n        if (currentItem !== this.playingItem) {\n          // Schedule change occured on INTERSTITIAL_ASSET_ENDED\n          if (this.itemsMatch(currentItem, this.playingItem) &&\n          // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition\n          !this.playingAsset // INTERSTITIAL_ASSET_ENDED side-effect\n          ) {\n            this.advanceAfterAssetEnded(interstitial, this.findItemIndex(this.playingItem), playingAssetListIndex);\n          }\n          // Navigation occured on INTERSTITIAL_ASSET_ENDED\n          return;\n        }\n        this.retreiveMediaSource(assetId, scheduledItem);\n        if (player.media && !((_this$detachedData3 = this.detachedData) != null && _this$detachedData3.mediaSource)) {\n          player.detachMedia();\n        }\n      }\n      if (!this.eventItemsMatch(currentItem, scheduledItem)) {\n        this.endedItem = currentItem;\n        this.playingItem = null;\n        this.log(`INTERSTITIAL_ENDED ${interstitial} ${segmentToString(currentItem)}`);\n        interstitial.hasPlayed = true;\n        this.hls.trigger(Events.INTERSTITIAL_ENDED, {\n          event: interstitial,\n          schedule: scheduleItems.slice(0),\n          scheduleIndex: index\n        });\n        // Exiting an Interstitial\n        if (interstitial.cue.once) {\n          var _this$schedule3;\n          // Remove interstitial with CUE attribute value of ONCE after it has played\n          this.updateSchedule();\n          const updatedScheduleItems = (_this$schedule3 = this.schedule) == null ? void 0 : _this$schedule3.items;\n          if (scheduledItem && updatedScheduleItems) {\n            const updatedIndex = this.findItemIndex(scheduledItem);\n            this.advanceSchedule(updatedIndex, updatedScheduleItems, assetListIndex, currentItem, playingLastItem);\n          }\n          return;\n        }\n      }\n    }\n    this.advanceSchedule(index, scheduleItems, assetListIndex, currentItem, playingLastItem);\n  }\n  advanceSchedule(index, scheduleItems, assetListIndex, currentItem, playedLastItem) {\n    const schedule = this.schedule;\n    if (!schedule) {\n      return;\n    }\n    const scheduledItem = scheduleItems[index] || null;\n    const media = this.primaryMedia;\n    // Cleanup out of range Interstitials\n    const playerQueue = this.playerQueue;\n    if (playerQueue.length) {\n      playerQueue.forEach(player => {\n        const interstitial = player.interstitial;\n        const queuedIndex = schedule.findEventIndex(interstitial.identifier);\n        if (queuedIndex < index || queuedIndex > index + 1) {\n          this.clearInterstitial(interstitial, scheduledItem);\n        }\n      });\n    }\n    // Setup scheduled item\n    if (this.isInterstitial(scheduledItem)) {\n      this.timelinePos = Math.min(Math.max(this.timelinePos, scheduledItem.start), scheduledItem.end);\n      // Handle Interstitial\n      const interstitial = scheduledItem.event;\n      // find asset index\n      if (assetListIndex === undefined) {\n        assetListIndex = schedule.findAssetIndex(interstitial, this.timelinePos);\n        const assetIndexCandidate = getNextAssetIndex(interstitial, assetListIndex - 1);\n        if (interstitial.isAssetPastPlayoutLimit(assetIndexCandidate) || interstitial.appendInPlace && this.timelinePos === scheduledItem.end) {\n          this.advanceAfterAssetEnded(interstitial, index, assetListIndex);\n          return;\n        }\n        assetListIndex = assetIndexCandidate;\n      }\n      // Ensure Interstitial is enqueued\n      const waitingItem = this.waitingItem;\n      if (!this.assetsBuffered(scheduledItem, media)) {\n        this.setBufferingItem(scheduledItem);\n      }\n      let player = this.preloadAssets(interstitial, assetListIndex);\n      if (!this.eventItemsMatch(scheduledItem, waitingItem || currentItem)) {\n        this.waitingItem = scheduledItem;\n        this.log(`INTERSTITIAL_STARTED ${segmentToString(scheduledItem)} ${interstitial.appendInPlace ? 'append in place' : ''}`);\n        this.hls.trigger(Events.INTERSTITIAL_STARTED, {\n          event: interstitial,\n          schedule: scheduleItems.slice(0),\n          scheduleIndex: index\n        });\n      }\n      if (!interstitial.assetListLoaded) {\n        // Waiting at end of primary content segment\n        // Expect setSchedulePosition to be called again once ASSET-LIST is loaded\n        this.log(`Waiting for ASSET-LIST to complete loading ${interstitial}`);\n        return;\n      }\n      if (interstitial.assetListLoader) {\n        interstitial.assetListLoader.destroy();\n        interstitial.assetListLoader = undefined;\n      }\n      if (!media) {\n        this.log(`Waiting for attachMedia to start Interstitial ${interstitial}`);\n        return;\n      }\n      // Update schedule and asset list position now that it can start\n      this.waitingItem = this.endedItem = null;\n      this.playingItem = scheduledItem;\n\n      // If asset-list is empty or missing asset index, advance to next item\n      const assetItem = interstitial.assetList[assetListIndex];\n      if (!assetItem) {\n        this.advanceAfterAssetEnded(interstitial, index, assetListIndex || 0);\n        return;\n      }\n\n      // Start Interstitial Playback\n      if (!player) {\n        player = this.getAssetPlayer(assetItem.identifier);\n      }\n      if (player === null || player.destroyed) {\n        const assetListLength = interstitial.assetList.length;\n        this.warn(`asset ${assetListIndex + 1}/${assetListLength} player destroyed ${interstitial}`);\n        player = this.createAssetPlayer(interstitial, assetItem, assetListIndex);\n        player.loadSource();\n      }\n      if (!this.eventItemsMatch(scheduledItem, this.bufferingItem)) {\n        if (interstitial.appendInPlace && this.isAssetBuffered(assetItem)) {\n          return;\n        }\n      }\n      this.startAssetPlayer(player, assetListIndex, scheduleItems, index, media);\n      if (this.shouldPlay) {\n        playWithCatch(player.media);\n      }\n    } else if (scheduledItem) {\n      this.resumePrimary(scheduledItem, index, currentItem);\n      if (this.shouldPlay) {\n        playWithCatch(this.hls.media);\n      }\n    } else if (playedLastItem && this.isInterstitial(currentItem)) {\n      // Maintain playingItem state at end of schedule (setSchedulePosition(-1) called to end program)\n      // this allows onSeeking handler to update schedule position\n      this.endedItem = null;\n      this.playingItem = currentItem;\n      if (!currentItem.event.appendInPlace) {\n        // Media must be re-attached to resume primary schedule if not sharing source\n        this.attachPrimary(schedule.durations.primary, null);\n      }\n    }\n  }\n  get playbackDisabled() {\n    return this.hls.config.enableInterstitialPlayback === false;\n  }\n  get primaryDetails() {\n    var _this$mediaSelection;\n    return (_this$mediaSelection = this.mediaSelection) == null ? void 0 : _this$mediaSelection.main.details;\n  }\n  get primaryLive() {\n    var _this$primaryDetails;\n    return !!((_this$primaryDetails = this.primaryDetails) != null && _this$primaryDetails.live);\n  }\n  resumePrimary(scheduledItem, index, fromItem) {\n    var _this$detachedData4, _this$schedule4;\n    this.playingItem = scheduledItem;\n    this.playingAsset = this.endedAsset = null;\n    this.waitingItem = this.endedItem = null;\n    this.bufferedToItem(scheduledItem);\n    this.log(`resuming ${segmentToString(scheduledItem)}`);\n    if (!((_this$detachedData4 = this.detachedData) != null && _this$detachedData4.mediaSource)) {\n      let timelinePos = this.timelinePos;\n      if (timelinePos < scheduledItem.start || timelinePos >= scheduledItem.end) {\n        timelinePos = this.getPrimaryResumption(scheduledItem, index);\n        this.log(timelineMessage('resumePrimary', timelinePos));\n        this.timelinePos = timelinePos;\n      }\n      this.attachPrimary(timelinePos, scheduledItem);\n    }\n    if (!fromItem) {\n      return;\n    }\n    const scheduleItems = (_this$schedule4 = this.schedule) == null ? void 0 : _this$schedule4.items;\n    if (!scheduleItems) {\n      return;\n    }\n    this.log(`INTERSTITIALS_PRIMARY_RESUMED ${segmentToString(scheduledItem)}`);\n    this.hls.trigger(Events.INTERSTITIALS_PRIMARY_RESUMED, {\n      schedule: scheduleItems.slice(0),\n      scheduleIndex: index\n    });\n    this.checkBuffer();\n  }\n  getPrimaryResumption(scheduledItem, index) {\n    const itemStart = scheduledItem.start;\n    if (this.primaryLive) {\n      const details = this.primaryDetails;\n      if (index === 0) {\n        return this.hls.startPosition;\n      } else if (details && (itemStart < details.fragmentStart || itemStart > details.edge)) {\n        return this.hls.liveSyncPosition || -1;\n      }\n    }\n    return itemStart;\n  }\n  isAssetBuffered(asset) {\n    const player = this.getAssetPlayer(asset.identifier);\n    if (player != null && player.hls) {\n      return player.hls.bufferedToEnd;\n    }\n    const bufferInfo = BufferHelper.bufferInfo(this.primaryMedia, this.timelinePos, 0);\n    return bufferInfo.end + 1 >= asset.timelineStart + (asset.duration || 0);\n  }\n  attachPrimary(timelinePos, item, skipSeekToStartPosition) {\n    if (item) {\n      this.setBufferingItem(item);\n    } else {\n      this.bufferingItem = this.playingItem;\n    }\n    this.bufferingAsset = null;\n    const media = this.primaryMedia;\n    if (!media) {\n      return;\n    }\n    const hls = this.hls;\n    if (hls.media) {\n      this.checkBuffer();\n    } else {\n      this.transferMediaTo(hls, media);\n      if (skipSeekToStartPosition) {\n        this.startLoadingPrimaryAt(timelinePos, skipSeekToStartPosition);\n      }\n    }\n    if (!skipSeekToStartPosition) {\n      // Set primary position to resume time\n      this.log(timelineMessage('attachPrimary', timelinePos));\n      this.timelinePos = timelinePos;\n      this.startLoadingPrimaryAt(timelinePos, skipSeekToStartPosition);\n    }\n  }\n  startLoadingPrimaryAt(timelinePos, skipSeekToStartPosition) {\n    var _hls$mainForwardBuffe;\n    const hls = this.hls;\n    if (!hls.loadingEnabled || !hls.media || Math.abs((((_hls$mainForwardBuffe = hls.mainForwardBufferInfo) == null ? void 0 : _hls$mainForwardBuffe.start) || hls.media.currentTime) - timelinePos) > 0.5) {\n      hls.startLoad(timelinePos, skipSeekToStartPosition);\n    } else if (!hls.bufferingEnabled) {\n      hls.resumeBuffering();\n    }\n  }\n\n  // HLS.js event callbacks\n  onManifestLoading() {\n    var _this$schedule5;\n    this.stopLoad();\n    (_this$schedule5 = this.schedule) == null || _this$schedule5.reset();\n    this.emptyPlayerQueue();\n    this.clearScheduleState();\n    this.shouldPlay = false;\n    this.bufferedPos = this.timelinePos = -1;\n    this.mediaSelection = this.altSelection = this.manager = this.requiredTracks = null;\n    // BUFFER_CODECS listener added here for buffer-controller to handle it first where it adds tracks\n    this.hls.off(Events.BUFFER_CODECS, this.onBufferCodecs, this);\n    this.hls.on(Events.BUFFER_CODECS, this.onBufferCodecs, this);\n  }\n  onLevelUpdated(event, data) {\n    if (data.level === -1 || !this.schedule) {\n      // level was removed\n      return;\n    }\n    const main = this.hls.levels[data.level];\n    if (!main.details) {\n      return;\n    }\n    const currentSelection = _objectSpread2(_objectSpread2({}, this.mediaSelection || this.altSelection), {}, {\n      main\n    });\n    this.mediaSelection = currentSelection;\n    this.schedule.parseInterstitialDateRanges(currentSelection, this.hls.config.interstitialAppendInPlace);\n    if (!this.effectivePlayingItem && this.schedule.items) {\n      this.checkStart();\n    }\n  }\n  onAudioTrackUpdated(event, data) {\n    const audio = this.hls.audioTracks[data.id];\n    const previousSelection = this.mediaSelection;\n    if (!previousSelection) {\n      this.altSelection = _objectSpread2(_objectSpread2({}, this.altSelection), {}, {\n        audio\n      });\n      return;\n    }\n    const currentSelection = _objectSpread2(_objectSpread2({}, previousSelection), {}, {\n      audio\n    });\n    this.mediaSelection = currentSelection;\n  }\n  onSubtitleTrackUpdated(event, data) {\n    const subtitles = this.hls.subtitleTracks[data.id];\n    const previousSelection = this.mediaSelection;\n    if (!previousSelection) {\n      this.altSelection = _objectSpread2(_objectSpread2({}, this.altSelection), {}, {\n        subtitles\n      });\n      return;\n    }\n    const currentSelection = _objectSpread2(_objectSpread2({}, previousSelection), {}, {\n      subtitles\n    });\n    this.mediaSelection = currentSelection;\n  }\n  onAudioTrackSwitching(event, data) {\n    const audioOption = getBasicSelectionOption(data);\n    this.playerQueue.forEach(({\n      hls\n    }) => hls && (hls.setAudioOption(data) || hls.setAudioOption(audioOption)));\n  }\n  onSubtitleTrackSwitch(event, data) {\n    const subtitleOption = getBasicSelectionOption(data);\n    this.playerQueue.forEach(({\n      hls\n    }) => hls && (hls.setSubtitleOption(data) || data.id !== -1 && hls.setSubtitleOption(subtitleOption)));\n  }\n  onBufferCodecs(event, data) {\n    const requiredTracks = data.tracks;\n    if (requiredTracks) {\n      this.requiredTracks = requiredTracks;\n    }\n  }\n  onBufferAppended(event, data) {\n    this.checkBuffer();\n  }\n  onBufferFlushed(event, data) {\n    const playingItem = this.playingItem;\n    if (playingItem && !this.itemsMatch(playingItem, this.bufferingItem) && !this.isInterstitial(playingItem)) {\n      const timelinePos = this.timelinePos;\n      this.bufferedPos = timelinePos;\n      this.checkBuffer();\n    }\n  }\n  onBufferedToEnd(event) {\n    if (!this.schedule) {\n      return;\n    }\n    // Buffered to post-roll\n    const interstitialEvents = this.schedule.events;\n    if (this.bufferedPos < Number.MAX_VALUE && interstitialEvents) {\n      for (let i = 0; i < interstitialEvents.length; i++) {\n        const interstitial = interstitialEvents[i];\n        if (interstitial.cue.post) {\n          var _this$schedule$items2;\n          const scheduleIndex = this.schedule.findEventIndex(interstitial.identifier);\n          const item = (_this$schedule$items2 = this.schedule.items) == null ? void 0 : _this$schedule$items2[scheduleIndex];\n          if (this.isInterstitial(item) && this.eventItemsMatch(item, this.bufferingItem)) {\n            this.bufferedToItem(item, 0);\n          }\n          break;\n        }\n      }\n      this.bufferedPos = Number.MAX_VALUE;\n    }\n  }\n  onMediaEnded(event) {\n    const playingItem = this.playingItem;\n    if (!this.playingLastItem && playingItem) {\n      const playingIndex = this.findItemIndex(playingItem);\n      this.setSchedulePosition(playingIndex + 1);\n    } else {\n      this.shouldPlay = false;\n    }\n  }\n  updateItem(previousItem, time) {\n    var _this$schedule6;\n    // find item in this.schedule.items;\n    const items = (_this$schedule6 = this.schedule) == null ? void 0 : _this$schedule6.items;\n    if (previousItem && items) {\n      const index = this.findItemIndex(previousItem, time);\n      return items[index] || null;\n    }\n    return null;\n  }\n  trimInPlace(updatedItem, itemBeforeUpdate) {\n    if (this.isInterstitial(updatedItem) && updatedItem.event.appendInPlace && itemBeforeUpdate.end - updatedItem.end > 0.25) {\n      updatedItem.event.assetList.forEach((asset, index) => {\n        if (updatedItem.event.isAssetPastPlayoutLimit(index)) {\n          this.clearAssetPlayer(asset.identifier, null);\n        }\n      });\n      const flushStart = updatedItem.end + 0.25;\n      const bufferInfo = BufferHelper.bufferInfo(this.primaryMedia, flushStart, 0);\n      if (bufferInfo.end > flushStart || (bufferInfo.nextStart || 0) > flushStart) {\n        this.log(`trim buffered interstitial ${segmentToString(updatedItem)} (was ${segmentToString(itemBeforeUpdate)})`);\n        const skipSeekToStartPosition = true;\n        this.attachPrimary(flushStart, null, skipSeekToStartPosition);\n        this.flushFrontBuffer(flushStart);\n      }\n    }\n  }\n  itemsMatch(a, b) {\n    return !!b && (a === b || a.event && b.event && this.eventItemsMatch(a, b) || !a.event && !b.event && this.findItemIndex(a) === this.findItemIndex(b));\n  }\n  eventItemsMatch(a, b) {\n    var _b$event;\n    return !!b && (a === b || a.event.identifier === ((_b$event = b.event) == null ? void 0 : _b$event.identifier));\n  }\n  findItemIndex(item, time) {\n    return item && this.schedule ? this.schedule.findItemIndex(item, time) : -1;\n  }\n  updateSchedule(forceUpdate = false) {\n    var _this$schedule7;\n    const mediaSelection = this.mediaSelection;\n    if (!mediaSelection) {\n      return;\n    }\n    (_this$schedule7 = this.schedule) == null || _this$schedule7.updateSchedule(mediaSelection, [], forceUpdate);\n  }\n\n  // Schedule buffer control\n  checkBuffer(starved) {\n    var _this$schedule8;\n    const items = (_this$schedule8 = this.schedule) == null ? void 0 : _this$schedule8.items;\n    if (!items) {\n      return;\n    }\n    // Find when combined forward buffer change reaches next schedule segment\n    const bufferInfo = BufferHelper.bufferInfo(this.primaryMedia, this.timelinePos, 0);\n    if (starved) {\n      this.bufferedPos = this.timelinePos;\n    }\n    starved || (starved = bufferInfo.len < 1);\n    this.updateBufferedPos(bufferInfo.end, items, starved);\n  }\n  updateBufferedPos(bufferEnd, items, bufferIsEmpty) {\n    const schedule = this.schedule;\n    const bufferingItem = this.bufferingItem;\n    if (this.bufferedPos > bufferEnd || !schedule) {\n      return;\n    }\n    if (items.length === 1 && this.itemsMatch(items[0], bufferingItem)) {\n      this.bufferedPos = bufferEnd;\n      return;\n    }\n    const playingItem = this.playingItem;\n    const playingIndex = this.findItemIndex(playingItem);\n    let bufferEndIndex = schedule.findItemIndexAtTime(bufferEnd);\n    if (this.bufferedPos < bufferEnd) {\n      var _nextItemToBuffer$eve;\n      const bufferingIndex = this.findItemIndex(bufferingItem);\n      const nextToBufferIndex = Math.min(bufferingIndex + 1, items.length - 1);\n      const nextItemToBuffer = items[nextToBufferIndex];\n      if (bufferEndIndex === -1 && bufferingItem && bufferEnd >= bufferingItem.end || (_nextItemToBuffer$eve = nextItemToBuffer.event) != null && _nextItemToBuffer$eve.appendInPlace && bufferEnd + 0.01 >= nextItemToBuffer.start) {\n        bufferEndIndex = nextToBufferIndex;\n      }\n      if (this.isInterstitial(bufferingItem)) {\n        const interstitial = bufferingItem.event;\n        if (nextToBufferIndex - playingIndex > 1 && interstitial.appendInPlace === false) {\n          // do not advance buffering item past Interstitial that requires source reset\n          return;\n        }\n        if (interstitial.assetList.length === 0 && interstitial.assetListLoader) {\n          // do not advance buffering item past Interstitial loading asset-list\n          return;\n        }\n      }\n      this.bufferedPos = bufferEnd;\n      if (bufferEndIndex > bufferingIndex && bufferEndIndex > playingIndex) {\n        this.bufferedToItem(nextItemToBuffer);\n      } else {\n        // allow more time than distance from edge for assets to load\n        const details = this.primaryDetails;\n        if (this.primaryLive && details && bufferEnd > details.edge - details.targetduration && nextItemToBuffer.start < details.edge + this.hls.config.interstitialLiveLookAhead && this.isInterstitial(nextItemToBuffer)) {\n          this.preloadAssets(nextItemToBuffer.event, 0);\n        }\n      }\n    } else if (bufferIsEmpty && playingItem && !this.itemsMatch(playingItem, bufferingItem)) {\n      if (bufferEndIndex === playingIndex) {\n        this.bufferedToItem(playingItem);\n      } else if (bufferEndIndex === playingIndex + 1) {\n        this.bufferedToItem(items[bufferEndIndex]);\n      }\n    }\n  }\n  assetsBuffered(item, media) {\n    const assetList = item.event.assetList;\n    if (assetList.length === 0) {\n      return false;\n    }\n    return !item.event.assetList.some(asset => {\n      const player = this.getAssetPlayer(asset.identifier);\n      return !(player != null && player.bufferedInPlaceToEnd(media));\n    });\n  }\n  setBufferingItem(item) {\n    const bufferingLast = this.bufferingItem;\n    const schedule = this.schedule;\n    if (!this.itemsMatch(item, bufferingLast) && schedule) {\n      const {\n        items,\n        events\n      } = schedule;\n      if (!items || !events) {\n        return bufferingLast;\n      }\n      const isInterstitial = this.isInterstitial(item);\n      const bufferingPlayer = this.getBufferingPlayer();\n      this.bufferingItem = item;\n      this.bufferedPos = Math.max(item.start, Math.min(item.end, this.timelinePos));\n      const timeRemaining = bufferingPlayer ? bufferingPlayer.remaining : bufferingLast ? bufferingLast.end - this.timelinePos : 0;\n      this.log(`INTERSTITIALS_BUFFERED_TO_BOUNDARY ${segmentToString(item)}` + (bufferingLast ? ` (${timeRemaining.toFixed(2)} remaining)` : ''));\n      if (!this.playbackDisabled) {\n        if (isInterstitial) {\n          const bufferIndex = schedule.findAssetIndex(item.event, this.bufferedPos);\n          // primary fragment loading will exit early in base-stream-controller while `bufferingItem` is set to an Interstitial block\n          item.event.assetList.forEach((asset, i) => {\n            const player = this.getAssetPlayer(asset.identifier);\n            if (player) {\n              if (i === bufferIndex) {\n                player.loadSource();\n              }\n              player.resumeBuffering();\n            }\n          });\n        } else {\n          this.hls.resumeBuffering();\n          this.playerQueue.forEach(player => player.pauseBuffering());\n        }\n      }\n      this.hls.trigger(Events.INTERSTITIALS_BUFFERED_TO_BOUNDARY, {\n        events: events.slice(0),\n        schedule: items.slice(0),\n        bufferingIndex: this.findItemIndex(item),\n        playingIndex: this.findItemIndex(this.playingItem)\n      });\n    } else if (this.bufferingItem !== item) {\n      this.bufferingItem = item;\n    }\n    return bufferingLast;\n  }\n  bufferedToItem(item, assetListIndex = 0) {\n    const bufferingLast = this.setBufferingItem(item);\n    if (this.playbackDisabled) {\n      return;\n    }\n    if (this.isInterstitial(item)) {\n      // Ensure asset list is loaded\n      this.bufferedToEvent(item, assetListIndex);\n    } else if (bufferingLast !== null) {\n      // If primary player is detached, it is also stopped, restart loading at primary position\n      this.bufferingAsset = null;\n      const detachedData = this.detachedData;\n      if (detachedData) {\n        if (detachedData.mediaSource) {\n          const skipSeekToStartPosition = true;\n          this.attachPrimary(item.start, item, skipSeekToStartPosition);\n        } else {\n          this.preloadPrimary(item);\n        }\n      } else {\n        // If not detached seek to resumption point\n        this.preloadPrimary(item);\n      }\n    }\n  }\n  preloadPrimary(item) {\n    const index = this.findItemIndex(item);\n    const timelinePos = this.getPrimaryResumption(item, index);\n    this.startLoadingPrimaryAt(timelinePos);\n  }\n  bufferedToEvent(item, assetListIndex) {\n    const interstitial = item.event;\n    const neverLoaded = interstitial.assetList.length === 0 && !interstitial.assetListLoader;\n    const playOnce = interstitial.cue.once;\n    if (neverLoaded || !playOnce) {\n      // Buffered to Interstitial boundary\n      const player = this.preloadAssets(interstitial, assetListIndex);\n      if (player != null && player.interstitial.appendInPlace) {\n        const media = this.primaryMedia;\n        if (media) {\n          this.bufferAssetPlayer(player, media);\n        }\n      }\n    }\n  }\n  preloadAssets(interstitial, assetListIndex) {\n    const uri = interstitial.assetUrl;\n    const assetListLength = interstitial.assetList.length;\n    const neverLoaded = assetListLength === 0 && !interstitial.assetListLoader;\n    const playOnce = interstitial.cue.once;\n    if (neverLoaded) {\n      const timelineStart = interstitial.timelineStart;\n      if (interstitial.appendInPlace) {\n        var _playingItem$nextEven;\n        const playingItem = this.playingItem;\n        if (!this.isInterstitial(playingItem) && (playingItem == null || (_playingItem$nextEven = playingItem.nextEvent) == null ? void 0 : _playingItem$nextEven.identifier) === interstitial.identifier) {\n          this.flushFrontBuffer(timelineStart + 0.25);\n        }\n      }\n      let hlsStartOffset;\n      let liveStartPosition = 0;\n      if (!this.playingItem && this.primaryLive) {\n        liveStartPosition = this.hls.startPosition;\n        if (liveStartPosition === -1) {\n          liveStartPosition = this.hls.liveSyncPosition || 0;\n        }\n      }\n      if (liveStartPosition && !(interstitial.cue.pre || interstitial.cue.post)) {\n        const startOffset = liveStartPosition - timelineStart;\n        if (startOffset > 0) {\n          hlsStartOffset = Math.round(startOffset * 1000) / 1000;\n        }\n      }\n      this.log(`Load interstitial asset ${assetListIndex + 1}/${uri ? 1 : assetListLength} ${interstitial}${hlsStartOffset ? ` live-start: ${liveStartPosition} start-offset: ${hlsStartOffset}` : ''}`);\n      if (uri) {\n        return this.createAsset(interstitial, 0, 0, timelineStart, interstitial.duration, uri);\n      }\n      const assetListLoader = this.assetListLoader.loadAssetList(interstitial, hlsStartOffset);\n      if (assetListLoader) {\n        interstitial.assetListLoader = assetListLoader;\n      }\n    } else if (!playOnce && assetListLength) {\n      // Re-buffered to Interstitial boundary, re-create asset player(s)\n      for (let i = assetListIndex; i < assetListLength; i++) {\n        const _asset = interstitial.assetList[i];\n        const playerIndex = this.getAssetPlayerQueueIndex(_asset.identifier);\n        if ((playerIndex === -1 || this.playerQueue[playerIndex].destroyed) && !_asset.error) {\n          this.createAssetPlayer(interstitial, _asset, i);\n        }\n      }\n      const asset = interstitial.assetList[assetListIndex];\n      // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition\n      if (asset) {\n        const player = this.getAssetPlayer(asset.identifier);\n        if (player) {\n          player.loadSource();\n        }\n        return player;\n      }\n    }\n    return null;\n  }\n  flushFrontBuffer(startOffset) {\n    // Force queued flushing of all buffers\n    const requiredTracks = this.requiredTracks;\n    if (!requiredTracks) {\n      return;\n    }\n    this.log(`Removing front buffer starting at ${startOffset}`);\n    const sourceBufferNames = Object.keys(requiredTracks);\n    sourceBufferNames.forEach(type => {\n      this.hls.trigger(Events.BUFFER_FLUSHING, {\n        startOffset,\n        endOffset: Infinity,\n        type\n      });\n    });\n  }\n\n  // Interstitial Asset Player control\n  getAssetPlayerQueueIndex(assetId) {\n    const playerQueue = this.playerQueue;\n    for (let i = 0; i < playerQueue.length; i++) {\n      if (assetId === playerQueue[i].assetId) {\n        return i;\n      }\n    }\n    return -1;\n  }\n  getAssetPlayer(assetId) {\n    const index = this.getAssetPlayerQueueIndex(assetId);\n    return this.playerQueue[index] || null;\n  }\n  getBufferingPlayer() {\n    const {\n      playerQueue,\n      primaryMedia\n    } = this;\n    if (primaryMedia) {\n      for (let i = 0; i < playerQueue.length; i++) {\n        if (playerQueue[i].media === primaryMedia) {\n          return playerQueue[i];\n        }\n      }\n    }\n    return null;\n  }\n  createAsset(interstitial, assetListIndex, startOffset, timelineStart, duration, uri) {\n    const assetItem = {\n      parentIdentifier: interstitial.identifier,\n      identifier: generateAssetIdentifier(interstitial, uri, assetListIndex),\n      duration,\n      startOffset,\n      timelineStart,\n      uri\n    };\n    return this.createAssetPlayer(interstitial, assetItem, assetListIndex);\n  }\n  createAssetPlayer(interstitial, assetItem, assetListIndex) {\n    const primary = this.hls;\n    const userConfig = primary.userConfig;\n    let videoPreference = userConfig.videoPreference;\n    const currentLevel = primary.loadLevelObj || primary.levels[primary.currentLevel];\n    // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition\n    if (videoPreference || currentLevel) {\n      videoPreference = _extends({}, videoPreference);\n      if (currentLevel.videoCodec) {\n        videoPreference.videoCodec = currentLevel.videoCodec;\n      }\n      // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition\n      if (currentLevel.videoRange) {\n        videoPreference.allowedVideoRanges = [currentLevel.videoRange];\n      }\n    }\n    const selectedAudio = primary.audioTracks[primary.audioTrack];\n    const selectedSubtitle = primary.subtitleTracks[primary.subtitleTrack];\n    let startPosition = 0;\n    if (this.primaryLive || interstitial.appendInPlace) {\n      const timePastStart = this.timelinePos - assetItem.timelineStart;\n      if (timePastStart > 1) {\n        const duration = assetItem.duration;\n        if (duration && timePastStart < duration) {\n          startPosition = timePastStart;\n        }\n      }\n    }\n    const assetId = assetItem.identifier;\n    const playerConfig = _objectSpread2(_objectSpread2({}, userConfig), {}, {\n      maxMaxBufferLength: Math.min(180, primary.config.maxMaxBufferLength),\n      autoStartLoad: true,\n      startFragPrefetch: true,\n      primarySessionId: primary.sessionId,\n      assetPlayerId: assetId,\n      abrEwmaDefaultEstimate: primary.bandwidthEstimate,\n      interstitialsController: undefined,\n      startPosition,\n      liveDurationInfinity: false,\n      testBandwidth: false,\n      videoPreference,\n      audioPreference: selectedAudio || userConfig.audioPreference,\n      subtitlePreference: selectedSubtitle || userConfig.subtitlePreference\n    });\n    // TODO: limit maxMaxBufferLength in asset players to prevent QEE\n    if (interstitial.appendInPlace) {\n      interstitial.appendInPlaceStarted = true;\n      if (assetItem.timelineStart) {\n        playerConfig.timelineOffset = assetItem.timelineStart;\n      }\n    }\n    const cmcd = playerConfig.cmcd;\n    if (cmcd != null && cmcd.sessionId && cmcd.contentId) {\n      playerConfig.cmcd = _extends({}, cmcd, {\n        contentId: hash(assetItem.uri)\n      });\n    }\n    if (this.getAssetPlayer(assetId)) {\n      this.warn(`Duplicate date range identifier ${interstitial} and asset ${assetId}`);\n    }\n    const player = new HlsAssetPlayer(this.HlsPlayerClass, playerConfig, interstitial, assetItem);\n    this.playerQueue.push(player);\n    interstitial.assetList[assetListIndex] = assetItem;\n    // Listen for LevelDetails and PTS change to update duration\n    let initialDuration = true;\n    const updateAssetPlayerDetails = details => {\n      if (details.live) {\n        var _this$schedule9;\n        const error = new Error(`Interstitials MUST be VOD assets ${interstitial}`);\n        const errorData = {\n          fatal: true,\n          type: ErrorTypes.OTHER_ERROR,\n          details: ErrorDetails.INTERSTITIAL_ASSET_ITEM_ERROR,\n          error\n        };\n        const scheduleIndex = ((_this$schedule9 = this.schedule) == null ? void 0 : _this$schedule9.findEventIndex(interstitial.identifier)) || -1;\n        this.handleAssetItemError(errorData, interstitial, scheduleIndex, assetListIndex, error.message);\n        return;\n      }\n      // Get time at end of last fragment\n      const duration = details.edge - details.fragmentStart;\n      const currentAssetDuration = assetItem.duration;\n      if (initialDuration || currentAssetDuration === null || duration > currentAssetDuration) {\n        initialDuration = false;\n        this.log(`Interstitial asset \"${assetId}\" duration change ${currentAssetDuration} > ${duration}`);\n        assetItem.duration = duration;\n        // Update schedule with new event and asset duration\n        this.updateSchedule();\n      }\n    };\n    player.on(Events.LEVEL_UPDATED, (event, {\n      details\n    }) => updateAssetPlayerDetails(details));\n    player.on(Events.LEVEL_PTS_UPDATED, (event, {\n      details\n    }) => updateAssetPlayerDetails(details));\n    player.on(Events.EVENT_CUE_ENTER, () => this.onInterstitialCueEnter());\n    const onBufferCodecs = (event, data) => {\n      const inQueuPlayer = this.getAssetPlayer(assetId);\n      if (inQueuPlayer && data.tracks) {\n        inQueuPlayer.off(Events.BUFFER_CODECS, onBufferCodecs);\n        inQueuPlayer.tracks = data.tracks;\n        const media = this.primaryMedia;\n        if (this.bufferingAsset === inQueuPlayer.assetItem && media && !inQueuPlayer.media) {\n          this.bufferAssetPlayer(inQueuPlayer, media);\n        }\n      }\n    };\n    player.on(Events.BUFFER_CODECS, onBufferCodecs);\n    const bufferedToEnd = () => {\n      var _this$schedule$items3;\n      const inQueuPlayer = this.getAssetPlayer(assetId);\n      this.log(`buffered to end of asset ${inQueuPlayer}`);\n      if (!inQueuPlayer || !this.schedule) {\n        return;\n      }\n      // Preload at end of asset\n      const scheduleIndex = this.schedule.findEventIndex(interstitial.identifier);\n      const item = (_this$schedule$items3 = this.schedule.items) == null ? void 0 : _this$schedule$items3[scheduleIndex];\n      if (this.isInterstitial(item)) {\n        this.advanceAssetBuffering(item, assetItem);\n      }\n    };\n    player.on(Events.BUFFERED_TO_END, bufferedToEnd);\n    const endedWithAssetIndex = assetIndex => {\n      return () => {\n        const inQueuPlayer = this.getAssetPlayer(assetId);\n        if (!inQueuPlayer || !this.schedule) {\n          return;\n        }\n        this.shouldPlay = true;\n        const scheduleIndex = this.schedule.findEventIndex(interstitial.identifier);\n        this.advanceAfterAssetEnded(interstitial, scheduleIndex, assetIndex);\n      };\n    };\n    player.once(Events.MEDIA_ENDED, endedWithAssetIndex(assetListIndex));\n    player.once(Events.PLAYOUT_LIMIT_REACHED, endedWithAssetIndex(Infinity));\n    player.on(Events.ERROR, (event, data) => {\n      if (!this.schedule) {\n        return;\n      }\n      const inQueuPlayer = this.getAssetPlayer(assetId);\n      if (data.details === ErrorDetails.BUFFER_STALLED_ERROR) {\n        if (inQueuPlayer != null && inQueuPlayer.appendInPlace) {\n          this.handleInPlaceStall(interstitial);\n          return;\n        }\n        this.onTimeupdate();\n        this.checkBuffer(true);\n        return;\n      }\n      this.handleAssetItemError(data, interstitial, this.schedule.findEventIndex(interstitial.identifier), assetListIndex, `Asset player error ${data.error} ${interstitial}`);\n    });\n    player.on(Events.DESTROYING, () => {\n      const inQueuPlayer = this.getAssetPlayer(assetId);\n      if (!inQueuPlayer || !this.schedule) {\n        return;\n      }\n      const error = new Error(`Asset player destroyed unexpectedly ${assetId}`);\n      const errorData = {\n        fatal: true,\n        type: ErrorTypes.OTHER_ERROR,\n        details: ErrorDetails.INTERSTITIAL_ASSET_ITEM_ERROR,\n        error\n      };\n      this.handleAssetItemError(errorData, interstitial, this.schedule.findEventIndex(interstitial.identifier), assetListIndex, error.message);\n    });\n    this.log(`INTERSTITIAL_ASSET_PLAYER_CREATED ${eventAssetToString(assetItem)}`);\n    this.hls.trigger(Events.INTERSTITIAL_ASSET_PLAYER_CREATED, {\n      asset: assetItem,\n      assetListIndex,\n      event: interstitial,\n      player\n    });\n    return player;\n  }\n  clearInterstitial(interstitial, toSegment) {\n    this.clearAssetPlayers(interstitial, toSegment);\n    // Remove asset list and resolved duration\n    interstitial.reset();\n  }\n  clearAssetPlayers(interstitial, toSegment) {\n    interstitial.assetList.forEach(asset => {\n      this.clearAssetPlayer(asset.identifier, toSegment);\n    });\n  }\n  resetAssetPlayer(assetId) {\n    // Reset asset player so that it's timeline can be adjusted without reloading the MVP\n    const playerIndex = this.getAssetPlayerQueueIndex(assetId);\n    if (playerIndex !== -1) {\n      this.log(`reset asset player \"${assetId}\" after error`);\n      const player = this.playerQueue[playerIndex];\n      this.transferMediaFromPlayer(player, null);\n      player.resetDetails();\n    }\n  }\n  clearAssetPlayer(assetId, toSegment) {\n    const playerIndex = this.getAssetPlayerQueueIndex(assetId);\n    if (playerIndex !== -1) {\n      const player = this.playerQueue[playerIndex];\n      this.log(`clear ${player} toSegment: ${toSegment ? segmentToString(toSegment) : toSegment}`);\n      this.transferMediaFromPlayer(player, toSegment);\n      this.playerQueue.splice(playerIndex, 1);\n      player.destroy();\n    }\n  }\n  emptyPlayerQueue() {\n    let player;\n    while (player = this.playerQueue.pop()) {\n      player.destroy();\n    }\n    this.playerQueue = [];\n  }\n  startAssetPlayer(player, assetListIndex, scheduleItems, scheduleIndex, media) {\n    const {\n      interstitial,\n      assetItem,\n      assetId\n    } = player;\n    const assetListLength = interstitial.assetList.length;\n    const playingAsset = this.playingAsset;\n    this.endedAsset = null;\n    this.playingAsset = assetItem;\n    if (!playingAsset || playingAsset.identifier !== assetId) {\n      if (playingAsset) {\n        // Exiting another Interstitial asset\n        this.clearAssetPlayer(playingAsset.identifier, scheduleItems[scheduleIndex]);\n        delete playingAsset.error;\n      }\n      this.log(`INTERSTITIAL_ASSET_STARTED ${assetListIndex + 1}/${assetListLength} ${eventAssetToString(assetItem)}`);\n      this.hls.trigger(Events.INTERSTITIAL_ASSET_STARTED, {\n        asset: assetItem,\n        assetListIndex,\n        event: interstitial,\n        schedule: scheduleItems.slice(0),\n        scheduleIndex,\n        player\n      });\n    }\n\n    // detach media and attach to interstitial player if it does not have another element attached\n    this.bufferAssetPlayer(player, media);\n  }\n  bufferAssetPlayer(player, media) {\n    var _this$schedule$items4, _this$detachedData5;\n    if (!this.schedule) {\n      return;\n    }\n    const {\n      interstitial,\n      assetItem\n    } = player;\n    const scheduleIndex = this.schedule.findEventIndex(interstitial.identifier);\n    const item = (_this$schedule$items4 = this.schedule.items) == null ? void 0 : _this$schedule$items4[scheduleIndex];\n    if (!item) {\n      return;\n    }\n    player.loadSource();\n    this.setBufferingItem(item);\n    this.bufferingAsset = assetItem;\n    const bufferingPlayer = this.getBufferingPlayer();\n    if (bufferingPlayer === player) {\n      return;\n    }\n    const appendInPlaceNext = interstitial.appendInPlace;\n    if (appendInPlaceNext && (bufferingPlayer == null ? void 0 : bufferingPlayer.interstitial.appendInPlace) === false) {\n      // Media is detached and not available to append in place\n      return;\n    }\n    const activeTracks = (bufferingPlayer == null ? void 0 : bufferingPlayer.tracks) || ((_this$detachedData5 = this.detachedData) == null ? void 0 : _this$detachedData5.tracks) || this.requiredTracks;\n    if (appendInPlaceNext && assetItem !== this.playingAsset) {\n      // Do not buffer another item if tracks are unknown or incompatible\n      if (!player.tracks) {\n        this.log(`Waiting for track info before buffering ${player}`);\n        return;\n      }\n      if (activeTracks && !isCompatibleTrackChange(activeTracks, player.tracks)) {\n        const error = new Error(`Asset ${eventAssetToString(assetItem)} SourceBuffer tracks ('${Object.keys(player.tracks)}') are not compatible with primary content tracks ('${Object.keys(activeTracks)}')`);\n        const errorData = {\n          fatal: true,\n          type: ErrorTypes.OTHER_ERROR,\n          details: ErrorDetails.INTERSTITIAL_ASSET_ITEM_ERROR,\n          error\n        };\n        const assetListIndex = interstitial.findAssetIndex(assetItem);\n        this.handleAssetItemError(errorData, interstitial, scheduleIndex, assetListIndex, error.message);\n        return;\n      }\n    }\n    this.transferMediaTo(player, media);\n  }\n  handleInPlaceStall(interstitial) {\n    const schedule = this.schedule;\n    const media = this.primaryMedia;\n    if (!schedule || !media) {\n      return;\n    }\n    const currentTime = media.currentTime;\n    const foundAssetIndex = schedule.findAssetIndex(interstitial, currentTime);\n    const stallingAsset = interstitial.assetList[foundAssetIndex];\n    if (stallingAsset) {\n      const player = this.getAssetPlayer(stallingAsset.identifier);\n      if (player) {\n        const assetCurrentTime = player.currentTime || currentTime - stallingAsset.timelineStart;\n        const distanceFromEnd = player.duration - assetCurrentTime;\n        this.warn(`Stalled at ${assetCurrentTime} of ${assetCurrentTime + distanceFromEnd} in ${player} ${interstitial} (media.currentTime: ${currentTime})`);\n        if (assetCurrentTime && (distanceFromEnd / media.playbackRate < 0.5 || player.bufferedInPlaceToEnd(media)) && player.hls) {\n          const scheduleIndex = schedule.findEventIndex(interstitial.identifier);\n          this.advanceAfterAssetEnded(interstitial, scheduleIndex, foundAssetIndex);\n        }\n      }\n    }\n  }\n  advanceInPlace(time) {\n    const media = this.primaryMedia;\n    if (media && media.currentTime < time) {\n      media.currentTime = time;\n    }\n  }\n  handleAssetItemError(data, interstitial, scheduleIndex, assetListIndex, errorMessage) {\n    if (data.details === ErrorDetails.BUFFER_STALLED_ERROR) {\n      return;\n    }\n    const assetItem = interstitial.assetList[assetListIndex] || null;\n    this.warn(`INTERSTITIAL_ASSET_ERROR ${assetItem ? eventAssetToString(assetItem) : assetItem} ${data.error}`);\n    if (!this.schedule) {\n      return;\n    }\n    const assetId = (assetItem == null ? void 0 : assetItem.identifier) || '';\n    const playerIndex = this.getAssetPlayerQueueIndex(assetId);\n    const player = this.playerQueue[playerIndex] || null;\n    const items = this.schedule.items;\n    const interstitialAssetError = _extends({}, data, {\n      fatal: false,\n      errorAction: createDoNothingErrorAction(true),\n      asset: assetItem,\n      assetListIndex,\n      event: interstitial,\n      schedule: items,\n      scheduleIndex,\n      player\n    });\n    this.hls.trigger(Events.INTERSTITIAL_ASSET_ERROR, interstitialAssetError);\n    if (!data.fatal) {\n      return;\n    }\n    const playingAsset = this.playingAsset;\n    const bufferingAsset = this.bufferingAsset;\n    const error = new Error(errorMessage);\n    if (assetItem) {\n      this.clearAssetPlayer(assetId, null);\n      assetItem.error = error;\n    }\n\n    // If all assets in interstitial fail, mark the interstitial with an error\n    if (!interstitial.assetList.some(asset => !asset.error)) {\n      interstitial.error = error;\n    } else {\n      // Reset level details and reload/parse media playlists to align with updated schedule\n      for (let i = assetListIndex; i < interstitial.assetList.length; i++) {\n        this.resetAssetPlayer(interstitial.assetList[i].identifier);\n      }\n    }\n    this.updateSchedule(true);\n    if (interstitial.error) {\n      this.primaryFallback(interstitial);\n    } else if (playingAsset && playingAsset.identifier === assetId) {\n      this.advanceAfterAssetEnded(interstitial, scheduleIndex, assetListIndex);\n    } else if (bufferingAsset && bufferingAsset.identifier === assetId && this.isInterstitial(this.bufferingItem)) {\n      this.advanceAssetBuffering(this.bufferingItem, bufferingAsset);\n    }\n  }\n  primaryFallback(interstitial) {\n    // Fallback to Primary by on current or future events by updating schedule to skip errored interstitials/assets\n    const flushStart = interstitial.timelineStart;\n    const playingItem = this.effectivePlayingItem;\n    let timelinePos = this.timelinePos;\n    // Update schedule now that interstitial/assets are flagged with `error` for fallback\n    if (playingItem) {\n      this.log(`Fallback to primary from event \"${interstitial.identifier}\" start: ${flushStart} pos: ${timelinePos} playing: ${segmentToString(playingItem)} error: ${interstitial.error}`);\n      if (timelinePos === -1) {\n        timelinePos = this.hls.startPosition;\n      }\n      const newPlayingItem = this.updateItem(playingItem, timelinePos);\n      if (this.itemsMatch(playingItem, newPlayingItem)) {\n        this.clearInterstitial(interstitial, null);\n      }\n      if (interstitial.appendInPlace) {\n        this.attachPrimary(flushStart, null);\n        this.flushFrontBuffer(flushStart);\n      }\n    } else if (timelinePos === -1) {\n      this.checkStart();\n      return;\n    }\n    if (!this.schedule) {\n      return;\n    }\n    const scheduleIndex = this.schedule.findItemIndexAtTime(timelinePos);\n    this.setSchedulePosition(scheduleIndex);\n  }\n\n  // Asset List loading\n  onAssetListLoaded(event, data) {\n    var _this$schedule0, _this$bufferingItem2;\n    const interstitial = data.event;\n    const interstitialId = interstitial.identifier;\n    const assets = data.assetListResponse.ASSETS;\n    if (!((_this$schedule0 = this.schedule) != null && _this$schedule0.hasEvent(interstitialId))) {\n      // Interstitial with id was removed\n      return;\n    }\n    const eventStart = interstitial.timelineStart;\n    const previousDuration = interstitial.duration;\n    let sumDuration = 0;\n    assets.forEach((asset, assetListIndex) => {\n      const duration = parseFloat(asset.DURATION);\n      this.createAsset(interstitial, assetListIndex, sumDuration, eventStart + sumDuration, duration, asset.URI);\n      sumDuration += duration;\n    });\n    interstitial.duration = sumDuration;\n    this.log(`Loaded asset-list with duration: ${sumDuration} (was: ${previousDuration}) ${interstitial}`);\n    const waitingItem = this.waitingItem;\n    const waitingForItem = (waitingItem == null ? void 0 : waitingItem.event.identifier) === interstitialId;\n\n    // Update schedule now that asset.DURATION(s) are parsed\n    this.updateSchedule();\n    const bufferingEvent = (_this$bufferingItem2 = this.bufferingItem) == null ? void 0 : _this$bufferingItem2.event;\n\n    // If buffer reached Interstitial, start buffering first asset\n    if (waitingForItem) {\n      var _this$schedule$items5;\n      // Advance schedule when waiting for asset list data to play\n      const scheduleIndex = this.schedule.findEventIndex(interstitialId);\n      const item = (_this$schedule$items5 = this.schedule.items) == null ? void 0 : _this$schedule$items5[scheduleIndex];\n      if (item) {\n        if (!this.playingItem && this.timelinePos > item.end) {\n          // Abandon if new duration is reduced enough to land playback in primary start\n          const index = this.schedule.findItemIndexAtTime(this.timelinePos);\n          if (index !== scheduleIndex) {\n            interstitial.error = new Error(`Interstitial ${assets.length ? 'no longer within playback range' : 'asset-list is empty'} ${this.timelinePos} ${interstitial}`);\n            this.log(interstitial.error.message);\n            this.updateSchedule(true);\n            this.primaryFallback(interstitial);\n            return;\n          }\n        }\n        this.setBufferingItem(item);\n      }\n      this.setSchedulePosition(scheduleIndex);\n    } else if ((bufferingEvent == null ? void 0 : bufferingEvent.identifier) === interstitialId) {\n      const assetItem = interstitial.assetList[0];\n      // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition\n      if (assetItem) {\n        const player = this.getAssetPlayer(assetItem.identifier);\n        if (bufferingEvent.appendInPlace) {\n          // If buffering (but not playback) has reached this item transfer media-source\n          const media = this.primaryMedia;\n          if (player && media) {\n            this.bufferAssetPlayer(player, media);\n          }\n        } else if (player) {\n          player.loadSource();\n        }\n      }\n    }\n  }\n  onError(event, data) {\n    if (!this.schedule) {\n      return;\n    }\n    switch (data.details) {\n      case ErrorDetails.ASSET_LIST_PARSING_ERROR:\n      case ErrorDetails.ASSET_LIST_LOAD_ERROR:\n      case ErrorDetails.ASSET_LIST_LOAD_TIMEOUT:\n        {\n          const interstitial = data.interstitial;\n          if (interstitial) {\n            this.updateSchedule(true);\n            this.primaryFallback(interstitial);\n          }\n          break;\n        }\n      case ErrorDetails.BUFFER_STALLED_ERROR:\n        {\n          const stallingItem = this.endedItem || this.waitingItem || this.playingItem;\n          if (this.isInterstitial(stallingItem) && stallingItem.event.appendInPlace) {\n            this.handleInPlaceStall(stallingItem.event);\n            return;\n          }\n          this.log(`Primary player stall @${this.timelinePos} bufferedPos: ${this.bufferedPos}`);\n          this.onTimeupdate();\n          this.checkBuffer(true);\n          break;\n        }\n    }\n  }\n}\n\nconst TICK_INTERVAL$2 = 500; // how often to tick in ms\n\nclass SubtitleStreamController extends BaseStreamController {\n  constructor(hls, fragmentTracker, keyLoader) {\n    super(hls, fragmentTracker, keyLoader, 'subtitle-stream-controller', PlaylistLevelType.SUBTITLE);\n    this.currentTrackId = -1;\n    this.tracksBuffered = [];\n    this.mainDetails = null;\n    this.registerListeners();\n  }\n  onHandlerDestroying() {\n    this.unregisterListeners();\n    super.onHandlerDestroying();\n    this.mainDetails = null;\n  }\n  registerListeners() {\n    super.registerListeners();\n    const {\n      hls\n    } = this;\n    hls.on(Events.LEVEL_LOADED, this.onLevelLoaded, this);\n    hls.on(Events.SUBTITLE_TRACKS_UPDATED, this.onSubtitleTracksUpdated, this);\n    hls.on(Events.SUBTITLE_TRACK_SWITCH, this.onSubtitleTrackSwitch, this);\n    hls.on(Events.SUBTITLE_TRACK_LOADED, this.onSubtitleTrackLoaded, this);\n    hls.on(Events.SUBTITLE_FRAG_PROCESSED, this.onSubtitleFragProcessed, this);\n    hls.on(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);\n  }\n  unregisterListeners() {\n    super.unregisterListeners();\n    const {\n      hls\n    } = this;\n    hls.off(Events.LEVEL_LOADED, this.onLevelLoaded, this);\n    hls.off(Events.SUBTITLE_TRACKS_UPDATED, this.onSubtitleTracksUpdated, this);\n    hls.off(Events.SUBTITLE_TRACK_SWITCH, this.onSubtitleTrackSwitch, this);\n    hls.off(Events.SUBTITLE_TRACK_LOADED, this.onSubtitleTrackLoaded, this);\n    hls.off(Events.SUBTITLE_FRAG_PROCESSED, this.onSubtitleFragProcessed, this);\n    hls.off(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);\n  }\n  startLoad(startPosition, skipSeekToStartPosition) {\n    this.stopLoad();\n    this.state = State.IDLE;\n    this.setInterval(TICK_INTERVAL$2);\n    this.nextLoadPosition = this.lastCurrentTime = startPosition + this.timelineOffset;\n    this.startPosition = skipSeekToStartPosition ? -1 : startPosition;\n    this.tick();\n  }\n  onManifestLoading() {\n    super.onManifestLoading();\n    this.mainDetails = null;\n  }\n  onMediaDetaching(event, data) {\n    this.tracksBuffered = [];\n    super.onMediaDetaching(event, data);\n  }\n  onLevelLoaded(event, data) {\n    this.mainDetails = data.details;\n  }\n  onSubtitleFragProcessed(event, data) {\n    const {\n      frag,\n      success\n    } = data;\n    if (!this.fragContextChanged(frag)) {\n      if (isMediaFragment(frag)) {\n        this.fragPrevious = frag;\n      }\n      this.state = State.IDLE;\n    }\n    if (!success) {\n      return;\n    }\n    const buffered = this.tracksBuffered[this.currentTrackId];\n    if (!buffered) {\n      return;\n    }\n\n    // Create/update a buffered array matching the interface used by BufferHelper.bufferedInfo\n    // so we can re-use the logic used to detect how much has been buffered\n    let timeRange;\n    const fragStart = frag.start;\n    for (let i = 0; i < buffered.length; i++) {\n      if (fragStart >= buffered[i].start && fragStart <= buffered[i].end) {\n        timeRange = buffered[i];\n        break;\n      }\n    }\n    const fragEnd = frag.start + frag.duration;\n    if (timeRange) {\n      timeRange.end = fragEnd;\n    } else {\n      timeRange = {\n        start: fragStart,\n        end: fragEnd\n      };\n      buffered.push(timeRange);\n    }\n    this.fragmentTracker.fragBuffered(frag);\n    this.fragBufferedComplete(frag, null);\n    if (this.media) {\n      this.tick();\n    }\n  }\n  onBufferFlushing(event, data) {\n    const {\n      startOffset,\n      endOffset\n    } = data;\n    if (startOffset === 0 && endOffset !== Number.POSITIVE_INFINITY) {\n      const endOffsetSubtitles = endOffset - 1;\n      if (endOffsetSubtitles <= 0) {\n        return;\n      }\n      data.endOffsetSubtitles = Math.max(0, endOffsetSubtitles);\n      this.tracksBuffered.forEach(buffered => {\n        for (let i = 0; i < buffered.length;) {\n          if (buffered[i].end <= endOffsetSubtitles) {\n            buffered.shift();\n            continue;\n          } else if (buffered[i].start < endOffsetSubtitles) {\n            buffered[i].start = endOffsetSubtitles;\n          } else {\n            break;\n          }\n          i++;\n        }\n      });\n      this.fragmentTracker.removeFragmentsInRange(startOffset, endOffsetSubtitles, PlaylistLevelType.SUBTITLE);\n    }\n  }\n\n  // If something goes wrong, proceed to next frag, if we were processing one.\n  onError(event, data) {\n    const frag = data.frag;\n    if ((frag == null ? void 0 : frag.type) === PlaylistLevelType.SUBTITLE) {\n      if (data.details === ErrorDetails.FRAG_GAP) {\n        this.fragmentTracker.fragBuffered(frag, true);\n      }\n      if (this.fragCurrent) {\n        this.fragCurrent.abortRequests();\n      }\n      if (this.state !== State.STOPPED) {\n        this.state = State.IDLE;\n      }\n    }\n  }\n\n  // Got all new subtitle levels.\n  onSubtitleTracksUpdated(event, {\n    subtitleTracks\n  }) {\n    if (this.levels && subtitleOptionsIdentical(this.levels, subtitleTracks)) {\n      this.levels = subtitleTracks.map(mediaPlaylist => new Level(mediaPlaylist));\n      return;\n    }\n    this.tracksBuffered = [];\n    this.levels = subtitleTracks.map(mediaPlaylist => {\n      const level = new Level(mediaPlaylist);\n      this.tracksBuffered[level.id] = [];\n      return level;\n    });\n    this.fragmentTracker.removeFragmentsInRange(0, Number.POSITIVE_INFINITY, PlaylistLevelType.SUBTITLE);\n    this.fragPrevious = null;\n    this.mediaBuffer = null;\n  }\n  onSubtitleTrackSwitch(event, data) {\n    var _this$levels;\n    this.currentTrackId = data.id;\n    if (!((_this$levels = this.levels) != null && _this$levels.length) || this.currentTrackId === -1) {\n      this.clearInterval();\n      return;\n    }\n\n    // Check if track has the necessary details to load fragments\n    const currentTrack = this.levels[this.currentTrackId];\n    if (currentTrack != null && currentTrack.details) {\n      this.mediaBuffer = this.mediaBufferTimeRanges;\n    } else {\n      this.mediaBuffer = null;\n    }\n    if (currentTrack && this.state !== State.STOPPED) {\n      this.setInterval(TICK_INTERVAL$2);\n    }\n  }\n\n  // Got a new set of subtitle fragments.\n  onSubtitleTrackLoaded(event, data) {\n    var _track$details;\n    const {\n      currentTrackId,\n      levels\n    } = this;\n    const {\n      details: newDetails,\n      id: trackId\n    } = data;\n    if (!levels) {\n      this.warn(`Subtitle tracks were reset while loading level ${trackId}`);\n      return;\n    }\n    const track = levels[trackId];\n    if (trackId >= levels.length || !track) {\n      return;\n    }\n    this.log(`Subtitle track ${trackId} loaded [${newDetails.startSN},${newDetails.endSN}]${newDetails.lastPartSn ? `[part-${newDetails.lastPartSn}-${newDetails.lastPartIndex}]` : ''},duration:${newDetails.totalduration}`);\n    this.mediaBuffer = this.mediaBufferTimeRanges;\n    let sliding = 0;\n    if (newDetails.live || (_track$details = track.details) != null && _track$details.live) {\n      if (newDetails.deltaUpdateFailed) {\n        return;\n      }\n      const mainDetails = this.mainDetails;\n      if (!mainDetails) {\n        this.startFragRequested = false;\n        return;\n      }\n      const mainSlidingStartFragment = mainDetails.fragments[0];\n      if (!track.details) {\n        if (newDetails.hasProgramDateTime && mainDetails.hasProgramDateTime) {\n          alignMediaPlaylistByPDT(newDetails, mainDetails);\n          sliding = newDetails.fragmentStart;\n        } else if (mainSlidingStartFragment) {\n          // line up live playlist with main so that fragments in range are loaded\n          sliding = mainSlidingStartFragment.start;\n          addSliding(newDetails, sliding);\n        }\n      } else {\n        var _this$levelLastLoaded;\n        sliding = this.alignPlaylists(newDetails, track.details, (_this$levelLastLoaded = this.levelLastLoaded) == null ? void 0 : _this$levelLastLoaded.details);\n        if (sliding === 0 && mainSlidingStartFragment) {\n          // realign with main when there is no overlap with last refresh\n          sliding = mainSlidingStartFragment.start;\n          addSliding(newDetails, sliding);\n        }\n      }\n      // compute start position if we are aligned with the main playlist\n      if (mainDetails && !this.startFragRequested) {\n        this.setStartPosition(mainDetails, sliding);\n      }\n    }\n    track.details = newDetails;\n    this.levelLastLoaded = track;\n    if (trackId !== currentTrackId) {\n      return;\n    }\n    this.hls.trigger(Events.SUBTITLE_TRACK_UPDATED, {\n      details: newDetails,\n      id: trackId,\n      groupId: data.groupId\n    });\n\n    // trigger handler right now\n    this.tick();\n\n    // If playlist is misaligned because of bad PDT or drift, delete details to resync with main on reload\n    if (newDetails.live && !this.fragCurrent && this.media && this.state === State.IDLE) {\n      const foundFrag = findFragmentByPTS(null, newDetails.fragments, this.media.currentTime, 0);\n      if (!foundFrag) {\n        this.warn('Subtitle playlist not aligned with playback');\n        track.details = undefined;\n      }\n    }\n  }\n  _handleFragmentLoadComplete(fragLoadedData) {\n    const {\n      frag,\n      payload\n    } = fragLoadedData;\n    const decryptData = frag.decryptdata;\n    const hls = this.hls;\n    if (this.fragContextChanged(frag)) {\n      return;\n    }\n    // check to see if the payload needs to be decrypted\n    if (payload && payload.byteLength > 0 && decryptData != null && decryptData.key && decryptData.iv && isFullSegmentEncryption(decryptData.method)) {\n      const startTime = performance.now();\n      // decrypt the subtitles\n      this.decrypter.decrypt(new Uint8Array(payload), decryptData.key.buffer, decryptData.iv.buffer, getAesModeFromFullSegmentMethod(decryptData.method)).catch(err => {\n        hls.trigger(Events.ERROR, {\n          type: ErrorTypes.MEDIA_ERROR,\n          details: ErrorDetails.FRAG_DECRYPT_ERROR,\n          fatal: false,\n          error: err,\n          reason: err.message,\n          frag\n        });\n        throw err;\n      }).then(decryptedData => {\n        const endTime = performance.now();\n        hls.trigger(Events.FRAG_DECRYPTED, {\n          frag,\n          payload: decryptedData,\n          stats: {\n            tstart: startTime,\n            tdecrypt: endTime\n          }\n        });\n      }).catch(err => {\n        this.warn(`${err.name}: ${err.message}`);\n        this.state = State.IDLE;\n      });\n    }\n  }\n  doTick() {\n    if (!this.media) {\n      this.state = State.IDLE;\n      return;\n    }\n    if (this.state === State.IDLE) {\n      const {\n        currentTrackId,\n        levels\n      } = this;\n      const track = levels == null ? void 0 : levels[currentTrackId];\n      if (!track || !levels.length || !track.details) {\n        return;\n      }\n      if (this.waitForLive(track)) {\n        return;\n      }\n      const {\n        config\n      } = this;\n      const currentTime = this.getLoadPosition();\n      const bufferedInfo = BufferHelper.bufferedInfo(this.tracksBuffered[this.currentTrackId] || [], currentTime, config.maxBufferHole);\n      const {\n        end: targetBufferTime,\n        len: bufferLen\n      } = bufferedInfo;\n      const trackDetails = track.details;\n      const maxBufLen = this.hls.maxBufferLength + trackDetails.levelTargetDuration;\n      if (bufferLen > maxBufLen) {\n        return;\n      }\n      const fragments = trackDetails.fragments;\n      const fragLen = fragments.length;\n      const end = trackDetails.edge;\n      let foundFrag = null;\n      const fragPrevious = this.fragPrevious;\n      if (targetBufferTime < end) {\n        const tolerance = config.maxFragLookUpTolerance;\n        const lookupTolerance = targetBufferTime > end - tolerance ? 0 : tolerance;\n        foundFrag = findFragmentByPTS(fragPrevious, fragments, Math.max(fragments[0].start, targetBufferTime), lookupTolerance);\n        if (!foundFrag && fragPrevious && fragPrevious.start < fragments[0].start) {\n          foundFrag = fragments[0];\n        }\n      } else {\n        foundFrag = fragments[fragLen - 1];\n      }\n      foundFrag = this.filterReplacedPrimary(foundFrag, track.details);\n      if (!foundFrag) {\n        return;\n      }\n      // Load earlier fragment in same discontinuity to make up for misaligned playlists and cues that extend beyond end of segment\n      const curSNIdx = foundFrag.sn - trackDetails.startSN;\n      const prevFrag = fragments[curSNIdx - 1];\n      if (prevFrag && prevFrag.cc === foundFrag.cc && this.fragmentTracker.getState(prevFrag) === FragmentState.NOT_LOADED) {\n        foundFrag = prevFrag;\n      }\n      if (this.fragmentTracker.getState(foundFrag) === FragmentState.NOT_LOADED) {\n        // only load if fragment is not loaded\n        const fragToLoad = this.mapToInitFragWhenRequired(foundFrag);\n        if (fragToLoad) {\n          this.loadFragment(fragToLoad, track, targetBufferTime);\n        }\n      }\n    }\n  }\n  loadFragment(frag, level, targetBufferTime) {\n    if (!isMediaFragment(frag)) {\n      this._loadInitSegment(frag, level);\n    } else {\n      super.loadFragment(frag, level, targetBufferTime);\n    }\n  }\n  get mediaBufferTimeRanges() {\n    return new BufferableInstance(this.tracksBuffered[this.currentTrackId] || []);\n  }\n}\nclass BufferableInstance {\n  constructor(timeranges) {\n    this.buffered = void 0;\n    const getRange = (name, index, length) => {\n      index = index >>> 0;\n      if (index > length - 1) {\n        throw new DOMException(`Failed to execute '${name}' on 'TimeRanges': The index provided (${index}) is greater than the maximum bound (${length})`);\n      }\n      return timeranges[index][name];\n    };\n    this.buffered = {\n      get length() {\n        return timeranges.length;\n      },\n      end(index) {\n        return getRange('end', index, timeranges.length);\n      },\n      start(index) {\n        return getRange('start', index, timeranges.length);\n      }\n    };\n  }\n}\n\n/**\n *\n * This code was ported from the dash.js project at:\n *   https://github.com/Dash-Industry-Forum/dash.js/blob/development/externals/cea608-parser.js\n *   https://github.com/Dash-Industry-Forum/dash.js/commit/8269b26a761e0853bb21d78780ed945144ecdd4d#diff-71bc295a2d6b6b7093a1d3290d53a4b2\n *\n * The original copyright appears below:\n *\n * The copyright in this software is being made available under the BSD License,\n * included below. This software may be subject to other third party and contributor\n * rights, including patent rights, and no such rights are granted under this license.\n *\n * Copyright (c) 2015-2016, DASH Industry Forum.\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without modification,\n * are permitted provided that the following conditions are met:\n *  1. Redistributions of source code must retain the above copyright notice, this\n *  list of conditions and the following disclaimer.\n *  * Redistributions in binary form must reproduce the above copyright notice,\n *  this list of conditions and the following disclaimer in the documentation and/or\n *  other materials provided with the distribution.\n *  2. Neither the name of Dash Industry Forum nor the names of its\n *  contributors may be used to endorse or promote products derived from this software\n *  without specific prior written permission.\n *\n *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS AS IS AND ANY\n *  EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n *  WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n *  IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT,\n *  INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n *  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n *  PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,\n *  WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n *  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n *  POSSIBILITY OF SUCH DAMAGE.\n */\n/**\n *  Exceptions from regular ASCII. CodePoints are mapped to UTF-16 codes\n */\n\nconst specialCea608CharsCodes = {\n  0x2a: 0xe1,\n  // lowercase a, acute accent\n  0x5c: 0xe9,\n  // lowercase e, acute accent\n  0x5e: 0xed,\n  // lowercase i, acute accent\n  0x5f: 0xf3,\n  // lowercase o, acute accent\n  0x60: 0xfa,\n  // lowercase u, acute accent\n  0x7b: 0xe7,\n  // lowercase c with cedilla\n  0x7c: 0xf7,\n  // division symbol\n  0x7d: 0xd1,\n  // uppercase N tilde\n  0x7e: 0xf1,\n  // lowercase n tilde\n  0x7f: 0x2588,\n  // Full block\n  // THIS BLOCK INCLUDES THE 16 EXTENDED (TWO-BYTE) LINE 21 CHARACTERS\n  // THAT COME FROM HI BYTE=0x11 AND LOW BETWEEN 0x30 AND 0x3F\n  // THIS MEANS THAT \\x50 MUST BE ADDED TO THE VALUES\n  0x80: 0xae,\n  // Registered symbol (R)\n  0x81: 0xb0,\n  // degree sign\n  0x82: 0xbd,\n  // 1/2 symbol\n  0x83: 0xbf,\n  // Inverted (open) question mark\n  0x84: 0x2122,\n  // Trademark symbol (TM)\n  0x85: 0xa2,\n  // Cents symbol\n  0x86: 0xa3,\n  // Pounds sterling\n  0x87: 0x266a,\n  // Music 8'th note\n  0x88: 0xe0,\n  // lowercase a, grave accent\n  0x89: 0x20,\n  // transparent space (regular)\n  0x8a: 0xe8,\n  // lowercase e, grave accent\n  0x8b: 0xe2,\n  // lowercase a, circumflex accent\n  0x8c: 0xea,\n  // lowercase e, circumflex accent\n  0x8d: 0xee,\n  // lowercase i, circumflex accent\n  0x8e: 0xf4,\n  // lowercase o, circumflex accent\n  0x8f: 0xfb,\n  // lowercase u, circumflex accent\n  // THIS BLOCK INCLUDES THE 32 EXTENDED (TWO-BYTE) LINE 21 CHARACTERS\n  // THAT COME FROM HI BYTE=0x12 AND LOW BETWEEN 0x20 AND 0x3F\n  0x90: 0xc1,\n  // capital letter A with acute\n  0x91: 0xc9,\n  // capital letter E with acute\n  0x92: 0xd3,\n  // capital letter O with acute\n  0x93: 0xda,\n  // capital letter U with acute\n  0x94: 0xdc,\n  // capital letter U with diaresis\n  0x95: 0xfc,\n  // lowercase letter U with diaeresis\n  0x96: 0x2018,\n  // opening single quote\n  0x97: 0xa1,\n  // inverted exclamation mark\n  0x98: 0x2a,\n  // asterisk\n  0x99: 0x2019,\n  // closing single quote\n  0x9a: 0x2501,\n  // box drawings heavy horizontal\n  0x9b: 0xa9,\n  // copyright sign\n  0x9c: 0x2120,\n  // Service mark\n  0x9d: 0x2022,\n  // (round) bullet\n  0x9e: 0x201c,\n  // Left double quotation mark\n  0x9f: 0x201d,\n  // Right double quotation mark\n  0xa0: 0xc0,\n  // uppercase A, grave accent\n  0xa1: 0xc2,\n  // uppercase A, circumflex\n  0xa2: 0xc7,\n  // uppercase C with cedilla\n  0xa3: 0xc8,\n  // uppercase E, grave accent\n  0xa4: 0xca,\n  // uppercase E, circumflex\n  0xa5: 0xcb,\n  // capital letter E with diaresis\n  0xa6: 0xeb,\n  // lowercase letter e with diaresis\n  0xa7: 0xce,\n  // uppercase I, circumflex\n  0xa8: 0xcf,\n  // uppercase I, with diaresis\n  0xa9: 0xef,\n  // lowercase i, with diaresis\n  0xaa: 0xd4,\n  // uppercase O, circumflex\n  0xab: 0xd9,\n  // uppercase U, grave accent\n  0xac: 0xf9,\n  // lowercase u, grave accent\n  0xad: 0xdb,\n  // uppercase U, circumflex\n  0xae: 0xab,\n  // left-pointing double angle quotation mark\n  0xaf: 0xbb,\n  // right-pointing double angle quotation mark\n  // THIS BLOCK INCLUDES THE 32 EXTENDED (TWO-BYTE) LINE 21 CHARACTERS\n  // THAT COME FROM HI BYTE=0x13 AND LOW BETWEEN 0x20 AND 0x3F\n  0xb0: 0xc3,\n  // Uppercase A, tilde\n  0xb1: 0xe3,\n  // Lowercase a, tilde\n  0xb2: 0xcd,\n  // Uppercase I, acute accent\n  0xb3: 0xcc,\n  // Uppercase I, grave accent\n  0xb4: 0xec,\n  // Lowercase i, grave accent\n  0xb5: 0xd2,\n  // Uppercase O, grave accent\n  0xb6: 0xf2,\n  // Lowercase o, grave accent\n  0xb7: 0xd5,\n  // Uppercase O, tilde\n  0xb8: 0xf5,\n  // Lowercase o, tilde\n  0xb9: 0x7b,\n  // Open curly brace\n  0xba: 0x7d,\n  // Closing curly brace\n  0xbb: 0x5c,\n  // Backslash\n  0xbc: 0x5e,\n  // Caret\n  0xbd: 0x5f,\n  // Underscore\n  0xbe: 0x7c,\n  // Pipe (vertical line)\n  0xbf: 0x223c,\n  // Tilde operator\n  0xc0: 0xc4,\n  // Uppercase A, umlaut\n  0xc1: 0xe4,\n  // Lowercase A, umlaut\n  0xc2: 0xd6,\n  // Uppercase O, umlaut\n  0xc3: 0xf6,\n  // Lowercase o, umlaut\n  0xc4: 0xdf,\n  // Esszett (sharp S)\n  0xc5: 0xa5,\n  // Yen symbol\n  0xc6: 0xa4,\n  // Generic currency sign\n  0xc7: 0x2503,\n  // Box drawings heavy vertical\n  0xc8: 0xc5,\n  // Uppercase A, ring\n  0xc9: 0xe5,\n  // Lowercase A, ring\n  0xca: 0xd8,\n  // Uppercase O, stroke\n  0xcb: 0xf8,\n  // Lowercase o, strok\n  0xcc: 0x250f,\n  // Box drawings heavy down and right\n  0xcd: 0x2513,\n  // Box drawings heavy down and left\n  0xce: 0x2517,\n  // Box drawings heavy up and right\n  0xcf: 0x251b // Box drawings heavy up and left\n};\n\n/**\n * Utils\n */\nconst getCharForByte = byte => String.fromCharCode(specialCea608CharsCodes[byte] || byte);\nconst NR_ROWS = 15;\nconst NR_COLS = 100;\n// Tables to look up row from PAC data\nconst rowsLowCh1 = {\n  0x11: 1,\n  0x12: 3,\n  0x15: 5,\n  0x16: 7,\n  0x17: 9,\n  0x10: 11,\n  0x13: 12,\n  0x14: 14\n};\nconst rowsHighCh1 = {\n  0x11: 2,\n  0x12: 4,\n  0x15: 6,\n  0x16: 8,\n  0x17: 10,\n  0x13: 13,\n  0x14: 15\n};\nconst rowsLowCh2 = {\n  0x19: 1,\n  0x1a: 3,\n  0x1d: 5,\n  0x1e: 7,\n  0x1f: 9,\n  0x18: 11,\n  0x1b: 12,\n  0x1c: 14\n};\nconst rowsHighCh2 = {\n  0x19: 2,\n  0x1a: 4,\n  0x1d: 6,\n  0x1e: 8,\n  0x1f: 10,\n  0x1b: 13,\n  0x1c: 15\n};\nconst backgroundColors = ['white', 'green', 'blue', 'cyan', 'red', 'yellow', 'magenta', 'black', 'transparent'];\nclass CaptionsLogger {\n  constructor() {\n    this.time = null;\n    this.verboseLevel = 0;\n  }\n  log(severity, msg) {\n    if (this.verboseLevel >= severity) {\n      const m = typeof msg === 'function' ? msg() : msg;\n      logger.log(`${this.time} [${severity}] ${m}`);\n    }\n  }\n}\nconst numArrayToHexArray = function numArrayToHexArray(numArray) {\n  const hexArray = [];\n  for (let j = 0; j < numArray.length; j++) {\n    hexArray.push(numArray[j].toString(16));\n  }\n  return hexArray;\n};\nclass PenState {\n  constructor() {\n    this.foreground = 'white';\n    this.underline = false;\n    this.italics = false;\n    this.background = 'black';\n    this.flash = false;\n  }\n  reset() {\n    this.foreground = 'white';\n    this.underline = false;\n    this.italics = false;\n    this.background = 'black';\n    this.flash = false;\n  }\n  setStyles(styles) {\n    const attribs = ['foreground', 'underline', 'italics', 'background', 'flash'];\n    for (let i = 0; i < attribs.length; i++) {\n      const style = attribs[i];\n      if (styles.hasOwnProperty(style)) {\n        this[style] = styles[style];\n      }\n    }\n  }\n  isDefault() {\n    return this.foreground === 'white' && !this.underline && !this.italics && this.background === 'black' && !this.flash;\n  }\n  equals(other) {\n    return this.foreground === other.foreground && this.underline === other.underline && this.italics === other.italics && this.background === other.background && this.flash === other.flash;\n  }\n  copy(newPenState) {\n    this.foreground = newPenState.foreground;\n    this.underline = newPenState.underline;\n    this.italics = newPenState.italics;\n    this.background = newPenState.background;\n    this.flash = newPenState.flash;\n  }\n  toString() {\n    return 'color=' + this.foreground + ', underline=' + this.underline + ', italics=' + this.italics + ', background=' + this.background + ', flash=' + this.flash;\n  }\n}\n\n/**\n * Unicode character with styling and background.\n * @constructor\n */\nclass StyledUnicodeChar {\n  constructor() {\n    this.uchar = ' ';\n    this.penState = new PenState();\n  }\n  reset() {\n    this.uchar = ' ';\n    this.penState.reset();\n  }\n  setChar(uchar, newPenState) {\n    this.uchar = uchar;\n    this.penState.copy(newPenState);\n  }\n  setPenState(newPenState) {\n    this.penState.copy(newPenState);\n  }\n  equals(other) {\n    return this.uchar === other.uchar && this.penState.equals(other.penState);\n  }\n  copy(newChar) {\n    this.uchar = newChar.uchar;\n    this.penState.copy(newChar.penState);\n  }\n  isEmpty() {\n    return this.uchar === ' ' && this.penState.isDefault();\n  }\n}\n\n/**\n * CEA-608 row consisting of NR_COLS instances of StyledUnicodeChar.\n * @constructor\n */\nclass Row {\n  constructor(logger) {\n    this.chars = [];\n    this.pos = 0;\n    this.currPenState = new PenState();\n    this.cueStartTime = null;\n    this.logger = void 0;\n    for (let i = 0; i < NR_COLS; i++) {\n      this.chars.push(new StyledUnicodeChar());\n    }\n    this.logger = logger;\n  }\n  equals(other) {\n    for (let i = 0; i < NR_COLS; i++) {\n      if (!this.chars[i].equals(other.chars[i])) {\n        return false;\n      }\n    }\n    return true;\n  }\n  copy(other) {\n    for (let i = 0; i < NR_COLS; i++) {\n      this.chars[i].copy(other.chars[i]);\n    }\n  }\n  isEmpty() {\n    let empty = true;\n    for (let i = 0; i < NR_COLS; i++) {\n      if (!this.chars[i].isEmpty()) {\n        empty = false;\n        break;\n      }\n    }\n    return empty;\n  }\n\n  /**\n   *  Set the cursor to a valid column.\n   */\n  setCursor(absPos) {\n    if (this.pos !== absPos) {\n      this.pos = absPos;\n    }\n    if (this.pos < 0) {\n      this.logger.log(3, 'Negative cursor position ' + this.pos);\n      this.pos = 0;\n    } else if (this.pos > NR_COLS) {\n      this.logger.log(3, 'Too large cursor position ' + this.pos);\n      this.pos = NR_COLS;\n    }\n  }\n\n  /**\n   * Move the cursor relative to current position.\n   */\n  moveCursor(relPos) {\n    const newPos = this.pos + relPos;\n    if (relPos > 1) {\n      for (let i = this.pos + 1; i < newPos + 1; i++) {\n        this.chars[i].setPenState(this.currPenState);\n      }\n    }\n    this.setCursor(newPos);\n  }\n\n  /**\n   * Backspace, move one step back and clear character.\n   */\n  backSpace() {\n    this.moveCursor(-1);\n    this.chars[this.pos].setChar(' ', this.currPenState);\n  }\n  insertChar(byte) {\n    if (byte >= 0x90) {\n      // Extended char\n      this.backSpace();\n    }\n    const char = getCharForByte(byte);\n    if (this.pos >= NR_COLS) {\n      this.logger.log(0, () => 'Cannot insert ' + byte.toString(16) + ' (' + char + ') at position ' + this.pos + '. Skipping it!');\n      return;\n    }\n    this.chars[this.pos].setChar(char, this.currPenState);\n    this.moveCursor(1);\n  }\n  clearFromPos(startPos) {\n    let i;\n    for (i = startPos; i < NR_COLS; i++) {\n      this.chars[i].reset();\n    }\n  }\n  clear() {\n    this.clearFromPos(0);\n    this.pos = 0;\n    this.currPenState.reset();\n  }\n  clearToEndOfRow() {\n    this.clearFromPos(this.pos);\n  }\n  getTextString() {\n    const chars = [];\n    let empty = true;\n    for (let i = 0; i < NR_COLS; i++) {\n      const char = this.chars[i].uchar;\n      if (char !== ' ') {\n        empty = false;\n      }\n      chars.push(char);\n    }\n    if (empty) {\n      return '';\n    } else {\n      return chars.join('');\n    }\n  }\n  setPenStyles(styles) {\n    this.currPenState.setStyles(styles);\n    const currChar = this.chars[this.pos];\n    currChar.setPenState(this.currPenState);\n  }\n}\n\n/**\n * Keep a CEA-608 screen of 32x15 styled characters\n * @constructor\n */\nclass CaptionScreen {\n  constructor(logger) {\n    this.rows = [];\n    this.currRow = NR_ROWS - 1;\n    this.nrRollUpRows = null;\n    this.lastOutputScreen = null;\n    this.logger = void 0;\n    for (let i = 0; i < NR_ROWS; i++) {\n      this.rows.push(new Row(logger));\n    }\n    this.logger = logger;\n  }\n  reset() {\n    for (let i = 0; i < NR_ROWS; i++) {\n      this.rows[i].clear();\n    }\n    this.currRow = NR_ROWS - 1;\n  }\n  equals(other) {\n    let equal = true;\n    for (let i = 0; i < NR_ROWS; i++) {\n      if (!this.rows[i].equals(other.rows[i])) {\n        equal = false;\n        break;\n      }\n    }\n    return equal;\n  }\n  copy(other) {\n    for (let i = 0; i < NR_ROWS; i++) {\n      this.rows[i].copy(other.rows[i]);\n    }\n  }\n  isEmpty() {\n    let empty = true;\n    for (let i = 0; i < NR_ROWS; i++) {\n      if (!this.rows[i].isEmpty()) {\n        empty = false;\n        break;\n      }\n    }\n    return empty;\n  }\n  backSpace() {\n    const row = this.rows[this.currRow];\n    row.backSpace();\n  }\n  clearToEndOfRow() {\n    const row = this.rows[this.currRow];\n    row.clearToEndOfRow();\n  }\n\n  /**\n   * Insert a character (without styling) in the current row.\n   */\n  insertChar(char) {\n    const row = this.rows[this.currRow];\n    row.insertChar(char);\n  }\n  setPen(styles) {\n    const row = this.rows[this.currRow];\n    row.setPenStyles(styles);\n  }\n  moveCursor(relPos) {\n    const row = this.rows[this.currRow];\n    row.moveCursor(relPos);\n  }\n  setCursor(absPos) {\n    this.logger.log(2, 'setCursor: ' + absPos);\n    const row = this.rows[this.currRow];\n    row.setCursor(absPos);\n  }\n  setPAC(pacData) {\n    this.logger.log(2, () => 'pacData = ' + stringify(pacData));\n    let newRow = pacData.row - 1;\n    if (this.nrRollUpRows && newRow < this.nrRollUpRows - 1) {\n      newRow = this.nrRollUpRows - 1;\n    }\n\n    // Make sure this only affects Roll-up Captions by checking this.nrRollUpRows\n    if (this.nrRollUpRows && this.currRow !== newRow) {\n      // clear all rows first\n      for (let i = 0; i < NR_ROWS; i++) {\n        this.rows[i].clear();\n      }\n\n      // Copy this.nrRollUpRows rows from lastOutputScreen and place it in the newRow location\n      // topRowIndex - the start of rows to copy (inclusive index)\n      const topRowIndex = this.currRow + 1 - this.nrRollUpRows;\n      // We only copy if the last position was already shown.\n      // We use the cueStartTime value to check this.\n      const lastOutputScreen = this.lastOutputScreen;\n      if (lastOutputScreen) {\n        const prevLineTime = lastOutputScreen.rows[topRowIndex].cueStartTime;\n        const time = this.logger.time;\n        if (prevLineTime !== null && time !== null && prevLineTime < time) {\n          for (let i = 0; i < this.nrRollUpRows; i++) {\n            this.rows[newRow - this.nrRollUpRows + i + 1].copy(lastOutputScreen.rows[topRowIndex + i]);\n          }\n        }\n      }\n    }\n    this.currRow = newRow;\n    const row = this.rows[this.currRow];\n    if (pacData.indent !== null) {\n      const indent = pacData.indent;\n      const prevPos = Math.max(indent - 1, 0);\n      row.setCursor(pacData.indent);\n      pacData.color = row.chars[prevPos].penState.foreground;\n    }\n    const styles = {\n      foreground: pacData.color,\n      underline: pacData.underline,\n      italics: pacData.italics,\n      background: 'black',\n      flash: false\n    };\n    this.setPen(styles);\n  }\n\n  /**\n   * Set background/extra foreground, but first do back_space, and then insert space (backwards compatibility).\n   */\n  setBkgData(bkgData) {\n    this.logger.log(2, () => 'bkgData = ' + stringify(bkgData));\n    this.backSpace();\n    this.setPen(bkgData);\n    this.insertChar(0x20); // Space\n  }\n  setRollUpRows(nrRows) {\n    this.nrRollUpRows = nrRows;\n  }\n  rollUp() {\n    if (this.nrRollUpRows === null) {\n      this.logger.log(3, 'roll_up but nrRollUpRows not set yet');\n      return; // Not properly setup\n    }\n    this.logger.log(1, () => this.getDisplayText());\n    const topRowIndex = this.currRow + 1 - this.nrRollUpRows;\n    const topRow = this.rows.splice(topRowIndex, 1)[0];\n    topRow.clear();\n    this.rows.splice(this.currRow, 0, topRow);\n    this.logger.log(2, 'Rolling up');\n    // this.logger.log(VerboseLevel.TEXT, this.get_display_text())\n  }\n\n  /**\n   * Get all non-empty rows with as unicode text.\n   */\n  getDisplayText(asOneRow) {\n    asOneRow = asOneRow || false;\n    const displayText = [];\n    let text = '';\n    let rowNr = -1;\n    for (let i = 0; i < NR_ROWS; i++) {\n      const rowText = this.rows[i].getTextString();\n      if (rowText) {\n        rowNr = i + 1;\n        if (asOneRow) {\n          displayText.push('Row ' + rowNr + \": '\" + rowText + \"'\");\n        } else {\n          displayText.push(rowText.trim());\n        }\n      }\n    }\n    if (displayText.length > 0) {\n      if (asOneRow) {\n        text = '[' + displayText.join(' | ') + ']';\n      } else {\n        text = displayText.join('\\n');\n      }\n    }\n    return text;\n  }\n  getTextAndFormat() {\n    return this.rows;\n  }\n}\n\n// var modes = ['MODE_ROLL-UP', 'MODE_POP-ON', 'MODE_PAINT-ON', 'MODE_TEXT'];\n\nclass Cea608Channel {\n  constructor(channelNumber, outputFilter, logger) {\n    this.chNr = void 0;\n    this.outputFilter = void 0;\n    this.mode = void 0;\n    this.verbose = void 0;\n    this.displayedMemory = void 0;\n    this.nonDisplayedMemory = void 0;\n    this.lastOutputScreen = void 0;\n    this.currRollUpRow = void 0;\n    this.writeScreen = void 0;\n    this.cueStartTime = void 0;\n    this.logger = void 0;\n    this.chNr = channelNumber;\n    this.outputFilter = outputFilter;\n    this.mode = null;\n    this.verbose = 0;\n    this.displayedMemory = new CaptionScreen(logger);\n    this.nonDisplayedMemory = new CaptionScreen(logger);\n    this.lastOutputScreen = new CaptionScreen(logger);\n    this.currRollUpRow = this.displayedMemory.rows[NR_ROWS - 1];\n    this.writeScreen = this.displayedMemory;\n    this.mode = null;\n    this.cueStartTime = null; // Keeps track of where a cue started.\n    this.logger = logger;\n  }\n  reset() {\n    this.mode = null;\n    this.displayedMemory.reset();\n    this.nonDisplayedMemory.reset();\n    this.lastOutputScreen.reset();\n    this.outputFilter.reset();\n    this.currRollUpRow = this.displayedMemory.rows[NR_ROWS - 1];\n    this.writeScreen = this.displayedMemory;\n    this.mode = null;\n    this.cueStartTime = null;\n  }\n  getHandler() {\n    return this.outputFilter;\n  }\n  setHandler(newHandler) {\n    this.outputFilter = newHandler;\n  }\n  setPAC(pacData) {\n    this.writeScreen.setPAC(pacData);\n  }\n  setBkgData(bkgData) {\n    this.writeScreen.setBkgData(bkgData);\n  }\n  setMode(newMode) {\n    if (newMode === this.mode) {\n      return;\n    }\n    this.mode = newMode;\n    this.logger.log(2, () => 'MODE=' + newMode);\n    if (this.mode === 'MODE_POP-ON') {\n      this.writeScreen = this.nonDisplayedMemory;\n    } else {\n      this.writeScreen = this.displayedMemory;\n      this.writeScreen.reset();\n    }\n    if (this.mode !== 'MODE_ROLL-UP') {\n      this.displayedMemory.nrRollUpRows = null;\n      this.nonDisplayedMemory.nrRollUpRows = null;\n    }\n    this.mode = newMode;\n  }\n  insertChars(chars) {\n    for (let i = 0; i < chars.length; i++) {\n      this.writeScreen.insertChar(chars[i]);\n    }\n    const screen = this.writeScreen === this.displayedMemory ? 'DISP' : 'NON_DISP';\n    this.logger.log(2, () => screen + ': ' + this.writeScreen.getDisplayText(true));\n    if (this.mode === 'MODE_PAINT-ON' || this.mode === 'MODE_ROLL-UP') {\n      this.logger.log(1, () => 'DISPLAYED: ' + this.displayedMemory.getDisplayText(true));\n      this.outputDataUpdate();\n    }\n  }\n  ccRCL() {\n    // Resume Caption Loading (switch mode to Pop On)\n    this.logger.log(2, 'RCL - Resume Caption Loading');\n    this.setMode('MODE_POP-ON');\n  }\n  ccBS() {\n    // BackSpace\n    this.logger.log(2, 'BS - BackSpace');\n    if (this.mode === 'MODE_TEXT') {\n      return;\n    }\n    this.writeScreen.backSpace();\n    if (this.writeScreen === this.displayedMemory) {\n      this.outputDataUpdate();\n    }\n  }\n  ccAOF() {\n    // Reserved (formerly Alarm Off)\n  }\n  ccAON() {\n    // Reserved (formerly Alarm On)\n  }\n  ccDER() {\n    // Delete to End of Row\n    this.logger.log(2, 'DER- Delete to End of Row');\n    this.writeScreen.clearToEndOfRow();\n    this.outputDataUpdate();\n  }\n  ccRU(nrRows) {\n    // Roll-Up Captions-2,3,or 4 Rows\n    this.logger.log(2, 'RU(' + nrRows + ') - Roll Up');\n    this.writeScreen = this.displayedMemory;\n    this.setMode('MODE_ROLL-UP');\n    this.writeScreen.setRollUpRows(nrRows);\n  }\n  ccFON() {\n    // Flash On\n    this.logger.log(2, 'FON - Flash On');\n    this.writeScreen.setPen({\n      flash: true\n    });\n  }\n  ccRDC() {\n    // Resume Direct Captioning (switch mode to PaintOn)\n    this.logger.log(2, 'RDC - Resume Direct Captioning');\n    this.setMode('MODE_PAINT-ON');\n  }\n  ccTR() {\n    // Text Restart in text mode (not supported, however)\n    this.logger.log(2, 'TR');\n    this.setMode('MODE_TEXT');\n  }\n  ccRTD() {\n    // Resume Text Display in Text mode (not supported, however)\n    this.logger.log(2, 'RTD');\n    this.setMode('MODE_TEXT');\n  }\n  ccEDM() {\n    // Erase Displayed Memory\n    this.logger.log(2, 'EDM - Erase Displayed Memory');\n    this.displayedMemory.reset();\n    this.outputDataUpdate(true);\n  }\n  ccCR() {\n    // Carriage Return\n    this.logger.log(2, 'CR - Carriage Return');\n    this.writeScreen.rollUp();\n    this.outputDataUpdate(true);\n  }\n  ccENM() {\n    // Erase Non-Displayed Memory\n    this.logger.log(2, 'ENM - Erase Non-displayed Memory');\n    this.nonDisplayedMemory.reset();\n  }\n  ccEOC() {\n    // End of Caption (Flip Memories)\n    this.logger.log(2, 'EOC - End Of Caption');\n    if (this.mode === 'MODE_POP-ON') {\n      const tmp = this.displayedMemory;\n      this.displayedMemory = this.nonDisplayedMemory;\n      this.nonDisplayedMemory = tmp;\n      this.writeScreen = this.nonDisplayedMemory;\n      this.logger.log(1, () => 'DISP: ' + this.displayedMemory.getDisplayText());\n    }\n    this.outputDataUpdate(true);\n  }\n  ccTO(nrCols) {\n    // Tab Offset 1,2, or 3 columns\n    this.logger.log(2, 'TO(' + nrCols + ') - Tab Offset');\n    this.writeScreen.moveCursor(nrCols);\n  }\n  ccMIDROW(secondByte) {\n    // Parse MIDROW command\n    const styles = {\n      flash: false\n    };\n    styles.underline = secondByte % 2 === 1;\n    styles.italics = secondByte >= 0x2e;\n    if (!styles.italics) {\n      const colorIndex = Math.floor(secondByte / 2) - 0x10;\n      const colors = ['white', 'green', 'blue', 'cyan', 'red', 'yellow', 'magenta'];\n      styles.foreground = colors[colorIndex];\n    } else {\n      styles.foreground = 'white';\n    }\n    this.logger.log(2, 'MIDROW: ' + stringify(styles));\n    this.writeScreen.setPen(styles);\n  }\n  outputDataUpdate(dispatch = false) {\n    const time = this.logger.time;\n    if (time === null) {\n      return;\n    }\n    if (this.outputFilter) {\n      if (this.cueStartTime === null && !this.displayedMemory.isEmpty()) {\n        // Start of a new cue\n        this.cueStartTime = time;\n      } else {\n        if (!this.displayedMemory.equals(this.lastOutputScreen)) {\n          this.outputFilter.newCue(this.cueStartTime, time, this.lastOutputScreen);\n          if (dispatch && this.outputFilter.dispatchCue) {\n            this.outputFilter.dispatchCue();\n          }\n          this.cueStartTime = this.displayedMemory.isEmpty() ? null : time;\n        }\n      }\n      this.lastOutputScreen.copy(this.displayedMemory);\n    }\n  }\n  cueSplitAtTime(t) {\n    if (this.outputFilter) {\n      if (!this.displayedMemory.isEmpty()) {\n        if (this.outputFilter.newCue) {\n          this.outputFilter.newCue(this.cueStartTime, t, this.displayedMemory);\n        }\n        this.cueStartTime = t;\n      }\n    }\n  }\n}\n\n// Will be 1 or 2 when parsing captions\n\nclass Cea608Parser {\n  constructor(field, out1, out2) {\n    this.channels = void 0;\n    this.currentChannel = 0;\n    this.cmdHistory = createCmdHistory();\n    this.logger = void 0;\n    const logger = this.logger = new CaptionsLogger();\n    this.channels = [null, new Cea608Channel(field, out1, logger), new Cea608Channel(field + 1, out2, logger)];\n  }\n  getHandler(channel) {\n    return this.channels[channel].getHandler();\n  }\n  setHandler(channel, newHandler) {\n    this.channels[channel].setHandler(newHandler);\n  }\n\n  /**\n   * Add data for time t in forms of list of bytes (unsigned ints). The bytes are treated as pairs.\n   */\n  addData(time, byteList) {\n    this.logger.time = time;\n    for (let i = 0; i < byteList.length; i += 2) {\n      const a = byteList[i] & 0x7f;\n      const b = byteList[i + 1] & 0x7f;\n      let cmdFound = false;\n      let charsFound = null;\n      if (a === 0 && b === 0) {\n        continue;\n      } else {\n        this.logger.log(3, () => '[' + numArrayToHexArray([byteList[i], byteList[i + 1]]) + '] -> (' + numArrayToHexArray([a, b]) + ')');\n      }\n      const cmdHistory = this.cmdHistory;\n      const isControlCode = a >= 0x10 && a <= 0x1f;\n      if (isControlCode) {\n        // Skip redundant control codes\n        if (hasCmdRepeated(a, b, cmdHistory)) {\n          setLastCmd(null, null, cmdHistory);\n          this.logger.log(3, () => 'Repeated command (' + numArrayToHexArray([a, b]) + ') is dropped');\n          continue;\n        }\n        setLastCmd(a, b, this.cmdHistory);\n        cmdFound = this.parseCmd(a, b);\n        if (!cmdFound) {\n          cmdFound = this.parseMidrow(a, b);\n        }\n        if (!cmdFound) {\n          cmdFound = this.parsePAC(a, b);\n        }\n        if (!cmdFound) {\n          cmdFound = this.parseBackgroundAttributes(a, b);\n        }\n      } else {\n        setLastCmd(null, null, cmdHistory);\n      }\n      if (!cmdFound) {\n        charsFound = this.parseChars(a, b);\n        if (charsFound) {\n          const currChNr = this.currentChannel;\n          if (currChNr && currChNr > 0) {\n            const channel = this.channels[currChNr];\n            channel.insertChars(charsFound);\n          } else {\n            this.logger.log(2, 'No channel found yet. TEXT-MODE?');\n          }\n        }\n      }\n      if (!cmdFound && !charsFound) {\n        this.logger.log(2, () => \"Couldn't parse cleaned data \" + numArrayToHexArray([a, b]) + ' orig: ' + numArrayToHexArray([byteList[i], byteList[i + 1]]));\n      }\n    }\n  }\n\n  /**\n   * Parse Command.\n   * @returns True if a command was found\n   */\n  parseCmd(a, b) {\n    const cond1 = (a === 0x14 || a === 0x1c || a === 0x15 || a === 0x1d) && b >= 0x20 && b <= 0x2f;\n    const cond2 = (a === 0x17 || a === 0x1f) && b >= 0x21 && b <= 0x23;\n    if (!(cond1 || cond2)) {\n      return false;\n    }\n    const chNr = a === 0x14 || a === 0x15 || a === 0x17 ? 1 : 2;\n    const channel = this.channels[chNr];\n    if (a === 0x14 || a === 0x15 || a === 0x1c || a === 0x1d) {\n      if (b === 0x20) {\n        channel.ccRCL();\n      } else if (b === 0x21) {\n        channel.ccBS();\n      } else if (b === 0x22) {\n        channel.ccAOF();\n      } else if (b === 0x23) {\n        channel.ccAON();\n      } else if (b === 0x24) {\n        channel.ccDER();\n      } else if (b === 0x25) {\n        channel.ccRU(2);\n      } else if (b === 0x26) {\n        channel.ccRU(3);\n      } else if (b === 0x27) {\n        channel.ccRU(4);\n      } else if (b === 0x28) {\n        channel.ccFON();\n      } else if (b === 0x29) {\n        channel.ccRDC();\n      } else if (b === 0x2a) {\n        channel.ccTR();\n      } else if (b === 0x2b) {\n        channel.ccRTD();\n      } else if (b === 0x2c) {\n        channel.ccEDM();\n      } else if (b === 0x2d) {\n        channel.ccCR();\n      } else if (b === 0x2e) {\n        channel.ccENM();\n      } else if (b === 0x2f) {\n        channel.ccEOC();\n      }\n    } else {\n      // a == 0x17 || a == 0x1F\n      channel.ccTO(b - 0x20);\n    }\n    this.currentChannel = chNr;\n    return true;\n  }\n\n  /**\n   * Parse midrow styling command\n   */\n  parseMidrow(a, b) {\n    let chNr = 0;\n    if ((a === 0x11 || a === 0x19) && b >= 0x20 && b <= 0x2f) {\n      if (a === 0x11) {\n        chNr = 1;\n      } else {\n        chNr = 2;\n      }\n      if (chNr !== this.currentChannel) {\n        this.logger.log(0, 'Mismatch channel in midrow parsing');\n        return false;\n      }\n      const channel = this.channels[chNr];\n      if (!channel) {\n        return false;\n      }\n      channel.ccMIDROW(b);\n      this.logger.log(3, () => 'MIDROW (' + numArrayToHexArray([a, b]) + ')');\n      return true;\n    }\n    return false;\n  }\n\n  /**\n   * Parse Preable Access Codes (Table 53).\n   * @returns {Boolean} Tells if PAC found\n   */\n  parsePAC(a, b) {\n    let row;\n    const case1 = (a >= 0x11 && a <= 0x17 || a >= 0x19 && a <= 0x1f) && b >= 0x40 && b <= 0x7f;\n    const case2 = (a === 0x10 || a === 0x18) && b >= 0x40 && b <= 0x5f;\n    if (!(case1 || case2)) {\n      return false;\n    }\n    const chNr = a <= 0x17 ? 1 : 2;\n    if (b >= 0x40 && b <= 0x5f) {\n      row = chNr === 1 ? rowsLowCh1[a] : rowsLowCh2[a];\n    } else {\n      // 0x60 <= b <= 0x7F\n      row = chNr === 1 ? rowsHighCh1[a] : rowsHighCh2[a];\n    }\n    const channel = this.channels[chNr];\n    if (!channel) {\n      return false;\n    }\n    channel.setPAC(this.interpretPAC(row, b));\n    this.currentChannel = chNr;\n    return true;\n  }\n\n  /**\n   * Interpret the second byte of the pac, and return the information.\n   * @returns pacData with style parameters\n   */\n  interpretPAC(row, byte) {\n    let pacIndex;\n    const pacData = {\n      color: null,\n      italics: false,\n      indent: null,\n      underline: false,\n      row: row\n    };\n    if (byte > 0x5f) {\n      pacIndex = byte - 0x60;\n    } else {\n      pacIndex = byte - 0x40;\n    }\n    pacData.underline = (pacIndex & 1) === 1;\n    if (pacIndex <= 0xd) {\n      pacData.color = ['white', 'green', 'blue', 'cyan', 'red', 'yellow', 'magenta', 'white'][Math.floor(pacIndex / 2)];\n    } else if (pacIndex <= 0xf) {\n      pacData.italics = true;\n      pacData.color = 'white';\n    } else {\n      pacData.indent = Math.floor((pacIndex - 0x10) / 2) * 4;\n    }\n    return pacData; // Note that row has zero offset. The spec uses 1.\n  }\n\n  /**\n   * Parse characters.\n   * @returns An array with 1 to 2 codes corresponding to chars, if found. null otherwise.\n   */\n  parseChars(a, b) {\n    let channelNr;\n    let charCodes = null;\n    let charCode1 = null;\n    if (a >= 0x19) {\n      channelNr = 2;\n      charCode1 = a - 8;\n    } else {\n      channelNr = 1;\n      charCode1 = a;\n    }\n    if (charCode1 >= 0x11 && charCode1 <= 0x13) {\n      // Special character\n      let oneCode;\n      if (charCode1 === 0x11) {\n        oneCode = b + 0x50;\n      } else if (charCode1 === 0x12) {\n        oneCode = b + 0x70;\n      } else {\n        oneCode = b + 0x90;\n      }\n      this.logger.log(2, () => \"Special char '\" + getCharForByte(oneCode) + \"' in channel \" + channelNr);\n      charCodes = [oneCode];\n    } else if (a >= 0x20 && a <= 0x7f) {\n      charCodes = b === 0 ? [a] : [a, b];\n    }\n    if (charCodes) {\n      this.logger.log(3, () => 'Char codes =  ' + numArrayToHexArray(charCodes).join(','));\n    }\n    return charCodes;\n  }\n\n  /**\n   * Parse extended background attributes as well as new foreground color black.\n   * @returns True if background attributes are found\n   */\n  parseBackgroundAttributes(a, b) {\n    const case1 = (a === 0x10 || a === 0x18) && b >= 0x20 && b <= 0x2f;\n    const case2 = (a === 0x17 || a === 0x1f) && b >= 0x2d && b <= 0x2f;\n    if (!(case1 || case2)) {\n      return false;\n    }\n    let index;\n    const bkgData = {};\n    if (a === 0x10 || a === 0x18) {\n      index = Math.floor((b - 0x20) / 2);\n      bkgData.background = backgroundColors[index];\n      if (b % 2 === 1) {\n        bkgData.background = bkgData.background + '_semi';\n      }\n    } else if (b === 0x2d) {\n      bkgData.background = 'transparent';\n    } else {\n      bkgData.foreground = 'black';\n      if (b === 0x2f) {\n        bkgData.underline = true;\n      }\n    }\n    const chNr = a <= 0x17 ? 1 : 2;\n    const channel = this.channels[chNr];\n    channel.setBkgData(bkgData);\n    return true;\n  }\n\n  /**\n   * Reset state of parser and its channels.\n   */\n  reset() {\n    for (let i = 0; i < Object.keys(this.channels).length; i++) {\n      const channel = this.channels[i];\n      if (channel) {\n        channel.reset();\n      }\n    }\n    setLastCmd(null, null, this.cmdHistory);\n  }\n\n  /**\n   * Trigger the generation of a cue, and the start of a new one if displayScreens are not empty.\n   */\n  cueSplitAtTime(t) {\n    for (let i = 0; i < this.channels.length; i++) {\n      const channel = this.channels[i];\n      if (channel) {\n        channel.cueSplitAtTime(t);\n      }\n    }\n  }\n}\nfunction setLastCmd(a, b, cmdHistory) {\n  cmdHistory.a = a;\n  cmdHistory.b = b;\n}\nfunction hasCmdRepeated(a, b, cmdHistory) {\n  return cmdHistory.a === a && cmdHistory.b === b;\n}\nfunction createCmdHistory() {\n  return {\n    a: null,\n    b: null\n  };\n}\n\n/**\n * Copyright 2013 vtt.js Contributors\n *\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nvar VTTCue = (function () {\n  if (optionalSelf != null && optionalSelf.VTTCue) {\n    return self.VTTCue;\n  }\n  const AllowedDirections = ['', 'lr', 'rl'];\n  const AllowedAlignments = ['start', 'middle', 'end', 'left', 'right'];\n  function isAllowedValue(allowed, value) {\n    if (typeof value !== 'string') {\n      return false;\n    }\n    // necessary for assuring the generic conforms to the Array interface\n    if (!Array.isArray(allowed)) {\n      return false;\n    }\n    // reset the type so that the next narrowing works well\n    const lcValue = value.toLowerCase();\n    // use the allow list to narrow the type to a specific subset of strings\n    if (~allowed.indexOf(lcValue)) {\n      return lcValue;\n    }\n    return false;\n  }\n  function findDirectionSetting(value) {\n    return isAllowedValue(AllowedDirections, value);\n  }\n  function findAlignSetting(value) {\n    return isAllowedValue(AllowedAlignments, value);\n  }\n  function extend(obj, ...rest) {\n    let i = 1;\n    for (; i < arguments.length; i++) {\n      const cobj = arguments[i];\n      for (const p in cobj) {\n        obj[p] = cobj[p];\n      }\n    }\n    return obj;\n  }\n  function VTTCue(startTime, endTime, text) {\n    const cue = this;\n    const baseObj = {\n      enumerable: true\n    };\n    /**\n     * Shim implementation specific properties. These properties are not in\n     * the spec.\n     */\n\n    // Lets us know when the VTTCue's data has changed in such a way that we need\n    // to recompute its display state. This lets us compute its display state\n    // lazily.\n    cue.hasBeenReset = false;\n\n    /**\n     * VTTCue and TextTrackCue properties\n     * http://dev.w3.org/html5/webvtt/#vttcue-interface\n     */\n\n    let _id = '';\n    let _pauseOnExit = false;\n    let _startTime = startTime;\n    let _endTime = endTime;\n    let _text = text;\n    let _region = null;\n    let _vertical = '';\n    let _snapToLines = true;\n    let _line = 'auto';\n    let _lineAlign = 'start';\n    let _position = 50;\n    let _positionAlign = 'middle';\n    let _size = 50;\n    let _align = 'middle';\n    Object.defineProperty(cue, 'id', extend({}, baseObj, {\n      get: function () {\n        return _id;\n      },\n      set: function (value) {\n        _id = '' + value;\n      }\n    }));\n    Object.defineProperty(cue, 'pauseOnExit', extend({}, baseObj, {\n      get: function () {\n        return _pauseOnExit;\n      },\n      set: function (value) {\n        _pauseOnExit = !!value;\n      }\n    }));\n    Object.defineProperty(cue, 'startTime', extend({}, baseObj, {\n      get: function () {\n        return _startTime;\n      },\n      set: function (value) {\n        if (typeof value !== 'number') {\n          throw new TypeError('Start time must be set to a number.');\n        }\n        _startTime = value;\n        this.hasBeenReset = true;\n      }\n    }));\n    Object.defineProperty(cue, 'endTime', extend({}, baseObj, {\n      get: function () {\n        return _endTime;\n      },\n      set: function (value) {\n        if (typeof value !== 'number') {\n          throw new TypeError('End time must be set to a number.');\n        }\n        _endTime = value;\n        this.hasBeenReset = true;\n      }\n    }));\n    Object.defineProperty(cue, 'text', extend({}, baseObj, {\n      get: function () {\n        return _text;\n      },\n      set: function (value) {\n        _text = '' + value;\n        this.hasBeenReset = true;\n      }\n    }));\n\n    // todo: implement VTTRegion polyfill?\n    Object.defineProperty(cue, 'region', extend({}, baseObj, {\n      get: function () {\n        return _region;\n      },\n      set: function (value) {\n        _region = value;\n        this.hasBeenReset = true;\n      }\n    }));\n    Object.defineProperty(cue, 'vertical', extend({}, baseObj, {\n      get: function () {\n        return _vertical;\n      },\n      set: function (value) {\n        const setting = findDirectionSetting(value);\n        // Have to check for false because the setting an be an empty string.\n        if (setting === false) {\n          throw new SyntaxError('An invalid or illegal string was specified.');\n        }\n        _vertical = setting;\n        this.hasBeenReset = true;\n      }\n    }));\n    Object.defineProperty(cue, 'snapToLines', extend({}, baseObj, {\n      get: function () {\n        return _snapToLines;\n      },\n      set: function (value) {\n        _snapToLines = !!value;\n        this.hasBeenReset = true;\n      }\n    }));\n    Object.defineProperty(cue, 'line', extend({}, baseObj, {\n      get: function () {\n        return _line;\n      },\n      set: function (value) {\n        if (typeof value !== 'number' && value !== 'auto') {\n          throw new SyntaxError('An invalid number or illegal string was specified.');\n        }\n        _line = value;\n        this.hasBeenReset = true;\n      }\n    }));\n    Object.defineProperty(cue, 'lineAlign', extend({}, baseObj, {\n      get: function () {\n        return _lineAlign;\n      },\n      set: function (value) {\n        const setting = findAlignSetting(value);\n        if (!setting) {\n          throw new SyntaxError('An invalid or illegal string was specified.');\n        }\n        _lineAlign = setting;\n        this.hasBeenReset = true;\n      }\n    }));\n    Object.defineProperty(cue, 'position', extend({}, baseObj, {\n      get: function () {\n        return _position;\n      },\n      set: function (value) {\n        if (value < 0 || value > 100) {\n          throw new Error('Position must be between 0 and 100.');\n        }\n        _position = value;\n        this.hasBeenReset = true;\n      }\n    }));\n    Object.defineProperty(cue, 'positionAlign', extend({}, baseObj, {\n      get: function () {\n        return _positionAlign;\n      },\n      set: function (value) {\n        const setting = findAlignSetting(value);\n        if (!setting) {\n          throw new SyntaxError('An invalid or illegal string was specified.');\n        }\n        _positionAlign = setting;\n        this.hasBeenReset = true;\n      }\n    }));\n    Object.defineProperty(cue, 'size', extend({}, baseObj, {\n      get: function () {\n        return _size;\n      },\n      set: function (value) {\n        if (value < 0 || value > 100) {\n          throw new Error('Size must be between 0 and 100.');\n        }\n        _size = value;\n        this.hasBeenReset = true;\n      }\n    }));\n    Object.defineProperty(cue, 'align', extend({}, baseObj, {\n      get: function () {\n        return _align;\n      },\n      set: function (value) {\n        const setting = findAlignSetting(value);\n        if (!setting) {\n          throw new SyntaxError('An invalid or illegal string was specified.');\n        }\n        _align = setting;\n        this.hasBeenReset = true;\n      }\n    }));\n\n    /**\n     * Other <track> spec defined properties\n     */\n\n    // http://www.whatwg.org/specs/web-apps/current-work/multipage/the-video-element.html#text-track-cue-display-state\n    cue.displayState = undefined;\n  }\n\n  /**\n   * VTTCue methods\n   */\n\n  VTTCue.prototype.getCueAsHTML = function () {\n    // Assume WebVTT.convertCueToDOMTree is on the global.\n    const WebVTT = self.WebVTT;\n    return WebVTT.convertCueToDOMTree(self, this.text);\n  };\n  // this is a polyfill hack\n  return VTTCue;\n})();\n\n/*\n * Source: https://github.com/mozilla/vtt.js/blob/master/dist/vtt.js\n */\n\nclass StringDecoder {\n  decode(data, options) {\n    if (!data) {\n      return '';\n    }\n    if (typeof data !== 'string') {\n      throw new Error('Error - expected string data.');\n    }\n    return decodeURIComponent(encodeURIComponent(data));\n  }\n}\n\n// Try to parse input as a time stamp.\nfunction parseTimeStamp(input) {\n  function computeSeconds(h, m, s, f) {\n    return (h | 0) * 3600 + (m | 0) * 60 + (s | 0) + parseFloat(f || 0);\n  }\n  const m = input.match(/^(?:(\\d+):)?(\\d{2}):(\\d{2})(\\.\\d+)?/);\n  if (!m) {\n    return null;\n  }\n  if (parseFloat(m[2]) > 59) {\n    // Timestamp takes the form of [hours]:[minutes].[milliseconds]\n    // First position is hours as it's over 59.\n    return computeSeconds(m[2], m[3], 0, m[4]);\n  }\n  // Timestamp takes the form of [hours (optional)]:[minutes]:[seconds].[milliseconds]\n  return computeSeconds(m[1], m[2], m[3], m[4]);\n}\n\n// A settings object holds key/value pairs and will ignore anything but the first\n// assignment to a specific key.\nclass Settings {\n  constructor() {\n    this.values = Object.create(null);\n  }\n  // Only accept the first assignment to any key.\n  set(k, v) {\n    if (!this.get(k) && v !== '') {\n      this.values[k] = v;\n    }\n  }\n  // Return the value for a key, or a default value.\n  // If 'defaultKey' is passed then 'dflt' is assumed to be an object with\n  // a number of possible default values as properties where 'defaultKey' is\n  // the key of the property that will be chosen; otherwise it's assumed to be\n  // a single value.\n  get(k, dflt, defaultKey) {\n    if (defaultKey) {\n      return this.has(k) ? this.values[k] : dflt[defaultKey];\n    }\n    return this.has(k) ? this.values[k] : dflt;\n  }\n  // Check whether we have a value for a key.\n  has(k) {\n    return k in this.values;\n  }\n  // Accept a setting if its one of the given alternatives.\n  alt(k, v, a) {\n    for (let n = 0; n < a.length; ++n) {\n      if (v === a[n]) {\n        this.set(k, v);\n        break;\n      }\n    }\n  }\n  // Accept a setting if its a valid (signed) integer.\n  integer(k, v) {\n    if (/^-?\\d+$/.test(v)) {\n      // integer\n      this.set(k, parseInt(v, 10));\n    }\n  }\n  // Accept a setting if its a valid percentage.\n  percent(k, v) {\n    if (/^([\\d]{1,3})(\\.[\\d]*)?%$/.test(v)) {\n      const percent = parseFloat(v);\n      if (percent >= 0 && percent <= 100) {\n        this.set(k, percent);\n        return true;\n      }\n    }\n    return false;\n  }\n}\n\n// Helper function to parse input into groups separated by 'groupDelim', and\n// interpret each group as a key/value pair separated by 'keyValueDelim'.\nfunction parseOptions(input, callback, keyValueDelim, groupDelim) {\n  const groups = groupDelim ? input.split(groupDelim) : [input];\n  for (const i in groups) {\n    if (typeof groups[i] !== 'string') {\n      continue;\n    }\n    const kv = groups[i].split(keyValueDelim);\n    if (kv.length !== 2) {\n      continue;\n    }\n    const k = kv[0];\n    const v = kv[1];\n    callback(k, v);\n  }\n}\nconst defaults = new VTTCue(0, 0, '');\n// 'middle' was changed to 'center' in the spec: https://github.com/w3c/webvtt/pull/244\n//  Safari doesn't yet support this change, but FF and Chrome do.\nconst center = defaults.align === 'middle' ? 'middle' : 'center';\nfunction parseCue(input, cue, regionList) {\n  // Remember the original input if we need to throw an error.\n  const oInput = input;\n  // 4.1 WebVTT timestamp\n  function consumeTimeStamp() {\n    const ts = parseTimeStamp(input);\n    if (ts === null) {\n      throw new Error('Malformed timestamp: ' + oInput);\n    }\n\n    // Remove time stamp from input.\n    input = input.replace(/^[^\\sa-zA-Z-]+/, '');\n    return ts;\n  }\n\n  // 4.4.2 WebVTT cue settings\n  function consumeCueSettings(input, cue) {\n    const settings = new Settings();\n    parseOptions(input, function (k, v) {\n      let vals;\n      switch (k) {\n        case 'region':\n          // Find the last region we parsed with the same region id.\n          for (let i = regionList.length - 1; i >= 0; i--) {\n            if (regionList[i].id === v) {\n              settings.set(k, regionList[i].region);\n              break;\n            }\n          }\n          break;\n        case 'vertical':\n          settings.alt(k, v, ['rl', 'lr']);\n          break;\n        case 'line':\n          vals = v.split(',');\n          settings.integer(k, vals[0]);\n          if (settings.percent(k, vals[0])) {\n            settings.set('snapToLines', false);\n          }\n          settings.alt(k, vals[0], ['auto']);\n          if (vals.length === 2) {\n            settings.alt('lineAlign', vals[1], ['start', center, 'end']);\n          }\n          break;\n        case 'position':\n          vals = v.split(',');\n          settings.percent(k, vals[0]);\n          if (vals.length === 2) {\n            settings.alt('positionAlign', vals[1], ['start', center, 'end', 'line-left', 'line-right', 'auto']);\n          }\n          break;\n        case 'size':\n          settings.percent(k, v);\n          break;\n        case 'align':\n          settings.alt(k, v, ['start', center, 'end', 'left', 'right']);\n          break;\n      }\n    }, /:/, /\\s/);\n\n    // Apply default values for any missing fields.\n    cue.region = settings.get('region', null);\n    cue.vertical = settings.get('vertical', '');\n    let line = settings.get('line', 'auto');\n    if (line === 'auto' && defaults.line === -1) {\n      // set numeric line number for Safari\n      line = -1;\n    }\n    cue.line = line;\n    cue.lineAlign = settings.get('lineAlign', 'start');\n    cue.snapToLines = settings.get('snapToLines', true);\n    cue.size = settings.get('size', 100);\n    cue.align = settings.get('align', center);\n    let position = settings.get('position', 'auto');\n    if (position === 'auto' && defaults.position === 50) {\n      // set numeric position for Safari\n      position = cue.align === 'start' || cue.align === 'left' ? 0 : cue.align === 'end' || cue.align === 'right' ? 100 : 50;\n    }\n    cue.position = position;\n  }\n  function skipWhitespace() {\n    input = input.replace(/^\\s+/, '');\n  }\n\n  // 4.1 WebVTT cue timings.\n  skipWhitespace();\n  cue.startTime = consumeTimeStamp(); // (1) collect cue start time\n  skipWhitespace();\n  if (input.slice(0, 3) !== '-->') {\n    // (3) next characters must match '-->'\n    throw new Error(\"Malformed time stamp (time stamps must be separated by '-->'): \" + oInput);\n  }\n  input = input.slice(3);\n  skipWhitespace();\n  cue.endTime = consumeTimeStamp(); // (5) collect cue end time\n\n  // 4.1 WebVTT cue settings list.\n  skipWhitespace();\n  consumeCueSettings(input, cue);\n}\nfunction fixLineBreaks(input) {\n  return input.replace(/<br(?: \\/)?>/gi, '\\n');\n}\nclass VTTParser {\n  constructor() {\n    this.state = 'INITIAL';\n    this.buffer = '';\n    this.decoder = new StringDecoder();\n    this.regionList = [];\n    this.cue = null;\n    this.oncue = void 0;\n    this.onparsingerror = void 0;\n    this.onflush = void 0;\n  }\n  parse(data) {\n    const _this = this;\n\n    // If there is no data then we won't decode it, but will just try to parse\n    // whatever is in buffer already. This may occur in circumstances, for\n    // example when flush() is called.\n    if (data) {\n      // Try to decode the data that we received.\n      _this.buffer += _this.decoder.decode(data, {\n        stream: true\n      });\n    }\n    function collectNextLine() {\n      let buffer = _this.buffer;\n      let pos = 0;\n      buffer = fixLineBreaks(buffer);\n      while (pos < buffer.length && buffer[pos] !== '\\r' && buffer[pos] !== '\\n') {\n        ++pos;\n      }\n      const line = buffer.slice(0, pos);\n      // Advance the buffer early in case we fail below.\n      if (buffer[pos] === '\\r') {\n        ++pos;\n      }\n      if (buffer[pos] === '\\n') {\n        ++pos;\n      }\n      _this.buffer = buffer.slice(pos);\n      return line;\n    }\n\n    // 3.2 WebVTT metadata header syntax\n    function parseHeader(input) {\n      parseOptions(input, function (k, v) {\n        // switch (k) {\n        // case 'region':\n        // 3.3 WebVTT region metadata header syntax\n        // console.log('parse region', v);\n        // parseRegion(v);\n        // break;\n        // }\n      }, /:/);\n    }\n\n    // 5.1 WebVTT file parsing.\n    try {\n      let line = '';\n      if (_this.state === 'INITIAL') {\n        // We can't start parsing until we have the first line.\n        if (!/\\r\\n|\\n/.test(_this.buffer)) {\n          return this;\n        }\n        line = collectNextLine();\n        // strip of UTF-8 BOM if any\n        // https://en.wikipedia.org/wiki/Byte_order_mark#UTF-8\n        const m = line.match(/^()?WEBVTT([ \\t].*)?$/);\n        if (!(m != null && m[0])) {\n          throw new Error('Malformed WebVTT signature.');\n        }\n        _this.state = 'HEADER';\n      }\n      let alreadyCollectedLine = false;\n      while (_this.buffer) {\n        // We can't parse a line until we have the full line.\n        if (!/\\r\\n|\\n/.test(_this.buffer)) {\n          return this;\n        }\n        if (!alreadyCollectedLine) {\n          line = collectNextLine();\n        } else {\n          alreadyCollectedLine = false;\n        }\n        switch (_this.state) {\n          case 'HEADER':\n            // 13-18 - Allow a header (metadata) under the WEBVTT line.\n            if (/:/.test(line)) {\n              parseHeader(line);\n            } else if (!line) {\n              // An empty line terminates the header and starts the body (cues).\n              _this.state = 'ID';\n            }\n            continue;\n          case 'NOTE':\n            // Ignore NOTE blocks.\n            if (!line) {\n              _this.state = 'ID';\n            }\n            continue;\n          case 'ID':\n            // Check for the start of NOTE blocks.\n            if (/^NOTE($|[ \\t])/.test(line)) {\n              _this.state = 'NOTE';\n              break;\n            }\n            // 19-29 - Allow any number of line terminators, then initialize new cue values.\n            if (!line) {\n              continue;\n            }\n            _this.cue = new VTTCue(0, 0, '');\n            _this.state = 'CUE';\n            // 30-39 - Check if self line contains an optional identifier or timing data.\n            if (line.indexOf('-->') === -1) {\n              _this.cue.id = line;\n              continue;\n            }\n          // Process line as start of a cue.\n          /* falls through */\n          case 'CUE':\n            // 40 - Collect cue timings and settings.\n            if (!_this.cue) {\n              _this.state = 'BADCUE';\n              continue;\n            }\n            try {\n              parseCue(line, _this.cue, _this.regionList);\n            } catch (e) {\n              // In case of an error ignore rest of the cue.\n              _this.cue = null;\n              _this.state = 'BADCUE';\n              continue;\n            }\n            _this.state = 'CUETEXT';\n            continue;\n          case 'CUETEXT':\n            {\n              const hasSubstring = line.indexOf('-->') !== -1;\n              // 34 - If we have an empty line then report the cue.\n              // 35 - If we have the special substring '-->' then report the cue,\n              // but do not collect the line as we need to process the current\n              // one as a new cue.\n              if (!line || hasSubstring && (alreadyCollectedLine = true)) {\n                // We are done parsing self cue.\n                if (_this.oncue && _this.cue) {\n                  _this.oncue(_this.cue);\n                }\n                _this.cue = null;\n                _this.state = 'ID';\n                continue;\n              }\n              if (_this.cue === null) {\n                continue;\n              }\n              if (_this.cue.text) {\n                _this.cue.text += '\\n';\n              }\n              _this.cue.text += line;\n            }\n            continue;\n          case 'BADCUE':\n            // 54-62 - Collect and discard the remaining cue.\n            if (!line) {\n              _this.state = 'ID';\n            }\n        }\n      }\n    } catch (e) {\n      // If we are currently parsing a cue, report what we have.\n      if (_this.state === 'CUETEXT' && _this.cue && _this.oncue) {\n        _this.oncue(_this.cue);\n      }\n      _this.cue = null;\n      // Enter BADWEBVTT state if header was not parsed correctly otherwise\n      // another exception occurred so enter BADCUE state.\n      _this.state = _this.state === 'INITIAL' ? 'BADWEBVTT' : 'BADCUE';\n    }\n    return this;\n  }\n  flush() {\n    const _this = this;\n    try {\n      // Finish decoding the stream.\n      // _this.buffer += _this.decoder.decode();\n      // Synthesize the end of the current cue or region.\n      if (_this.cue || _this.state === 'HEADER') {\n        _this.buffer += '\\n\\n';\n        _this.parse();\n      }\n      // If we've flushed, parsed, and we're still on the INITIAL state then\n      // that means we don't have enough of the stream to parse the first\n      // line.\n      if (_this.state === 'INITIAL' || _this.state === 'BADWEBVTT') {\n        throw new Error('Malformed WebVTT signature.');\n      }\n    } catch (e) {\n      if (_this.onparsingerror) {\n        _this.onparsingerror(e);\n      }\n    }\n    if (_this.onflush) {\n      _this.onflush();\n    }\n    return this;\n  }\n}\n\nconst LINEBREAKS = /\\r\\n|\\n\\r|\\n|\\r/g;\n\n// String.prototype.startsWith is not supported in IE11\nconst startsWith = function startsWith(inputString, searchString, position = 0) {\n  return inputString.slice(position, position + searchString.length) === searchString;\n};\nconst cueString2millis = function cueString2millis(timeString) {\n  let ts = parseInt(timeString.slice(-3));\n  const secs = parseInt(timeString.slice(-6, -4));\n  const mins = parseInt(timeString.slice(-9, -7));\n  const hours = timeString.length > 9 ? parseInt(timeString.substring(0, timeString.indexOf(':'))) : 0;\n  if (!isFiniteNumber(ts) || !isFiniteNumber(secs) || !isFiniteNumber(mins) || !isFiniteNumber(hours)) {\n    throw Error(`Malformed X-TIMESTAMP-MAP: Local:${timeString}`);\n  }\n  ts += 1000 * secs;\n  ts += 60 * 1000 * mins;\n  ts += 60 * 60 * 1000 * hours;\n  return ts;\n};\n\n// Create a unique hash id for a cue based on start/end times and text.\n// This helps timeline-controller to avoid showing repeated captions.\nfunction generateCueId(startTime, endTime, text) {\n  return hash(startTime.toString()) + hash(endTime.toString()) + hash(text);\n}\nconst calculateOffset = function calculateOffset(vttCCs, cc, presentationTime) {\n  let currCC = vttCCs[cc];\n  let prevCC = vttCCs[currCC.prevCC];\n\n  // This is the first discontinuity or cues have been processed since the last discontinuity\n  // Offset = current discontinuity time\n  if (!prevCC || !prevCC.new && currCC.new) {\n    vttCCs.ccOffset = vttCCs.presentationOffset = currCC.start;\n    currCC.new = false;\n    return;\n  }\n\n  // There have been discontinuities since cues were last parsed.\n  // Offset = time elapsed\n  while ((_prevCC = prevCC) != null && _prevCC.new) {\n    var _prevCC;\n    vttCCs.ccOffset += currCC.start - prevCC.start;\n    currCC.new = false;\n    currCC = prevCC;\n    prevCC = vttCCs[currCC.prevCC];\n  }\n  vttCCs.presentationOffset = presentationTime;\n};\nfunction parseWebVTT(vttByteArray, initPTS, vttCCs, cc, timeOffset, callBack, errorCallBack) {\n  const parser = new VTTParser();\n  // Convert byteArray into string, replacing any somewhat exotic linefeeds with \"\\n\", then split on that character.\n  // Uint8Array.prototype.reduce is not implemented in IE11\n  const vttLines = utf8ArrayToStr(new Uint8Array(vttByteArray)).trim().replace(LINEBREAKS, '\\n').split('\\n');\n  const cues = [];\n  const init90kHz = initPTS ? toMpegTsClockFromTimescale(initPTS.baseTime, initPTS.timescale) : 0;\n  let cueTime = '00:00.000';\n  let timestampMapMPEGTS = 0;\n  let timestampMapLOCAL = 0;\n  let parsingError;\n  let inHeader = true;\n  parser.oncue = function (cue) {\n    // Adjust cue timing; clamp cues to start no earlier than - and drop cues that don't end after - 0 on timeline.\n    const currCC = vttCCs[cc];\n    let cueOffset = vttCCs.ccOffset;\n\n    // Calculate subtitle PTS offset\n    const webVttMpegTsMapOffset = (timestampMapMPEGTS - init90kHz) / 90000;\n\n    // Update offsets for new discontinuities\n    if (currCC != null && currCC.new) {\n      if (timestampMapLOCAL !== undefined) {\n        // When local time is provided, offset = discontinuity start time - local time\n        cueOffset = vttCCs.ccOffset = currCC.start;\n      } else {\n        calculateOffset(vttCCs, cc, webVttMpegTsMapOffset);\n      }\n    }\n    if (webVttMpegTsMapOffset) {\n      if (!initPTS) {\n        parsingError = new Error('Missing initPTS for VTT MPEGTS');\n        return;\n      }\n      // If we have MPEGTS, offset = presentation time + discontinuity offset\n      cueOffset = webVttMpegTsMapOffset - vttCCs.presentationOffset;\n    }\n    const duration = cue.endTime - cue.startTime;\n    const startTime = normalizePts((cue.startTime + cueOffset - timestampMapLOCAL) * 90000, timeOffset * 90000) / 90000;\n    cue.startTime = Math.max(startTime, 0);\n    cue.endTime = Math.max(startTime + duration, 0);\n\n    //trim trailing webvtt block whitespaces\n    const text = cue.text.trim();\n\n    // Fix encoding of special characters\n    cue.text = decodeURIComponent(encodeURIComponent(text));\n\n    // If the cue was not assigned an id from the VTT file (line above the content), create one.\n    if (!cue.id) {\n      cue.id = generateCueId(cue.startTime, cue.endTime, text);\n    }\n    if (cue.endTime > 0) {\n      cues.push(cue);\n    }\n  };\n  parser.onparsingerror = function (error) {\n    parsingError = error;\n  };\n  parser.onflush = function () {\n    if (parsingError) {\n      errorCallBack(parsingError);\n      return;\n    }\n    callBack(cues);\n  };\n\n  // Go through contents line by line.\n  vttLines.forEach(line => {\n    if (inHeader) {\n      // Look for X-TIMESTAMP-MAP in header.\n      if (startsWith(line, 'X-TIMESTAMP-MAP=')) {\n        // Once found, no more are allowed anyway, so stop searching.\n        inHeader = false;\n        // Extract LOCAL and MPEGTS.\n        line.slice(16).split(',').forEach(timestamp => {\n          if (startsWith(timestamp, 'LOCAL:')) {\n            cueTime = timestamp.slice(6);\n          } else if (startsWith(timestamp, 'MPEGTS:')) {\n            timestampMapMPEGTS = parseInt(timestamp.slice(7));\n          }\n        });\n        try {\n          // Convert cue time to seconds\n          timestampMapLOCAL = cueString2millis(cueTime) / 1000;\n        } catch (error) {\n          parsingError = error;\n        }\n        // Return without parsing X-TIMESTAMP-MAP line.\n        return;\n      } else if (line === '') {\n        inHeader = false;\n      }\n    }\n    // Parse line by default.\n    parser.parse(line + '\\n');\n  });\n  parser.flush();\n}\n\nconst IMSC1_CODEC = 'stpp.ttml.im1t';\n\n// Time format: h:m:s:frames(.subframes)\nconst HMSF_REGEX = /^(\\d{2,}):(\\d{2}):(\\d{2}):(\\d{2})\\.?(\\d+)?$/;\n\n// Time format: hours, minutes, seconds, milliseconds, frames, ticks\nconst TIME_UNIT_REGEX = /^(\\d*(?:\\.\\d*)?)(h|m|s|ms|f|t)$/;\nconst textAlignToLineAlign = {\n  left: 'start',\n  center: 'center',\n  right: 'end',\n  start: 'start',\n  end: 'end'\n};\nfunction parseIMSC1(payload, initPTS, callBack, errorCallBack) {\n  const results = findBox(new Uint8Array(payload), ['mdat']);\n  if (results.length === 0) {\n    errorCallBack(new Error('Could not parse IMSC1 mdat'));\n    return;\n  }\n  const ttmlList = results.map(mdat => utf8ArrayToStr(mdat));\n  const syncTime = toTimescaleFromScale(initPTS.baseTime, 1, initPTS.timescale);\n  try {\n    ttmlList.forEach(ttml => callBack(parseTTML(ttml, syncTime)));\n  } catch (error) {\n    errorCallBack(error);\n  }\n}\nfunction parseTTML(ttml, syncTime) {\n  const parser = new DOMParser();\n  const xmlDoc = parser.parseFromString(ttml, 'text/xml');\n  const tt = xmlDoc.getElementsByTagName('tt')[0];\n  if (!tt) {\n    throw new Error('Invalid ttml');\n  }\n  const defaultRateInfo = {\n    frameRate: 30,\n    subFrameRate: 1,\n    frameRateMultiplier: 0,\n    tickRate: 0\n  };\n  const rateInfo = Object.keys(defaultRateInfo).reduce((result, key) => {\n    result[key] = tt.getAttribute(`ttp:${key}`) || defaultRateInfo[key];\n    return result;\n  }, {});\n  const trim = tt.getAttribute('xml:space') !== 'preserve';\n  const styleElements = collectionToDictionary(getElementCollection(tt, 'styling', 'style'));\n  const regionElements = collectionToDictionary(getElementCollection(tt, 'layout', 'region'));\n  const cueElements = getElementCollection(tt, 'body', '[begin]');\n  return [].map.call(cueElements, cueElement => {\n    const cueText = getTextContent(cueElement, trim);\n    if (!cueText || !cueElement.hasAttribute('begin')) {\n      return null;\n    }\n    const startTime = parseTtmlTime(cueElement.getAttribute('begin'), rateInfo);\n    const duration = parseTtmlTime(cueElement.getAttribute('dur'), rateInfo);\n    let endTime = parseTtmlTime(cueElement.getAttribute('end'), rateInfo);\n    if (startTime === null) {\n      throw timestampParsingError(cueElement);\n    }\n    if (endTime === null) {\n      if (duration === null) {\n        throw timestampParsingError(cueElement);\n      }\n      endTime = startTime + duration;\n    }\n    const cue = new VTTCue(startTime - syncTime, endTime - syncTime, cueText);\n    cue.id = generateCueId(cue.startTime, cue.endTime, cue.text);\n    const region = regionElements[cueElement.getAttribute('region')];\n    const style = styleElements[cueElement.getAttribute('style')];\n\n    // Apply styles to cue\n    const styles = getTtmlStyles(region, style, styleElements);\n    const {\n      textAlign\n    } = styles;\n    if (textAlign) {\n      // cue.positionAlign not settable in FF~2016\n      const lineAlign = textAlignToLineAlign[textAlign];\n      if (lineAlign) {\n        cue.lineAlign = lineAlign;\n      }\n      cue.align = textAlign;\n    }\n    _extends(cue, styles);\n    return cue;\n  }).filter(cue => cue !== null);\n}\nfunction getElementCollection(fromElement, parentName, childName) {\n  const parent = fromElement.getElementsByTagName(parentName)[0];\n  if (parent) {\n    return [].slice.call(parent.querySelectorAll(childName));\n  }\n  return [];\n}\nfunction collectionToDictionary(elementsWithId) {\n  return elementsWithId.reduce((dict, element) => {\n    const id = element.getAttribute('xml:id');\n    if (id) {\n      dict[id] = element;\n    }\n    return dict;\n  }, {});\n}\nfunction getTextContent(element, trim) {\n  return [].slice.call(element.childNodes).reduce((str, node, i) => {\n    var _node$childNodes;\n    if (node.nodeName === 'br' && i) {\n      return str + '\\n';\n    }\n    if ((_node$childNodes = node.childNodes) != null && _node$childNodes.length) {\n      return getTextContent(node, trim);\n    } else if (trim) {\n      return str + node.textContent.trim().replace(/\\s+/g, ' ');\n    }\n    return str + node.textContent;\n  }, '');\n}\nfunction getTtmlStyles(region, style, styleElements) {\n  const ttsNs = 'http://www.w3.org/ns/ttml#styling';\n  let regionStyle = null;\n  const styleAttributes = ['displayAlign', 'textAlign', 'color', 'backgroundColor', 'fontSize', 'fontFamily'\n  // 'fontWeight',\n  // 'lineHeight',\n  // 'wrapOption',\n  // 'fontStyle',\n  // 'direction',\n  // 'writingMode'\n  ];\n  const regionStyleName = region != null && region.hasAttribute('style') ? region.getAttribute('style') : null;\n  if (regionStyleName && styleElements.hasOwnProperty(regionStyleName)) {\n    regionStyle = styleElements[regionStyleName];\n  }\n  return styleAttributes.reduce((styles, name) => {\n    const value = getAttributeNS(style, ttsNs, name) || getAttributeNS(region, ttsNs, name) || getAttributeNS(regionStyle, ttsNs, name);\n    if (value) {\n      styles[name] = value;\n    }\n    return styles;\n  }, {});\n}\nfunction getAttributeNS(element, ns, name) {\n  if (!element) {\n    return null;\n  }\n  return element.hasAttributeNS(ns, name) ? element.getAttributeNS(ns, name) : null;\n}\nfunction timestampParsingError(node) {\n  return new Error(`Could not parse ttml timestamp ${node}`);\n}\nfunction parseTtmlTime(timeAttributeValue, rateInfo) {\n  if (!timeAttributeValue) {\n    return null;\n  }\n  let seconds = parseTimeStamp(timeAttributeValue);\n  if (seconds === null) {\n    if (HMSF_REGEX.test(timeAttributeValue)) {\n      seconds = parseHoursMinutesSecondsFrames(timeAttributeValue, rateInfo);\n    } else if (TIME_UNIT_REGEX.test(timeAttributeValue)) {\n      seconds = parseTimeUnits(timeAttributeValue, rateInfo);\n    }\n  }\n  return seconds;\n}\nfunction parseHoursMinutesSecondsFrames(timeAttributeValue, rateInfo) {\n  const m = HMSF_REGEX.exec(timeAttributeValue);\n  const frames = (m[4] | 0) + (m[5] | 0) / rateInfo.subFrameRate;\n  return (m[1] | 0) * 3600 + (m[2] | 0) * 60 + (m[3] | 0) + frames / rateInfo.frameRate;\n}\nfunction parseTimeUnits(timeAttributeValue, rateInfo) {\n  const m = TIME_UNIT_REGEX.exec(timeAttributeValue);\n  const value = Number(m[1]);\n  const unit = m[2];\n  switch (unit) {\n    case 'h':\n      return value * 3600;\n    case 'm':\n      return value * 60;\n    case 'ms':\n      return value * 1000;\n    case 'f':\n      return value / rateInfo.frameRate;\n    case 't':\n      return value / rateInfo.tickRate;\n  }\n  return value;\n}\n\nclass OutputFilter {\n  constructor(timelineController, trackName) {\n    this.timelineController = void 0;\n    this.cueRanges = [];\n    this.trackName = void 0;\n    this.startTime = null;\n    this.endTime = null;\n    this.screen = null;\n    this.timelineController = timelineController;\n    this.trackName = trackName;\n  }\n  dispatchCue() {\n    if (this.startTime === null) {\n      return;\n    }\n    this.timelineController.addCues(this.trackName, this.startTime, this.endTime, this.screen, this.cueRanges);\n    this.startTime = null;\n  }\n  newCue(startTime, endTime, screen) {\n    if (this.startTime === null || this.startTime > startTime) {\n      this.startTime = startTime;\n    }\n    this.endTime = endTime;\n    this.screen = screen;\n    this.timelineController.createCaptionsTrack(this.trackName);\n  }\n  reset() {\n    this.cueRanges = [];\n    this.startTime = null;\n  }\n}\n\nclass TimelineController {\n  constructor(hls) {\n    this.hls = void 0;\n    this.media = null;\n    this.config = void 0;\n    this.enabled = true;\n    this.Cues = void 0;\n    this.textTracks = [];\n    this.tracks = [];\n    this.initPTS = [];\n    this.unparsedVttFrags = [];\n    this.captionsTracks = {};\n    this.nonNativeCaptionsTracks = {};\n    this.cea608Parser1 = void 0;\n    this.cea608Parser2 = void 0;\n    this.lastCc = -1;\n    // Last video (CEA-608) fragment CC\n    this.lastSn = -1;\n    // Last video (CEA-608) fragment MSN\n    this.lastPartIndex = -1;\n    // Last video (CEA-608) fragment Part Index\n    this.prevCC = -1;\n    // Last subtitle fragment CC\n    this.vttCCs = newVTTCCs();\n    this.captionsProperties = void 0;\n    this.hls = hls;\n    this.config = hls.config;\n    this.Cues = hls.config.cueHandler;\n    this.captionsProperties = {\n      textTrack1: {\n        label: this.config.captionsTextTrack1Label,\n        languageCode: this.config.captionsTextTrack1LanguageCode\n      },\n      textTrack2: {\n        label: this.config.captionsTextTrack2Label,\n        languageCode: this.config.captionsTextTrack2LanguageCode\n      },\n      textTrack3: {\n        label: this.config.captionsTextTrack3Label,\n        languageCode: this.config.captionsTextTrack3LanguageCode\n      },\n      textTrack4: {\n        label: this.config.captionsTextTrack4Label,\n        languageCode: this.config.captionsTextTrack4LanguageCode\n      }\n    };\n    hls.on(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);\n    hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.on(Events.MANIFEST_LOADED, this.onManifestLoaded, this);\n    hls.on(Events.SUBTITLE_TRACKS_UPDATED, this.onSubtitleTracksUpdated, this);\n    hls.on(Events.FRAG_LOADING, this.onFragLoading, this);\n    hls.on(Events.FRAG_LOADED, this.onFragLoaded, this);\n    hls.on(Events.FRAG_PARSING_USERDATA, this.onFragParsingUserdata, this);\n    hls.on(Events.FRAG_DECRYPTED, this.onFragDecrypted, this);\n    hls.on(Events.INIT_PTS_FOUND, this.onInitPtsFound, this);\n    hls.on(Events.SUBTITLE_TRACKS_CLEARED, this.onSubtitleTracksCleared, this);\n    hls.on(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);\n  }\n  destroy() {\n    const {\n      hls\n    } = this;\n    hls.off(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);\n    hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.off(Events.MANIFEST_LOADED, this.onManifestLoaded, this);\n    hls.off(Events.SUBTITLE_TRACKS_UPDATED, this.onSubtitleTracksUpdated, this);\n    hls.off(Events.FRAG_LOADING, this.onFragLoading, this);\n    hls.off(Events.FRAG_LOADED, this.onFragLoaded, this);\n    hls.off(Events.FRAG_PARSING_USERDATA, this.onFragParsingUserdata, this);\n    hls.off(Events.FRAG_DECRYPTED, this.onFragDecrypted, this);\n    hls.off(Events.INIT_PTS_FOUND, this.onInitPtsFound, this);\n    hls.off(Events.SUBTITLE_TRACKS_CLEARED, this.onSubtitleTracksCleared, this);\n    hls.off(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);\n    // @ts-ignore\n    this.hls = this.config = this.media = null;\n    this.cea608Parser1 = this.cea608Parser2 = undefined;\n  }\n  initCea608Parsers() {\n    const channel1 = new OutputFilter(this, 'textTrack1');\n    const channel2 = new OutputFilter(this, 'textTrack2');\n    const channel3 = new OutputFilter(this, 'textTrack3');\n    const channel4 = new OutputFilter(this, 'textTrack4');\n    this.cea608Parser1 = new Cea608Parser(1, channel1, channel2);\n    this.cea608Parser2 = new Cea608Parser(3, channel3, channel4);\n  }\n  addCues(trackName, startTime, endTime, screen, cueRanges) {\n    // skip cues which overlap more than 50% with previously parsed time ranges\n    let merged = false;\n    for (let i = cueRanges.length; i--;) {\n      const cueRange = cueRanges[i];\n      const overlap = intersection(cueRange[0], cueRange[1], startTime, endTime);\n      if (overlap >= 0) {\n        cueRange[0] = Math.min(cueRange[0], startTime);\n        cueRange[1] = Math.max(cueRange[1], endTime);\n        merged = true;\n        if (overlap / (endTime - startTime) > 0.5) {\n          return;\n        }\n      }\n    }\n    if (!merged) {\n      cueRanges.push([startTime, endTime]);\n    }\n    if (this.config.renderTextTracksNatively) {\n      const track = this.captionsTracks[trackName];\n      this.Cues.newCue(track, startTime, endTime, screen);\n    } else {\n      const cues = this.Cues.newCue(null, startTime, endTime, screen);\n      this.hls.trigger(Events.CUES_PARSED, {\n        type: 'captions',\n        cues,\n        track: trackName\n      });\n    }\n  }\n\n  // Triggered when an initial PTS is found; used for synchronisation of WebVTT.\n  onInitPtsFound(event, {\n    frag,\n    id,\n    initPTS,\n    timescale,\n    trackId\n  }) {\n    const {\n      unparsedVttFrags\n    } = this;\n    if (id === PlaylistLevelType.MAIN) {\n      this.initPTS[frag.cc] = {\n        baseTime: initPTS,\n        timescale,\n        trackId\n      };\n    }\n\n    // Due to asynchronous processing, initial PTS may arrive later than the first VTT fragments are loaded.\n    // Parse any unparsed fragments upon receiving the initial PTS.\n    if (unparsedVttFrags.length) {\n      this.unparsedVttFrags = [];\n      unparsedVttFrags.forEach(data => {\n        if (this.initPTS[data.frag.cc]) {\n          this.onFragLoaded(Events.FRAG_LOADED, data);\n        } else {\n          this.hls.trigger(Events.SUBTITLE_FRAG_PROCESSED, {\n            success: false,\n            frag: data.frag,\n            error: new Error('Subtitle discontinuity domain does not match main')\n          });\n        }\n      });\n    }\n  }\n  getExistingTrack(label, language) {\n    const {\n      media\n    } = this;\n    if (media) {\n      for (let i = 0; i < media.textTracks.length; i++) {\n        const textTrack = media.textTracks[i];\n        if (canReuseVttTextTrack(textTrack, {\n          name: label,\n          lang: language,\n          characteristics: 'transcribes-spoken-dialog,describes-music-and-sound'})) {\n          return textTrack;\n        }\n      }\n    }\n    return null;\n  }\n  createCaptionsTrack(trackName) {\n    if (this.config.renderTextTracksNatively) {\n      this.createNativeTrack(trackName);\n    } else {\n      this.createNonNativeTrack(trackName);\n    }\n  }\n  createNativeTrack(trackName) {\n    if (this.captionsTracks[trackName]) {\n      return;\n    }\n    const {\n      captionsProperties,\n      captionsTracks,\n      media\n    } = this;\n    const {\n      label,\n      languageCode\n    } = captionsProperties[trackName];\n    // Enable reuse of existing text track.\n    const existingTrack = this.getExistingTrack(label, languageCode);\n    if (!existingTrack) {\n      const textTrack = this.createTextTrack('captions', label, languageCode);\n      if (textTrack) {\n        // Set a special property on the track so we know it's managed by Hls.js\n        textTrack[trackName] = true;\n        captionsTracks[trackName] = textTrack;\n      }\n    } else {\n      captionsTracks[trackName] = existingTrack;\n      clearCurrentCues(captionsTracks[trackName]);\n      sendAddTrackEvent(captionsTracks[trackName], media);\n    }\n  }\n  createNonNativeTrack(trackName) {\n    if (this.nonNativeCaptionsTracks[trackName]) {\n      return;\n    }\n    // Create a list of a single track for the provider to consume\n    const trackProperties = this.captionsProperties[trackName];\n    if (!trackProperties) {\n      return;\n    }\n    const label = trackProperties.label;\n    const track = {\n      _id: trackName,\n      label,\n      kind: 'captions',\n      default: trackProperties.media ? !!trackProperties.media.default : false,\n      closedCaptions: trackProperties.media\n    };\n    this.nonNativeCaptionsTracks[trackName] = track;\n    this.hls.trigger(Events.NON_NATIVE_TEXT_TRACKS_FOUND, {\n      tracks: [track]\n    });\n  }\n  createTextTrack(kind, label, lang) {\n    const media = this.media;\n    if (!media) {\n      return;\n    }\n    return media.addTextTrack(kind, label, lang);\n  }\n  onMediaAttaching(event, data) {\n    this.media = data.media;\n    if (!data.mediaSource) {\n      this._cleanTracks();\n    }\n  }\n  onMediaDetaching(event, data) {\n    const transferringMedia = !!data.transferMedia;\n    this.media = null;\n    if (transferringMedia) {\n      return;\n    }\n    const {\n      captionsTracks\n    } = this;\n    Object.keys(captionsTracks).forEach(trackName => {\n      clearCurrentCues(captionsTracks[trackName]);\n      delete captionsTracks[trackName];\n    });\n    this.nonNativeCaptionsTracks = {};\n  }\n  onManifestLoading() {\n    // Detect discontinuity in video fragment (CEA-608) parsing\n    this.lastCc = -1;\n    this.lastSn = -1;\n    this.lastPartIndex = -1;\n    // Detect discontinuity in subtitle manifests\n    this.prevCC = -1;\n    this.vttCCs = newVTTCCs();\n    // Reset tracks\n    this._cleanTracks();\n    this.tracks = [];\n    this.captionsTracks = {};\n    this.nonNativeCaptionsTracks = {};\n    this.textTracks = [];\n    this.unparsedVttFrags = [];\n    this.initPTS = [];\n    if (this.cea608Parser1 && this.cea608Parser2) {\n      this.cea608Parser1.reset();\n      this.cea608Parser2.reset();\n    }\n  }\n  _cleanTracks() {\n    // clear outdated subtitles\n    const {\n      media\n    } = this;\n    if (!media) {\n      return;\n    }\n    const textTracks = media.textTracks;\n    if (textTracks) {\n      for (let i = 0; i < textTracks.length; i++) {\n        clearCurrentCues(textTracks[i]);\n      }\n    }\n  }\n  onSubtitleTracksUpdated(event, data) {\n    const tracks = data.subtitleTracks || [];\n    const hasIMSC1 = tracks.some(track => track.textCodec === IMSC1_CODEC);\n    if (this.config.enableWebVTT || hasIMSC1 && this.config.enableIMSC1) {\n      const listIsIdentical = subtitleOptionsIdentical(this.tracks, tracks);\n      if (listIsIdentical) {\n        this.tracks = tracks;\n        return;\n      }\n      this.textTracks = [];\n      this.tracks = tracks;\n      if (this.config.renderTextTracksNatively) {\n        const media = this.media;\n        const inUseTracks = media ? filterSubtitleTracks(media.textTracks) : null;\n        this.tracks.forEach((track, index) => {\n          // Reuse tracks with the same label and lang, but do not reuse 608/708 tracks\n          let textTrack;\n          if (inUseTracks) {\n            let inUseTrack = null;\n            for (let i = 0; i < inUseTracks.length; i++) {\n              if (inUseTracks[i] && canReuseVttTextTrack(inUseTracks[i], track)) {\n                inUseTrack = inUseTracks[i];\n                inUseTracks[i] = null;\n                break;\n              }\n            }\n            if (inUseTrack) {\n              textTrack = inUseTrack;\n            }\n          }\n          if (textTrack) {\n            clearCurrentCues(textTrack);\n          } else {\n            const textTrackKind = captionsOrSubtitlesFromCharacteristics(track);\n            textTrack = this.createTextTrack(textTrackKind, track.name, track.lang);\n            if (textTrack) {\n              textTrack.mode = 'disabled';\n            }\n          }\n          if (textTrack) {\n            this.textTracks.push(textTrack);\n          }\n        });\n        // Warn when video element has captions or subtitle TextTracks carried over from another source\n        if (inUseTracks != null && inUseTracks.length) {\n          const unusedTextTracks = inUseTracks.filter(t => t !== null).map(t => t.label);\n          if (unusedTextTracks.length) {\n            this.hls.logger.warn(`Media element contains unused subtitle tracks: ${unusedTextTracks.join(', ')}. Replace media element for each source to clear TextTracks and captions menu.`);\n          }\n        }\n      } else if (this.tracks.length) {\n        // Create a list of tracks for the provider to consume\n        const tracksList = this.tracks.map(track => {\n          return {\n            label: track.name,\n            kind: track.type.toLowerCase(),\n            default: track.default,\n            subtitleTrack: track\n          };\n        });\n        this.hls.trigger(Events.NON_NATIVE_TEXT_TRACKS_FOUND, {\n          tracks: tracksList\n        });\n      }\n    }\n  }\n  onManifestLoaded(event, data) {\n    if (this.config.enableCEA708Captions && data.captions) {\n      data.captions.forEach(captionsTrack => {\n        const instreamIdMatch = /(?:CC|SERVICE)([1-4])/.exec(captionsTrack.instreamId);\n        if (!instreamIdMatch) {\n          return;\n        }\n        const trackName = `textTrack${instreamIdMatch[1]}`;\n        const trackProperties = this.captionsProperties[trackName];\n        if (!trackProperties) {\n          return;\n        }\n        trackProperties.label = captionsTrack.name;\n        if (captionsTrack.lang) {\n          // optional attribute\n          trackProperties.languageCode = captionsTrack.lang;\n        }\n        trackProperties.media = captionsTrack;\n      });\n    }\n  }\n  closedCaptionsForLevel(frag) {\n    const level = this.hls.levels[frag.level];\n    return level == null ? void 0 : level.attrs['CLOSED-CAPTIONS'];\n  }\n  onFragLoading(event, data) {\n    // if this frag isn't contiguous, clear the parser so cues with bad start/end times aren't added to the textTrack\n    if (this.enabled && data.frag.type === PlaylistLevelType.MAIN) {\n      var _data$part$index, _data$part;\n      const {\n        cea608Parser1,\n        cea608Parser2,\n        lastSn\n      } = this;\n      const {\n        cc,\n        sn\n      } = data.frag;\n      const partIndex = (_data$part$index = (_data$part = data.part) == null ? void 0 : _data$part.index) != null ? _data$part$index : -1;\n      if (cea608Parser1 && cea608Parser2) {\n        if (sn !== lastSn + 1 || sn === lastSn && partIndex !== this.lastPartIndex + 1 || cc !== this.lastCc) {\n          cea608Parser1.reset();\n          cea608Parser2.reset();\n        }\n      }\n      this.lastCc = cc;\n      this.lastSn = sn;\n      this.lastPartIndex = partIndex;\n    }\n  }\n  onFragLoaded(event, data) {\n    const {\n      frag,\n      payload\n    } = data;\n    if (frag.type === PlaylistLevelType.SUBTITLE) {\n      // If fragment is subtitle type, parse as WebVTT.\n      if (payload.byteLength) {\n        const decryptData = frag.decryptdata;\n        // fragment after decryption has a stats object\n        const decrypted = 'stats' in data;\n        // If the subtitles are not encrypted, parse VTTs now. Otherwise, we need to wait.\n        if (decryptData == null || !decryptData.encrypted || decrypted) {\n          const trackPlaylistMedia = this.tracks[frag.level];\n          const vttCCs = this.vttCCs;\n          if (!vttCCs[frag.cc]) {\n            vttCCs[frag.cc] = {\n              start: frag.start,\n              prevCC: this.prevCC,\n              new: true\n            };\n            this.prevCC = frag.cc;\n          }\n          if (trackPlaylistMedia && trackPlaylistMedia.textCodec === IMSC1_CODEC) {\n            this._parseIMSC1(frag, payload);\n          } else {\n            this._parseVTTs(data);\n          }\n        }\n      } else {\n        // In case there is no payload, finish unsuccessfully.\n        this.hls.trigger(Events.SUBTITLE_FRAG_PROCESSED, {\n          success: false,\n          frag,\n          error: new Error('Empty subtitle payload')\n        });\n      }\n    }\n  }\n  _parseIMSC1(frag, payload) {\n    const hls = this.hls;\n    parseIMSC1(payload, this.initPTS[frag.cc], cues => {\n      this._appendCues(cues, frag.level);\n      hls.trigger(Events.SUBTITLE_FRAG_PROCESSED, {\n        success: true,\n        frag: frag\n      });\n    }, error => {\n      hls.logger.log(`Failed to parse IMSC1: ${error}`);\n      hls.trigger(Events.SUBTITLE_FRAG_PROCESSED, {\n        success: false,\n        frag: frag,\n        error\n      });\n    });\n  }\n  _parseVTTs(data) {\n    var _frag$initSegment;\n    const {\n      frag,\n      payload\n    } = data;\n    // We need an initial synchronisation PTS. Store fragments as long as none has arrived\n    const {\n      initPTS,\n      unparsedVttFrags\n    } = this;\n    const maxAvCC = initPTS.length - 1;\n    if (!initPTS[frag.cc] && maxAvCC === -1) {\n      unparsedVttFrags.push(data);\n      return;\n    }\n    const hls = this.hls;\n    // Parse the WebVTT file contents.\n    const payloadWebVTT = (_frag$initSegment = frag.initSegment) != null && _frag$initSegment.data ? appendUint8Array(frag.initSegment.data, new Uint8Array(payload)).buffer : payload;\n    parseWebVTT(payloadWebVTT, this.initPTS[frag.cc], this.vttCCs, frag.cc, frag.start, cues => {\n      this._appendCues(cues, frag.level);\n      hls.trigger(Events.SUBTITLE_FRAG_PROCESSED, {\n        success: true,\n        frag: frag\n      });\n    }, error => {\n      const missingInitPTS = error.message === 'Missing initPTS for VTT MPEGTS';\n      if (missingInitPTS) {\n        unparsedVttFrags.push(data);\n      } else {\n        this._fallbackToIMSC1(frag, payload);\n      }\n      // Something went wrong while parsing. Trigger event with success false.\n      hls.logger.log(`Failed to parse VTT cue: ${error}`);\n      if (missingInitPTS && maxAvCC > frag.cc) {\n        return;\n      }\n      hls.trigger(Events.SUBTITLE_FRAG_PROCESSED, {\n        success: false,\n        frag: frag,\n        error\n      });\n    });\n  }\n  _fallbackToIMSC1(frag, payload) {\n    // If textCodec is unknown, try parsing as IMSC1. Set textCodec based on the result\n    const trackPlaylistMedia = this.tracks[frag.level];\n    if (!trackPlaylistMedia.textCodec) {\n      parseIMSC1(payload, this.initPTS[frag.cc], () => {\n        trackPlaylistMedia.textCodec = IMSC1_CODEC;\n        this._parseIMSC1(frag, payload);\n      }, () => {\n        trackPlaylistMedia.textCodec = 'wvtt';\n      });\n    }\n  }\n  _appendCues(cues, fragLevel) {\n    const hls = this.hls;\n    if (this.config.renderTextTracksNatively) {\n      const textTrack = this.textTracks[fragLevel];\n      // WebVTTParser.parse is an async method and if the currently selected text track mode is set to \"disabled\"\n      // before parsing is done then don't try to access currentTrack.cues.getCueById as cues will be null\n      // and trying to access getCueById method of cues will throw an exception\n      // Because we check if the mode is disabled, we can force check `cues` below. They can't be null.\n      if (!textTrack || textTrack.mode === 'disabled') {\n        return;\n      }\n      cues.forEach(cue => addCueToTrack(textTrack, cue));\n    } else {\n      const currentTrack = this.tracks[fragLevel];\n      if (!currentTrack) {\n        return;\n      }\n      const track = currentTrack.default ? 'default' : 'subtitles' + fragLevel;\n      hls.trigger(Events.CUES_PARSED, {\n        type: 'subtitles',\n        cues,\n        track\n      });\n    }\n  }\n  onFragDecrypted(event, data) {\n    const {\n      frag\n    } = data;\n    if (frag.type === PlaylistLevelType.SUBTITLE) {\n      this.onFragLoaded(Events.FRAG_LOADED, data);\n    }\n  }\n  onSubtitleTracksCleared() {\n    this.tracks = [];\n    this.captionsTracks = {};\n  }\n  onFragParsingUserdata(event, data) {\n    if (!this.enabled || !this.config.enableCEA708Captions) {\n      return;\n    }\n    const {\n      frag,\n      samples\n    } = data;\n    if (frag.type === PlaylistLevelType.MAIN && this.closedCaptionsForLevel(frag) === 'NONE') {\n      return;\n    }\n    // If the event contains captions (found in the bytes property), push all bytes into the parser immediately\n    // It will create the proper timestamps based on the PTS value\n    for (let i = 0; i < samples.length; i++) {\n      const ccBytes = samples[i].bytes;\n      if (ccBytes) {\n        if (!this.cea608Parser1) {\n          this.initCea608Parsers();\n        }\n        const ccdatas = this.extractCea608Data(ccBytes);\n        this.cea608Parser1.addData(samples[i].pts, ccdatas[0]);\n        this.cea608Parser2.addData(samples[i].pts, ccdatas[1]);\n      }\n    }\n  }\n  onBufferFlushing(event, {\n    startOffset,\n    endOffset,\n    endOffsetSubtitles,\n    type\n  }) {\n    const {\n      media\n    } = this;\n    if (!media || media.currentTime < endOffset) {\n      return;\n    }\n    // Clear 608 caption cues from the captions TextTracks when the video back buffer is flushed\n    // Forward cues are never removed because we can loose streamed 608 content from recent fragments\n    if (!type || type === 'video') {\n      const {\n        captionsTracks\n      } = this;\n      Object.keys(captionsTracks).forEach(trackName => removeCuesInRange(captionsTracks[trackName], startOffset, endOffset));\n    }\n    if (this.config.renderTextTracksNatively) {\n      // Clear VTT/IMSC1 subtitle cues from the subtitle TextTracks when the back buffer is flushed\n      if (startOffset === 0 && endOffsetSubtitles !== undefined) {\n        const {\n          textTracks\n        } = this;\n        Object.keys(textTracks).forEach(trackName => removeCuesInRange(textTracks[trackName], startOffset, endOffsetSubtitles));\n      }\n    }\n  }\n  extractCea608Data(byteArray) {\n    const actualCCBytes = [[], []];\n    const count = byteArray[0] & 0x1f;\n    let position = 2;\n    for (let j = 0; j < count; j++) {\n      const tmpByte = byteArray[position++];\n      const ccbyte1 = 0x7f & byteArray[position++];\n      const ccbyte2 = 0x7f & byteArray[position++];\n      if (ccbyte1 === 0 && ccbyte2 === 0) {\n        continue;\n      }\n      const ccValid = (0x04 & tmpByte) !== 0; // Support all four channels\n      if (ccValid) {\n        const ccType = 0x03 & tmpByte;\n        if (0x00 /* CEA608 field1*/ === ccType || 0x01 /* CEA608 field2*/ === ccType) {\n          // Exclude CEA708 CC data.\n          actualCCBytes[ccType].push(ccbyte1);\n          actualCCBytes[ccType].push(ccbyte2);\n        }\n      }\n    }\n    return actualCCBytes;\n  }\n}\nfunction captionsOrSubtitlesFromCharacteristics(track) {\n  if (track.characteristics) {\n    if (/transcribes-spoken-dialog/gi.test(track.characteristics) && /describes-music-and-sound/gi.test(track.characteristics)) {\n      return 'captions';\n    }\n  }\n  return 'subtitles';\n}\nfunction canReuseVttTextTrack(inUseTrack, manifestTrack) {\n  return !!inUseTrack && inUseTrack.kind === captionsOrSubtitlesFromCharacteristics(manifestTrack) && subtitleTrackMatchesTextTrack(manifestTrack, inUseTrack);\n}\nfunction intersection(x1, x2, y1, y2) {\n  return Math.min(x2, y2) - Math.max(x1, y1);\n}\nfunction newVTTCCs() {\n  return {\n    ccOffset: 0,\n    presentationOffset: 0,\n    0: {\n      start: 0,\n      prevCC: -1,\n      new: true\n    }\n  };\n}\n\nconst WHITESPACE_CHAR = /\\s/;\nconst Cues = {\n  newCue(track, startTime, endTime, captionScreen) {\n    const result = [];\n    let row;\n    // the type data states this is VTTCue, but it can potentially be a TextTrackCue on old browsers\n    let cue;\n    let indenting;\n    let indent;\n    let text;\n    const Cue = self.VTTCue || self.TextTrackCue;\n    for (let r = 0; r < captionScreen.rows.length; r++) {\n      row = captionScreen.rows[r];\n      indenting = true;\n      indent = 0;\n      text = '';\n      if (!row.isEmpty()) {\n        var _track$cues;\n        for (let c = 0; c < row.chars.length; c++) {\n          if (WHITESPACE_CHAR.test(row.chars[c].uchar) && indenting) {\n            indent++;\n          } else {\n            text += row.chars[c].uchar;\n            indenting = false;\n          }\n        }\n        // To be used for cleaning-up orphaned roll-up captions\n        row.cueStartTime = startTime;\n\n        // Give a slight bump to the endTime if it's equal to startTime to avoid a SyntaxError in IE\n        if (startTime === endTime) {\n          endTime += 0.0001;\n        }\n        if (indent >= 16) {\n          indent--;\n        } else {\n          indent++;\n        }\n        const cueText = fixLineBreaks(text.trim());\n        const id = generateCueId(startTime, endTime, cueText);\n\n        // If this cue already exists in the track do not push it\n        if (!(track != null && (_track$cues = track.cues) != null && _track$cues.getCueById(id))) {\n          cue = new Cue(startTime, endTime, cueText);\n          cue.id = id;\n          cue.line = r + 1;\n          cue.align = 'left';\n          // Clamp the position between 10 and 80 percent (CEA-608 PAC indent code)\n          // https://dvcs.w3.org/hg/text-tracks/raw-file/default/608toVTT/608toVTT.html#positioning-in-cea-608\n          // Firefox throws an exception and captions break with out of bounds 0-100 values\n          cue.position = 10 + Math.min(80, Math.floor(indent * 8 / 32) * 10);\n          result.push(cue);\n        }\n      }\n    }\n    if (track && result.length) {\n      // Sort bottom cues in reverse order so that they render in line order when overlapping in Chrome\n      result.sort((cueA, cueB) => {\n        if (cueA.line === 'auto' || cueB.line === 'auto') {\n          return 0;\n        }\n        if (cueA.line > 8 && cueB.line > 8) {\n          return cueB.line - cueA.line;\n        }\n        return cueA.line - cueB.line;\n      });\n      result.forEach(cue => addCueToTrack(track, cue));\n    }\n    return result;\n  }\n};\n\nfunction fetchSupported() {\n  if (\n  // @ts-ignore\n  self.fetch && self.AbortController && self.ReadableStream && self.Request) {\n    try {\n      new self.ReadableStream({}); // eslint-disable-line no-new\n      return true;\n    } catch (e) {\n      /* noop */\n    }\n  }\n  return false;\n}\nconst BYTERANGE = /(\\d+)-(\\d+)\\/(\\d+)/;\nclass FetchLoader {\n  constructor(config) {\n    this.fetchSetup = void 0;\n    this.requestTimeout = void 0;\n    this.request = null;\n    this.response = null;\n    this.controller = void 0;\n    this.context = null;\n    this.config = null;\n    this.callbacks = null;\n    this.stats = void 0;\n    this.loader = null;\n    this.fetchSetup = config.fetchSetup || getRequest;\n    this.controller = new self.AbortController();\n    this.stats = new LoadStats();\n  }\n  destroy() {\n    this.loader = this.callbacks = this.context = this.config = this.request = null;\n    this.abortInternal();\n    this.response = null;\n    // @ts-ignore\n    this.fetchSetup = this.controller = this.stats = null;\n  }\n  abortInternal() {\n    if (this.controller && !this.stats.loading.end) {\n      this.stats.aborted = true;\n      this.controller.abort();\n    }\n  }\n  abort() {\n    var _this$callbacks;\n    this.abortInternal();\n    if ((_this$callbacks = this.callbacks) != null && _this$callbacks.onAbort) {\n      this.callbacks.onAbort(this.stats, this.context, this.response);\n    }\n  }\n  load(context, config, callbacks) {\n    const stats = this.stats;\n    if (stats.loading.start) {\n      throw new Error('Loader can only be used once.');\n    }\n    stats.loading.start = self.performance.now();\n    const initParams = getRequestParameters(context, this.controller.signal);\n    const isArrayBuffer = context.responseType === 'arraybuffer';\n    const LENGTH = isArrayBuffer ? 'byteLength' : 'length';\n    const {\n      maxTimeToFirstByteMs,\n      maxLoadTimeMs\n    } = config.loadPolicy;\n    this.context = context;\n    this.config = config;\n    this.callbacks = callbacks;\n    this.request = this.fetchSetup(context, initParams);\n    self.clearTimeout(this.requestTimeout);\n    config.timeout = maxTimeToFirstByteMs && isFiniteNumber(maxTimeToFirstByteMs) ? maxTimeToFirstByteMs : maxLoadTimeMs;\n    this.requestTimeout = self.setTimeout(() => {\n      if (this.callbacks) {\n        this.abortInternal();\n        this.callbacks.onTimeout(stats, context, this.response);\n      }\n    }, config.timeout);\n    const fetchPromise = isPromise(this.request) ? this.request.then(self.fetch) : self.fetch(this.request);\n    fetchPromise.then(response => {\n      var _this$callbacks2;\n      this.response = this.loader = response;\n      const first = Math.max(self.performance.now(), stats.loading.start);\n      self.clearTimeout(this.requestTimeout);\n      config.timeout = maxLoadTimeMs;\n      this.requestTimeout = self.setTimeout(() => {\n        if (this.callbacks) {\n          this.abortInternal();\n          this.callbacks.onTimeout(stats, context, this.response);\n        }\n      }, maxLoadTimeMs - (first - stats.loading.start));\n      if (!response.ok) {\n        const {\n          status,\n          statusText\n        } = response;\n        throw new FetchError(statusText || 'fetch, bad network response', status, response);\n      }\n      stats.loading.first = first;\n      stats.total = getContentLength(response.headers) || stats.total;\n      const onProgress = (_this$callbacks2 = this.callbacks) == null ? void 0 : _this$callbacks2.onProgress;\n      if (onProgress && isFiniteNumber(config.highWaterMark)) {\n        return this.loadProgressively(response, stats, context, config.highWaterMark, onProgress);\n      }\n      if (isArrayBuffer) {\n        return response.arrayBuffer();\n      }\n      if (context.responseType === 'json') {\n        return response.json();\n      }\n      return response.text();\n    }).then(responseData => {\n      var _this$callbacks3, _this$callbacks4;\n      const response = this.response;\n      if (!response) {\n        throw new Error('loader destroyed');\n      }\n      self.clearTimeout(this.requestTimeout);\n      stats.loading.end = Math.max(self.performance.now(), stats.loading.first);\n      const total = responseData[LENGTH];\n      if (total) {\n        stats.loaded = stats.total = total;\n      }\n      const loaderResponse = {\n        url: response.url,\n        data: responseData,\n        code: response.status\n      };\n      const onProgress = (_this$callbacks3 = this.callbacks) == null ? void 0 : _this$callbacks3.onProgress;\n      if (onProgress && !isFiniteNumber(config.highWaterMark)) {\n        onProgress(stats, context, responseData, response);\n      }\n      (_this$callbacks4 = this.callbacks) == null || _this$callbacks4.onSuccess(loaderResponse, stats, context, response);\n    }).catch(error => {\n      var _this$callbacks5;\n      self.clearTimeout(this.requestTimeout);\n      if (stats.aborted) {\n        return;\n      }\n      // CORS errors result in an undefined code. Set it to 0 here to align with XHR's behavior\n      // when destroying, 'error' itself can be undefined\n      const code = !error ? 0 : error.code || 0;\n      const text = !error ? null : error.message;\n      (_this$callbacks5 = this.callbacks) == null || _this$callbacks5.onError({\n        code,\n        text\n      }, context, error ? error.details : null, stats);\n    });\n  }\n  getCacheAge() {\n    let result = null;\n    if (this.response) {\n      const ageHeader = this.response.headers.get('age');\n      result = ageHeader ? parseFloat(ageHeader) : null;\n    }\n    return result;\n  }\n  getResponseHeader(name) {\n    return this.response ? this.response.headers.get(name) : null;\n  }\n  loadProgressively(response, stats, context, highWaterMark = 0, onProgress) {\n    const chunkCache = new ChunkCache();\n    const reader = response.body.getReader();\n    const pump = () => {\n      return reader.read().then(data => {\n        if (data.done) {\n          if (chunkCache.dataLength) {\n            onProgress(stats, context, chunkCache.flush().buffer, response);\n          }\n          return Promise.resolve(new ArrayBuffer(0));\n        }\n        const chunk = data.value;\n        const len = chunk.length;\n        stats.loaded += len;\n        if (len < highWaterMark || chunkCache.dataLength) {\n          // The current chunk is too small to to be emitted or the cache already has data\n          // Push it to the cache\n          chunkCache.push(chunk);\n          if (chunkCache.dataLength >= highWaterMark) {\n            // flush in order to join the typed arrays\n            onProgress(stats, context, chunkCache.flush().buffer, response);\n          }\n        } else {\n          // If there's nothing cached already, and the chache is large enough\n          // just emit the progress event\n          onProgress(stats, context, chunk.buffer, response);\n        }\n        return pump();\n      }).catch(() => {\n        /* aborted */\n        return Promise.reject();\n      });\n    };\n    return pump();\n  }\n}\nfunction getRequestParameters(context, signal) {\n  const initParams = {\n    method: 'GET',\n    mode: 'cors',\n    credentials: 'same-origin',\n    signal,\n    headers: new self.Headers(_extends({}, context.headers))\n  };\n  if (context.rangeEnd) {\n    initParams.headers.set('Range', 'bytes=' + context.rangeStart + '-' + String(context.rangeEnd - 1));\n  }\n  return initParams;\n}\nfunction getByteRangeLength(byteRangeHeader) {\n  const result = BYTERANGE.exec(byteRangeHeader);\n  if (result) {\n    return parseInt(result[2]) - parseInt(result[1]) + 1;\n  }\n}\nfunction getContentLength(headers) {\n  const contentRange = headers.get('Content-Range');\n  if (contentRange) {\n    const byteRangeLength = getByteRangeLength(contentRange);\n    if (isFiniteNumber(byteRangeLength)) {\n      return byteRangeLength;\n    }\n  }\n  const contentLength = headers.get('Content-Length');\n  if (contentLength) {\n    return parseInt(contentLength);\n  }\n}\nfunction getRequest(context, initParams) {\n  return new self.Request(context.url, initParams);\n}\nclass FetchError extends Error {\n  constructor(message, code, details) {\n    super(message);\n    this.code = void 0;\n    this.details = void 0;\n    this.code = code;\n    this.details = details;\n  }\n}\n\nconst AGE_HEADER_LINE_REGEX = /^age:\\s*[\\d.]+\\s*$/im;\nclass XhrLoader {\n  constructor(config) {\n    this.xhrSetup = void 0;\n    this.requestTimeout = void 0;\n    this.retryTimeout = void 0;\n    this.retryDelay = void 0;\n    this.config = null;\n    this.callbacks = null;\n    this.context = null;\n    this.loader = null;\n    this.stats = void 0;\n    this.xhrSetup = config ? config.xhrSetup || null : null;\n    this.stats = new LoadStats();\n    this.retryDelay = 0;\n  }\n  destroy() {\n    this.callbacks = null;\n    this.abortInternal();\n    this.loader = null;\n    this.config = null;\n    this.context = null;\n    this.xhrSetup = null;\n  }\n  abortInternal() {\n    const loader = this.loader;\n    self.clearTimeout(this.requestTimeout);\n    self.clearTimeout(this.retryTimeout);\n    if (loader) {\n      loader.onreadystatechange = null;\n      loader.onprogress = null;\n      if (loader.readyState !== 4) {\n        this.stats.aborted = true;\n        loader.abort();\n      }\n    }\n  }\n  abort() {\n    var _this$callbacks;\n    this.abortInternal();\n    if ((_this$callbacks = this.callbacks) != null && _this$callbacks.onAbort) {\n      this.callbacks.onAbort(this.stats, this.context, this.loader);\n    }\n  }\n  load(context, config, callbacks) {\n    if (this.stats.loading.start) {\n      throw new Error('Loader can only be used once.');\n    }\n    this.stats.loading.start = self.performance.now();\n    this.context = context;\n    this.config = config;\n    this.callbacks = callbacks;\n    this.loadInternal();\n  }\n  loadInternal() {\n    const {\n      config,\n      context\n    } = this;\n    if (!config || !context) {\n      return;\n    }\n    const xhr = this.loader = new self.XMLHttpRequest();\n    const stats = this.stats;\n    stats.loading.first = 0;\n    stats.loaded = 0;\n    stats.aborted = false;\n    const xhrSetup = this.xhrSetup;\n    if (xhrSetup) {\n      Promise.resolve().then(() => {\n        if (this.loader !== xhr || this.stats.aborted) return;\n        return xhrSetup(xhr, context.url);\n      }).catch(error => {\n        if (this.loader !== xhr || this.stats.aborted) return;\n        xhr.open('GET', context.url, true);\n        return xhrSetup(xhr, context.url);\n      }).then(() => {\n        if (this.loader !== xhr || this.stats.aborted) return;\n        this.openAndSendXhr(xhr, context, config);\n      }).catch(error => {\n        var _this$callbacks2;\n        // IE11 throws an exception on xhr.open if attempting to access an HTTP resource over HTTPS\n        (_this$callbacks2 = this.callbacks) == null || _this$callbacks2.onError({\n          code: xhr.status,\n          text: error.message\n        }, context, xhr, stats);\n        return;\n      });\n    } else {\n      this.openAndSendXhr(xhr, context, config);\n    }\n  }\n  openAndSendXhr(xhr, context, config) {\n    if (!xhr.readyState) {\n      xhr.open('GET', context.url, true);\n    }\n    const headers = context.headers;\n    const {\n      maxTimeToFirstByteMs,\n      maxLoadTimeMs\n    } = config.loadPolicy;\n    if (headers) {\n      for (const header in headers) {\n        xhr.setRequestHeader(header, headers[header]);\n      }\n    }\n    if (context.rangeEnd) {\n      xhr.setRequestHeader('Range', 'bytes=' + context.rangeStart + '-' + (context.rangeEnd - 1));\n    }\n    xhr.onreadystatechange = this.readystatechange.bind(this);\n    xhr.onprogress = this.loadprogress.bind(this);\n    xhr.responseType = context.responseType;\n    // setup timeout before we perform request\n    self.clearTimeout(this.requestTimeout);\n    config.timeout = maxTimeToFirstByteMs && isFiniteNumber(maxTimeToFirstByteMs) ? maxTimeToFirstByteMs : maxLoadTimeMs;\n    this.requestTimeout = self.setTimeout(this.loadtimeout.bind(this), config.timeout);\n    xhr.send();\n  }\n  readystatechange() {\n    const {\n      context,\n      loader: xhr,\n      stats\n    } = this;\n    if (!context || !xhr) {\n      return;\n    }\n    const readyState = xhr.readyState;\n    const config = this.config;\n\n    // don't proceed if xhr has been aborted\n    if (stats.aborted) {\n      return;\n    }\n\n    // >= HEADERS_RECEIVED\n    if (readyState >= 2) {\n      if (stats.loading.first === 0) {\n        stats.loading.first = Math.max(self.performance.now(), stats.loading.start);\n        // readyState >= 2 AND readyState !==4 (readyState = HEADERS_RECEIVED || LOADING) rearm timeout as xhr not finished yet\n        if (config.timeout !== config.loadPolicy.maxLoadTimeMs) {\n          self.clearTimeout(this.requestTimeout);\n          config.timeout = config.loadPolicy.maxLoadTimeMs;\n          this.requestTimeout = self.setTimeout(this.loadtimeout.bind(this), config.loadPolicy.maxLoadTimeMs - (stats.loading.first - stats.loading.start));\n        }\n      }\n      if (readyState === 4) {\n        self.clearTimeout(this.requestTimeout);\n        xhr.onreadystatechange = null;\n        xhr.onprogress = null;\n        const status = xhr.status;\n        // http status between 200 to 299 are all successful\n        const useResponseText = xhr.responseType === 'text' ? xhr.responseText : null;\n        if (status >= 200 && status < 300) {\n          const data = useResponseText != null ? useResponseText : xhr.response;\n          if (data != null) {\n            var _this$callbacks3, _this$callbacks4;\n            stats.loading.end = Math.max(self.performance.now(), stats.loading.first);\n            const len = xhr.responseType === 'arraybuffer' ? data.byteLength : data.length;\n            stats.loaded = stats.total = len;\n            stats.bwEstimate = stats.total * 8000 / (stats.loading.end - stats.loading.first);\n            const onProgress = (_this$callbacks3 = this.callbacks) == null ? void 0 : _this$callbacks3.onProgress;\n            if (onProgress) {\n              onProgress(stats, context, data, xhr);\n            }\n            const _response = {\n              url: xhr.responseURL,\n              data: data,\n              code: status\n            };\n            (_this$callbacks4 = this.callbacks) == null || _this$callbacks4.onSuccess(_response, stats, context, xhr);\n            return;\n          }\n        }\n\n        // Handle bad status or nullish response\n        const retryConfig = config.loadPolicy.errorRetry;\n        const retryCount = stats.retry;\n        // if max nb of retries reached or if http status between 400 and 499 (such error cannot be recovered, retrying is useless), return error\n        const response = {\n          url: context.url,\n          data: undefined,\n          code: status\n        };\n        if (shouldRetry(retryConfig, retryCount, false, response)) {\n          this.retry(retryConfig);\n        } else {\n          var _this$callbacks5;\n          logger.error(`${status} while loading ${context.url}`);\n          (_this$callbacks5 = this.callbacks) == null || _this$callbacks5.onError({\n            code: status,\n            text: xhr.statusText\n          }, context, xhr, stats);\n        }\n      }\n    }\n  }\n  loadtimeout() {\n    if (!this.config) return;\n    const retryConfig = this.config.loadPolicy.timeoutRetry;\n    const retryCount = this.stats.retry;\n    if (shouldRetry(retryConfig, retryCount, true)) {\n      this.retry(retryConfig);\n    } else {\n      var _this$context;\n      logger.warn(`timeout while loading ${(_this$context = this.context) == null ? void 0 : _this$context.url}`);\n      const callbacks = this.callbacks;\n      if (callbacks) {\n        this.abortInternal();\n        callbacks.onTimeout(this.stats, this.context, this.loader);\n      }\n    }\n  }\n  retry(retryConfig) {\n    const {\n      context,\n      stats\n    } = this;\n    this.retryDelay = getRetryDelay(retryConfig, stats.retry);\n    stats.retry++;\n    logger.warn(`${status ? 'HTTP Status ' + status : 'Timeout'} while loading ${context == null ? void 0 : context.url}, retrying ${stats.retry}/${retryConfig.maxNumRetry} in ${this.retryDelay}ms`);\n    // abort and reset internal state\n    this.abortInternal();\n    this.loader = null;\n    // schedule retry\n    self.clearTimeout(this.retryTimeout);\n    this.retryTimeout = self.setTimeout(this.loadInternal.bind(this), this.retryDelay);\n  }\n  loadprogress(event) {\n    const stats = this.stats;\n    stats.loaded = event.loaded;\n    if (event.lengthComputable) {\n      stats.total = event.total;\n    }\n  }\n  getCacheAge() {\n    let result = null;\n    if (this.loader && AGE_HEADER_LINE_REGEX.test(this.loader.getAllResponseHeaders())) {\n      const ageHeader = this.loader.getResponseHeader('age');\n      result = ageHeader ? parseFloat(ageHeader) : null;\n    }\n    return result;\n  }\n  getResponseHeader(name) {\n    if (this.loader && new RegExp(`^${name}:\\\\s*[\\\\d.]+\\\\s*$`, 'im').test(this.loader.getAllResponseHeaders())) {\n      return this.loader.getResponseHeader(name);\n    }\n    return null;\n  }\n}\n\n/**\n * @deprecated use fragLoadPolicy.default\n */\n\n/**\n * @deprecated use manifestLoadPolicy.default and playlistLoadPolicy.default\n */\n\nconst defaultLoadPolicy = {\n  maxTimeToFirstByteMs: 8000,\n  maxLoadTimeMs: 20000,\n  timeoutRetry: null,\n  errorRetry: null\n};\n\n/**\n * @ignore\n * If possible, keep hlsDefaultConfig shallow\n * It is cloned whenever a new Hls instance is created, by keeping the config\n * shallow the properties are cloned, and we don't end up manipulating the default\n */\nconst hlsDefaultConfig = _objectSpread2(_objectSpread2({\n  autoStartLoad: true,\n  // used by stream-controller\n  startPosition: -1,\n  // used by stream-controller\n  defaultAudioCodec: undefined,\n  // used by stream-controller\n  debug: false,\n  // used by logger\n  capLevelOnFPSDrop: false,\n  // used by fps-controller\n  capLevelToPlayerSize: false,\n  // used by cap-level-controller\n  ignoreDevicePixelRatio: false,\n  // used by cap-level-controller\n  maxDevicePixelRatio: Number.POSITIVE_INFINITY,\n  // used by cap-level-controller\n  preferManagedMediaSource: true,\n  initialLiveManifestSize: 1,\n  // used by stream-controller\n  maxBufferLength: 30,\n  // used by stream-controller\n  backBufferLength: Infinity,\n  // used by buffer-controller\n  frontBufferFlushThreshold: Infinity,\n  startOnSegmentBoundary: false,\n  // used by stream-controller\n  maxBufferSize: 60 * 1000 * 1000,\n  // used by stream-controller\n  maxFragLookUpTolerance: 0.25,\n  // used by stream-controller\n  maxBufferHole: 0.1,\n  // used by stream-controller and gap-controller\n  detectStallWithCurrentTimeMs: 1250,\n  // used by gap-controller\n  highBufferWatchdogPeriod: 2,\n  // used by gap-controller\n  nudgeOffset: 0.1,\n  // used by gap-controller\n  nudgeMaxRetry: 3,\n  // used by gap-controller\n  nudgeOnVideoHole: true,\n  // used by gap-controller\n  liveSyncMode: 'edge',\n  // used by stream-controller\n  liveSyncDurationCount: 3,\n  // used by latency-controller\n  liveSyncOnStallIncrease: 1,\n  // used by latency-controller\n  liveMaxLatencyDurationCount: Infinity,\n  // used by latency-controller\n  liveSyncDuration: undefined,\n  // used by latency-controller\n  liveMaxLatencyDuration: undefined,\n  // used by latency-controller\n  maxLiveSyncPlaybackRate: 1,\n  // used by latency-controller\n  liveDurationInfinity: false,\n  // used by buffer-controller\n  /**\n   * @deprecated use backBufferLength\n   */\n  liveBackBufferLength: null,\n  // used by buffer-controller\n  maxMaxBufferLength: 600,\n  // used by stream-controller\n  enableWorker: true,\n  // used by transmuxer\n  workerPath: null,\n  // used by transmuxer\n  enableSoftwareAES: true,\n  // used by decrypter\n  startLevel: undefined,\n  // used by level-controller\n  startFragPrefetch: false,\n  // used by stream-controller\n  fpsDroppedMonitoringPeriod: 5000,\n  // used by fps-controller\n  fpsDroppedMonitoringThreshold: 0.2,\n  // used by fps-controller\n  appendErrorMaxRetry: 3,\n  // used by buffer-controller\n  ignorePlaylistParsingErrors: false,\n  loader: XhrLoader,\n  // loader: FetchLoader,\n  fLoader: undefined,\n  // used by fragment-loader\n  pLoader: undefined,\n  // used by playlist-loader\n  xhrSetup: undefined,\n  // used by xhr-loader\n  licenseXhrSetup: undefined,\n  // used by eme-controller\n  licenseResponseCallback: undefined,\n  // used by eme-controller\n  abrController: AbrController,\n  bufferController: BufferController,\n  capLevelController: CapLevelController,\n  errorController: ErrorController,\n  fpsController: FPSController,\n  stretchShortVideoTrack: false,\n  // used by mp4-remuxer\n  maxAudioFramesDrift: 1,\n  // used by mp4-remuxer\n  forceKeyFrameOnDiscontinuity: true,\n  // used by ts-demuxer\n  abrEwmaFastLive: 3,\n  // used by abr-controller\n  abrEwmaSlowLive: 9,\n  // used by abr-controller\n  abrEwmaFastVoD: 3,\n  // used by abr-controller\n  abrEwmaSlowVoD: 9,\n  // used by abr-controller\n  abrEwmaDefaultEstimate: 5e5,\n  // 500 kbps  // used by abr-controller\n  abrEwmaDefaultEstimateMax: 5e6,\n  // 5 mbps\n  abrBandWidthFactor: 0.95,\n  // used by abr-controller\n  abrBandWidthUpFactor: 0.7,\n  // used by abr-controller\n  abrMaxWithRealBitrate: false,\n  // used by abr-controller\n  maxStarvationDelay: 4,\n  // used by abr-controller\n  maxLoadingDelay: 4,\n  // used by abr-controller\n  minAutoBitrate: 0,\n  // used by hls\n  emeEnabled: false,\n  // used by eme-controller\n  widevineLicenseUrl: undefined,\n  // used by eme-controller\n  drmSystems: {},\n  // used by eme-controller\n  drmSystemOptions: {},\n  // used by eme-controller\n  requestMediaKeySystemAccessFunc: requestMediaKeySystemAccess ,\n  // used by eme-controller\n  requireKeySystemAccessOnStart: false,\n  // used by eme-controller\n  testBandwidth: true,\n  progressive: false,\n  lowLatencyMode: true,\n  cmcd: undefined,\n  enableDateRangeMetadataCues: true,\n  enableEmsgMetadataCues: true,\n  enableEmsgKLVMetadata: false,\n  enableID3MetadataCues: true,\n  enableInterstitialPlayback: true,\n  interstitialAppendInPlace: true,\n  interstitialLiveLookAhead: 10,\n  useMediaCapabilities: true,\n  preserveManualLevelOnError: false,\n  certLoadPolicy: {\n    default: defaultLoadPolicy\n  },\n  keyLoadPolicy: {\n    default: {\n      maxTimeToFirstByteMs: 8000,\n      maxLoadTimeMs: 20000,\n      timeoutRetry: {\n        maxNumRetry: 1,\n        retryDelayMs: 1000,\n        maxRetryDelayMs: 20000,\n        backoff: 'linear'\n      },\n      errorRetry: {\n        maxNumRetry: 8,\n        retryDelayMs: 1000,\n        maxRetryDelayMs: 20000,\n        backoff: 'linear'\n      }\n    }\n  },\n  manifestLoadPolicy: {\n    default: {\n      maxTimeToFirstByteMs: Infinity,\n      maxLoadTimeMs: 20000,\n      timeoutRetry: {\n        maxNumRetry: 2,\n        retryDelayMs: 0,\n        maxRetryDelayMs: 0\n      },\n      errorRetry: {\n        maxNumRetry: 1,\n        retryDelayMs: 1000,\n        maxRetryDelayMs: 8000\n      }\n    }\n  },\n  playlistLoadPolicy: {\n    default: {\n      maxTimeToFirstByteMs: 10000,\n      maxLoadTimeMs: 20000,\n      timeoutRetry: {\n        maxNumRetry: 2,\n        retryDelayMs: 0,\n        maxRetryDelayMs: 0\n      },\n      errorRetry: {\n        maxNumRetry: 2,\n        retryDelayMs: 1000,\n        maxRetryDelayMs: 8000\n      }\n    }\n  },\n  fragLoadPolicy: {\n    default: {\n      maxTimeToFirstByteMs: 10000,\n      maxLoadTimeMs: 120000,\n      timeoutRetry: {\n        maxNumRetry: 4,\n        retryDelayMs: 0,\n        maxRetryDelayMs: 0\n      },\n      errorRetry: {\n        maxNumRetry: 6,\n        retryDelayMs: 1000,\n        maxRetryDelayMs: 8000\n      }\n    }\n  },\n  steeringManifestLoadPolicy: {\n    default: {\n      maxTimeToFirstByteMs: 10000,\n      maxLoadTimeMs: 20000,\n      timeoutRetry: {\n        maxNumRetry: 2,\n        retryDelayMs: 0,\n        maxRetryDelayMs: 0\n      },\n      errorRetry: {\n        maxNumRetry: 1,\n        retryDelayMs: 1000,\n        maxRetryDelayMs: 8000\n      }\n    } \n  },\n  interstitialAssetListLoadPolicy: {\n    default: {\n      maxTimeToFirstByteMs: 10000,\n      maxLoadTimeMs: 30000,\n      timeoutRetry: {\n        maxNumRetry: 0,\n        retryDelayMs: 0,\n        maxRetryDelayMs: 0\n      },\n      errorRetry: {\n        maxNumRetry: 0,\n        retryDelayMs: 1000,\n        maxRetryDelayMs: 8000\n      }\n    } \n  },\n  // These default settings are deprecated in favor of the above policies\n  // and are maintained for backwards compatibility\n  manifestLoadingTimeOut: 10000,\n  manifestLoadingMaxRetry: 1,\n  manifestLoadingRetryDelay: 1000,\n  manifestLoadingMaxRetryTimeout: 64000,\n  levelLoadingTimeOut: 10000,\n  levelLoadingMaxRetry: 4,\n  levelLoadingRetryDelay: 1000,\n  levelLoadingMaxRetryTimeout: 64000,\n  fragLoadingTimeOut: 20000,\n  fragLoadingMaxRetry: 6,\n  fragLoadingRetryDelay: 1000,\n  fragLoadingMaxRetryTimeout: 64000\n}, timelineConfig()), {}, {\n  subtitleStreamController: SubtitleStreamController ,\n  subtitleTrackController: SubtitleTrackController ,\n  timelineController: TimelineController ,\n  audioStreamController: AudioStreamController ,\n  audioTrackController: AudioTrackController ,\n  emeController: EMEController ,\n  cmcdController: CMCDController ,\n  contentSteeringController: ContentSteeringController ,\n  interstitialsController: InterstitialsController \n});\nfunction timelineConfig() {\n  return {\n    cueHandler: Cues,\n    // used by timeline-controller\n    enableWebVTT: true,\n    // used by timeline-controller\n    enableIMSC1: true,\n    // used by timeline-controller\n    enableCEA708Captions: true,\n    // used by timeline-controller\n    captionsTextTrack1Label: 'English',\n    // used by timeline-controller\n    captionsTextTrack1LanguageCode: 'en',\n    // used by timeline-controller\n    captionsTextTrack2Label: 'Spanish',\n    // used by timeline-controller\n    captionsTextTrack2LanguageCode: 'es',\n    // used by timeline-controller\n    captionsTextTrack3Label: 'Unknown CC',\n    // used by timeline-controller\n    captionsTextTrack3LanguageCode: '',\n    // used by timeline-controller\n    captionsTextTrack4Label: 'Unknown CC',\n    // used by timeline-controller\n    captionsTextTrack4LanguageCode: '',\n    // used by timeline-controller\n    renderTextTracksNatively: true\n  };\n}\n\n/**\n * @ignore\n */\nfunction mergeConfig(defaultConfig, userConfig, logger) {\n  if ((userConfig.liveSyncDurationCount || userConfig.liveMaxLatencyDurationCount) && (userConfig.liveSyncDuration || userConfig.liveMaxLatencyDuration)) {\n    throw new Error(\"Illegal hls.js config: don't mix up liveSyncDurationCount/liveMaxLatencyDurationCount and liveSyncDuration/liveMaxLatencyDuration\");\n  }\n  if (userConfig.liveMaxLatencyDurationCount !== undefined && (userConfig.liveSyncDurationCount === undefined || userConfig.liveMaxLatencyDurationCount <= userConfig.liveSyncDurationCount)) {\n    throw new Error('Illegal hls.js config: \"liveMaxLatencyDurationCount\" must be greater than \"liveSyncDurationCount\"');\n  }\n  if (userConfig.liveMaxLatencyDuration !== undefined && (userConfig.liveSyncDuration === undefined || userConfig.liveMaxLatencyDuration <= userConfig.liveSyncDuration)) {\n    throw new Error('Illegal hls.js config: \"liveMaxLatencyDuration\" must be greater than \"liveSyncDuration\"');\n  }\n  const defaultsCopy = deepCpy(defaultConfig);\n\n  // Backwards compatibility with deprecated config values\n  const deprecatedSettingTypes = ['manifest', 'level', 'frag'];\n  const deprecatedSettings = ['TimeOut', 'MaxRetry', 'RetryDelay', 'MaxRetryTimeout'];\n  deprecatedSettingTypes.forEach(type => {\n    const policyName = `${type === 'level' ? 'playlist' : type}LoadPolicy`;\n    const policyNotSet = userConfig[policyName] === undefined;\n    const report = [];\n    deprecatedSettings.forEach(setting => {\n      const deprecatedSetting = `${type}Loading${setting}`;\n      const value = userConfig[deprecatedSetting];\n      if (value !== undefined && policyNotSet) {\n        report.push(deprecatedSetting);\n        const settings = defaultsCopy[policyName].default;\n        userConfig[policyName] = {\n          default: settings\n        };\n        switch (setting) {\n          case 'TimeOut':\n            settings.maxLoadTimeMs = value;\n            settings.maxTimeToFirstByteMs = value;\n            break;\n          case 'MaxRetry':\n            settings.errorRetry.maxNumRetry = value;\n            settings.timeoutRetry.maxNumRetry = value;\n            break;\n          case 'RetryDelay':\n            settings.errorRetry.retryDelayMs = value;\n            settings.timeoutRetry.retryDelayMs = value;\n            break;\n          case 'MaxRetryTimeout':\n            settings.errorRetry.maxRetryDelayMs = value;\n            settings.timeoutRetry.maxRetryDelayMs = value;\n            break;\n        }\n      }\n    });\n    if (report.length) {\n      logger.warn(`hls.js config: \"${report.join('\", \"')}\" setting(s) are deprecated, use \"${policyName}\": ${stringify(userConfig[policyName])}`);\n    }\n  });\n  return _objectSpread2(_objectSpread2({}, defaultsCopy), userConfig);\n}\nfunction deepCpy(obj) {\n  if (obj && typeof obj === 'object') {\n    if (Array.isArray(obj)) {\n      return obj.map(deepCpy);\n    }\n    return Object.keys(obj).reduce((result, key) => {\n      result[key] = deepCpy(obj[key]);\n      return result;\n    }, {});\n  }\n  return obj;\n}\n\n/**\n * @ignore\n */\nfunction enableStreamingMode(config, logger) {\n  const currentLoader = config.loader;\n  if (currentLoader !== FetchLoader && currentLoader !== XhrLoader) {\n    // If a developer has configured their own loader, respect that choice\n    logger.log('[config]: Custom loader detected, cannot enable progressive streaming');\n    config.progressive = false;\n  } else {\n    const canStreamProgressively = fetchSupported();\n    if (canStreamProgressively) {\n      config.loader = FetchLoader;\n      config.progressive = true;\n      config.enableSoftwareAES = true;\n      logger.log('[config]: Progressive streaming enabled, using FetchLoader');\n    }\n  }\n}\n\nconst MAX_START_GAP_JUMP = 2.0;\nconst SKIP_BUFFER_HOLE_STEP_SECONDS = 0.1;\nconst SKIP_BUFFER_RANGE_START = 0.05;\nconst TICK_INTERVAL$1 = 100;\nclass GapController extends TaskLoop {\n  constructor(hls, fragmentTracker) {\n    super('gap-controller', hls.logger);\n    this.hls = void 0;\n    this.fragmentTracker = void 0;\n    this.media = null;\n    this.mediaSource = void 0;\n    this.nudgeRetry = 0;\n    this.stallReported = false;\n    this.stalled = null;\n    this.moved = false;\n    this.seeking = false;\n    this.buffered = {};\n    this.lastCurrentTime = 0;\n    this.ended = 0;\n    this.waiting = 0;\n    this.onMediaPlaying = () => {\n      this.ended = 0;\n      this.waiting = 0;\n    };\n    this.onMediaWaiting = () => {\n      var _this$media;\n      if ((_this$media = this.media) != null && _this$media.seeking) {\n        return;\n      }\n      this.waiting = self.performance.now();\n      this.tick();\n    };\n    this.onMediaEnded = () => {\n      if (this.hls) {\n        var _this$media2;\n        // ended is set when triggering MEDIA_ENDED so that we do not trigger it again on stall or on tick with media.ended\n        this.ended = ((_this$media2 = this.media) == null ? void 0 : _this$media2.currentTime) || 1;\n        this.hls.trigger(Events.MEDIA_ENDED, {\n          stalled: false\n        });\n      }\n    };\n    this.hls = hls;\n    this.fragmentTracker = fragmentTracker;\n    this.registerListeners();\n  }\n  registerListeners() {\n    const {\n      hls\n    } = this;\n    if (hls) {\n      hls.on(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n      hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n      hls.on(Events.BUFFER_APPENDED, this.onBufferAppended, this);\n    }\n  }\n  unregisterListeners() {\n    const {\n      hls\n    } = this;\n    if (hls) {\n      hls.off(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n      hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n      hls.off(Events.BUFFER_APPENDED, this.onBufferAppended, this);\n    }\n  }\n  destroy() {\n    super.destroy();\n    this.unregisterListeners();\n    this.media = this.hls = this.fragmentTracker = null;\n    this.mediaSource = undefined;\n  }\n  onMediaAttached(event, data) {\n    this.setInterval(TICK_INTERVAL$1);\n    this.mediaSource = data.mediaSource;\n    const media = this.media = data.media;\n    addEventListener(media, 'playing', this.onMediaPlaying);\n    addEventListener(media, 'waiting', this.onMediaWaiting);\n    addEventListener(media, 'ended', this.onMediaEnded);\n  }\n  onMediaDetaching(event, data) {\n    this.clearInterval();\n    const {\n      media\n    } = this;\n    if (media) {\n      removeEventListener(media, 'playing', this.onMediaPlaying);\n      removeEventListener(media, 'waiting', this.onMediaWaiting);\n      removeEventListener(media, 'ended', this.onMediaEnded);\n      this.media = null;\n    }\n    this.mediaSource = undefined;\n  }\n  onBufferAppended(event, data) {\n    this.buffered = data.timeRanges;\n  }\n  get hasBuffered() {\n    return Object.keys(this.buffered).length > 0;\n  }\n  tick() {\n    var _this$media3;\n    if (!((_this$media3 = this.media) != null && _this$media3.readyState) || !this.hasBuffered) {\n      return;\n    }\n    const currentTime = this.media.currentTime;\n    this.poll(currentTime, this.lastCurrentTime);\n    this.lastCurrentTime = currentTime;\n  }\n\n  /**\n   * Checks if the playhead is stuck within a gap, and if so, attempts to free it.\n   * A gap is an unbuffered range between two buffered ranges (or the start and the first buffered range).\n   *\n   * @param lastCurrentTime - Previously read playhead position\n   */\n  poll(currentTime, lastCurrentTime) {\n    var _this$hls, _this$hls2;\n    const config = (_this$hls = this.hls) == null ? void 0 : _this$hls.config;\n    if (!config) {\n      return;\n    }\n    const media = this.media;\n    if (!media) {\n      return;\n    }\n    const {\n      seeking\n    } = media;\n    const seeked = this.seeking && !seeking;\n    const beginSeek = !this.seeking && seeking;\n    const pausedEndedOrHalted = media.paused && !seeking || media.ended || media.playbackRate === 0;\n    this.seeking = seeking;\n\n    // The playhead is moving, no-op\n    if (currentTime !== lastCurrentTime) {\n      if (lastCurrentTime) {\n        this.ended = 0;\n      }\n      this.moved = true;\n      if (!seeking) {\n        this.nudgeRetry = 0;\n        // When crossing between buffered video time ranges, but not audio, flush pipeline with seek (Chrome)\n        if (config.nudgeOnVideoHole && !pausedEndedOrHalted && currentTime > lastCurrentTime) {\n          this.nudgeOnVideoHole(currentTime, lastCurrentTime);\n        }\n      }\n      if (this.waiting === 0) {\n        this.stallResolved(currentTime);\n      }\n      return;\n    }\n\n    // Clear stalled state when beginning or finishing seeking so that we don't report stalls coming out of a seek\n    if (beginSeek || seeked) {\n      if (seeked) {\n        this.stallResolved(currentTime);\n      }\n      return;\n    }\n\n    // The playhead should not be moving\n    if (pausedEndedOrHalted) {\n      this.nudgeRetry = 0;\n      this.stallResolved(currentTime);\n      // Fire MEDIA_ENDED to workaround event not being dispatched by browser\n      if (!this.ended && media.ended && this.hls) {\n        this.ended = currentTime || 1;\n        this.hls.trigger(Events.MEDIA_ENDED, {\n          stalled: false\n        });\n      }\n      return;\n    }\n    if (!BufferHelper.getBuffered(media).length) {\n      this.nudgeRetry = 0;\n      return;\n    }\n\n    // Resolve stalls at buffer holes using the main buffer, whose ranges are the intersections of the A/V sourcebuffers\n    const bufferInfo = BufferHelper.bufferInfo(media, currentTime, 0);\n    const nextStart = bufferInfo.nextStart || 0;\n    const fragmentTracker = this.fragmentTracker;\n    if (seeking && fragmentTracker && this.hls) {\n      // Is there a fragment loading/parsing/appending before currentTime?\n      const inFlightDependency = getInFlightDependency(this.hls.inFlightFragments, currentTime);\n\n      // Waiting for seeking in a buffered range to complete\n      const hasEnoughBuffer = bufferInfo.len > MAX_START_GAP_JUMP;\n      // Next buffered range is too far ahead to jump to while still seeking\n      const noBufferHole = !nextStart || inFlightDependency || nextStart - currentTime > MAX_START_GAP_JUMP && !fragmentTracker.getPartialFragment(currentTime);\n      if (hasEnoughBuffer || noBufferHole) {\n        return;\n      }\n      // Reset moved state when seeking to a point in or before a gap/hole\n      this.moved = false;\n    }\n\n    // Skip start gaps if we haven't played, but the last poll detected the start of a stall\n    // The addition poll gives the browser a chance to jump the gap for us\n    const levelDetails = (_this$hls2 = this.hls) == null ? void 0 : _this$hls2.latestLevelDetails;\n    if (!this.moved && this.stalled !== null && fragmentTracker) {\n      // There is no playable buffer (seeked, waiting for buffer)\n      const isBuffered = bufferInfo.len > 0;\n      if (!isBuffered && !nextStart) {\n        return;\n      }\n      // Jump start gaps within jump threshold\n      const startJump = Math.max(nextStart, bufferInfo.start || 0) - currentTime;\n\n      // When joining a live stream with audio tracks, account for live playlist window sliding by allowing\n      // a larger jump over start gaps caused by the audio-stream-controller buffering a start fragment\n      // that begins over 1 target duration after the video start position.\n      const isLive = !!(levelDetails != null && levelDetails.live);\n      const maxStartGapJump = isLive ? levelDetails.targetduration * 2 : MAX_START_GAP_JUMP;\n      const appended = appendedFragAtPosition(currentTime, fragmentTracker);\n      if (startJump > 0 && (startJump <= maxStartGapJump || appended)) {\n        if (!media.paused) {\n          this._trySkipBufferHole(appended);\n        }\n        return;\n      }\n    }\n\n    // Start tracking stall time\n    const detectStallWithCurrentTimeMs = config.detectStallWithCurrentTimeMs;\n    const tnow = self.performance.now();\n    const tWaiting = this.waiting;\n    let stalled = this.stalled;\n    if (stalled === null) {\n      // Use time of recent \"waiting\" event\n      if (tWaiting > 0 && tnow - tWaiting < detectStallWithCurrentTimeMs) {\n        stalled = this.stalled = tWaiting;\n      } else {\n        this.stalled = tnow;\n        return;\n      }\n    }\n    const stalledDuration = tnow - stalled;\n    if (!seeking && (stalledDuration >= detectStallWithCurrentTimeMs || tWaiting) && this.hls) {\n      var _this$mediaSource;\n      // Dispatch MEDIA_ENDED when media.ended/ended event is not signalled at end of stream\n      if (((_this$mediaSource = this.mediaSource) == null ? void 0 : _this$mediaSource.readyState) === 'ended' && !(levelDetails != null && levelDetails.live) && Math.abs(currentTime - ((levelDetails == null ? void 0 : levelDetails.edge) || 0)) < 1) {\n        if (this.ended) {\n          return;\n        }\n        this.ended = currentTime || 1;\n        this.hls.trigger(Events.MEDIA_ENDED, {\n          stalled: true\n        });\n        return;\n      }\n      // Report stalling after trying to fix\n      this._reportStall(bufferInfo);\n      if (!this.media || !this.hls) {\n        return;\n      }\n    }\n    const bufferedWithHoles = BufferHelper.bufferInfo(media, currentTime, config.maxBufferHole);\n    this._tryFixBufferStall(bufferedWithHoles, stalledDuration, currentTime);\n  }\n  stallResolved(currentTime) {\n    const stalled = this.stalled;\n    if (stalled && this.hls) {\n      this.stalled = null;\n      // The playhead is now moving, but was previously stalled\n      if (this.stallReported) {\n        const stalledDuration = self.performance.now() - stalled;\n        this.log(`playback not stuck anymore @${currentTime}, after ${Math.round(stalledDuration)}ms`);\n        this.stallReported = false;\n        this.waiting = 0;\n        this.hls.trigger(Events.STALL_RESOLVED, {});\n      }\n    }\n  }\n  nudgeOnVideoHole(currentTime, lastCurrentTime) {\n    var _this$buffered$audio;\n    // Chrome will play one second past a hole in video buffered time ranges without rendering any video from the subsequent range and then stall as long as audio is buffered:\n    // https://github.com/video-dev/hls.js/issues/5631\n    // https://issues.chromium.org/issues/40280613#comment10\n    // Detect the potential for this situation and proactively seek to flush the video pipeline once the playhead passes the start of the video hole.\n    // When there are audio and video buffers and currentTime is past the end of the first video buffered range...\n    const videoSourceBuffered = this.buffered.video;\n    if (this.hls && this.media && this.fragmentTracker && (_this$buffered$audio = this.buffered.audio) != null && _this$buffered$audio.length && videoSourceBuffered && videoSourceBuffered.length > 1 && currentTime > videoSourceBuffered.end(0)) {\n      // and audio is buffered at the playhead\n      const audioBufferInfo = BufferHelper.bufferedInfo(BufferHelper.timeRangesToArray(this.buffered.audio), currentTime, 0);\n      if (audioBufferInfo.len > 1 && lastCurrentTime >= audioBufferInfo.start) {\n        const videoTimes = BufferHelper.timeRangesToArray(videoSourceBuffered);\n        const lastBufferedIndex = BufferHelper.bufferedInfo(videoTimes, lastCurrentTime, 0).bufferedIndex;\n        // nudge when crossing into another video buffered range (hole).\n        if (lastBufferedIndex > -1 && lastBufferedIndex < videoTimes.length - 1) {\n          const bufferedIndex = BufferHelper.bufferedInfo(videoTimes, currentTime, 0).bufferedIndex;\n          const holeStart = videoTimes[lastBufferedIndex].end;\n          const holeEnd = videoTimes[lastBufferedIndex + 1].start;\n          if ((bufferedIndex === -1 || bufferedIndex > lastBufferedIndex) && holeEnd - holeStart < 1 &&\n          // `maxBufferHole` may be too small and setting it to 0 should not disable this feature\n          currentTime - holeStart < 2) {\n            const error = new Error(`nudging playhead to flush pipeline after video hole. currentTime: ${currentTime} hole: ${holeStart} -> ${holeEnd} buffered index: ${bufferedIndex}`);\n            this.warn(error.message);\n            // Magic number to flush the pipeline without interuption to audio playback:\n            this.media.currentTime += 0.000001;\n            let frag = appendedFragAtPosition(currentTime, this.fragmentTracker);\n            if (frag && 'fragment' in frag) {\n              frag = frag.fragment;\n            } else if (!frag) {\n              frag = undefined;\n            }\n            const bufferInfo = BufferHelper.bufferInfo(this.media, currentTime, 0);\n            this.hls.trigger(Events.ERROR, {\n              type: ErrorTypes.MEDIA_ERROR,\n              details: ErrorDetails.BUFFER_SEEK_OVER_HOLE,\n              fatal: false,\n              error,\n              reason: error.message,\n              frag,\n              buffer: bufferInfo.len,\n              bufferInfo\n            });\n          }\n        }\n      }\n    }\n  }\n\n  /**\n   * Detects and attempts to fix known buffer stalling issues.\n   * @param bufferInfo - The properties of the current buffer.\n   * @param stalledDurationMs - The amount of time Hls.js has been stalling for.\n   * @private\n   */\n  _tryFixBufferStall(bufferInfo, stalledDurationMs, currentTime) {\n    var _this$hls3, _this$hls4;\n    const {\n      fragmentTracker,\n      media\n    } = this;\n    const config = (_this$hls3 = this.hls) == null ? void 0 : _this$hls3.config;\n    if (!media || !fragmentTracker || !config) {\n      return;\n    }\n    const levelDetails = (_this$hls4 = this.hls) == null ? void 0 : _this$hls4.latestLevelDetails;\n    const appended = appendedFragAtPosition(currentTime, fragmentTracker);\n    if (appended || levelDetails != null && levelDetails.live && currentTime < levelDetails.fragmentStart) {\n      // Try to skip over the buffer hole caused by a partial fragment\n      // This method isn't limited by the size of the gap between buffered ranges\n      const targetTime = this._trySkipBufferHole(appended);\n      // we return here in this case, meaning\n      // the branch below only executes when we haven't seeked to a new position\n      if (targetTime || !this.media) {\n        return;\n      }\n    }\n\n    // if we haven't had to skip over a buffer hole of a partial fragment\n    // we may just have to \"nudge\" the playlist as the browser decoding/rendering engine\n    // needs to cross some sort of threshold covering all source-buffers content\n    // to start playing properly.\n    const bufferedRanges = bufferInfo.buffered;\n    const adjacentTraversal = this.adjacentTraversal(bufferInfo, currentTime);\n    if ((bufferedRanges && bufferedRanges.length > 1 && bufferInfo.len > config.maxBufferHole || bufferInfo.nextStart && (bufferInfo.nextStart - currentTime < config.maxBufferHole || adjacentTraversal)) && (stalledDurationMs > config.highBufferWatchdogPeriod * 1000 || this.waiting)) {\n      this.warn('Trying to nudge playhead over buffer-hole');\n      // Try to nudge currentTime over a buffer hole if we've been stalling for the configured amount of seconds\n      // We only try to jump the hole if it's under the configured size\n      this._tryNudgeBuffer(bufferInfo);\n    }\n  }\n  adjacentTraversal(bufferInfo, currentTime) {\n    const fragmentTracker = this.fragmentTracker;\n    const nextStart = bufferInfo.nextStart;\n    if (fragmentTracker && nextStart) {\n      const current = fragmentTracker.getFragAtPos(currentTime, PlaylistLevelType.MAIN);\n      const next = fragmentTracker.getFragAtPos(nextStart, PlaylistLevelType.MAIN);\n      if (current && next) {\n        return next.sn - current.sn < 2;\n      }\n    }\n    return false;\n  }\n\n  /**\n   * Triggers a BUFFER_STALLED_ERROR event, but only once per stall period.\n   * @param bufferLen - The playhead distance from the end of the current buffer segment.\n   * @private\n   */\n  _reportStall(bufferInfo) {\n    const {\n      hls,\n      media,\n      stallReported,\n      stalled\n    } = this;\n    if (!stallReported && stalled !== null && media && hls) {\n      // Report stalled error once\n      this.stallReported = true;\n      const error = new Error(`Playback stalling at @${media.currentTime} due to low buffer (${stringify(bufferInfo)})`);\n      this.warn(error.message);\n      hls.trigger(Events.ERROR, {\n        type: ErrorTypes.MEDIA_ERROR,\n        details: ErrorDetails.BUFFER_STALLED_ERROR,\n        fatal: false,\n        error,\n        buffer: bufferInfo.len,\n        bufferInfo,\n        stalled: {\n          start: stalled\n        }\n      });\n    }\n  }\n\n  /**\n   * Attempts to fix buffer stalls by jumping over known gaps caused by partial fragments\n   * @param appended - The fragment or part found at the current time (where playback is stalling).\n   * @private\n   */\n  _trySkipBufferHole(appended) {\n    var _this$hls5;\n    const {\n      fragmentTracker,\n      media\n    } = this;\n    const config = (_this$hls5 = this.hls) == null ? void 0 : _this$hls5.config;\n    if (!media || !fragmentTracker || !config) {\n      return 0;\n    }\n\n    // Check if currentTime is between unbuffered regions of partial fragments\n    const currentTime = media.currentTime;\n    const bufferInfo = BufferHelper.bufferInfo(media, currentTime, 0);\n    const startTime = currentTime < bufferInfo.start ? bufferInfo.start : bufferInfo.nextStart;\n    if (startTime && this.hls) {\n      const bufferStarved = bufferInfo.len <= config.maxBufferHole;\n      const waiting = bufferInfo.len > 0 && bufferInfo.len < 1 && media.readyState < 3;\n      const gapLength = startTime - currentTime;\n      if (gapLength > 0 && (bufferStarved || waiting)) {\n        // Only allow large gaps to be skipped if it is a start gap, or all fragments in skip range are partial\n        if (gapLength > config.maxBufferHole) {\n          let startGap = false;\n          if (currentTime === 0) {\n            const startFrag = fragmentTracker.getAppendedFrag(0, PlaylistLevelType.MAIN);\n            if (startFrag && startTime < startFrag.end) {\n              startGap = true;\n            }\n          }\n          if (!startGap && appended) {\n            var _this$hls$loadLevelOb;\n            // Do not seek when selected variant playlist is unloaded\n            if (!((_this$hls$loadLevelOb = this.hls.loadLevelObj) != null && _this$hls$loadLevelOb.details)) {\n              return 0;\n            }\n            // Do not seek when required fragments are inflight or appending\n            const inFlightDependency = getInFlightDependency(this.hls.inFlightFragments, startTime);\n            if (inFlightDependency) {\n              return 0;\n            }\n            // Do not seek if we can't walk tracked fragments to end of gap\n            let moreToLoad = false;\n            let pos = appended.end;\n            while (pos < startTime) {\n              const provisioned = appendedFragAtPosition(pos, fragmentTracker);\n              if (provisioned) {\n                pos += provisioned.duration;\n              } else {\n                moreToLoad = true;\n                break;\n              }\n            }\n            if (moreToLoad) {\n              return 0;\n            }\n          }\n        }\n        const targetTime = Math.max(startTime + SKIP_BUFFER_RANGE_START, currentTime + SKIP_BUFFER_HOLE_STEP_SECONDS);\n        this.warn(`skipping hole, adjusting currentTime from ${currentTime} to ${targetTime}`);\n        this.moved = true;\n        media.currentTime = targetTime;\n        if (!(appended != null && appended.gap)) {\n          const error = new Error(`fragment loaded with buffer holes, seeking from ${currentTime} to ${targetTime}`);\n          const errorData = {\n            type: ErrorTypes.MEDIA_ERROR,\n            details: ErrorDetails.BUFFER_SEEK_OVER_HOLE,\n            fatal: false,\n            error,\n            reason: error.message,\n            buffer: bufferInfo.len,\n            bufferInfo\n          };\n          if (appended) {\n            if ('fragment' in appended) {\n              errorData.part = appended;\n            } else {\n              errorData.frag = appended;\n            }\n          }\n          this.hls.trigger(Events.ERROR, errorData);\n        }\n        return targetTime;\n      }\n    }\n    return 0;\n  }\n\n  /**\n   * Attempts to fix buffer stalls by advancing the mediaElement's current time by a small amount.\n   * @private\n   */\n  _tryNudgeBuffer(bufferInfo) {\n    const {\n      hls,\n      media,\n      nudgeRetry\n    } = this;\n    const config = hls == null ? void 0 : hls.config;\n    if (!media || !config) {\n      return 0;\n    }\n    const currentTime = media.currentTime;\n    this.nudgeRetry++;\n    if (nudgeRetry < config.nudgeMaxRetry) {\n      const targetTime = currentTime + (nudgeRetry + 1) * config.nudgeOffset;\n      // playback stalled in buffered area ... let's nudge currentTime to try to overcome this\n      const error = new Error(`Nudging 'currentTime' from ${currentTime} to ${targetTime}`);\n      this.warn(error.message);\n      media.currentTime = targetTime;\n      hls.trigger(Events.ERROR, {\n        type: ErrorTypes.MEDIA_ERROR,\n        details: ErrorDetails.BUFFER_NUDGE_ON_STALL,\n        error,\n        fatal: false,\n        buffer: bufferInfo.len,\n        bufferInfo\n      });\n    } else {\n      const error = new Error(`Playhead still not moving while enough data buffered @${currentTime} after ${config.nudgeMaxRetry} nudges`);\n      this.error(error.message);\n      hls.trigger(Events.ERROR, {\n        type: ErrorTypes.MEDIA_ERROR,\n        details: ErrorDetails.BUFFER_STALLED_ERROR,\n        error,\n        fatal: true,\n        buffer: bufferInfo.len,\n        bufferInfo\n      });\n    }\n  }\n}\nfunction getInFlightDependency(inFlightFragments, currentTime) {\n  const main = inFlight(inFlightFragments.main);\n  if (main && main.start <= currentTime) {\n    return main;\n  }\n  const audio = inFlight(inFlightFragments.audio);\n  if (audio && audio.start <= currentTime) {\n    return audio;\n  }\n  return null;\n}\nfunction inFlight(inFlightData) {\n  if (!inFlightData) {\n    return null;\n  }\n  switch (inFlightData.state) {\n    case State.IDLE:\n    case State.STOPPED:\n    case State.ENDED:\n    case State.ERROR:\n      return null;\n  }\n  return inFlightData.frag;\n}\nfunction appendedFragAtPosition(pos, fragmentTracker) {\n  return fragmentTracker.getAppendedFrag(pos, PlaylistLevelType.MAIN) || fragmentTracker.getPartialFragment(pos);\n}\n\nconst MIN_CUE_DURATION = 0.25;\nfunction getCueClass() {\n  if (typeof self === 'undefined') return undefined;\n  return self.VTTCue || self.TextTrackCue;\n}\nfunction createCueWithDataFields(Cue, startTime, endTime, data, type) {\n  let cue = new Cue(startTime, endTime, '');\n  try {\n    cue.value = data;\n    if (type) {\n      cue.type = type;\n    }\n  } catch (e) {\n    cue = new Cue(startTime, endTime, stringify(type ? _objectSpread2({\n      type\n    }, data) : data));\n  }\n  return cue;\n}\n\n// VTTCue latest draft allows an infinite duration, fallback\n// to MAX_VALUE if necessary\nconst MAX_CUE_ENDTIME = (() => {\n  const Cue = getCueClass();\n  try {\n    Cue && new Cue(0, Number.POSITIVE_INFINITY, '');\n  } catch (e) {\n    return Number.MAX_VALUE;\n  }\n  return Number.POSITIVE_INFINITY;\n})();\nclass ID3TrackController {\n  constructor(hls) {\n    this.hls = void 0;\n    this.id3Track = null;\n    this.media = null;\n    this.dateRangeCuesAppended = {};\n    this.removeCues = true;\n    this.assetCue = void 0;\n    this.onEventCueEnter = () => {\n      if (!this.hls) {\n        return;\n      }\n      this.hls.trigger(Events.EVENT_CUE_ENTER, {});\n    };\n    this.hls = hls;\n    this._registerListeners();\n  }\n  destroy() {\n    this._unregisterListeners();\n    this.id3Track = null;\n    this.media = null;\n    this.dateRangeCuesAppended = {};\n    // @ts-ignore\n    this.hls = this.onEventCueEnter = null;\n  }\n  _registerListeners() {\n    const {\n      hls\n    } = this;\n    if (hls) {\n      hls.on(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);\n      hls.on(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n      hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n      hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      hls.on(Events.FRAG_PARSING_METADATA, this.onFragParsingMetadata, this);\n      hls.on(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);\n      hls.on(Events.LEVEL_UPDATED, this.onLevelUpdated, this);\n      hls.on(Events.LEVEL_PTS_UPDATED, this.onLevelPtsUpdated, this);\n    }\n  }\n  _unregisterListeners() {\n    const {\n      hls\n    } = this;\n    if (hls) {\n      hls.off(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);\n      hls.off(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n      hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n      hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      hls.off(Events.FRAG_PARSING_METADATA, this.onFragParsingMetadata, this);\n      hls.off(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);\n      hls.off(Events.LEVEL_UPDATED, this.onLevelUpdated, this);\n      hls.off(Events.LEVEL_PTS_UPDATED, this.onLevelPtsUpdated, this);\n    }\n  }\n  // Add ID3 metatadata text track.\n  onMediaAttaching(event, data) {\n    var _data$overrides;\n    this.media = data.media;\n    if (((_data$overrides = data.overrides) == null ? void 0 : _data$overrides.cueRemoval) === false) {\n      this.removeCues = false;\n    }\n  }\n  onMediaAttached() {\n    var _this$hls;\n    const details = (_this$hls = this.hls) == null ? void 0 : _this$hls.latestLevelDetails;\n    if (details) {\n      this.updateDateRangeCues(details);\n    }\n  }\n  onMediaDetaching(event, data) {\n    this.media = null;\n    const transferringMedia = !!data.transferMedia;\n    if (transferringMedia) {\n      return;\n    }\n    if (this.id3Track) {\n      if (this.removeCues) {\n        clearCurrentCues(this.id3Track, this.onEventCueEnter);\n      }\n      this.id3Track = null;\n    }\n    this.dateRangeCuesAppended = {};\n  }\n  onManifestLoading() {\n    this.dateRangeCuesAppended = {};\n  }\n  createTrack(media) {\n    const track = this.getID3Track(media.textTracks);\n    track.mode = 'hidden';\n    return track;\n  }\n  getID3Track(textTracks) {\n    if (!this.media) {\n      return;\n    }\n    for (let i = 0; i < textTracks.length; i++) {\n      const textTrack = textTracks[i];\n      if (textTrack.kind === 'metadata' && textTrack.label === 'id3') {\n        // send 'addtrack' when reusing the textTrack for metadata,\n        // same as what we do for captions\n        sendAddTrackEvent(textTrack, this.media);\n        return textTrack;\n      }\n    }\n    return this.media.addTextTrack('metadata', 'id3');\n  }\n  onFragParsingMetadata(event, data) {\n    if (!this.media || !this.hls) {\n      return;\n    }\n    const {\n      enableEmsgMetadataCues,\n      enableID3MetadataCues\n    } = this.hls.config;\n    if (!enableEmsgMetadataCues && !enableID3MetadataCues) {\n      return;\n    }\n    const {\n      samples\n    } = data;\n\n    // create track dynamically\n    if (!this.id3Track) {\n      this.id3Track = this.createTrack(this.media);\n    }\n    const Cue = getCueClass();\n    if (!Cue) {\n      return;\n    }\n    for (let i = 0; i < samples.length; i++) {\n      const type = samples[i].type;\n      if (type === MetadataSchema.emsg && !enableEmsgMetadataCues || !enableID3MetadataCues) {\n        continue;\n      }\n      const frames = getId3Frames(samples[i].data);\n      const startTime = samples[i].pts;\n      let endTime = startTime + samples[i].duration;\n      if (endTime > MAX_CUE_ENDTIME) {\n        endTime = MAX_CUE_ENDTIME;\n      }\n      const timeDiff = endTime - startTime;\n      if (timeDiff <= 0) {\n        endTime = startTime + MIN_CUE_DURATION;\n      }\n      for (let j = 0; j < frames.length; j++) {\n        const frame = frames[j];\n        // Safari doesn't put the timestamp frame in the TextTrack\n        if (!isId3TimestampFrame(frame)) {\n          // add a bounds to any unbounded cues\n          this.updateId3CueEnds(startTime, type);\n          const cue = createCueWithDataFields(Cue, startTime, endTime, frame, type);\n          if (cue) {\n            this.id3Track.addCue(cue);\n          }\n        }\n      }\n    }\n  }\n  updateId3CueEnds(startTime, type) {\n    var _this$id3Track;\n    const cues = (_this$id3Track = this.id3Track) == null ? void 0 : _this$id3Track.cues;\n    if (cues) {\n      for (let i = cues.length; i--;) {\n        const cue = cues[i];\n        if (cue.type === type && cue.startTime < startTime && cue.endTime === MAX_CUE_ENDTIME) {\n          cue.endTime = startTime;\n        }\n      }\n    }\n  }\n  onBufferFlushing(event, {\n    startOffset,\n    endOffset,\n    type\n  }) {\n    const {\n      id3Track,\n      hls\n    } = this;\n    if (!hls) {\n      return;\n    }\n    const {\n      config: {\n        enableEmsgMetadataCues,\n        enableID3MetadataCues\n      }\n    } = hls;\n    if (id3Track && (enableEmsgMetadataCues || enableID3MetadataCues)) {\n      let predicate;\n      if (type === 'audio') {\n        predicate = cue => cue.type === MetadataSchema.audioId3 && enableID3MetadataCues;\n      } else if (type === 'video') {\n        predicate = cue => cue.type === MetadataSchema.emsg && enableEmsgMetadataCues;\n      } else {\n        predicate = cue => cue.type === MetadataSchema.audioId3 && enableID3MetadataCues || cue.type === MetadataSchema.emsg && enableEmsgMetadataCues;\n      }\n      removeCuesInRange(id3Track, startOffset, endOffset, predicate);\n    }\n  }\n  onLevelUpdated(event, {\n    details\n  }) {\n    this.updateDateRangeCues(details, true);\n  }\n  onLevelPtsUpdated(event, data) {\n    if (Math.abs(data.drift) > 0.01) {\n      this.updateDateRangeCues(data.details);\n    }\n  }\n  updateDateRangeCues(details, removeOldCues) {\n    if (!this.hls || !this.media) {\n      return;\n    }\n    const {\n      assetPlayerId,\n      timelineOffset,\n      enableDateRangeMetadataCues,\n      interstitialsController\n    } = this.hls.config;\n    if (!enableDateRangeMetadataCues) {\n      return;\n    }\n    const Cue = getCueClass();\n    if (assetPlayerId && timelineOffset && !interstitialsController) {\n      const {\n        fragmentStart,\n        fragmentEnd\n      } = details;\n      let cue = this.assetCue;\n      if (cue) {\n        cue.startTime = fragmentStart;\n        cue.endTime = fragmentEnd;\n      } else if (Cue) {\n        cue = this.assetCue = createCueWithDataFields(Cue, fragmentStart, fragmentEnd, {\n          assetPlayerId: this.hls.config.assetPlayerId\n        }, 'hlsjs.interstitial.asset');\n        if (cue) {\n          cue.id = assetPlayerId;\n          this.id3Track || (this.id3Track = this.createTrack(this.media));\n          this.id3Track.addCue(cue);\n          cue.addEventListener('enter', this.onEventCueEnter);\n        }\n      }\n    }\n    if (!details.hasProgramDateTime) {\n      return;\n    }\n    const {\n      id3Track\n    } = this;\n    const {\n      dateRanges\n    } = details;\n    const ids = Object.keys(dateRanges);\n    let dateRangeCuesAppended = this.dateRangeCuesAppended;\n    // Remove cues from track not found in details.dateRanges\n    if (id3Track && removeOldCues) {\n      var _id3Track$cues;\n      if ((_id3Track$cues = id3Track.cues) != null && _id3Track$cues.length) {\n        const idsToRemove = Object.keys(dateRangeCuesAppended).filter(id => !ids.includes(id));\n        for (let i = idsToRemove.length; i--;) {\n          var _dateRangeCuesAppende;\n          const id = idsToRemove[i];\n          const cues = (_dateRangeCuesAppende = dateRangeCuesAppended[id]) == null ? void 0 : _dateRangeCuesAppende.cues;\n          delete dateRangeCuesAppended[id];\n          if (cues) {\n            Object.keys(cues).forEach(key => {\n              const cue = cues[key];\n              if (cue) {\n                cue.removeEventListener('enter', this.onEventCueEnter);\n                try {\n                  id3Track.removeCue(cue);\n                } catch (e) {\n                  /* no-op */\n                }\n              }\n            });\n          }\n        }\n      } else {\n        dateRangeCuesAppended = this.dateRangeCuesAppended = {};\n      }\n    }\n    // Exit if the playlist does not have Date Ranges or does not have Program Date Time\n    const lastFragment = details.fragments[details.fragments.length - 1];\n    if (ids.length === 0 || !isFiniteNumber(lastFragment == null ? void 0 : lastFragment.programDateTime)) {\n      return;\n    }\n    this.id3Track || (this.id3Track = this.createTrack(this.media));\n    for (let i = 0; i < ids.length; i++) {\n      const id = ids[i];\n      const dateRange = dateRanges[id];\n      const startTime = dateRange.startTime;\n\n      // Process DateRanges to determine end-time (known DURATION, END-DATE, or END-ON-NEXT)\n      const appendedDateRangeCues = dateRangeCuesAppended[id];\n      const cues = (appendedDateRangeCues == null ? void 0 : appendedDateRangeCues.cues) || {};\n      let durationKnown = (appendedDateRangeCues == null ? void 0 : appendedDateRangeCues.durationKnown) || false;\n      let endTime = MAX_CUE_ENDTIME;\n      const {\n        duration,\n        endDate\n      } = dateRange;\n      if (endDate && duration !== null) {\n        endTime = startTime + duration;\n        durationKnown = true;\n      } else if (dateRange.endOnNext && !durationKnown) {\n        const nextDateRangeWithSameClass = ids.reduce((candidateDateRange, id) => {\n          if (id !== dateRange.id) {\n            const otherDateRange = dateRanges[id];\n            if (otherDateRange.class === dateRange.class && otherDateRange.startDate > dateRange.startDate && (!candidateDateRange || dateRange.startDate < candidateDateRange.startDate)) {\n              return otherDateRange;\n            }\n          }\n          return candidateDateRange;\n        }, null);\n        if (nextDateRangeWithSameClass) {\n          endTime = nextDateRangeWithSameClass.startTime;\n          durationKnown = true;\n        }\n      }\n\n      // Create TextTrack Cues for each MetadataGroup Item (select DateRange attribute)\n      // This is to emulate Safari HLS playback handling of DateRange tags\n      const attributes = Object.keys(dateRange.attr);\n      for (let j = 0; j < attributes.length; j++) {\n        const key = attributes[j];\n        if (!isDateRangeCueAttribute(key)) {\n          continue;\n        }\n        const cue = cues[key];\n        if (cue) {\n          if (durationKnown && !(appendedDateRangeCues != null && appendedDateRangeCues.durationKnown)) {\n            cue.endTime = endTime;\n          } else if (Math.abs(cue.startTime - startTime) > 0.01) {\n            cue.startTime = startTime;\n            cue.endTime = endTime;\n          }\n        } else if (Cue) {\n          let data = dateRange.attr[key];\n          if (isSCTE35Attribute(key)) {\n            data = hexToArrayBuffer(data);\n          }\n          const payload = {\n            key,\n            data\n          };\n          const _cue = createCueWithDataFields(Cue, startTime, endTime, payload, MetadataSchema.dateRange);\n          if (_cue) {\n            _cue.id = id;\n            this.id3Track.addCue(_cue);\n            cues[key] = _cue;\n            if (interstitialsController) {\n              if (key === 'X-ASSET-LIST' || key === 'X-ASSET-URL') {\n                _cue.addEventListener('enter', this.onEventCueEnter);\n              }\n            }\n          }\n        }\n      }\n\n      // Keep track of processed DateRanges by ID for updating cues with new DateRange tag attributes\n      dateRangeCuesAppended[id] = {\n        cues,\n        dateRange,\n        durationKnown\n      };\n    }\n  }\n}\n\nclass LatencyController {\n  constructor(hls) {\n    this.hls = void 0;\n    this.config = void 0;\n    this.media = null;\n    this.currentTime = 0;\n    this.stallCount = 0;\n    this._latency = null;\n    this._targetLatencyUpdated = false;\n    this.onTimeupdate = () => {\n      const {\n        media\n      } = this;\n      const levelDetails = this.levelDetails;\n      if (!media || !levelDetails) {\n        return;\n      }\n      this.currentTime = media.currentTime;\n      const latency = this.computeLatency();\n      if (latency === null) {\n        return;\n      }\n      this._latency = latency;\n\n      // Adapt playbackRate to meet target latency in low-latency mode\n      const {\n        lowLatencyMode,\n        maxLiveSyncPlaybackRate\n      } = this.config;\n      if (!lowLatencyMode || maxLiveSyncPlaybackRate === 1 || !levelDetails.live) {\n        return;\n      }\n      const targetLatency = this.targetLatency;\n      if (targetLatency === null) {\n        return;\n      }\n      const distanceFromTarget = latency - targetLatency;\n      // Only adjust playbackRate when within one target duration of targetLatency\n      // and more than one second from under-buffering.\n      // Playback further than one target duration from target can be considered DVR playback.\n      const liveMinLatencyDuration = Math.min(this.maxLatency, targetLatency + levelDetails.targetduration);\n      const inLiveRange = distanceFromTarget < liveMinLatencyDuration;\n      if (inLiveRange && distanceFromTarget > 0.05 && this.forwardBufferLength > 1) {\n        const max = Math.min(2, Math.max(1.0, maxLiveSyncPlaybackRate));\n        const rate = Math.round(2 / (1 + Math.exp(-0.75 * distanceFromTarget - this.edgeStalled)) * 20) / 20;\n        const playbackRate = Math.min(max, Math.max(1, rate));\n        this.changeMediaPlaybackRate(media, playbackRate);\n      } else if (media.playbackRate !== 1 && media.playbackRate !== 0) {\n        this.changeMediaPlaybackRate(media, 1);\n      }\n    };\n    this.hls = hls;\n    this.config = hls.config;\n    this.registerListeners();\n  }\n  get levelDetails() {\n    var _this$hls;\n    return ((_this$hls = this.hls) == null ? void 0 : _this$hls.latestLevelDetails) || null;\n  }\n  get latency() {\n    return this._latency || 0;\n  }\n  get maxLatency() {\n    const {\n      config\n    } = this;\n    if (config.liveMaxLatencyDuration !== undefined) {\n      return config.liveMaxLatencyDuration;\n    }\n    const levelDetails = this.levelDetails;\n    return levelDetails ? config.liveMaxLatencyDurationCount * levelDetails.targetduration : 0;\n  }\n  get targetLatency() {\n    const levelDetails = this.levelDetails;\n    if (levelDetails === null || this.hls === null) {\n      return null;\n    }\n    const {\n      holdBack,\n      partHoldBack,\n      targetduration\n    } = levelDetails;\n    const {\n      liveSyncDuration,\n      liveSyncDurationCount,\n      lowLatencyMode\n    } = this.config;\n    const userConfig = this.hls.userConfig;\n    let targetLatency = lowLatencyMode ? partHoldBack || holdBack : holdBack;\n    if (this._targetLatencyUpdated || userConfig.liveSyncDuration || userConfig.liveSyncDurationCount || targetLatency === 0) {\n      targetLatency = liveSyncDuration !== undefined ? liveSyncDuration : liveSyncDurationCount * targetduration;\n    }\n    const maxLiveSyncOnStallIncrease = targetduration;\n    return targetLatency + Math.min(this.stallCount * this.config.liveSyncOnStallIncrease, maxLiveSyncOnStallIncrease);\n  }\n  set targetLatency(latency) {\n    this.stallCount = 0;\n    this.config.liveSyncDuration = latency;\n    this._targetLatencyUpdated = true;\n  }\n  get liveSyncPosition() {\n    const liveEdge = this.estimateLiveEdge();\n    const targetLatency = this.targetLatency;\n    if (liveEdge === null || targetLatency === null) {\n      return null;\n    }\n    const levelDetails = this.levelDetails;\n    if (levelDetails === null) {\n      return null;\n    }\n    const edge = levelDetails.edge;\n    const syncPosition = liveEdge - targetLatency - this.edgeStalled;\n    const min = edge - levelDetails.totalduration;\n    const max = edge - (this.config.lowLatencyMode && levelDetails.partTarget || levelDetails.targetduration);\n    return Math.min(Math.max(min, syncPosition), max);\n  }\n  get drift() {\n    const levelDetails = this.levelDetails;\n    if (levelDetails === null) {\n      return 1;\n    }\n    return levelDetails.drift;\n  }\n  get edgeStalled() {\n    const levelDetails = this.levelDetails;\n    if (levelDetails === null) {\n      return 0;\n    }\n    const maxLevelUpdateAge = (this.config.lowLatencyMode && levelDetails.partTarget || levelDetails.targetduration) * 3;\n    return Math.max(levelDetails.age - maxLevelUpdateAge, 0);\n  }\n  get forwardBufferLength() {\n    const {\n      media\n    } = this;\n    const levelDetails = this.levelDetails;\n    if (!media || !levelDetails) {\n      return 0;\n    }\n    const bufferedRanges = media.buffered.length;\n    return (bufferedRanges ? media.buffered.end(bufferedRanges - 1) : levelDetails.edge) - this.currentTime;\n  }\n  destroy() {\n    this.unregisterListeners();\n    this.onMediaDetaching();\n    this.hls = null;\n  }\n  registerListeners() {\n    const {\n      hls\n    } = this;\n    if (!hls) {\n      return;\n    }\n    hls.on(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n    hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.on(Events.LEVEL_UPDATED, this.onLevelUpdated, this);\n    hls.on(Events.ERROR, this.onError, this);\n  }\n  unregisterListeners() {\n    const {\n      hls\n    } = this;\n    if (!hls) {\n      return;\n    }\n    hls.off(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n    hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.off(Events.LEVEL_UPDATED, this.onLevelUpdated, this);\n    hls.off(Events.ERROR, this.onError, this);\n  }\n  onMediaAttached(event, data) {\n    this.media = data.media;\n    this.media.addEventListener('timeupdate', this.onTimeupdate);\n  }\n  onMediaDetaching() {\n    if (this.media) {\n      this.media.removeEventListener('timeupdate', this.onTimeupdate);\n      this.media = null;\n    }\n  }\n  onManifestLoading() {\n    this._latency = null;\n    this.stallCount = 0;\n  }\n  onLevelUpdated(event, {\n    details\n  }) {\n    if (details.advanced) {\n      this.onTimeupdate();\n    }\n    if (!details.live && this.media) {\n      this.media.removeEventListener('timeupdate', this.onTimeupdate);\n    }\n  }\n  onError(event, data) {\n    var _this$levelDetails;\n    if (data.details !== ErrorDetails.BUFFER_STALLED_ERROR) {\n      return;\n    }\n    this.stallCount++;\n    if (this.hls && (_this$levelDetails = this.levelDetails) != null && _this$levelDetails.live) {\n      this.hls.logger.warn('[latency-controller]: Stall detected, adjusting target latency');\n    }\n  }\n  changeMediaPlaybackRate(media, playbackRate) {\n    var _this$hls2, _this$targetLatency;\n    if (media.playbackRate === playbackRate) {\n      return;\n    }\n    (_this$hls2 = this.hls) == null || _this$hls2.logger.debug(`[latency-controller]: latency=${this.latency.toFixed(3)}, targetLatency=${(_this$targetLatency = this.targetLatency) == null ? void 0 : _this$targetLatency.toFixed(3)}, forwardBufferLength=${this.forwardBufferLength.toFixed(3)}: adjusting playback rate from ${media.playbackRate} to ${playbackRate}`);\n    media.playbackRate = playbackRate;\n  }\n  estimateLiveEdge() {\n    const levelDetails = this.levelDetails;\n    if (levelDetails === null) {\n      return null;\n    }\n    return levelDetails.edge + levelDetails.age;\n  }\n  computeLatency() {\n    const liveEdge = this.estimateLiveEdge();\n    if (liveEdge === null) {\n      return null;\n    }\n    return liveEdge - this.currentTime;\n  }\n}\n\nclass LevelController extends BasePlaylistController {\n  constructor(hls, contentSteeringController) {\n    super(hls, 'level-controller');\n    this._levels = [];\n    this._firstLevel = -1;\n    this._maxAutoLevel = -1;\n    this._startLevel = void 0;\n    this.currentLevel = null;\n    this.currentLevelIndex = -1;\n    this.manualLevelIndex = -1;\n    this.steering = void 0;\n    this.onParsedComplete = void 0;\n    this.steering = contentSteeringController;\n    this._registerListeners();\n  }\n  _registerListeners() {\n    const {\n      hls\n    } = this;\n    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.on(Events.MANIFEST_LOADED, this.onManifestLoaded, this);\n    hls.on(Events.LEVEL_LOADED, this.onLevelLoaded, this);\n    hls.on(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);\n    hls.on(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n    hls.on(Events.ERROR, this.onError, this);\n  }\n  _unregisterListeners() {\n    const {\n      hls\n    } = this;\n    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.off(Events.MANIFEST_LOADED, this.onManifestLoaded, this);\n    hls.off(Events.LEVEL_LOADED, this.onLevelLoaded, this);\n    hls.off(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);\n    hls.off(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n    hls.off(Events.ERROR, this.onError, this);\n  }\n  destroy() {\n    this._unregisterListeners();\n    this.steering = null;\n    this.resetLevels();\n    super.destroy();\n  }\n  stopLoad() {\n    const levels = this._levels;\n\n    // clean up live level details to force reload them, and reset load errors\n    levels.forEach(level => {\n      level.loadError = 0;\n      level.fragmentError = 0;\n    });\n    super.stopLoad();\n  }\n  resetLevels() {\n    this._startLevel = undefined;\n    this.manualLevelIndex = -1;\n    this.currentLevelIndex = -1;\n    this.currentLevel = null;\n    this._levels = [];\n    this._maxAutoLevel = -1;\n  }\n  onManifestLoading(event, data) {\n    this.resetLevels();\n  }\n  onManifestLoaded(event, data) {\n    const preferManagedMediaSource = this.hls.config.preferManagedMediaSource;\n    const levels = [];\n    const redundantSet = {};\n    const generatePathwaySet = {};\n    let resolutionFound = false;\n    let videoCodecFound = false;\n    let audioCodecFound = false;\n    data.levels.forEach(levelParsed => {\n      const attributes = levelParsed.attrs;\n      let {\n        audioCodec,\n        videoCodec\n      } = levelParsed;\n      if (audioCodec) {\n        // Returns empty and set to undefined for 'mp4a.40.34' with fallback to 'audio/mpeg' SourceBuffer\n        levelParsed.audioCodec = audioCodec = getCodecCompatibleName(audioCodec, preferManagedMediaSource) || undefined;\n      }\n      if (videoCodec) {\n        videoCodec = levelParsed.videoCodec = convertAVC1ToAVCOTI(videoCodec);\n      }\n\n      // only keep levels with supported audio/video codecs\n      const {\n        width,\n        height,\n        unknownCodecs\n      } = levelParsed;\n      const unknownUnsupportedCodecCount = (unknownCodecs == null ? void 0 : unknownCodecs.length) || 0;\n      resolutionFound || (resolutionFound = !!(width && height));\n      videoCodecFound || (videoCodecFound = !!videoCodec);\n      audioCodecFound || (audioCodecFound = !!audioCodec);\n      if (unknownUnsupportedCodecCount || audioCodec && !this.isAudioSupported(audioCodec) || videoCodec && !this.isVideoSupported(videoCodec)) {\n        this.log(`Some or all CODECS not supported \"${attributes.CODECS}\"`);\n        return;\n      }\n      const {\n        CODECS,\n        'FRAME-RATE': FRAMERATE,\n        'HDCP-LEVEL': HDCP,\n        'PATHWAY-ID': PATHWAY,\n        RESOLUTION,\n        'VIDEO-RANGE': VIDEO_RANGE\n      } = attributes;\n      const contentSteeringPrefix = `${PATHWAY || '.'}-`;\n      const levelKey = `${contentSteeringPrefix}${levelParsed.bitrate}-${RESOLUTION}-${FRAMERATE}-${CODECS}-${VIDEO_RANGE}-${HDCP}`;\n      if (!redundantSet[levelKey]) {\n        const level = this.createLevel(levelParsed);\n        redundantSet[levelKey] = level;\n        generatePathwaySet[levelKey] = 1;\n        levels.push(level);\n      } else if (redundantSet[levelKey].uri !== levelParsed.url && !levelParsed.attrs['PATHWAY-ID']) {\n        // Assign Pathway IDs to Redundant Streams (default Pathways is \".\". Redundant Streams \"..\", \"...\", and so on.)\n        // Content Steering controller to handles Pathway fallback on error\n        const pathwayCount = generatePathwaySet[levelKey] += 1;\n        levelParsed.attrs['PATHWAY-ID'] = new Array(pathwayCount + 1).join('.');\n        const level = this.createLevel(levelParsed);\n        redundantSet[levelKey] = level;\n        levels.push(level);\n      } else {\n        redundantSet[levelKey].addGroupId('audio', attributes.AUDIO);\n        redundantSet[levelKey].addGroupId('text', attributes.SUBTITLES);\n      }\n    });\n    this.filterAndSortMediaOptions(levels, data, resolutionFound, videoCodecFound, audioCodecFound);\n  }\n  createLevel(levelParsed) {\n    const level = new Level(levelParsed);\n    const supplemental = levelParsed.supplemental;\n    if (supplemental != null && supplemental.videoCodec && !this.isVideoSupported(supplemental.videoCodec)) {\n      const error = new Error(`SUPPLEMENTAL-CODECS not supported \"${supplemental.videoCodec}\"`);\n      this.log(error.message);\n      level.supportedResult = getUnsupportedResult(error, []);\n    }\n    return level;\n  }\n  isAudioSupported(codec) {\n    return areCodecsMediaSourceSupported(codec, 'audio', this.hls.config.preferManagedMediaSource);\n  }\n  isVideoSupported(codec) {\n    return areCodecsMediaSourceSupported(codec, 'video', this.hls.config.preferManagedMediaSource);\n  }\n  filterAndSortMediaOptions(filteredLevels, data, resolutionFound, videoCodecFound, audioCodecFound) {\n    var _data$stats;\n    let audioTracks = [];\n    let subtitleTracks = [];\n    let levels = filteredLevels;\n    const statsParsing = ((_data$stats = data.stats) == null ? void 0 : _data$stats.parsing) || {};\n\n    // remove audio-only and invalid video-range levels if we also have levels with video codecs or RESOLUTION signalled\n    if ((resolutionFound || videoCodecFound) && audioCodecFound) {\n      levels = levels.filter(({\n        videoCodec,\n        videoRange,\n        width,\n        height\n      }) => (!!videoCodec || !!(width && height)) && isVideoRange(videoRange));\n    }\n    if (levels.length === 0) {\n      // Dispatch error after MANIFEST_LOADED is done propagating\n      // eslint-disable-next-line @typescript-eslint/no-floating-promises\n      Promise.resolve().then(() => {\n        if (this.hls) {\n          let message = 'no level with compatible codecs found in manifest';\n          let reason = message;\n          if (data.levels.length) {\n            reason = `one or more CODECS in variant not supported: ${stringify(data.levels.map(level => level.attrs.CODECS).filter((value, index, array) => array.indexOf(value) === index))}`;\n            this.warn(reason);\n            message += ` (${reason})`;\n          }\n          const error = new Error(message);\n          this.hls.trigger(Events.ERROR, {\n            type: ErrorTypes.MEDIA_ERROR,\n            details: ErrorDetails.MANIFEST_INCOMPATIBLE_CODECS_ERROR,\n            fatal: true,\n            url: data.url,\n            error,\n            reason\n          });\n        }\n      });\n      statsParsing.end = performance.now();\n      return;\n    }\n    if (data.audioTracks) {\n      audioTracks = data.audioTracks.filter(track => !track.audioCodec || this.isAudioSupported(track.audioCodec));\n      // Assign ids after filtering as array indices by group-id\n      assignTrackIdsByGroup(audioTracks);\n    }\n    if (data.subtitles) {\n      subtitleTracks = data.subtitles;\n      assignTrackIdsByGroup(subtitleTracks);\n    }\n    // start bitrate is the first bitrate of the manifest\n    const unsortedLevels = levels.slice(0);\n    // sort levels from lowest to highest\n    levels.sort((a, b) => {\n      if (a.attrs['HDCP-LEVEL'] !== b.attrs['HDCP-LEVEL']) {\n        return (a.attrs['HDCP-LEVEL'] || '') > (b.attrs['HDCP-LEVEL'] || '') ? 1 : -1;\n      }\n      // sort on height before bitrate for cap-level-controller\n      if (resolutionFound && a.height !== b.height) {\n        return a.height - b.height;\n      }\n      if (a.frameRate !== b.frameRate) {\n        return a.frameRate - b.frameRate;\n      }\n      if (a.videoRange !== b.videoRange) {\n        return VideoRangeValues.indexOf(a.videoRange) - VideoRangeValues.indexOf(b.videoRange);\n      }\n      if (a.videoCodec !== b.videoCodec) {\n        const valueA = videoCodecPreferenceValue(a.videoCodec);\n        const valueB = videoCodecPreferenceValue(b.videoCodec);\n        if (valueA !== valueB) {\n          return valueB - valueA;\n        }\n      }\n      if (a.uri === b.uri && a.codecSet !== b.codecSet) {\n        const valueA = codecsSetSelectionPreferenceValue(a.codecSet);\n        const valueB = codecsSetSelectionPreferenceValue(b.codecSet);\n        if (valueA !== valueB) {\n          return valueB - valueA;\n        }\n      }\n      if (a.averageBitrate !== b.averageBitrate) {\n        return a.averageBitrate - b.averageBitrate;\n      }\n      return 0;\n    });\n    let firstLevelInPlaylist = unsortedLevels[0];\n    if (this.steering) {\n      levels = this.steering.filterParsedLevels(levels);\n      if (levels.length !== unsortedLevels.length) {\n        for (let i = 0; i < unsortedLevels.length; i++) {\n          if (unsortedLevels[i].pathwayId === levels[0].pathwayId) {\n            firstLevelInPlaylist = unsortedLevels[i];\n            break;\n          }\n        }\n      }\n    }\n    this._levels = levels;\n\n    // find index of first level in sorted levels\n    for (let i = 0; i < levels.length; i++) {\n      if (levels[i] === firstLevelInPlaylist) {\n        var _this$hls$userConfig;\n        this._firstLevel = i;\n        const firstLevelBitrate = firstLevelInPlaylist.bitrate;\n        const bandwidthEstimate = this.hls.bandwidthEstimate;\n        this.log(`manifest loaded, ${levels.length} level(s) found, first bitrate: ${firstLevelBitrate}`);\n        // Update default bwe to first variant bitrate as long it has not been configured or set\n        if (((_this$hls$userConfig = this.hls.userConfig) == null ? void 0 : _this$hls$userConfig.abrEwmaDefaultEstimate) === undefined) {\n          const startingBwEstimate = Math.min(firstLevelBitrate, this.hls.config.abrEwmaDefaultEstimateMax);\n          if (startingBwEstimate > bandwidthEstimate && bandwidthEstimate === this.hls.abrEwmaDefaultEstimate) {\n            this.hls.bandwidthEstimate = startingBwEstimate;\n          }\n        }\n        break;\n      }\n    }\n\n    // Audio is only alternate if manifest include a URI along with the audio group tag,\n    // and this is not an audio-only stream where levels contain audio-only\n    const audioOnly = audioCodecFound && !videoCodecFound;\n    const config = this.hls.config;\n    const altAudioEnabled = !!(config.audioStreamController && config.audioTrackController);\n    const edata = {\n      levels,\n      audioTracks,\n      subtitleTracks,\n      sessionData: data.sessionData,\n      sessionKeys: data.sessionKeys,\n      firstLevel: this._firstLevel,\n      stats: data.stats,\n      audio: audioCodecFound,\n      video: videoCodecFound,\n      altAudio: altAudioEnabled && !audioOnly && audioTracks.some(t => !!t.url)\n    };\n    statsParsing.end = performance.now();\n    this.hls.trigger(Events.MANIFEST_PARSED, edata);\n  }\n  get levels() {\n    if (this._levels.length === 0) {\n      return null;\n    }\n    return this._levels;\n  }\n  get loadLevelObj() {\n    return this.currentLevel;\n  }\n  get level() {\n    return this.currentLevelIndex;\n  }\n  set level(newLevel) {\n    const levels = this._levels;\n    if (levels.length === 0) {\n      return;\n    }\n    // check if level idx is valid\n    if (newLevel < 0 || newLevel >= levels.length) {\n      // invalid level id given, trigger error\n      const error = new Error('invalid level idx');\n      const fatal = newLevel < 0;\n      this.hls.trigger(Events.ERROR, {\n        type: ErrorTypes.OTHER_ERROR,\n        details: ErrorDetails.LEVEL_SWITCH_ERROR,\n        level: newLevel,\n        fatal,\n        error,\n        reason: error.message\n      });\n      if (fatal) {\n        return;\n      }\n      newLevel = Math.min(newLevel, levels.length - 1);\n    }\n    const lastLevelIndex = this.currentLevelIndex;\n    const lastLevel = this.currentLevel;\n    const lastPathwayId = lastLevel ? lastLevel.attrs['PATHWAY-ID'] : undefined;\n    const level = levels[newLevel];\n    const pathwayId = level.attrs['PATHWAY-ID'];\n    this.currentLevelIndex = newLevel;\n    this.currentLevel = level;\n    if (lastLevelIndex === newLevel && lastLevel && lastPathwayId === pathwayId) {\n      return;\n    }\n    this.log(`Switching to level ${newLevel} (${level.height ? level.height + 'p ' : ''}${level.videoRange ? level.videoRange + ' ' : ''}${level.codecSet ? level.codecSet + ' ' : ''}@${level.bitrate})${pathwayId ? ' with Pathway ' + pathwayId : ''} from level ${lastLevelIndex}${lastPathwayId ? ' with Pathway ' + lastPathwayId : ''}`);\n    const levelSwitchingData = {\n      level: newLevel,\n      attrs: level.attrs,\n      details: level.details,\n      bitrate: level.bitrate,\n      averageBitrate: level.averageBitrate,\n      maxBitrate: level.maxBitrate,\n      realBitrate: level.realBitrate,\n      width: level.width,\n      height: level.height,\n      codecSet: level.codecSet,\n      audioCodec: level.audioCodec,\n      videoCodec: level.videoCodec,\n      audioGroups: level.audioGroups,\n      subtitleGroups: level.subtitleGroups,\n      loaded: level.loaded,\n      loadError: level.loadError,\n      fragmentError: level.fragmentError,\n      name: level.name,\n      id: level.id,\n      uri: level.uri,\n      url: level.url,\n      urlId: 0,\n      audioGroupIds: level.audioGroupIds,\n      textGroupIds: level.textGroupIds\n    };\n    this.hls.trigger(Events.LEVEL_SWITCHING, levelSwitchingData);\n    // check if we need to load playlist for this level\n    const levelDetails = level.details;\n    if (!levelDetails || levelDetails.live) {\n      // level not retrieved yet, or live playlist we need to (re)load it\n      const hlsUrlParameters = this.switchParams(level.uri, lastLevel == null ? void 0 : lastLevel.details, levelDetails);\n      this.loadPlaylist(hlsUrlParameters);\n    }\n  }\n  get manualLevel() {\n    return this.manualLevelIndex;\n  }\n  set manualLevel(newLevel) {\n    this.manualLevelIndex = newLevel;\n    if (this._startLevel === undefined) {\n      this._startLevel = newLevel;\n    }\n    if (newLevel !== -1) {\n      this.level = newLevel;\n    }\n  }\n  get firstLevel() {\n    return this._firstLevel;\n  }\n  set firstLevel(newLevel) {\n    this._firstLevel = newLevel;\n  }\n  get startLevel() {\n    // Setting hls.startLevel (this._startLevel) overrides config.startLevel\n    if (this._startLevel === undefined) {\n      const configStartLevel = this.hls.config.startLevel;\n      if (configStartLevel !== undefined) {\n        return configStartLevel;\n      }\n      return this.hls.firstAutoLevel;\n    }\n    return this._startLevel;\n  }\n  set startLevel(newLevel) {\n    this._startLevel = newLevel;\n  }\n  get pathways() {\n    if (this.steering) {\n      return this.steering.pathways();\n    }\n    return [];\n  }\n  get pathwayPriority() {\n    if (this.steering) {\n      return this.steering.pathwayPriority;\n    }\n    return null;\n  }\n  set pathwayPriority(pathwayPriority) {\n    if (this.steering) {\n      const pathwaysList = this.steering.pathways();\n      const filteredPathwayPriority = pathwayPriority.filter(pathwayId => {\n        return pathwaysList.indexOf(pathwayId) !== -1;\n      });\n      if (pathwayPriority.length < 1) {\n        this.warn(`pathwayPriority ${pathwayPriority} should contain at least one pathway from list: ${pathwaysList}`);\n        return;\n      }\n      this.steering.pathwayPriority = filteredPathwayPriority;\n    }\n  }\n  onError(event, data) {\n    if (data.fatal || !data.context) {\n      return;\n    }\n    if (data.context.type === PlaylistContextType.LEVEL && data.context.level === this.level) {\n      this.checkRetry(data);\n    }\n  }\n\n  // reset errors on the successful load of a fragment\n  onFragBuffered(event, {\n    frag\n  }) {\n    if (frag !== undefined && frag.type === PlaylistLevelType.MAIN) {\n      const el = frag.elementaryStreams;\n      if (!Object.keys(el).some(type => !!el[type])) {\n        return;\n      }\n      const level = this._levels[frag.level];\n      if (level != null && level.loadError) {\n        this.log(`Resetting level error count of ${level.loadError} on frag buffered`);\n        level.loadError = 0;\n      }\n    }\n  }\n  onLevelLoaded(event, data) {\n    var _data$deliveryDirecti2;\n    const {\n      level,\n      details\n    } = data;\n    const curLevel = data.levelInfo;\n    if (!curLevel) {\n      var _data$deliveryDirecti;\n      this.warn(`Invalid level index ${level}`);\n      if ((_data$deliveryDirecti = data.deliveryDirectives) != null && _data$deliveryDirecti.skip) {\n        details.deltaUpdateFailed = true;\n      }\n      return;\n    }\n\n    // only process level loaded events matching with expected level or prior to switch when media playlist is loaded directly\n    if (curLevel === this.currentLevel || data.withoutMultiVariant) {\n      // reset level load error counter on successful level loaded only if there is no issues with fragments\n      if (curLevel.fragmentError === 0) {\n        curLevel.loadError = 0;\n      }\n      // Ignore matching details populated by loading a Media Playlist directly\n      let previousDetails = curLevel.details;\n      if (previousDetails === data.details && previousDetails.advanced) {\n        previousDetails = undefined;\n      }\n      this.playlistLoaded(level, data, previousDetails);\n    } else if ((_data$deliveryDirecti2 = data.deliveryDirectives) != null && _data$deliveryDirecti2.skip) {\n      // received a delta playlist update that cannot be merged\n      details.deltaUpdateFailed = true;\n    }\n  }\n  loadPlaylist(hlsUrlParameters) {\n    super.loadPlaylist();\n    if (this.shouldLoadPlaylist(this.currentLevel)) {\n      this.scheduleLoading(this.currentLevel, hlsUrlParameters);\n    }\n  }\n  loadingPlaylist(currentLevel, hlsUrlParameters) {\n    super.loadingPlaylist(currentLevel, hlsUrlParameters);\n    const url = this.getUrlWithDirectives(currentLevel.uri, hlsUrlParameters);\n    const currentLevelIndex = this.currentLevelIndex;\n    const pathwayId = currentLevel.attrs['PATHWAY-ID'];\n    const details = currentLevel.details;\n    const age = details == null ? void 0 : details.age;\n    this.log(`Loading level index ${currentLevelIndex}${(hlsUrlParameters == null ? void 0 : hlsUrlParameters.msn) !== undefined ? ' at sn ' + hlsUrlParameters.msn + ' part ' + hlsUrlParameters.part : ''}${pathwayId ? ' Pathway ' + pathwayId : ''}${age && details.live ? ' age ' + age.toFixed(1) + (details.type ? ' ' + details.type || 0 : '') : ''} ${url}`);\n    this.hls.trigger(Events.LEVEL_LOADING, {\n      url,\n      level: currentLevelIndex,\n      levelInfo: currentLevel,\n      pathwayId: currentLevel.attrs['PATHWAY-ID'],\n      id: 0,\n      // Deprecated Level urlId\n      deliveryDirectives: hlsUrlParameters || null\n    });\n  }\n  get nextLoadLevel() {\n    if (this.manualLevelIndex !== -1) {\n      return this.manualLevelIndex;\n    } else {\n      return this.hls.nextAutoLevel;\n    }\n  }\n  set nextLoadLevel(nextLevel) {\n    this.level = nextLevel;\n    if (this.manualLevelIndex === -1) {\n      this.hls.nextAutoLevel = nextLevel;\n    }\n  }\n  removeLevel(levelIndex) {\n    var _this$currentLevel;\n    if (this._levels.length === 1) {\n      return;\n    }\n    const levels = this._levels.filter((level, index) => {\n      if (index !== levelIndex) {\n        return true;\n      }\n      if (this.steering) {\n        this.steering.removeLevel(level);\n      }\n      if (level === this.currentLevel) {\n        this.currentLevel = null;\n        this.currentLevelIndex = -1;\n        if (level.details) {\n          level.details.fragments.forEach(f => f.level = -1);\n        }\n      }\n      return false;\n    });\n    reassignFragmentLevelIndexes(levels);\n    this._levels = levels;\n    if (this.currentLevelIndex > -1 && (_this$currentLevel = this.currentLevel) != null && _this$currentLevel.details) {\n      this.currentLevelIndex = this.currentLevel.details.fragments[0].level;\n    }\n    if (this.manualLevelIndex > -1) {\n      this.manualLevelIndex = this.currentLevelIndex;\n    }\n    const maxLevel = levels.length - 1;\n    this._firstLevel = Math.min(this._firstLevel, maxLevel);\n    if (this._startLevel) {\n      this._startLevel = Math.min(this._startLevel, maxLevel);\n    }\n    this.hls.trigger(Events.LEVELS_UPDATED, {\n      levels\n    });\n  }\n  onLevelsUpdated(event, {\n    levels\n  }) {\n    this._levels = levels;\n  }\n  checkMaxAutoUpdated() {\n    const {\n      autoLevelCapping,\n      maxAutoLevel,\n      maxHdcpLevel\n    } = this.hls;\n    if (this._maxAutoLevel !== maxAutoLevel) {\n      this._maxAutoLevel = maxAutoLevel;\n      this.hls.trigger(Events.MAX_AUTO_LEVEL_UPDATED, {\n        autoLevelCapping,\n        levels: this.levels,\n        maxAutoLevel,\n        minAutoLevel: this.hls.minAutoLevel,\n        maxHdcpLevel\n      });\n    }\n  }\n}\nfunction assignTrackIdsByGroup(tracks) {\n  const groups = {};\n  tracks.forEach(track => {\n    const groupId = track.groupId || '';\n    track.id = groups[groupId] = groups[groupId] || 0;\n    groups[groupId]++;\n  });\n}\n\nfunction getSourceBuffer() {\n  return self.SourceBuffer || self.WebKitSourceBuffer;\n}\nfunction isMSESupported() {\n  const mediaSource = getMediaSource();\n  if (!mediaSource) {\n    return false;\n  }\n\n  // if SourceBuffer is exposed ensure its API is valid\n  // Older browsers do not expose SourceBuffer globally so checking SourceBuffer.prototype is impossible\n  const sourceBuffer = getSourceBuffer();\n  return !sourceBuffer || sourceBuffer.prototype && typeof sourceBuffer.prototype.appendBuffer === 'function' && typeof sourceBuffer.prototype.remove === 'function';\n}\nfunction isSupported() {\n  if (!isMSESupported()) {\n    return false;\n  }\n  const mediaSource = getMediaSource();\n  return typeof (mediaSource == null ? void 0 : mediaSource.isTypeSupported) === 'function' && (['avc1.42E01E,mp4a.40.2', 'av01.0.01M.08', 'vp09.00.50.08'].some(codecsForVideoContainer => mediaSource.isTypeSupported(mimeTypeForCodec(codecsForVideoContainer, 'video'))) || ['mp4a.40.2', 'fLaC'].some(codecForAudioContainer => mediaSource.isTypeSupported(mimeTypeForCodec(codecForAudioContainer, 'audio'))));\n}\nfunction changeTypeSupported() {\n  var _sourceBuffer$prototy;\n  const sourceBuffer = getSourceBuffer();\n  return typeof (sourceBuffer == null || (_sourceBuffer$prototy = sourceBuffer.prototype) == null ? void 0 : _sourceBuffer$prototy.changeType) === 'function';\n}\n\nconst TICK_INTERVAL = 100; // how often to tick in ms\n\nclass StreamController extends BaseStreamController {\n  constructor(hls, fragmentTracker, keyLoader) {\n    super(hls, fragmentTracker, keyLoader, 'stream-controller', PlaylistLevelType.MAIN);\n    this.audioCodecSwap = false;\n    this.level = -1;\n    this._forceStartLoad = false;\n    this._hasEnoughToStart = false;\n    this.altAudio = 0;\n    this.audioOnly = false;\n    this.fragPlaying = null;\n    this.fragLastKbps = 0;\n    this.couldBacktrack = false;\n    this.backtrackFragment = null;\n    this.audioCodecSwitch = false;\n    this.videoBuffer = null;\n    this.onMediaPlaying = () => {\n      // tick to speed up FRAG_CHANGED triggering\n      this.tick();\n    };\n    this.onMediaSeeked = () => {\n      const media = this.media;\n      const currentTime = media ? media.currentTime : null;\n      if (currentTime === null || !isFiniteNumber(currentTime)) {\n        return;\n      }\n      this.log(`Media seeked to ${currentTime.toFixed(3)}`);\n\n      // If seeked was issued before buffer was appended do not tick immediately\n      if (!this.getBufferedFrag(currentTime)) {\n        return;\n      }\n      const bufferInfo = this.getFwdBufferInfoAtPos(media, currentTime, PlaylistLevelType.MAIN, 0);\n      if (bufferInfo === null || bufferInfo.len === 0) {\n        this.warn(`Main forward buffer length at ${currentTime} on \"seeked\" event ${bufferInfo ? bufferInfo.len : 'empty'})`);\n        return;\n      }\n\n      // tick to speed up FRAG_CHANGED triggering\n      this.tick();\n    };\n    this.registerListeners();\n  }\n  registerListeners() {\n    super.registerListeners();\n    const {\n      hls\n    } = this;\n    hls.on(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n    hls.on(Events.LEVEL_LOADING, this.onLevelLoading, this);\n    hls.on(Events.LEVEL_LOADED, this.onLevelLoaded, this);\n    hls.on(Events.FRAG_LOAD_EMERGENCY_ABORTED, this.onFragLoadEmergencyAborted, this);\n    hls.on(Events.AUDIO_TRACK_SWITCHING, this.onAudioTrackSwitching, this);\n    hls.on(Events.AUDIO_TRACK_SWITCHED, this.onAudioTrackSwitched, this);\n    hls.on(Events.BUFFER_CREATED, this.onBufferCreated, this);\n    hls.on(Events.BUFFER_FLUSHED, this.onBufferFlushed, this);\n    hls.on(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);\n    hls.on(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n  }\n  unregisterListeners() {\n    super.unregisterListeners();\n    const {\n      hls\n    } = this;\n    hls.off(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n    hls.off(Events.LEVEL_LOADED, this.onLevelLoaded, this);\n    hls.off(Events.FRAG_LOAD_EMERGENCY_ABORTED, this.onFragLoadEmergencyAborted, this);\n    hls.off(Events.AUDIO_TRACK_SWITCHING, this.onAudioTrackSwitching, this);\n    hls.off(Events.AUDIO_TRACK_SWITCHED, this.onAudioTrackSwitched, this);\n    hls.off(Events.BUFFER_CREATED, this.onBufferCreated, this);\n    hls.off(Events.BUFFER_FLUSHED, this.onBufferFlushed, this);\n    hls.off(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);\n    hls.off(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n  }\n  onHandlerDestroying() {\n    // @ts-ignore\n    this.onMediaPlaying = this.onMediaSeeked = null;\n    this.unregisterListeners();\n    super.onHandlerDestroying();\n  }\n  startLoad(startPosition, skipSeekToStartPosition) {\n    if (this.levels) {\n      const {\n        lastCurrentTime,\n        hls\n      } = this;\n      this.stopLoad();\n      this.setInterval(TICK_INTERVAL);\n      this.level = -1;\n      if (!this.startFragRequested) {\n        // determine load level\n        let startLevel = hls.startLevel;\n        if (startLevel === -1) {\n          if (hls.config.testBandwidth && this.levels.length > 1) {\n            // -1 : guess start Level by doing a bitrate test by loading first fragment of lowest quality level\n            startLevel = 0;\n            this.bitrateTest = true;\n          } else {\n            startLevel = hls.firstAutoLevel;\n          }\n        }\n        // set new level to playlist loader : this will trigger start level load\n        // hls.nextLoadLevel remains until it is set to a new value or until a new frag is successfully loaded\n        hls.nextLoadLevel = startLevel;\n        this.level = hls.loadLevel;\n        this._hasEnoughToStart = !!skipSeekToStartPosition;\n      }\n      // if startPosition undefined but lastCurrentTime set, set startPosition to last currentTime\n      if (lastCurrentTime > 0 && startPosition === -1 && !skipSeekToStartPosition) {\n        this.log(`Override startPosition with lastCurrentTime @${lastCurrentTime.toFixed(3)}`);\n        startPosition = lastCurrentTime;\n      }\n      this.state = State.IDLE;\n      this.nextLoadPosition = this.lastCurrentTime = startPosition + this.timelineOffset;\n      this.startPosition = skipSeekToStartPosition ? -1 : startPosition;\n      this.tick();\n    } else {\n      this._forceStartLoad = true;\n      this.state = State.STOPPED;\n    }\n  }\n  stopLoad() {\n    this._forceStartLoad = false;\n    super.stopLoad();\n  }\n  doTick() {\n    switch (this.state) {\n      case State.WAITING_LEVEL:\n        {\n          const {\n            levels,\n            level\n          } = this;\n          const currentLevel = levels == null ? void 0 : levels[level];\n          const details = currentLevel == null ? void 0 : currentLevel.details;\n          if (details && (!details.live || this.levelLastLoaded === currentLevel && !this.waitForLive(currentLevel))) {\n            if (this.waitForCdnTuneIn(details)) {\n              break;\n            }\n            this.state = State.IDLE;\n            break;\n          } else if (this.hls.nextLoadLevel !== this.level) {\n            this.state = State.IDLE;\n            break;\n          }\n          break;\n        }\n      case State.FRAG_LOADING_WAITING_RETRY:\n        this.checkRetryDate();\n        break;\n    }\n    if (this.state === State.IDLE) {\n      this.doTickIdle();\n    }\n    this.onTickEnd();\n  }\n  onTickEnd() {\n    var _this$media;\n    super.onTickEnd();\n    if ((_this$media = this.media) != null && _this$media.readyState && this.media.seeking === false) {\n      this.lastCurrentTime = this.media.currentTime;\n    }\n    this.checkFragmentChanged();\n  }\n  doTickIdle() {\n    const {\n      hls,\n      levelLastLoaded,\n      levels,\n      media\n    } = this;\n\n    // if start level not parsed yet OR\n    // if video not attached AND start fragment already requested OR start frag prefetch not enabled\n    // exit loop, as we either need more info (level not parsed) or we need media to be attached to load new fragment\n    if (levelLastLoaded === null || !media && !this.primaryPrefetch && (this.startFragRequested || !hls.config.startFragPrefetch)) {\n      return;\n    }\n\n    // If the \"main\" level is audio-only but we are loading an alternate track in the same group, do not load anything\n    if (this.altAudio && this.audioOnly) {\n      return;\n    }\n    const level = this.buffering ? hls.nextLoadLevel : hls.loadLevel;\n    if (!(levels != null && levels[level])) {\n      return;\n    }\n    const levelInfo = levels[level];\n\n    // if buffer length is less than maxBufLen try to load a new fragment\n\n    const bufferInfo = this.getMainFwdBufferInfo();\n    if (bufferInfo === null) {\n      return;\n    }\n    const lastDetails = this.getLevelDetails();\n    if (lastDetails && this._streamEnded(bufferInfo, lastDetails)) {\n      const data = {};\n      if (this.altAudio === 2) {\n        data.type = 'video';\n      }\n      this.hls.trigger(Events.BUFFER_EOS, data);\n      this.state = State.ENDED;\n      return;\n    }\n    if (!this.buffering) {\n      return;\n    }\n\n    // set next load level : this will trigger a playlist load if needed\n    if (hls.loadLevel !== level && hls.manualLevel === -1) {\n      this.log(`Adapting to level ${level} from level ${this.level}`);\n    }\n    this.level = hls.nextLoadLevel = level;\n    const levelDetails = levelInfo.details;\n    // if level info not retrieved yet, switch state and wait for level retrieval\n    // if live playlist, ensure that new playlist has been refreshed to avoid loading/try to load\n    // a useless and outdated fragment (that might even introduce load error if it is already out of the live playlist)\n    if (!levelDetails || this.state === State.WAITING_LEVEL || this.waitForLive(levelInfo)) {\n      this.level = level;\n      this.state = State.WAITING_LEVEL;\n      this.startFragRequested = false;\n      return;\n    }\n    const bufferLen = bufferInfo.len;\n\n    // compute max Buffer Length that we could get from this load level, based on level bitrate. don't buffer more than 60 MB and more than 30s\n    const maxBufLen = this.getMaxBufferLength(levelInfo.maxBitrate);\n\n    // Stay idle if we are still with buffer margins\n    if (bufferLen >= maxBufLen) {\n      return;\n    }\n    if (this.backtrackFragment && this.backtrackFragment.start > bufferInfo.end) {\n      this.backtrackFragment = null;\n    }\n    const targetBufferTime = this.backtrackFragment ? this.backtrackFragment.start : bufferInfo.end;\n    let frag = this.getNextFragment(targetBufferTime, levelDetails);\n    // Avoid backtracking by loading an earlier segment in streams with segments that do not start with a key frame (flagged by `couldBacktrack`)\n    if (this.couldBacktrack && !this.fragPrevious && frag && isMediaFragment(frag) && this.fragmentTracker.getState(frag) !== FragmentState.OK) {\n      var _this$backtrackFragme;\n      const backtrackSn = ((_this$backtrackFragme = this.backtrackFragment) != null ? _this$backtrackFragme : frag).sn;\n      const fragIdx = backtrackSn - levelDetails.startSN;\n      const backtrackFrag = levelDetails.fragments[fragIdx - 1];\n      if (backtrackFrag && frag.cc === backtrackFrag.cc) {\n        frag = backtrackFrag;\n        this.fragmentTracker.removeFragment(backtrackFrag);\n      }\n    } else if (this.backtrackFragment && bufferInfo.len) {\n      this.backtrackFragment = null;\n    }\n    // Avoid loop loading by using nextLoadPosition set for backtracking and skipping consecutive GAP tags\n    if (frag && this.isLoopLoading(frag, targetBufferTime)) {\n      const gapStart = frag.gap;\n      if (!gapStart) {\n        // Cleanup the fragment tracker before trying to find the next unbuffered fragment\n        const type = this.audioOnly && !this.altAudio ? ElementaryStreamTypes.AUDIO : ElementaryStreamTypes.VIDEO;\n        const mediaBuffer = (type === ElementaryStreamTypes.VIDEO ? this.videoBuffer : this.mediaBuffer) || this.media;\n        if (mediaBuffer) {\n          this.afterBufferFlushed(mediaBuffer, type, PlaylistLevelType.MAIN);\n        }\n      }\n      frag = this.getNextFragmentLoopLoading(frag, levelDetails, bufferInfo, PlaylistLevelType.MAIN, maxBufLen);\n    }\n    if (!frag) {\n      return;\n    }\n    if (frag.initSegment && !frag.initSegment.data && !this.bitrateTest) {\n      frag = frag.initSegment;\n    }\n    this.loadFragment(frag, levelInfo, targetBufferTime);\n  }\n  loadFragment(frag, level, targetBufferTime) {\n    // Check if fragment is not loaded\n    const fragState = this.fragmentTracker.getState(frag);\n    if (fragState === FragmentState.NOT_LOADED || fragState === FragmentState.PARTIAL) {\n      if (!isMediaFragment(frag)) {\n        this._loadInitSegment(frag, level);\n      } else if (this.bitrateTest) {\n        this.log(`Fragment ${frag.sn} of level ${frag.level} is being downloaded to test bitrate and will not be buffered`);\n        this._loadBitrateTestFrag(frag, level);\n      } else {\n        super.loadFragment(frag, level, targetBufferTime);\n      }\n    } else {\n      this.clearTrackerIfNeeded(frag);\n    }\n  }\n  getBufferedFrag(position) {\n    return this.fragmentTracker.getBufferedFrag(position, PlaylistLevelType.MAIN);\n  }\n  followingBufferedFrag(frag) {\n    if (frag) {\n      // try to get range of next fragment (500ms after this range)\n      return this.getBufferedFrag(frag.end + 0.5);\n    }\n    return null;\n  }\n\n  /*\n    on immediate level switch :\n     - pause playback if playing\n     - cancel any pending load request\n     - and trigger a buffer flush\n  */\n  immediateLevelSwitch() {\n    this.abortCurrentFrag();\n    this.flushMainBuffer(0, Number.POSITIVE_INFINITY);\n  }\n\n  /**\n   * try to switch ASAP without breaking video playback:\n   * in order to ensure smooth but quick level switching,\n   * we need to find the next flushable buffer range\n   * we should take into account new segment fetch time\n   */\n  nextLevelSwitch() {\n    const {\n      levels,\n      media\n    } = this;\n    // ensure that media is defined and that metadata are available (to retrieve currentTime)\n    if (media != null && media.readyState) {\n      let fetchdelay;\n      const fragPlayingCurrent = this.getAppendedFrag(media.currentTime);\n      if (fragPlayingCurrent && fragPlayingCurrent.start > 1) {\n        // flush buffer preceding current fragment (flush until current fragment start offset)\n        // minus 1s to avoid video freezing, that could happen if we flush keyframe of current video ...\n        this.flushMainBuffer(0, fragPlayingCurrent.start - 1);\n      }\n      const levelDetails = this.getLevelDetails();\n      if (levelDetails != null && levelDetails.live) {\n        const bufferInfo = this.getMainFwdBufferInfo();\n        // Do not flush in live stream with low buffer\n        if (!bufferInfo || bufferInfo.len < levelDetails.targetduration * 2) {\n          return;\n        }\n      }\n      if (!media.paused && levels) {\n        // add a safety delay of 1s\n        const nextLevelId = this.hls.nextLoadLevel;\n        const nextLevel = levels[nextLevelId];\n        const fragLastKbps = this.fragLastKbps;\n        if (fragLastKbps && this.fragCurrent) {\n          fetchdelay = this.fragCurrent.duration * nextLevel.maxBitrate / (1000 * fragLastKbps) + 1;\n        } else {\n          fetchdelay = 0;\n        }\n      } else {\n        fetchdelay = 0;\n      }\n      // this.log('fetchdelay:'+fetchdelay);\n      // find buffer range that will be reached once new fragment will be fetched\n      const bufferedFrag = this.getBufferedFrag(media.currentTime + fetchdelay);\n      if (bufferedFrag) {\n        // we can flush buffer range following this one without stalling playback\n        const nextBufferedFrag = this.followingBufferedFrag(bufferedFrag);\n        if (nextBufferedFrag) {\n          // if we are here, we can also cancel any loading/demuxing in progress, as they are useless\n          this.abortCurrentFrag();\n          // start flush position is in next buffered frag. Leave some padding for non-independent segments and smoother playback.\n          const maxStart = nextBufferedFrag.maxStartPTS ? nextBufferedFrag.maxStartPTS : nextBufferedFrag.start;\n          const fragDuration = nextBufferedFrag.duration;\n          const startPts = Math.max(bufferedFrag.end, maxStart + Math.min(Math.max(fragDuration - this.config.maxFragLookUpTolerance, fragDuration * (this.couldBacktrack ? 0.5 : 0.125)), fragDuration * (this.couldBacktrack ? 0.75 : 0.25)));\n          this.flushMainBuffer(startPts, Number.POSITIVE_INFINITY);\n        }\n      }\n    }\n  }\n  abortCurrentFrag() {\n    const fragCurrent = this.fragCurrent;\n    this.fragCurrent = null;\n    this.backtrackFragment = null;\n    if (fragCurrent) {\n      fragCurrent.abortRequests();\n      this.fragmentTracker.removeFragment(fragCurrent);\n    }\n    switch (this.state) {\n      case State.KEY_LOADING:\n      case State.FRAG_LOADING:\n      case State.FRAG_LOADING_WAITING_RETRY:\n      case State.PARSING:\n      case State.PARSED:\n        this.state = State.IDLE;\n        break;\n    }\n    this.nextLoadPosition = this.getLoadPosition();\n  }\n  flushMainBuffer(startOffset, endOffset) {\n    super.flushMainBuffer(startOffset, endOffset, this.altAudio === 2 ? 'video' : null);\n  }\n  onMediaAttached(event, data) {\n    super.onMediaAttached(event, data);\n    const media = data.media;\n    addEventListener(media, 'playing', this.onMediaPlaying);\n    addEventListener(media, 'seeked', this.onMediaSeeked);\n  }\n  onMediaDetaching(event, data) {\n    const {\n      media\n    } = this;\n    if (media) {\n      removeEventListener(media, 'playing', this.onMediaPlaying);\n      removeEventListener(media, 'seeked', this.onMediaSeeked);\n    }\n    this.videoBuffer = null;\n    this.fragPlaying = null;\n    super.onMediaDetaching(event, data);\n    const transferringMedia = !!data.transferMedia;\n    if (transferringMedia) {\n      return;\n    }\n    this._hasEnoughToStart = false;\n  }\n  onManifestLoading() {\n    super.onManifestLoading();\n    // reset buffer on manifest loading\n    this.log('Trigger BUFFER_RESET');\n    this.hls.trigger(Events.BUFFER_RESET, undefined);\n    this.couldBacktrack = false;\n    this.fragLastKbps = 0;\n    this.fragPlaying = this.backtrackFragment = null;\n    this.altAudio = 0;\n    this.audioOnly = false;\n  }\n  onManifestParsed(event, data) {\n    // detect if we have different kind of audio codecs used amongst playlists\n    let aac = false;\n    let heaac = false;\n    for (let i = 0; i < data.levels.length; i++) {\n      const codec = data.levels[i].audioCodec;\n      if (codec) {\n        aac = aac || codec.indexOf('mp4a.40.2') !== -1;\n        heaac = heaac || codec.indexOf('mp4a.40.5') !== -1;\n      }\n    }\n    this.audioCodecSwitch = aac && heaac && !changeTypeSupported();\n    if (this.audioCodecSwitch) {\n      this.log('Both AAC/HE-AAC audio found in levels; declaring level codec as HE-AAC');\n    }\n    this.levels = data.levels;\n    this.startFragRequested = false;\n  }\n  onLevelLoading(event, data) {\n    const {\n      levels\n    } = this;\n    if (!levels || this.state !== State.IDLE) {\n      return;\n    }\n    const level = data.levelInfo;\n    if (!level.details || level.details.live && (this.levelLastLoaded !== level || level.details.expired) || this.waitForCdnTuneIn(level.details)) {\n      this.state = State.WAITING_LEVEL;\n    }\n  }\n  onLevelLoaded(event, data) {\n    var _curLevel$details;\n    const {\n      levels,\n      startFragRequested\n    } = this;\n    const newLevelId = data.level;\n    const newDetails = data.details;\n    const duration = newDetails.totalduration;\n    if (!levels) {\n      this.warn(`Levels were reset while loading level ${newLevelId}`);\n      return;\n    }\n    this.log(`Level ${newLevelId} loaded [${newDetails.startSN},${newDetails.endSN}]${newDetails.lastPartSn ? `[part-${newDetails.lastPartSn}-${newDetails.lastPartIndex}]` : ''}, cc [${newDetails.startCC}, ${newDetails.endCC}] duration:${duration}`);\n    const curLevel = data.levelInfo;\n    const fragCurrent = this.fragCurrent;\n    if (fragCurrent && (this.state === State.FRAG_LOADING || this.state === State.FRAG_LOADING_WAITING_RETRY)) {\n      if (fragCurrent.level !== data.level && fragCurrent.loader) {\n        this.abortCurrentFrag();\n      }\n    }\n    let sliding = 0;\n    if (newDetails.live || (_curLevel$details = curLevel.details) != null && _curLevel$details.live) {\n      var _this$levelLastLoaded;\n      this.checkLiveUpdate(newDetails);\n      if (newDetails.deltaUpdateFailed) {\n        return;\n      }\n      sliding = this.alignPlaylists(newDetails, curLevel.details, (_this$levelLastLoaded = this.levelLastLoaded) == null ? void 0 : _this$levelLastLoaded.details);\n    }\n    // override level info\n    curLevel.details = newDetails;\n    this.levelLastLoaded = curLevel;\n    if (!startFragRequested) {\n      this.setStartPosition(newDetails, sliding);\n    }\n    this.hls.trigger(Events.LEVEL_UPDATED, {\n      details: newDetails,\n      level: newLevelId\n    });\n\n    // only switch back to IDLE state if we were waiting for level to start downloading a new fragment\n    if (this.state === State.WAITING_LEVEL) {\n      if (this.waitForCdnTuneIn(newDetails)) {\n        // Wait for Low-Latency CDN Tune-in\n        return;\n      }\n      this.state = State.IDLE;\n    }\n    if (startFragRequested && newDetails.live) {\n      this.synchronizeToLiveEdge(newDetails);\n    }\n\n    // trigger handler right now\n    this.tick();\n  }\n  synchronizeToLiveEdge(levelDetails) {\n    const {\n      config,\n      media\n    } = this;\n    if (!media) {\n      return;\n    }\n    const liveSyncPosition = this.hls.liveSyncPosition;\n    const currentTime = this.getLoadPosition();\n    const start = levelDetails.fragmentStart;\n    const end = levelDetails.edge;\n    const withinSlidingWindow = currentTime >= start - config.maxFragLookUpTolerance && currentTime <= end;\n    // Continue if we can seek forward to sync position or if current time is outside of sliding window\n    if (liveSyncPosition !== null && media.duration > liveSyncPosition && (currentTime < liveSyncPosition || !withinSlidingWindow)) {\n      // Continue if buffer is starving or if current time is behind max latency\n      const maxLatency = config.liveMaxLatencyDuration !== undefined ? config.liveMaxLatencyDuration : config.liveMaxLatencyDurationCount * levelDetails.targetduration;\n      if (!withinSlidingWindow && media.readyState < 4 || currentTime < end - maxLatency) {\n        if (!this._hasEnoughToStart) {\n          this.nextLoadPosition = liveSyncPosition;\n        }\n        // Only seek if ready and there is not a significant forward buffer available for playback\n        if (media.readyState) {\n          this.warn(`Playback: ${currentTime.toFixed(3)} is located too far from the end of live sliding playlist: ${end}, reset currentTime to : ${liveSyncPosition.toFixed(3)}`);\n          if (this.config.liveSyncMode === 'buffered') {\n            var _bufferInfo$buffered;\n            const bufferInfo = BufferHelper.bufferInfo(media, liveSyncPosition, 0);\n            if (!((_bufferInfo$buffered = bufferInfo.buffered) != null && _bufferInfo$buffered.length)) {\n              media.currentTime = liveSyncPosition;\n              return;\n            }\n            const isLiveSyncInBuffer = bufferInfo.start <= currentTime;\n            if (isLiveSyncInBuffer) {\n              media.currentTime = liveSyncPosition;\n              return;\n            }\n            const {\n              nextStart\n            } = BufferHelper.bufferedInfo(bufferInfo.buffered, currentTime, 0);\n            if (nextStart) {\n              media.currentTime = nextStart;\n            }\n          } else {\n            media.currentTime = liveSyncPosition;\n          }\n        }\n      }\n    }\n  }\n  _handleFragmentLoadProgress(data) {\n    var _frag$initSegment;\n    const frag = data.frag;\n    const {\n      part,\n      payload\n    } = data;\n    const {\n      levels\n    } = this;\n    if (!levels) {\n      this.warn(`Levels were reset while fragment load was in progress. Fragment ${frag.sn} of level ${frag.level} will not be buffered`);\n      return;\n    }\n    const currentLevel = levels[frag.level];\n    if (!currentLevel) {\n      this.warn(`Level ${frag.level} not found on progress`);\n      return;\n    }\n    const details = currentLevel.details;\n    if (!details) {\n      this.warn(`Dropping fragment ${frag.sn} of level ${frag.level} after level details were reset`);\n      this.fragmentTracker.removeFragment(frag);\n      return;\n    }\n    const videoCodec = currentLevel.videoCodec;\n\n    // time Offset is accurate if level PTS is known, or if playlist is not sliding (not live)\n    const accurateTimeOffset = details.PTSKnown || !details.live;\n    const initSegmentData = (_frag$initSegment = frag.initSegment) == null ? void 0 : _frag$initSegment.data;\n    const audioCodec = this._getAudioCodec(currentLevel);\n\n    // transmux the MPEG-TS data to ISO-BMFF segments\n    // this.log(`Transmuxing ${frag.sn} of [${details.startSN} ,${details.endSN}],level ${frag.level}, cc ${frag.cc}`);\n    const transmuxer = this.transmuxer = this.transmuxer || new TransmuxerInterface(this.hls, PlaylistLevelType.MAIN, this._handleTransmuxComplete.bind(this), this._handleTransmuxerFlush.bind(this));\n    const partIndex = part ? part.index : -1;\n    const partial = partIndex !== -1;\n    const chunkMeta = new ChunkMetadata(frag.level, frag.sn, frag.stats.chunkCount, payload.byteLength, partIndex, partial);\n    const initPTS = this.initPTS[frag.cc];\n    transmuxer.push(payload, initSegmentData, audioCodec, videoCodec, frag, part, details.totalduration, accurateTimeOffset, chunkMeta, initPTS);\n  }\n  onAudioTrackSwitching(event, data) {\n    const hls = this.hls;\n    // if any URL found on new audio track, it is an alternate audio track\n    const fromAltAudio = this.altAudio !== 0;\n    const altAudio = useAlternateAudio(data.url, hls);\n    // if we switch on main audio, ensure that main fragment scheduling is synced with media.buffered\n    // don't do anything if we switch to alt audio: audio stream controller is handling it.\n    // we will just have to change buffer scheduling on audioTrackSwitched\n    if (!altAudio) {\n      if (this.mediaBuffer !== this.media) {\n        this.log('Switching on main audio, use media.buffered to schedule main fragment loading');\n        this.mediaBuffer = this.media;\n        const fragCurrent = this.fragCurrent;\n        // we need to refill audio buffer from main: cancel any frag loading to speed up audio switch\n        if (fragCurrent) {\n          this.log('Switching to main audio track, cancel main fragment load');\n          fragCurrent.abortRequests();\n          this.fragmentTracker.removeFragment(fragCurrent);\n        }\n        // destroy transmuxer to force init segment generation (following audio switch)\n        this.resetTransmuxer();\n        // switch to IDLE state to load new fragment\n        this.resetLoadingState();\n      } else if (this.audioOnly) {\n        // Reset audio transmuxer so when switching back to main audio we're not still appending where we left off\n        this.resetTransmuxer();\n      }\n      // If switching from alt to main audio, flush all audio and trigger track switched\n      if (fromAltAudio) {\n        this.altAudio = 0;\n        this.fragmentTracker.removeAllFragments();\n        hls.once(Events.BUFFER_FLUSHED, () => {\n          if (!this.hls) {\n            return;\n          }\n          this.hls.trigger(Events.AUDIO_TRACK_SWITCHED, data);\n        });\n        hls.trigger(Events.BUFFER_FLUSHING, {\n          startOffset: 0,\n          endOffset: Number.POSITIVE_INFINITY,\n          type: null\n        });\n        return;\n      }\n      hls.trigger(Events.AUDIO_TRACK_SWITCHED, data);\n    } else {\n      this.altAudio = 1;\n    }\n  }\n  onAudioTrackSwitched(event, data) {\n    const altAudio = useAlternateAudio(data.url, this.hls);\n    if (altAudio) {\n      const videoBuffer = this.videoBuffer;\n      // if we switched on alternate audio, ensure that main fragment scheduling is synced with video sourcebuffer buffered\n      if (videoBuffer && this.mediaBuffer !== videoBuffer) {\n        this.log('Switching on alternate audio, use video.buffered to schedule main fragment loading');\n        this.mediaBuffer = videoBuffer;\n      }\n    }\n    this.altAudio = altAudio ? 2 : 0;\n    this.tick();\n  }\n  onBufferCreated(event, data) {\n    const tracks = data.tracks;\n    let mediaTrack;\n    let name;\n    let alternate = false;\n    for (const type in tracks) {\n      const track = tracks[type];\n      if (track.id === 'main') {\n        name = type;\n        mediaTrack = track;\n        // keep video source buffer reference\n        if (type === 'video') {\n          const videoTrack = tracks[type];\n          if (videoTrack) {\n            this.videoBuffer = videoTrack.buffer;\n          }\n        }\n      } else {\n        alternate = true;\n      }\n    }\n    if (alternate && mediaTrack) {\n      this.log(`Alternate track found, use ${name}.buffered to schedule main fragment loading`);\n      this.mediaBuffer = mediaTrack.buffer;\n    } else {\n      this.mediaBuffer = this.media;\n    }\n  }\n  onFragBuffered(event, data) {\n    const {\n      frag,\n      part\n    } = data;\n    const bufferedMainFragment = frag.type === PlaylistLevelType.MAIN;\n    if (bufferedMainFragment) {\n      if (this.fragContextChanged(frag)) {\n        // If a level switch was requested while a fragment was buffering, it will emit the FRAG_BUFFERED event upon completion\n        // Avoid setting state back to IDLE, since that will interfere with a level switch\n        this.warn(`Fragment ${frag.sn}${part ? ' p: ' + part.index : ''} of level ${frag.level} finished buffering, but was aborted. state: ${this.state}`);\n        if (this.state === State.PARSED) {\n          this.state = State.IDLE;\n        }\n        return;\n      }\n      const stats = part ? part.stats : frag.stats;\n      this.fragLastKbps = Math.round(8 * stats.total / (stats.buffering.end - stats.loading.first));\n      if (isMediaFragment(frag)) {\n        this.fragPrevious = frag;\n      }\n      this.fragBufferedComplete(frag, part);\n    }\n    const media = this.media;\n    if (!media) {\n      return;\n    }\n    if (!this._hasEnoughToStart && BufferHelper.getBuffered(media).length) {\n      this._hasEnoughToStart = true;\n      this.seekToStartPos();\n    }\n    if (bufferedMainFragment) {\n      this.tick();\n    }\n  }\n  get hasEnoughToStart() {\n    return this._hasEnoughToStart;\n  }\n  onError(event, data) {\n    var _data$context;\n    if (data.fatal) {\n      this.state = State.ERROR;\n      return;\n    }\n    switch (data.details) {\n      case ErrorDetails.FRAG_GAP:\n      case ErrorDetails.FRAG_PARSING_ERROR:\n      case ErrorDetails.FRAG_DECRYPT_ERROR:\n      case ErrorDetails.FRAG_LOAD_ERROR:\n      case ErrorDetails.FRAG_LOAD_TIMEOUT:\n      case ErrorDetails.KEY_LOAD_ERROR:\n      case ErrorDetails.KEY_LOAD_TIMEOUT:\n        this.onFragmentOrKeyLoadError(PlaylistLevelType.MAIN, data);\n        break;\n      case ErrorDetails.LEVEL_LOAD_ERROR:\n      case ErrorDetails.LEVEL_LOAD_TIMEOUT:\n      case ErrorDetails.LEVEL_PARSING_ERROR:\n        // in case of non fatal error while loading level, if level controller is not retrying to load level, switch back to IDLE\n        if (!data.levelRetry && this.state === State.WAITING_LEVEL && ((_data$context = data.context) == null ? void 0 : _data$context.type) === PlaylistContextType.LEVEL) {\n          this.state = State.IDLE;\n        }\n        break;\n      case ErrorDetails.BUFFER_ADD_CODEC_ERROR:\n      case ErrorDetails.BUFFER_APPEND_ERROR:\n        if (data.parent !== 'main') {\n          return;\n        }\n        if (this.reduceLengthAndFlushBuffer(data)) {\n          this.resetLoadingState();\n        }\n        break;\n      case ErrorDetails.BUFFER_FULL_ERROR:\n        if (data.parent !== 'main') {\n          return;\n        }\n        if (this.reduceLengthAndFlushBuffer(data)) {\n          const isAssetPlayer = !this.config.interstitialsController && this.config.assetPlayerId;\n          if (isAssetPlayer) {\n            // Use currentTime in buffer estimate to prevent loading more until playback advances\n            this._hasEnoughToStart = true;\n          } else {\n            this.flushMainBuffer(0, Number.POSITIVE_INFINITY);\n          }\n        }\n        break;\n      case ErrorDetails.INTERNAL_EXCEPTION:\n        this.recoverWorkerError(data);\n        break;\n    }\n  }\n  onFragLoadEmergencyAborted() {\n    this.state = State.IDLE;\n    // if loadedmetadata is not set, it means that we are emergency switch down on first frag\n    // in that case, reset startFragRequested flag\n    if (!this._hasEnoughToStart) {\n      this.startFragRequested = false;\n      this.nextLoadPosition = this.lastCurrentTime;\n    }\n    this.tickImmediate();\n  }\n  onBufferFlushed(event, {\n    type\n  }) {\n    if (type !== ElementaryStreamTypes.AUDIO || !this.altAudio) {\n      const mediaBuffer = (type === ElementaryStreamTypes.VIDEO ? this.videoBuffer : this.mediaBuffer) || this.media;\n      if (mediaBuffer) {\n        this.afterBufferFlushed(mediaBuffer, type, PlaylistLevelType.MAIN);\n        this.tick();\n      }\n    }\n  }\n  onLevelsUpdated(event, data) {\n    if (this.level > -1 && this.fragCurrent) {\n      this.level = this.fragCurrent.level;\n      if (this.level === -1) {\n        this.resetWhenMissingContext(this.fragCurrent);\n      }\n    }\n    this.levels = data.levels;\n  }\n  swapAudioCodec() {\n    this.audioCodecSwap = !this.audioCodecSwap;\n  }\n\n  /**\n   * Seeks to the set startPosition if not equal to the mediaElement's current time.\n   */\n  seekToStartPos() {\n    const {\n      media\n    } = this;\n    if (!media) {\n      return;\n    }\n    const currentTime = media.currentTime;\n    let startPosition = this.startPosition;\n    // only adjust currentTime if different from startPosition or if startPosition not buffered\n    // at that stage, there should be only one buffered range, as we reach that code after first fragment has been buffered\n    if (startPosition >= 0 && currentTime < startPosition) {\n      if (media.seeking) {\n        this.log(`could not seek to ${startPosition}, already seeking at ${currentTime}`);\n        return;\n      }\n\n      // Offset start position by timeline offset\n      const timelineOffset = this.timelineOffset;\n      if (timelineOffset && startPosition) {\n        startPosition += timelineOffset;\n      }\n      const details = this.getLevelDetails();\n      const buffered = BufferHelper.getBuffered(media);\n      const bufferStart = buffered.length ? buffered.start(0) : 0;\n      const delta = bufferStart - startPosition;\n      const skipTolerance = Math.max(this.config.maxBufferHole, this.config.maxFragLookUpTolerance);\n      if (this.config.startOnSegmentBoundary || delta > 0 && (delta < skipTolerance || this.loadingParts && delta < 2 * ((details == null ? void 0 : details.partTarget) || 0))) {\n        this.log(`adjusting start position by ${delta} to match buffer start`);\n        startPosition += delta;\n        this.startPosition = startPosition;\n      }\n      if (currentTime < startPosition) {\n        this.log(`seek to target start position ${startPosition} from current time ${currentTime} buffer start ${bufferStart}`);\n        media.currentTime = startPosition;\n      }\n    }\n  }\n  _getAudioCodec(currentLevel) {\n    let audioCodec = this.config.defaultAudioCodec || currentLevel.audioCodec;\n    if (this.audioCodecSwap && audioCodec) {\n      this.log('Swapping audio codec');\n      if (audioCodec.indexOf('mp4a.40.5') !== -1) {\n        audioCodec = 'mp4a.40.2';\n      } else {\n        audioCodec = 'mp4a.40.5';\n      }\n    }\n    return audioCodec;\n  }\n  _loadBitrateTestFrag(fragment, level) {\n    fragment.bitrateTest = true;\n    this._doFragLoad(fragment, level).then(data => {\n      const {\n        hls\n      } = this;\n      const frag = data == null ? void 0 : data.frag;\n      if (!frag || this.fragContextChanged(frag)) {\n        return;\n      }\n      level.fragmentError = 0;\n      this.state = State.IDLE;\n      this.startFragRequested = false;\n      this.bitrateTest = false;\n      const stats = frag.stats;\n      // Bitrate tests fragments are neither parsed nor buffered\n      stats.parsing.start = stats.parsing.end = stats.buffering.start = stats.buffering.end = self.performance.now();\n      hls.trigger(Events.FRAG_LOADED, data);\n      frag.bitrateTest = false;\n    }).catch(reason => {\n      if (this.state === State.STOPPED || this.state === State.ERROR) {\n        return;\n      }\n      this.warn(reason);\n      this.resetFragmentLoading(fragment);\n    });\n  }\n  _handleTransmuxComplete(transmuxResult) {\n    const id = this.playlistType;\n    const {\n      hls\n    } = this;\n    const {\n      remuxResult,\n      chunkMeta\n    } = transmuxResult;\n    const context = this.getCurrentContext(chunkMeta);\n    if (!context) {\n      this.resetWhenMissingContext(chunkMeta);\n      return;\n    }\n    const {\n      frag,\n      part,\n      level\n    } = context;\n    const {\n      video,\n      text,\n      id3,\n      initSegment\n    } = remuxResult;\n    const {\n      details\n    } = level;\n    // The audio-stream-controller handles audio buffering if Hls.js is playing an alternate audio track\n    const audio = this.altAudio ? undefined : remuxResult.audio;\n\n    // Check if the current fragment has been aborted. We check this by first seeing if we're still playing the current level.\n    // If we are, subsequently check if the currently loading fragment (fragCurrent) has changed.\n    if (this.fragContextChanged(frag)) {\n      this.fragmentTracker.removeFragment(frag);\n      return;\n    }\n    this.state = State.PARSING;\n    if (initSegment) {\n      const tracks = initSegment.tracks;\n      if (tracks) {\n        const mapFragment = frag.initSegment || frag;\n        if (this.unhandledEncryptionError(initSegment, frag)) {\n          return;\n        }\n        this._bufferInitSegment(level, tracks, mapFragment, chunkMeta);\n        hls.trigger(Events.FRAG_PARSING_INIT_SEGMENT, {\n          frag: mapFragment,\n          id,\n          tracks\n        });\n      }\n      const baseTime = initSegment.initPTS;\n      const timescale = initSegment.timescale;\n      const initPTS = this.initPTS[frag.cc];\n      if (isFiniteNumber(baseTime) && (!initPTS || initPTS.baseTime !== baseTime || initPTS.timescale !== timescale)) {\n        const trackId = initSegment.trackId;\n        this.initPTS[frag.cc] = {\n          baseTime,\n          timescale,\n          trackId\n        };\n        hls.trigger(Events.INIT_PTS_FOUND, {\n          frag,\n          id,\n          initPTS: baseTime,\n          timescale,\n          trackId\n        });\n      }\n    }\n\n    // Avoid buffering if backtracking this fragment\n    if (video && details) {\n      if (audio && video.type === 'audiovideo') {\n        this.logMuxedErr(frag);\n      }\n      const prevFrag = details.fragments[frag.sn - 1 - details.startSN];\n      const isFirstFragment = frag.sn === details.startSN;\n      const isFirstInDiscontinuity = !prevFrag || frag.cc > prevFrag.cc;\n      if (remuxResult.independent !== false) {\n        const {\n          startPTS,\n          endPTS,\n          startDTS,\n          endDTS\n        } = video;\n        if (part) {\n          part.elementaryStreams[video.type] = {\n            startPTS,\n            endPTS,\n            startDTS,\n            endDTS\n          };\n        } else {\n          if (video.firstKeyFrame && video.independent && chunkMeta.id === 1 && !isFirstInDiscontinuity) {\n            this.couldBacktrack = true;\n          }\n          if (video.dropped && video.independent) {\n            // Backtrack if dropped frames create a gap after currentTime\n\n            const bufferInfo = this.getMainFwdBufferInfo();\n            const targetBufferTime = (bufferInfo ? bufferInfo.end : this.getLoadPosition()) + this.config.maxBufferHole;\n            const startTime = video.firstKeyFramePTS ? video.firstKeyFramePTS : startPTS;\n            if (!isFirstFragment && targetBufferTime < startTime - this.config.maxBufferHole && !isFirstInDiscontinuity) {\n              this.backtrack(frag);\n              return;\n            } else if (isFirstInDiscontinuity) {\n              // Mark segment with a gap to avoid loop loading\n              frag.gap = true;\n            }\n            // Set video stream start to fragment start so that truncated samples do not distort the timeline, and mark it partial\n            frag.setElementaryStreamInfo(video.type, frag.start, endPTS, frag.start, endDTS, true);\n          } else if (isFirstFragment && startPTS - (details.appliedTimelineOffset || 0) > MAX_START_GAP_JUMP) {\n            // Mark segment with a gap to skip large start gap\n            frag.gap = true;\n          }\n        }\n        frag.setElementaryStreamInfo(video.type, startPTS, endPTS, startDTS, endDTS);\n        if (this.backtrackFragment) {\n          this.backtrackFragment = frag;\n        }\n        this.bufferFragmentData(video, frag, part, chunkMeta, isFirstFragment || isFirstInDiscontinuity);\n      } else if (isFirstFragment || isFirstInDiscontinuity) {\n        // Mark segment with a gap to avoid loop loading\n        frag.gap = true;\n      } else {\n        this.backtrack(frag);\n        return;\n      }\n    }\n    if (audio) {\n      const {\n        startPTS,\n        endPTS,\n        startDTS,\n        endDTS\n      } = audio;\n      if (part) {\n        part.elementaryStreams[ElementaryStreamTypes.AUDIO] = {\n          startPTS,\n          endPTS,\n          startDTS,\n          endDTS\n        };\n      }\n      frag.setElementaryStreamInfo(ElementaryStreamTypes.AUDIO, startPTS, endPTS, startDTS, endDTS);\n      this.bufferFragmentData(audio, frag, part, chunkMeta);\n    }\n    if (details && id3 != null && id3.samples.length) {\n      const emittedID3 = {\n        id,\n        frag,\n        details,\n        samples: id3.samples\n      };\n      hls.trigger(Events.FRAG_PARSING_METADATA, emittedID3);\n    }\n    if (details && text) {\n      const emittedText = {\n        id,\n        frag,\n        details,\n        samples: text.samples\n      };\n      hls.trigger(Events.FRAG_PARSING_USERDATA, emittedText);\n    }\n  }\n  logMuxedErr(frag) {\n    this.warn(`${isMediaFragment(frag) ? 'Media' : 'Init'} segment with muxed audiovideo where only video expected: ${frag.url}`);\n  }\n  _bufferInitSegment(currentLevel, tracks, frag, chunkMeta) {\n    if (this.state !== State.PARSING) {\n      return;\n    }\n    this.audioOnly = !!tracks.audio && !tracks.video;\n\n    // if audio track is expected to come from audio stream controller, discard any coming from main\n    if (this.altAudio && !this.audioOnly) {\n      delete tracks.audio;\n      if (tracks.audiovideo) {\n        this.logMuxedErr(frag);\n      }\n    }\n    // include levelCodec in audio and video tracks\n    const {\n      audio,\n      video,\n      audiovideo\n    } = tracks;\n    if (audio) {\n      const levelCodec = currentLevel.audioCodec;\n      let audioCodec = pickMostCompleteCodecName(audio.codec, levelCodec);\n      // Add level and profile to make up for remuxer not being able to parse full codec\n      // (logger warning \"Unhandled audio codec...\")\n      if (audioCodec === 'mp4a') {\n        audioCodec = 'mp4a.40.5';\n      }\n      // Handle `audioCodecSwitch`\n      const ua = navigator.userAgent.toLowerCase();\n      if (this.audioCodecSwitch) {\n        if (audioCodec) {\n          if (audioCodec.indexOf('mp4a.40.5') !== -1) {\n            audioCodec = 'mp4a.40.2';\n          } else {\n            audioCodec = 'mp4a.40.5';\n          }\n        }\n        // In the case that AAC and HE-AAC audio codecs are signalled in manifest,\n        // force HE-AAC, as it seems that most browsers prefers it.\n        // don't force HE-AAC if mono stream, or in Firefox\n        const audioMetadata = audio.metadata;\n        if (audioMetadata && 'channelCount' in audioMetadata && (audioMetadata.channelCount || 1) !== 1 && ua.indexOf('firefox') === -1) {\n          audioCodec = 'mp4a.40.5';\n        }\n      }\n      // HE-AAC is broken on Android, always signal audio codec as AAC even if variant manifest states otherwise\n      if (audioCodec && audioCodec.indexOf('mp4a.40.5') !== -1 && ua.indexOf('android') !== -1 && audio.container !== 'audio/mpeg') {\n        // Exclude mpeg audio\n        audioCodec = 'mp4a.40.2';\n        this.log(`Android: force audio codec to ${audioCodec}`);\n      }\n      if (levelCodec && levelCodec !== audioCodec) {\n        this.log(`Swapping manifest audio codec \"${levelCodec}\" for \"${audioCodec}\"`);\n      }\n      audio.levelCodec = audioCodec;\n      audio.id = PlaylistLevelType.MAIN;\n      this.log(`Init audio buffer, container:${audio.container}, codecs[selected/level/parsed]=[${audioCodec || ''}/${levelCodec || ''}/${audio.codec}]`);\n      delete tracks.audiovideo;\n    }\n    if (video) {\n      video.levelCodec = currentLevel.videoCodec;\n      video.id = PlaylistLevelType.MAIN;\n      const parsedVideoCodec = video.codec;\n      if ((parsedVideoCodec == null ? void 0 : parsedVideoCodec.length) === 4) {\n        // Make up for passthrough-remuxer not being able to parse full codec\n        // (logger warning \"Unhandled video codec...\")\n        switch (parsedVideoCodec) {\n          case 'hvc1':\n          case 'hev1':\n            video.codec = 'hvc1.1.6.L120.90';\n            break;\n          case 'av01':\n            video.codec = 'av01.0.04M.08';\n            break;\n          case 'avc1':\n            video.codec = 'avc1.42e01e';\n            break;\n        }\n      }\n      this.log(`Init video buffer, container:${video.container}, codecs[level/parsed]=[${currentLevel.videoCodec || ''}/${parsedVideoCodec}]${video.codec !== parsedVideoCodec ? ' parsed-corrected=' + video.codec : ''}${video.supplemental ? ' supplemental=' + video.supplemental : ''}`);\n      delete tracks.audiovideo;\n    }\n    if (audiovideo) {\n      this.log(`Init audiovideo buffer, container:${audiovideo.container}, codecs[level/parsed]=[${currentLevel.codecs}/${audiovideo.codec}]`);\n      delete tracks.video;\n      delete tracks.audio;\n    }\n    const trackTypes = Object.keys(tracks);\n    if (trackTypes.length) {\n      this.hls.trigger(Events.BUFFER_CODECS, tracks);\n      if (!this.hls) {\n        // Exit after fatal tracks error\n        return;\n      }\n      // loop through tracks that are going to be provided to bufferController\n      trackTypes.forEach(trackName => {\n        const track = tracks[trackName];\n        const initSegment = track.initSegment;\n        if (initSegment != null && initSegment.byteLength) {\n          this.hls.trigger(Events.BUFFER_APPENDING, {\n            type: trackName,\n            data: initSegment,\n            frag,\n            part: null,\n            chunkMeta,\n            parent: frag.type\n          });\n        }\n      });\n    }\n    // trigger handler right now\n    this.tickImmediate();\n  }\n  getMainFwdBufferInfo() {\n    // Observe video SourceBuffer (this.mediaBuffer) only when alt-audio is used, otherwise observe combined media buffer\n    const bufferOutput = this.mediaBuffer && this.altAudio === 2 ? this.mediaBuffer : this.media;\n    return this.getFwdBufferInfo(bufferOutput, PlaylistLevelType.MAIN);\n  }\n  get maxBufferLength() {\n    const {\n      levels,\n      level\n    } = this;\n    const levelInfo = levels == null ? void 0 : levels[level];\n    if (!levelInfo) {\n      return this.config.maxBufferLength;\n    }\n    return this.getMaxBufferLength(levelInfo.maxBitrate);\n  }\n  backtrack(frag) {\n    this.couldBacktrack = true;\n    // Causes findFragments to backtrack through fragments to find the keyframe\n    this.backtrackFragment = frag;\n    this.resetTransmuxer();\n    this.flushBufferGap(frag);\n    this.fragmentTracker.removeFragment(frag);\n    this.fragPrevious = null;\n    this.nextLoadPosition = frag.start;\n    this.state = State.IDLE;\n  }\n  checkFragmentChanged() {\n    const video = this.media;\n    let fragPlayingCurrent = null;\n    if (video && video.readyState > 1 && video.seeking === false) {\n      const currentTime = video.currentTime;\n      /* if video element is in seeked state, currentTime can only increase.\n        (assuming that playback rate is positive ...)\n        As sometimes currentTime jumps back to zero after a\n        media decode error, check this, to avoid seeking back to\n        wrong position after a media decode error\n      */\n\n      if (BufferHelper.isBuffered(video, currentTime)) {\n        fragPlayingCurrent = this.getAppendedFrag(currentTime);\n      } else if (BufferHelper.isBuffered(video, currentTime + 0.1)) {\n        /* ensure that FRAG_CHANGED event is triggered at startup,\n          when first video frame is displayed and playback is paused.\n          add a tolerance of 100ms, in case current position is not buffered,\n          check if current pos+100ms is buffered and use that buffer range\n          for FRAG_CHANGED event reporting */\n        fragPlayingCurrent = this.getAppendedFrag(currentTime + 0.1);\n      }\n      if (fragPlayingCurrent) {\n        this.backtrackFragment = null;\n        const fragPlaying = this.fragPlaying;\n        const fragCurrentLevel = fragPlayingCurrent.level;\n        if (!fragPlaying || fragPlayingCurrent.sn !== fragPlaying.sn || fragPlaying.level !== fragCurrentLevel) {\n          this.fragPlaying = fragPlayingCurrent;\n          this.hls.trigger(Events.FRAG_CHANGED, {\n            frag: fragPlayingCurrent\n          });\n          if (!fragPlaying || fragPlaying.level !== fragCurrentLevel) {\n            this.hls.trigger(Events.LEVEL_SWITCHED, {\n              level: fragCurrentLevel\n            });\n          }\n        }\n      }\n    }\n  }\n  get nextLevel() {\n    const frag = this.nextBufferedFrag;\n    if (frag) {\n      return frag.level;\n    }\n    return -1;\n  }\n  get currentFrag() {\n    var _this$media2;\n    if (this.fragPlaying) {\n      return this.fragPlaying;\n    }\n    const currentTime = ((_this$media2 = this.media) == null ? void 0 : _this$media2.currentTime) || this.lastCurrentTime;\n    if (isFiniteNumber(currentTime)) {\n      return this.getAppendedFrag(currentTime);\n    }\n    return null;\n  }\n  get currentProgramDateTime() {\n    var _this$media3;\n    const currentTime = ((_this$media3 = this.media) == null ? void 0 : _this$media3.currentTime) || this.lastCurrentTime;\n    if (isFiniteNumber(currentTime)) {\n      const details = this.getLevelDetails();\n      const frag = this.currentFrag || (details ? findFragmentByPTS(null, details.fragments, currentTime) : null);\n      if (frag) {\n        const programDateTime = frag.programDateTime;\n        if (programDateTime !== null) {\n          const epocMs = programDateTime + (currentTime - frag.start) * 1000;\n          return new Date(epocMs);\n        }\n      }\n    }\n    return null;\n  }\n  get currentLevel() {\n    const frag = this.currentFrag;\n    if (frag) {\n      return frag.level;\n    }\n    return -1;\n  }\n  get nextBufferedFrag() {\n    const frag = this.currentFrag;\n    if (frag) {\n      return this.followingBufferedFrag(frag);\n    }\n    return null;\n  }\n  get forceStartLoad() {\n    return this._forceStartLoad;\n  }\n}\n\nclass KeyLoader extends Logger {\n  constructor(config, logger) {\n    super('key-loader', logger);\n    this.config = void 0;\n    this.keyIdToKeyInfo = {};\n    this.emeController = null;\n    this.config = config;\n  }\n  abort(type) {\n    for (const id in this.keyIdToKeyInfo) {\n      const loader = this.keyIdToKeyInfo[id].loader;\n      if (loader) {\n        var _loader$context;\n        if (type && type !== ((_loader$context = loader.context) == null ? void 0 : _loader$context.frag.type)) {\n          return;\n        }\n        loader.abort();\n      }\n    }\n  }\n  detach() {\n    for (const id in this.keyIdToKeyInfo) {\n      const keyInfo = this.keyIdToKeyInfo[id];\n      // Remove cached EME keys on detach\n      if (keyInfo.mediaKeySessionContext || keyInfo.decryptdata.isCommonEncryption) {\n        delete this.keyIdToKeyInfo[id];\n      }\n    }\n  }\n  destroy() {\n    this.detach();\n    for (const id in this.keyIdToKeyInfo) {\n      const loader = this.keyIdToKeyInfo[id].loader;\n      if (loader) {\n        loader.destroy();\n      }\n    }\n    this.keyIdToKeyInfo = {};\n  }\n  createKeyLoadError(frag, details = ErrorDetails.KEY_LOAD_ERROR, error, networkDetails, response) {\n    return new LoadError({\n      type: ErrorTypes.NETWORK_ERROR,\n      details,\n      fatal: false,\n      frag,\n      response,\n      error,\n      networkDetails\n    });\n  }\n  loadClear(loadingFrag, encryptedFragments, startFragRequested) {\n    if (this.emeController && this.config.emeEnabled && !this.emeController.getSelectedKeySystemFormats().length) {\n      // Access key-system with nearest key on start (loading frag is unencrypted)\n      if (encryptedFragments.length) {\n        for (let i = 0, l = encryptedFragments.length; i < l; i++) {\n          const frag = encryptedFragments[i];\n          // Loading at or before segment with EXT-X-KEY, or first frag loading and last EXT-X-KEY\n          if (loadingFrag.cc <= frag.cc && (!isMediaFragment(loadingFrag) || !isMediaFragment(frag) || loadingFrag.sn < frag.sn) || !startFragRequested && i == l - 1) {\n            return this.emeController.selectKeySystemFormat(frag).then(keySystemFormat => {\n              if (!this.emeController) {\n                return;\n              }\n              frag.setKeyFormat(keySystemFormat);\n              const keySystem = keySystemFormatToKeySystemDomain(keySystemFormat);\n              if (keySystem) {\n                return this.emeController.getKeySystemAccess([keySystem]);\n              }\n            });\n          }\n        }\n      }\n      if (this.config.requireKeySystemAccessOnStart) {\n        const keySystemsInConfig = getKeySystemsForConfig(this.config);\n        if (keySystemsInConfig.length) {\n          return this.emeController.getKeySystemAccess(keySystemsInConfig);\n        }\n      }\n    }\n    return null;\n  }\n  load(frag) {\n    if (!frag.decryptdata && frag.encrypted && this.emeController && this.config.emeEnabled) {\n      // Multiple keys, but none selected, resolve in eme-controller\n      return this.emeController.selectKeySystemFormat(frag).then(keySystemFormat => {\n        return this.loadInternal(frag, keySystemFormat);\n      });\n    }\n    return this.loadInternal(frag);\n  }\n  loadInternal(frag, keySystemFormat) {\n    var _keyInfo, _keyInfo2;\n    if (keySystemFormat) {\n      frag.setKeyFormat(keySystemFormat);\n    }\n    const decryptdata = frag.decryptdata;\n    if (!decryptdata) {\n      const error = new Error(keySystemFormat ? `Expected frag.decryptdata to be defined after setting format ${keySystemFormat}` : `Missing decryption data on fragment in onKeyLoading (emeEnabled with controller: ${this.emeController && this.config.emeEnabled})`);\n      return Promise.reject(this.createKeyLoadError(frag, ErrorDetails.KEY_LOAD_ERROR, error));\n    }\n    const uri = decryptdata.uri;\n    if (!uri) {\n      return Promise.reject(this.createKeyLoadError(frag, ErrorDetails.KEY_LOAD_ERROR, new Error(`Invalid key URI: \"${uri}\"`)));\n    }\n    const id = getKeyId(decryptdata);\n    let keyInfo = this.keyIdToKeyInfo[id];\n    if ((_keyInfo = keyInfo) != null && _keyInfo.decryptdata.key) {\n      decryptdata.key = keyInfo.decryptdata.key;\n      return Promise.resolve({\n        frag,\n        keyInfo\n      });\n    }\n    // Return key load promise once it has a mediakey session with an usable key status\n    if (this.emeController && (_keyInfo2 = keyInfo) != null && _keyInfo2.keyLoadPromise) {\n      const keyStatus = this.emeController.getKeyStatus(keyInfo.decryptdata);\n      switch (keyStatus) {\n        case 'usable':\n        case 'usable-in-future':\n          return keyInfo.keyLoadPromise.then(keyLoadedData => {\n            // Return the correct fragment with updated decryptdata key and loaded keyInfo\n            const {\n              keyInfo\n            } = keyLoadedData;\n            decryptdata.key = keyInfo.decryptdata.key;\n            return {\n              frag,\n              keyInfo\n            };\n          });\n      }\n      // If we have a key session and status and it is not pending or usable, continue\n      // This will go back to the eme-controller for expired keys to get a new keyLoadPromise\n    }\n\n    // Load the key or return the loading promise\n    this.log(`${this.keyIdToKeyInfo[id] ? 'Rel' : 'L'}oading${decryptdata.keyId ? ' keyId: ' + arrayToHex(decryptdata.keyId) : ''} URI: ${decryptdata.uri} from ${frag.type} ${frag.level}`);\n    keyInfo = this.keyIdToKeyInfo[id] = {\n      decryptdata,\n      keyLoadPromise: null,\n      loader: null,\n      mediaKeySessionContext: null\n    };\n    switch (decryptdata.method) {\n      case 'SAMPLE-AES':\n      case 'SAMPLE-AES-CENC':\n      case 'SAMPLE-AES-CTR':\n        if (decryptdata.keyFormat === 'identity') {\n          // loadKeyHTTP handles http(s) and data URLs\n          return this.loadKeyHTTP(keyInfo, frag);\n        }\n        return this.loadKeyEME(keyInfo, frag);\n      case 'AES-128':\n      case 'AES-256':\n      case 'AES-256-CTR':\n        return this.loadKeyHTTP(keyInfo, frag);\n      default:\n        return Promise.reject(this.createKeyLoadError(frag, ErrorDetails.KEY_LOAD_ERROR, new Error(`Key supplied with unsupported METHOD: \"${decryptdata.method}\"`)));\n    }\n  }\n  loadKeyEME(keyInfo, frag) {\n    const keyLoadedData = {\n      frag,\n      keyInfo\n    };\n    if (this.emeController && this.config.emeEnabled) {\n      var _frag$initSegment;\n      if (!keyInfo.decryptdata.keyId && (_frag$initSegment = frag.initSegment) != null && _frag$initSegment.data) {\n        const keyIds = parseKeyIdsFromTenc(frag.initSegment.data);\n        if (keyIds.length) {\n          let keyId = keyIds[0];\n          if (keyId.some(b => b !== 0)) {\n            this.log(`Using keyId found in init segment ${arrayToHex(keyId)}`);\n            LevelKey.setKeyIdForUri(keyInfo.decryptdata.uri, keyId);\n          } else {\n            keyId = LevelKey.addKeyIdForUri(keyInfo.decryptdata.uri);\n            this.log(`Generating keyId to patch media ${arrayToHex(keyId)}`);\n          }\n          keyInfo.decryptdata.keyId = keyId;\n        }\n      }\n      if (!keyInfo.decryptdata.keyId && !isMediaFragment(frag)) {\n        // Resolve so that unencrypted init segment is loaded\n        // key id is extracted from tenc box when processing key for next segment above\n        return Promise.resolve(keyLoadedData);\n      }\n      const keySessionContextPromise = this.emeController.loadKey(keyLoadedData);\n      return (keyInfo.keyLoadPromise = keySessionContextPromise.then(keySessionContext => {\n        keyInfo.mediaKeySessionContext = keySessionContext;\n        return keyLoadedData;\n      })).catch(error => {\n        // Remove promise for license renewal or retry\n        keyInfo.keyLoadPromise = null;\n        if ('data' in error) {\n          error.data.frag = frag;\n        }\n        throw error;\n      });\n    }\n    return Promise.resolve(keyLoadedData);\n  }\n  loadKeyHTTP(keyInfo, frag) {\n    const config = this.config;\n    const Loader = config.loader;\n    const keyLoader = new Loader(config);\n    frag.keyLoader = keyInfo.loader = keyLoader;\n    return keyInfo.keyLoadPromise = new Promise((resolve, reject) => {\n      const loaderContext = {\n        keyInfo,\n        frag,\n        responseType: 'arraybuffer',\n        url: keyInfo.decryptdata.uri\n      };\n\n      // maxRetry is 0 so that instead of retrying the same key on the same variant multiple times,\n      // key-loader will trigger an error and rely on stream-controller to handle retry logic.\n      // this will also align retry logic with fragment-loader\n      const loadPolicy = config.keyLoadPolicy.default;\n      const loaderConfig = {\n        loadPolicy,\n        timeout: loadPolicy.maxLoadTimeMs,\n        maxRetry: 0,\n        retryDelay: 0,\n        maxRetryDelay: 0\n      };\n      const loaderCallbacks = {\n        onSuccess: (response, stats, context, networkDetails) => {\n          const {\n            frag,\n            keyInfo\n          } = context;\n          const id = getKeyId(keyInfo.decryptdata);\n          if (!frag.decryptdata || keyInfo !== this.keyIdToKeyInfo[id]) {\n            return reject(this.createKeyLoadError(frag, ErrorDetails.KEY_LOAD_ERROR, new Error('after key load, decryptdata unset or changed'), networkDetails));\n          }\n          keyInfo.decryptdata.key = frag.decryptdata.key = new Uint8Array(response.data);\n\n          // detach fragment key loader on load success\n          frag.keyLoader = null;\n          keyInfo.loader = null;\n          resolve({\n            frag,\n            keyInfo\n          });\n        },\n        onError: (response, context, networkDetails, stats) => {\n          this.resetLoader(context);\n          reject(this.createKeyLoadError(frag, ErrorDetails.KEY_LOAD_ERROR, new Error(`HTTP Error ${response.code} loading key ${response.text}`), networkDetails, _objectSpread2({\n            url: loaderContext.url,\n            data: undefined\n          }, response)));\n        },\n        onTimeout: (stats, context, networkDetails) => {\n          this.resetLoader(context);\n          reject(this.createKeyLoadError(frag, ErrorDetails.KEY_LOAD_TIMEOUT, new Error('key loading timed out'), networkDetails));\n        },\n        onAbort: (stats, context, networkDetails) => {\n          this.resetLoader(context);\n          reject(this.createKeyLoadError(frag, ErrorDetails.INTERNAL_ABORTED, new Error('key loading aborted'), networkDetails));\n        }\n      };\n      keyLoader.load(loaderContext, loaderConfig, loaderCallbacks);\n    });\n  }\n  resetLoader(context) {\n    const {\n      frag,\n      keyInfo,\n      url: uri\n    } = context;\n    const loader = keyInfo.loader;\n    if (frag.keyLoader === loader) {\n      frag.keyLoader = null;\n      keyInfo.loader = null;\n    }\n    const id = getKeyId(keyInfo.decryptdata) || uri;\n    delete this.keyIdToKeyInfo[id];\n    if (loader) {\n      loader.destroy();\n    }\n  }\n}\nfunction getKeyId(decryptdata) {\n  if (decryptdata.keyFormat !== KeySystemFormats.FAIRPLAY) {\n    const keyId = decryptdata.keyId;\n    if (keyId) {\n      return arrayToHex(keyId);\n    }\n  }\n  return decryptdata.uri;\n}\n\nfunction mapContextToLevelType(context) {\n  const {\n    type\n  } = context;\n  switch (type) {\n    case PlaylistContextType.AUDIO_TRACK:\n      return PlaylistLevelType.AUDIO;\n    case PlaylistContextType.SUBTITLE_TRACK:\n      return PlaylistLevelType.SUBTITLE;\n    default:\n      return PlaylistLevelType.MAIN;\n  }\n}\nfunction getResponseUrl(response, context) {\n  let url = response.url;\n  // responseURL not supported on some browsers (it is used to detect URL redirection)\n  // data-uri mode also not supported (but no need to detect redirection)\n  if (url === undefined || url.indexOf('data:') === 0) {\n    // fallback to initial URL\n    url = context.url;\n  }\n  return url;\n}\nclass PlaylistLoader {\n  constructor(hls) {\n    this.hls = void 0;\n    this.loaders = Object.create(null);\n    this.variableList = null;\n    this.onManifestLoaded = this.checkAutostartLoad;\n    this.hls = hls;\n    this.registerListeners();\n  }\n  startLoad(startPosition) {}\n  stopLoad() {\n    this.destroyInternalLoaders();\n  }\n  registerListeners() {\n    const {\n      hls\n    } = this;\n    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.on(Events.LEVEL_LOADING, this.onLevelLoading, this);\n    hls.on(Events.AUDIO_TRACK_LOADING, this.onAudioTrackLoading, this);\n    hls.on(Events.SUBTITLE_TRACK_LOADING, this.onSubtitleTrackLoading, this);\n    hls.on(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);\n  }\n  unregisterListeners() {\n    const {\n      hls\n    } = this;\n    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.off(Events.LEVEL_LOADING, this.onLevelLoading, this);\n    hls.off(Events.AUDIO_TRACK_LOADING, this.onAudioTrackLoading, this);\n    hls.off(Events.SUBTITLE_TRACK_LOADING, this.onSubtitleTrackLoading, this);\n    hls.off(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);\n  }\n\n  /**\n   * Returns defaults or configured loader-type overloads (pLoader and loader config params)\n   */\n  createInternalLoader(context) {\n    const config = this.hls.config;\n    const PLoader = config.pLoader;\n    const Loader = config.loader;\n    const InternalLoader = PLoader || Loader;\n    const loader = new InternalLoader(config);\n    this.loaders[context.type] = loader;\n    return loader;\n  }\n  getInternalLoader(context) {\n    return this.loaders[context.type];\n  }\n  resetInternalLoader(contextType) {\n    if (this.loaders[contextType]) {\n      delete this.loaders[contextType];\n    }\n  }\n\n  /**\n   * Call `destroy` on all internal loader instances mapped (one per context type)\n   */\n  destroyInternalLoaders() {\n    for (const contextType in this.loaders) {\n      const loader = this.loaders[contextType];\n      if (loader) {\n        loader.destroy();\n      }\n      this.resetInternalLoader(contextType);\n    }\n  }\n  destroy() {\n    this.variableList = null;\n    this.unregisterListeners();\n    this.destroyInternalLoaders();\n  }\n  onManifestLoading(event, data) {\n    const {\n      url\n    } = data;\n    this.variableList = null;\n    this.load({\n      id: null,\n      level: 0,\n      responseType: 'text',\n      type: PlaylistContextType.MANIFEST,\n      url,\n      deliveryDirectives: null,\n      levelOrTrack: null\n    });\n  }\n  onLevelLoading(event, data) {\n    const {\n      id,\n      level,\n      pathwayId,\n      url,\n      deliveryDirectives,\n      levelInfo\n    } = data;\n    this.load({\n      id,\n      level,\n      pathwayId,\n      responseType: 'text',\n      type: PlaylistContextType.LEVEL,\n      url,\n      deliveryDirectives,\n      levelOrTrack: levelInfo\n    });\n  }\n  onAudioTrackLoading(event, data) {\n    const {\n      id,\n      groupId,\n      url,\n      deliveryDirectives,\n      track\n    } = data;\n    this.load({\n      id,\n      groupId,\n      level: null,\n      responseType: 'text',\n      type: PlaylistContextType.AUDIO_TRACK,\n      url,\n      deliveryDirectives,\n      levelOrTrack: track\n    });\n  }\n  onSubtitleTrackLoading(event, data) {\n    const {\n      id,\n      groupId,\n      url,\n      deliveryDirectives,\n      track\n    } = data;\n    this.load({\n      id,\n      groupId,\n      level: null,\n      responseType: 'text',\n      type: PlaylistContextType.SUBTITLE_TRACK,\n      url,\n      deliveryDirectives,\n      levelOrTrack: track\n    });\n  }\n  onLevelsUpdated(event, data) {\n    // abort and delete loader of removed levels\n    const loader = this.loaders[PlaylistContextType.LEVEL];\n    if (loader) {\n      const context = loader.context;\n      if (context && !data.levels.some(lvl => lvl === context.levelOrTrack)) {\n        loader.abort();\n        delete this.loaders[PlaylistContextType.LEVEL];\n      }\n    }\n  }\n  load(context) {\n    var _context$deliveryDire;\n    const config = this.hls.config;\n\n    // logger.debug(`[playlist-loader]: Loading playlist of type ${context.type}, level: ${context.level}, id: ${context.id}`);\n\n    // Check if a loader for this context already exists\n    let loader = this.getInternalLoader(context);\n    if (loader) {\n      const logger = this.hls.logger;\n      const loaderContext = loader.context;\n      if (loaderContext && loaderContext.levelOrTrack === context.levelOrTrack && (loaderContext.url === context.url || loaderContext.deliveryDirectives && !context.deliveryDirectives)) {\n        // same URL can't overlap, or wait for blocking request\n        if (loaderContext.url === context.url) {\n          logger.log(`[playlist-loader]: ignore ${context.url} ongoing request`);\n        } else {\n          logger.log(`[playlist-loader]: ignore ${context.url} in favor of ${loaderContext.url}`);\n        }\n        return;\n      }\n      logger.log(`[playlist-loader]: aborting previous loader for type: ${context.type}`);\n      loader.abort();\n    }\n\n    // apply different configs for retries depending on\n    // context (manifest, level, audio/subs playlist)\n    let loadPolicy;\n    if (context.type === PlaylistContextType.MANIFEST) {\n      loadPolicy = config.manifestLoadPolicy.default;\n    } else {\n      loadPolicy = _extends({}, config.playlistLoadPolicy.default, {\n        timeoutRetry: null,\n        errorRetry: null\n      });\n    }\n    loader = this.createInternalLoader(context);\n\n    // Override level/track timeout for LL-HLS requests\n    // (the default of 10000ms is counter productive to blocking playlist reload requests)\n    if (isFiniteNumber((_context$deliveryDire = context.deliveryDirectives) == null ? void 0 : _context$deliveryDire.part)) {\n      let levelDetails;\n      if (context.type === PlaylistContextType.LEVEL && context.level !== null) {\n        levelDetails = this.hls.levels[context.level].details;\n      } else if (context.type === PlaylistContextType.AUDIO_TRACK && context.id !== null) {\n        levelDetails = this.hls.audioTracks[context.id].details;\n      } else if (context.type === PlaylistContextType.SUBTITLE_TRACK && context.id !== null) {\n        levelDetails = this.hls.subtitleTracks[context.id].details;\n      }\n      if (levelDetails) {\n        const partTarget = levelDetails.partTarget;\n        const targetDuration = levelDetails.targetduration;\n        if (partTarget && targetDuration) {\n          const maxLowLatencyPlaylistRefresh = Math.max(partTarget * 3, targetDuration * 0.8) * 1000;\n          loadPolicy = _extends({}, loadPolicy, {\n            maxTimeToFirstByteMs: Math.min(maxLowLatencyPlaylistRefresh, loadPolicy.maxTimeToFirstByteMs),\n            maxLoadTimeMs: Math.min(maxLowLatencyPlaylistRefresh, loadPolicy.maxTimeToFirstByteMs)\n          });\n        }\n      }\n    }\n    const legacyRetryCompatibility = loadPolicy.errorRetry || loadPolicy.timeoutRetry || {};\n    const loaderConfig = {\n      loadPolicy,\n      timeout: loadPolicy.maxLoadTimeMs,\n      maxRetry: legacyRetryCompatibility.maxNumRetry || 0,\n      retryDelay: legacyRetryCompatibility.retryDelayMs || 0,\n      maxRetryDelay: legacyRetryCompatibility.maxRetryDelayMs || 0\n    };\n    const loaderCallbacks = {\n      onSuccess: (response, stats, context, networkDetails) => {\n        const loader = this.getInternalLoader(context);\n        this.resetInternalLoader(context.type);\n        const string = response.data;\n        stats.parsing.start = performance.now();\n        if (M3U8Parser.isMediaPlaylist(string) || context.type !== PlaylistContextType.MANIFEST) {\n          this.handleTrackOrLevelPlaylist(response, stats, context, networkDetails || null, loader);\n        } else {\n          this.handleMasterPlaylist(response, stats, context, networkDetails);\n        }\n      },\n      onError: (response, context, networkDetails, stats) => {\n        this.handleNetworkError(context, networkDetails, false, response, stats);\n      },\n      onTimeout: (stats, context, networkDetails) => {\n        this.handleNetworkError(context, networkDetails, true, undefined, stats);\n      }\n    };\n\n    // logger.debug(`[playlist-loader]: Calling internal loader delegate for URL: ${context.url}`);\n\n    loader.load(context, loaderConfig, loaderCallbacks);\n  }\n  checkAutostartLoad() {\n    if (!this.hls) {\n      return;\n    }\n    const {\n      config: {\n        autoStartLoad,\n        startPosition\n      },\n      forceStartLoad\n    } = this.hls;\n    if (autoStartLoad || forceStartLoad) {\n      this.hls.logger.log(`${autoStartLoad ? 'auto' : 'force'} startLoad with configured startPosition ${startPosition}`);\n      this.hls.startLoad(startPosition);\n    }\n  }\n  handleMasterPlaylist(response, stats, context, networkDetails) {\n    const hls = this.hls;\n    const string = response.data;\n    const url = getResponseUrl(response, context);\n    const parsedResult = M3U8Parser.parseMasterPlaylist(string, url);\n    if (parsedResult.playlistParsingError) {\n      stats.parsing.end = performance.now();\n      this.handleManifestParsingError(response, context, parsedResult.playlistParsingError, networkDetails, stats);\n      return;\n    }\n    const {\n      contentSteering,\n      levels,\n      sessionData,\n      sessionKeys,\n      startTimeOffset,\n      variableList\n    } = parsedResult;\n    this.variableList = variableList;\n\n    // Treat unknown codec as audio or video codec based on passing `isTypeSupported` check\n    // (allows for playback of any supported codec even if not indexed in utils/codecs)\n    levels.forEach(levelParsed => {\n      const {\n        unknownCodecs\n      } = levelParsed;\n      if (unknownCodecs) {\n        const {\n          preferManagedMediaSource\n        } = this.hls.config;\n        let {\n          audioCodec,\n          videoCodec\n        } = levelParsed;\n        for (let i = unknownCodecs.length; i--;) {\n          const unknownCodec = unknownCodecs[i];\n          if (areCodecsMediaSourceSupported(unknownCodec, 'audio', preferManagedMediaSource)) {\n            levelParsed.audioCodec = audioCodec = audioCodec ? `${audioCodec},${unknownCodec}` : unknownCodec;\n            sampleEntryCodesISO.audio[audioCodec.substring(0, 4)] = 2;\n            unknownCodecs.splice(i, 1);\n          } else if (areCodecsMediaSourceSupported(unknownCodec, 'video', preferManagedMediaSource)) {\n            levelParsed.videoCodec = videoCodec = videoCodec ? `${videoCodec},${unknownCodec}` : unknownCodec;\n            sampleEntryCodesISO.video[videoCodec.substring(0, 4)] = 2;\n            unknownCodecs.splice(i, 1);\n          }\n        }\n      }\n    });\n    const {\n      AUDIO: audioTracks = [],\n      SUBTITLES: subtitles,\n      'CLOSED-CAPTIONS': captions\n    } = M3U8Parser.parseMasterPlaylistMedia(string, url, parsedResult);\n    if (audioTracks.length) {\n      // check if we have found an audio track embedded in main playlist (audio track without URI attribute)\n      const embeddedAudioFound = audioTracks.some(audioTrack => !audioTrack.url);\n\n      // if no embedded audio track defined, but audio codec signaled in quality level,\n      // we need to signal this main audio track this could happen with playlists with\n      // alt audio rendition in which quality levels (main)\n      // contains both audio+video. but with mixed audio track not signaled\n      if (!embeddedAudioFound && levels[0].audioCodec && !levels[0].attrs.AUDIO) {\n        this.hls.logger.log('[playlist-loader]: audio codec signaled in quality level, but no embedded audio track signaled, create one');\n        audioTracks.unshift({\n          type: 'main',\n          name: 'main',\n          groupId: 'main',\n          default: false,\n          autoselect: false,\n          forced: false,\n          id: -1,\n          attrs: new AttrList({}),\n          bitrate: 0,\n          url: ''\n        });\n      }\n    }\n    hls.trigger(Events.MANIFEST_LOADED, {\n      levels,\n      audioTracks,\n      subtitles,\n      captions,\n      contentSteering,\n      url,\n      stats,\n      networkDetails,\n      sessionData,\n      sessionKeys,\n      startTimeOffset,\n      variableList\n    });\n  }\n  handleTrackOrLevelPlaylist(response, stats, context, networkDetails, loader) {\n    const hls = this.hls;\n    const {\n      id,\n      level,\n      type\n    } = context;\n    const url = getResponseUrl(response, context);\n    const levelId = isFiniteNumber(level) ? level : isFiniteNumber(id) ? id : 0;\n    const levelType = mapContextToLevelType(context);\n    const levelDetails = M3U8Parser.parseLevelPlaylist(response.data, url, levelId, levelType, 0, this.variableList);\n\n    // We have done our first request (Manifest-type) and receive\n    // not a master playlist but a chunk-list (track/level)\n    // We fire the manifest-loaded event anyway with the parsed level-details\n    // by creating a single-level structure for it.\n    if (type === PlaylistContextType.MANIFEST) {\n      const singleLevel = {\n        attrs: new AttrList({}),\n        bitrate: 0,\n        details: levelDetails,\n        name: '',\n        url\n      };\n      levelDetails.requestScheduled = stats.loading.start + computeReloadInterval(levelDetails, 0);\n      hls.trigger(Events.MANIFEST_LOADED, {\n        levels: [singleLevel],\n        audioTracks: [],\n        url,\n        stats,\n        networkDetails,\n        sessionData: null,\n        sessionKeys: null,\n        contentSteering: null,\n        startTimeOffset: null,\n        variableList: null\n      });\n    }\n\n    // save parsing time\n    stats.parsing.end = performance.now();\n\n    // extend the context with the new levelDetails property\n    context.levelDetails = levelDetails;\n    this.handlePlaylistLoaded(levelDetails, response, stats, context, networkDetails, loader);\n  }\n  handleManifestParsingError(response, context, error, networkDetails, stats) {\n    this.hls.trigger(Events.ERROR, {\n      type: ErrorTypes.NETWORK_ERROR,\n      details: ErrorDetails.MANIFEST_PARSING_ERROR,\n      fatal: context.type === PlaylistContextType.MANIFEST,\n      url: response.url,\n      err: error,\n      error,\n      reason: error.message,\n      response,\n      context,\n      networkDetails,\n      stats\n    });\n  }\n  handleNetworkError(context, networkDetails, timeout = false, response, stats) {\n    let message = `A network ${timeout ? 'timeout' : 'error' + (response ? ' (status ' + response.code + ')' : '')} occurred while loading ${context.type}`;\n    if (context.type === PlaylistContextType.LEVEL) {\n      message += `: ${context.level} id: ${context.id}`;\n    } else if (context.type === PlaylistContextType.AUDIO_TRACK || context.type === PlaylistContextType.SUBTITLE_TRACK) {\n      message += ` id: ${context.id} group-id: \"${context.groupId}\"`;\n    }\n    const error = new Error(message);\n    this.hls.logger.warn(`[playlist-loader]: ${message}`);\n    let details = ErrorDetails.UNKNOWN;\n    let fatal = false;\n    const loader = this.getInternalLoader(context);\n    switch (context.type) {\n      case PlaylistContextType.MANIFEST:\n        details = timeout ? ErrorDetails.MANIFEST_LOAD_TIMEOUT : ErrorDetails.MANIFEST_LOAD_ERROR;\n        fatal = true;\n        break;\n      case PlaylistContextType.LEVEL:\n        details = timeout ? ErrorDetails.LEVEL_LOAD_TIMEOUT : ErrorDetails.LEVEL_LOAD_ERROR;\n        fatal = false;\n        break;\n      case PlaylistContextType.AUDIO_TRACK:\n        details = timeout ? ErrorDetails.AUDIO_TRACK_LOAD_TIMEOUT : ErrorDetails.AUDIO_TRACK_LOAD_ERROR;\n        fatal = false;\n        break;\n      case PlaylistContextType.SUBTITLE_TRACK:\n        details = timeout ? ErrorDetails.SUBTITLE_TRACK_LOAD_TIMEOUT : ErrorDetails.SUBTITLE_LOAD_ERROR;\n        fatal = false;\n        break;\n    }\n    if (loader) {\n      this.resetInternalLoader(context.type);\n    }\n    const errorData = {\n      type: ErrorTypes.NETWORK_ERROR,\n      details,\n      fatal,\n      url: context.url,\n      loader,\n      context,\n      error,\n      networkDetails,\n      stats\n    };\n    if (response) {\n      const url = (networkDetails == null ? void 0 : networkDetails.url) || context.url;\n      errorData.response = _objectSpread2({\n        url,\n        data: undefined\n      }, response);\n    }\n    this.hls.trigger(Events.ERROR, errorData);\n  }\n  handlePlaylistLoaded(levelDetails, response, stats, context, networkDetails, loader) {\n    const hls = this.hls;\n    const {\n      type,\n      level,\n      levelOrTrack,\n      id,\n      groupId,\n      deliveryDirectives\n    } = context;\n    const url = getResponseUrl(response, context);\n    const parent = mapContextToLevelType(context);\n    let levelIndex = typeof context.level === 'number' && parent === PlaylistLevelType.MAIN ? level : undefined;\n    const error = levelDetails.playlistParsingError;\n    if (error) {\n      this.hls.logger.warn(`${error} ${levelDetails.url}`);\n      if (!hls.config.ignorePlaylistParsingErrors) {\n        hls.trigger(Events.ERROR, {\n          type: ErrorTypes.NETWORK_ERROR,\n          details: ErrorDetails.LEVEL_PARSING_ERROR,\n          fatal: false,\n          url,\n          error,\n          reason: error.message,\n          response,\n          context,\n          level: levelIndex,\n          parent,\n          networkDetails,\n          stats\n        });\n        return;\n      }\n      levelDetails.playlistParsingError = null;\n    }\n    if (!levelDetails.fragments.length) {\n      const _error = levelDetails.playlistParsingError = new Error('No Segments found in Playlist');\n      hls.trigger(Events.ERROR, {\n        type: ErrorTypes.NETWORK_ERROR,\n        details: ErrorDetails.LEVEL_EMPTY_ERROR,\n        fatal: false,\n        url,\n        error: _error,\n        reason: _error.message,\n        response,\n        context,\n        level: levelIndex,\n        parent,\n        networkDetails,\n        stats\n      });\n      return;\n    }\n    if (levelDetails.live && loader) {\n      if (loader.getCacheAge) {\n        levelDetails.ageHeader = loader.getCacheAge() || 0;\n      }\n      if (!loader.getCacheAge || isNaN(levelDetails.ageHeader)) {\n        levelDetails.ageHeader = 0;\n      }\n    }\n    switch (type) {\n      case PlaylistContextType.MANIFEST:\n      case PlaylistContextType.LEVEL:\n        if (levelIndex) {\n          if (!levelOrTrack) {\n            // fall-through to hls.levels[0]\n            levelIndex = 0;\n          } else {\n            if (levelOrTrack !== hls.levels[levelIndex]) {\n              // correct levelIndex when lower levels were removed from hls.levels\n              const updatedIndex = hls.levels.indexOf(levelOrTrack);\n              if (updatedIndex > -1) {\n                levelIndex = updatedIndex;\n              }\n            }\n          }\n        }\n        hls.trigger(Events.LEVEL_LOADED, {\n          details: levelDetails,\n          levelInfo: levelOrTrack || hls.levels[0],\n          level: levelIndex || 0,\n          id: id || 0,\n          stats,\n          networkDetails,\n          deliveryDirectives,\n          withoutMultiVariant: type === PlaylistContextType.MANIFEST\n        });\n        break;\n      case PlaylistContextType.AUDIO_TRACK:\n        hls.trigger(Events.AUDIO_TRACK_LOADED, {\n          details: levelDetails,\n          track: levelOrTrack,\n          id: id || 0,\n          groupId: groupId || '',\n          stats,\n          networkDetails,\n          deliveryDirectives\n        });\n        break;\n      case PlaylistContextType.SUBTITLE_TRACK:\n        hls.trigger(Events.SUBTITLE_TRACK_LOADED, {\n          details: levelDetails,\n          track: levelOrTrack,\n          id: id || 0,\n          groupId: groupId || '',\n          stats,\n          networkDetails,\n          deliveryDirectives\n        });\n        break;\n    }\n  }\n}\n\n/**\n * The `Hls` class is the core of the HLS.js library used to instantiate player instances.\n * @public\n */\nclass Hls {\n  /**\n   * Get the video-dev/hls.js package version.\n   */\n  static get version() {\n    return version;\n  }\n\n  /**\n   * Check if the required MediaSource Extensions are available.\n   */\n  static isMSESupported() {\n    return isMSESupported();\n  }\n\n  /**\n   * Check if MediaSource Extensions are available and isTypeSupported checks pass for any baseline codecs.\n   */\n  static isSupported() {\n    return isSupported();\n  }\n\n  /**\n   * Get the MediaSource global used for MSE playback (ManagedMediaSource, MediaSource, or WebKitMediaSource).\n   */\n  static getMediaSource() {\n    return getMediaSource();\n  }\n  static get Events() {\n    return Events;\n  }\n  static get MetadataSchema() {\n    return MetadataSchema;\n  }\n  static get ErrorTypes() {\n    return ErrorTypes;\n  }\n  static get ErrorDetails() {\n    return ErrorDetails;\n  }\n\n  /**\n   * Get the default configuration applied to new instances.\n   */\n  static get DefaultConfig() {\n    if (!Hls.defaultConfig) {\n      return hlsDefaultConfig;\n    }\n    return Hls.defaultConfig;\n  }\n\n  /**\n   * Replace the default configuration applied to new instances.\n   */\n  static set DefaultConfig(defaultConfig) {\n    Hls.defaultConfig = defaultConfig;\n  }\n\n  /**\n   * Creates an instance of an HLS client that can attach to exactly one `HTMLMediaElement`.\n   * @param userConfig - Configuration options applied over `Hls.DefaultConfig`\n   */\n  constructor(userConfig = {}) {\n    /**\n     * The runtime configuration used by the player. At instantiation this is combination of `hls.userConfig` merged over `Hls.DefaultConfig`.\n     */\n    this.config = void 0;\n    /**\n     * The configuration object provided on player instantiation.\n     */\n    this.userConfig = void 0;\n    /**\n     * The logger functions used by this player instance, configured on player instantiation.\n     */\n    this.logger = void 0;\n    this.coreComponents = void 0;\n    this.networkControllers = void 0;\n    this._emitter = new EventEmitter();\n    this._autoLevelCapping = -1;\n    this._maxHdcpLevel = null;\n    this.abrController = void 0;\n    this.bufferController = void 0;\n    this.capLevelController = void 0;\n    this.latencyController = void 0;\n    this.levelController = void 0;\n    this.streamController = void 0;\n    this.audioStreamController = void 0;\n    this.subtititleStreamController = void 0;\n    this.audioTrackController = void 0;\n    this.subtitleTrackController = void 0;\n    this.interstitialsController = void 0;\n    this.gapController = void 0;\n    this.emeController = void 0;\n    this.cmcdController = void 0;\n    this._media = null;\n    this._url = null;\n    this._sessionId = void 0;\n    this.triggeringException = void 0;\n    this.started = false;\n    const logger = this.logger = enableLogs(userConfig.debug || false, 'Hls instance', userConfig.assetPlayerId);\n    const config = this.config = mergeConfig(Hls.DefaultConfig, userConfig, logger);\n    this.userConfig = userConfig;\n    if (config.progressive) {\n      enableStreamingMode(config, logger);\n    }\n\n    // core controllers and network loaders\n    const {\n      abrController: _AbrController,\n      bufferController: _BufferController,\n      capLevelController: _CapLevelController,\n      errorController: _ErrorController,\n      fpsController: _FpsController\n    } = config;\n    const errorController = new _ErrorController(this);\n    const abrController = this.abrController = new _AbrController(this);\n    // FragmentTracker must be defined before StreamController because the order of event handling is important\n    const fragmentTracker = new FragmentTracker(this);\n    const _InterstitialsController = config.interstitialsController;\n    const interstitialsController = _InterstitialsController ? this.interstitialsController = new _InterstitialsController(this, Hls) : null;\n    const bufferController = this.bufferController = new _BufferController(this, fragmentTracker);\n    const capLevelController = this.capLevelController = new _CapLevelController(this);\n    const fpsController = new _FpsController(this);\n    const playListLoader = new PlaylistLoader(this);\n    const _ContentSteeringController = config.contentSteeringController;\n    // Instantiate ConentSteeringController before LevelController to receive Multivariant Playlist events first\n    const contentSteering = _ContentSteeringController ? new _ContentSteeringController(this) : null;\n    const levelController = this.levelController = new LevelController(this, contentSteering);\n    const id3TrackController = new ID3TrackController(this);\n    const keyLoader = new KeyLoader(this.config, this.logger);\n    const streamController = this.streamController = new StreamController(this, fragmentTracker, keyLoader);\n    const gapController = this.gapController = new GapController(this, fragmentTracker);\n\n    // Cap level controller uses streamController to flush the buffer\n    capLevelController.setStreamController(streamController);\n    // fpsController uses streamController to switch when frames are being dropped\n    fpsController.setStreamController(streamController);\n    const networkControllers = [playListLoader, levelController, streamController];\n    if (interstitialsController) {\n      networkControllers.splice(1, 0, interstitialsController);\n    }\n    if (contentSteering) {\n      networkControllers.splice(1, 0, contentSteering);\n    }\n    this.networkControllers = networkControllers;\n    const coreComponents = [abrController, bufferController, gapController, capLevelController, fpsController, id3TrackController, fragmentTracker];\n    this.audioTrackController = this.createController(config.audioTrackController, networkControllers);\n    const AudioStreamControllerClass = config.audioStreamController;\n    if (AudioStreamControllerClass) {\n      networkControllers.push(this.audioStreamController = new AudioStreamControllerClass(this, fragmentTracker, keyLoader));\n    }\n    // Instantiate subtitleTrackController before SubtitleStreamController to receive level events first\n    this.subtitleTrackController = this.createController(config.subtitleTrackController, networkControllers);\n    const SubtitleStreamControllerClass = config.subtitleStreamController;\n    if (SubtitleStreamControllerClass) {\n      networkControllers.push(this.subtititleStreamController = new SubtitleStreamControllerClass(this, fragmentTracker, keyLoader));\n    }\n    this.createController(config.timelineController, coreComponents);\n    keyLoader.emeController = this.emeController = this.createController(config.emeController, coreComponents);\n    this.cmcdController = this.createController(config.cmcdController, coreComponents);\n    this.latencyController = this.createController(LatencyController, coreComponents);\n    this.coreComponents = coreComponents;\n\n    // Error controller handles errors before and after all other controllers\n    // This listener will be invoked after all other controllers error listeners\n    networkControllers.push(errorController);\n    const onErrorOut = errorController.onErrorOut;\n    if (typeof onErrorOut === 'function') {\n      this.on(Events.ERROR, onErrorOut, errorController);\n    }\n    // Autostart load handler\n    this.on(Events.MANIFEST_LOADED, playListLoader.onManifestLoaded, playListLoader);\n  }\n  createController(ControllerClass, components) {\n    if (ControllerClass) {\n      const controllerInstance = new ControllerClass(this);\n      if (components) {\n        components.push(controllerInstance);\n      }\n      return controllerInstance;\n    }\n    return null;\n  }\n\n  // Delegate the EventEmitter through the public API of Hls.js\n  on(event, listener, context = this) {\n    this._emitter.on(event, listener, context);\n  }\n  once(event, listener, context = this) {\n    this._emitter.once(event, listener, context);\n  }\n  removeAllListeners(event) {\n    this._emitter.removeAllListeners(event);\n  }\n  off(event, listener, context = this, once) {\n    this._emitter.off(event, listener, context, once);\n  }\n  listeners(event) {\n    return this._emitter.listeners(event);\n  }\n  emit(event, name, eventObject) {\n    return this._emitter.emit(event, name, eventObject);\n  }\n  trigger(event, eventObject) {\n    if (this.config.debug) {\n      return this.emit(event, event, eventObject);\n    } else {\n      try {\n        return this.emit(event, event, eventObject);\n      } catch (error) {\n        this.logger.error('An internal error happened while handling event ' + event + '. Error message: \"' + error.message + '\". Here is a stacktrace:', error);\n        // Prevent recursion in error event handlers that throw #5497\n        if (!this.triggeringException) {\n          this.triggeringException = true;\n          const fatal = event === Events.ERROR;\n          this.trigger(Events.ERROR, {\n            type: ErrorTypes.OTHER_ERROR,\n            details: ErrorDetails.INTERNAL_EXCEPTION,\n            fatal,\n            event,\n            error\n          });\n          this.triggeringException = false;\n        }\n      }\n    }\n    return false;\n  }\n  listenerCount(event) {\n    return this._emitter.listenerCount(event);\n  }\n\n  /**\n   * Dispose of the instance\n   */\n  destroy() {\n    this.logger.log('destroy');\n    this.trigger(Events.DESTROYING, undefined);\n    this.detachMedia();\n    this.removeAllListeners();\n    this._autoLevelCapping = -1;\n    this._url = null;\n    this.networkControllers.forEach(component => component.destroy());\n    this.networkControllers.length = 0;\n    this.coreComponents.forEach(component => component.destroy());\n    this.coreComponents.length = 0;\n    // Remove any references that could be held in config options or callbacks\n    const config = this.config;\n    config.xhrSetup = config.fetchSetup = undefined;\n    // @ts-ignore\n    this.userConfig = null;\n  }\n\n  /**\n   * Attaches Hls.js to a media element\n   */\n  attachMedia(data) {\n    if (!data || 'media' in data && !data.media) {\n      const error = new Error(`attachMedia failed: invalid argument (${data})`);\n      this.trigger(Events.ERROR, {\n        type: ErrorTypes.OTHER_ERROR,\n        details: ErrorDetails.ATTACH_MEDIA_ERROR,\n        fatal: true,\n        error\n      });\n      return;\n    }\n    this.logger.log(`attachMedia`);\n    if (this._media) {\n      this.logger.warn(`media must be detached before attaching`);\n      this.detachMedia();\n    }\n    const attachMediaSource = 'media' in data;\n    const media = attachMediaSource ? data.media : data;\n    const attachingData = attachMediaSource ? data : {\n      media\n    };\n    this._media = media;\n    this.trigger(Events.MEDIA_ATTACHING, attachingData);\n  }\n\n  /**\n   * Detach Hls.js from the media\n   */\n  detachMedia() {\n    this.logger.log('detachMedia');\n    this.trigger(Events.MEDIA_DETACHING, {});\n    this._media = null;\n  }\n\n  /**\n   * Detach HTMLMediaElement, MediaSource, and SourceBuffers without reset, for attaching to another instance\n   */\n  transferMedia() {\n    this._media = null;\n    const transferMedia = this.bufferController.transferMedia();\n    this.trigger(Events.MEDIA_DETACHING, {\n      transferMedia\n    });\n    return transferMedia;\n  }\n\n  /**\n   * Set the source URL. Can be relative or absolute.\n   */\n  loadSource(url) {\n    this.stopLoad();\n    const media = this.media;\n    const loadedSource = this._url;\n    const loadingSource = this._url = urlToolkitExports.buildAbsoluteURL(self.location.href, url, {\n      alwaysNormalize: true\n    });\n    this._autoLevelCapping = -1;\n    this._maxHdcpLevel = null;\n    this.logger.log(`loadSource:${loadingSource}`);\n    if (media && loadedSource && (loadedSource !== loadingSource || this.bufferController.hasSourceTypes())) {\n      // Remove and re-create MediaSource\n      this.detachMedia();\n      this.attachMedia(media);\n    }\n    // when attaching to a source URL, trigger a playlist load\n    this.trigger(Events.MANIFEST_LOADING, {\n      url: url\n    });\n  }\n\n  /**\n   * Gets the currently loaded URL\n   */\n  get url() {\n    return this._url;\n  }\n\n  /**\n   * Whether or not enough has been buffered to seek to start position or use `media.currentTime` to determine next load position\n   */\n  get hasEnoughToStart() {\n    return this.streamController.hasEnoughToStart;\n  }\n\n  /**\n   * Get the startPosition set on startLoad(position) or on autostart with config.startPosition\n   */\n  get startPosition() {\n    return this.streamController.startPositionValue;\n  }\n\n  /**\n   * Start loading data from the stream source.\n   * Depending on default config, client starts loading automatically when a source is set.\n   *\n   * @param startPosition - Set the start position to stream from.\n   * Defaults to -1 (None: starts from earliest point)\n   */\n  startLoad(startPosition = -1, skipSeekToStartPosition) {\n    this.logger.log(`startLoad(${startPosition + (skipSeekToStartPosition ? ', <skip seek to start>' : '')})`);\n    this.started = true;\n    this.resumeBuffering();\n    for (let i = 0; i < this.networkControllers.length; i++) {\n      this.networkControllers[i].startLoad(startPosition, skipSeekToStartPosition);\n      if (!this.started || !this.networkControllers) {\n        break;\n      }\n    }\n  }\n\n  /**\n   * Stop loading of any stream data.\n   */\n  stopLoad() {\n    this.logger.log('stopLoad');\n    this.started = false;\n    for (let i = 0; i < this.networkControllers.length; i++) {\n      this.networkControllers[i].stopLoad();\n      if (this.started || !this.networkControllers) {\n        break;\n      }\n    }\n  }\n\n  /**\n   * Returns whether loading, toggled with `startLoad()` and `stopLoad()`, is active or not`.\n   */\n  get loadingEnabled() {\n    return this.started;\n  }\n\n  /**\n   * Returns state of fragment loading toggled by calling `pauseBuffering()` and `resumeBuffering()`.\n   */\n  get bufferingEnabled() {\n    return this.streamController.bufferingEnabled;\n  }\n\n  /**\n   * Resumes stream controller segment loading after `pauseBuffering` has been called.\n   */\n  resumeBuffering() {\n    if (!this.bufferingEnabled) {\n      this.logger.log(`resume buffering`);\n      this.networkControllers.forEach(controller => {\n        if (controller.resumeBuffering) {\n          controller.resumeBuffering();\n        }\n      });\n    }\n  }\n\n  /**\n   * Prevents stream controller from loading new segments until `resumeBuffering` is called.\n   * This allows for media buffering to be paused without interupting playlist loading.\n   */\n  pauseBuffering() {\n    if (this.bufferingEnabled) {\n      this.logger.log(`pause buffering`);\n      this.networkControllers.forEach(controller => {\n        if (controller.pauseBuffering) {\n          controller.pauseBuffering();\n        }\n      });\n    }\n  }\n  get inFlightFragments() {\n    const inFlightData = {\n      [PlaylistLevelType.MAIN]: this.streamController.inFlightFrag\n    };\n    if (this.audioStreamController) {\n      inFlightData[PlaylistLevelType.AUDIO] = this.audioStreamController.inFlightFrag;\n    }\n    if (this.subtititleStreamController) {\n      inFlightData[PlaylistLevelType.SUBTITLE] = this.subtititleStreamController.inFlightFrag;\n    }\n    return inFlightData;\n  }\n\n  /**\n   * Swap through possible audio codecs in the stream (for example to switch from stereo to 5.1)\n   */\n  swapAudioCodec() {\n    this.logger.log('swapAudioCodec');\n    this.streamController.swapAudioCodec();\n  }\n\n  /**\n   * When the media-element fails, this allows to detach and then re-attach it\n   * as one call (convenience method).\n   *\n   * Automatic recovery of media-errors by this process is configurable.\n   */\n  recoverMediaError() {\n    this.logger.log('recoverMediaError');\n    const media = this._media;\n    const time = media == null ? void 0 : media.currentTime;\n    this.detachMedia();\n    if (media) {\n      this.attachMedia(media);\n      if (time) {\n        this.startLoad(time);\n      }\n    }\n  }\n  removeLevel(levelIndex) {\n    this.levelController.removeLevel(levelIndex);\n  }\n\n  /**\n   * @returns a UUID for this player instance\n   */\n  get sessionId() {\n    let _sessionId = this._sessionId;\n    if (!_sessionId) {\n      _sessionId = this._sessionId = uuid();\n    }\n    return _sessionId;\n  }\n\n  /**\n   * @returns an array of levels (variants) sorted by HDCP-LEVEL, RESOLUTION (height), FRAME-RATE, CODECS, VIDEO-RANGE, and BANDWIDTH\n   */\n  get levels() {\n    const levels = this.levelController.levels;\n    return levels ? levels : [];\n  }\n\n  /**\n   * @returns LevelDetails of last loaded level (variant) or `null` prior to loading a media playlist.\n   */\n  get latestLevelDetails() {\n    return this.streamController.getLevelDetails() || null;\n  }\n\n  /**\n   * @returns Level object of selected level (variant) or `null` prior to selecting a level or once the level is removed.\n   */\n  get loadLevelObj() {\n    return this.levelController.loadLevelObj;\n  }\n\n  /**\n   * Index of quality level (variant) currently played\n   */\n  get currentLevel() {\n    return this.streamController.currentLevel;\n  }\n\n  /**\n   * Set quality level index immediately. This will flush the current buffer to replace the quality asap. That means playback will interrupt at least shortly to re-buffer and re-sync eventually. Set to -1 for automatic level selection.\n   */\n  set currentLevel(newLevel) {\n    this.logger.log(`set currentLevel:${newLevel}`);\n    this.levelController.manualLevel = newLevel;\n    this.streamController.immediateLevelSwitch();\n  }\n\n  /**\n   * Index of next quality level loaded as scheduled by stream controller.\n   */\n  get nextLevel() {\n    return this.streamController.nextLevel;\n  }\n\n  /**\n   * Set quality level index for next loaded data.\n   * This will switch the video quality asap, without interrupting playback.\n   * May abort current loading of data, and flush parts of buffer (outside currently played fragment region).\n   * @param newLevel - Pass -1 for automatic level selection\n   */\n  set nextLevel(newLevel) {\n    this.logger.log(`set nextLevel:${newLevel}`);\n    this.levelController.manualLevel = newLevel;\n    this.streamController.nextLevelSwitch();\n  }\n\n  /**\n   * Return the quality level of the currently or last (of none is loaded currently) segment\n   */\n  get loadLevel() {\n    return this.levelController.level;\n  }\n\n  /**\n   * Set quality level index for next loaded data in a conservative way.\n   * This will switch the quality without flushing, but interrupt current loading.\n   * Thus the moment when the quality switch will appear in effect will only be after the already existing buffer.\n   * @param newLevel - Pass -1 for automatic level selection\n   */\n  set loadLevel(newLevel) {\n    this.logger.log(`set loadLevel:${newLevel}`);\n    this.levelController.manualLevel = newLevel;\n  }\n\n  /**\n   * get next quality level loaded\n   */\n  get nextLoadLevel() {\n    return this.levelController.nextLoadLevel;\n  }\n\n  /**\n   * Set quality level of next loaded segment in a fully \"non-destructive\" way.\n   * Same as `loadLevel` but will wait for next switch (until current loading is done).\n   */\n  set nextLoadLevel(level) {\n    this.levelController.nextLoadLevel = level;\n  }\n\n  /**\n   * Return \"first level\": like a default level, if not set,\n   * falls back to index of first level referenced in manifest\n   */\n  get firstLevel() {\n    return Math.max(this.levelController.firstLevel, this.minAutoLevel);\n  }\n\n  /**\n   * Sets \"first-level\", see getter.\n   */\n  set firstLevel(newLevel) {\n    this.logger.log(`set firstLevel:${newLevel}`);\n    this.levelController.firstLevel = newLevel;\n  }\n\n  /**\n   * Return the desired start level for the first fragment that will be loaded.\n   * The default value of -1 indicates automatic start level selection.\n   * Setting hls.nextAutoLevel without setting a startLevel will result in\n   * the nextAutoLevel value being used for one fragment load.\n   */\n  get startLevel() {\n    const startLevel = this.levelController.startLevel;\n    if (startLevel === -1 && this.abrController.forcedAutoLevel > -1) {\n      return this.abrController.forcedAutoLevel;\n    }\n    return startLevel;\n  }\n\n  /**\n   * set  start level (level of first fragment that will be played back)\n   * if not overrided by user, first level appearing in manifest will be used as start level\n   * if -1 : automatic start level selection, playback will start from level matching download bandwidth\n   * (determined from download of first segment)\n   */\n  set startLevel(newLevel) {\n    this.logger.log(`set startLevel:${newLevel}`);\n    // if not in automatic start level detection, ensure startLevel is greater than minAutoLevel\n    if (newLevel !== -1) {\n      newLevel = Math.max(newLevel, this.minAutoLevel);\n    }\n    this.levelController.startLevel = newLevel;\n  }\n\n  /**\n   * Whether level capping is enabled.\n   * Default value is set via `config.capLevelToPlayerSize`.\n   */\n  get capLevelToPlayerSize() {\n    return this.config.capLevelToPlayerSize;\n  }\n\n  /**\n   * Enables or disables level capping. If disabled after previously enabled, `nextLevelSwitch` will be immediately called.\n   */\n  set capLevelToPlayerSize(shouldStartCapping) {\n    const newCapLevelToPlayerSize = !!shouldStartCapping;\n    if (newCapLevelToPlayerSize !== this.config.capLevelToPlayerSize) {\n      if (newCapLevelToPlayerSize) {\n        this.capLevelController.startCapping(); // If capping occurs, nextLevelSwitch will happen based on size.\n      } else {\n        this.capLevelController.stopCapping();\n        this.autoLevelCapping = -1;\n        this.streamController.nextLevelSwitch(); // Now we're uncapped, get the next level asap.\n      }\n      this.config.capLevelToPlayerSize = newCapLevelToPlayerSize;\n    }\n  }\n\n  /**\n   * Capping/max level value that should be used by automatic level selection algorithm (`ABRController`)\n   */\n  get autoLevelCapping() {\n    return this._autoLevelCapping;\n  }\n\n  /**\n   * Returns the current bandwidth estimate in bits per second, when available. Otherwise, `NaN` is returned.\n   */\n  get bandwidthEstimate() {\n    const {\n      bwEstimator\n    } = this.abrController;\n    if (!bwEstimator) {\n      return NaN;\n    }\n    return bwEstimator.getEstimate();\n  }\n  set bandwidthEstimate(abrEwmaDefaultEstimate) {\n    this.abrController.resetEstimator(abrEwmaDefaultEstimate);\n  }\n  get abrEwmaDefaultEstimate() {\n    const {\n      bwEstimator\n    } = this.abrController;\n    if (!bwEstimator) {\n      return NaN;\n    }\n    return bwEstimator.defaultEstimate;\n  }\n\n  /**\n   * get time to first byte estimate\n   * @type {number}\n   */\n  get ttfbEstimate() {\n    const {\n      bwEstimator\n    } = this.abrController;\n    if (!bwEstimator) {\n      return NaN;\n    }\n    return bwEstimator.getEstimateTTFB();\n  }\n\n  /**\n   * Capping/max level value that should be used by automatic level selection algorithm (`ABRController`)\n   */\n  set autoLevelCapping(newLevel) {\n    if (this._autoLevelCapping !== newLevel) {\n      this.logger.log(`set autoLevelCapping:${newLevel}`);\n      this._autoLevelCapping = newLevel;\n      this.levelController.checkMaxAutoUpdated();\n    }\n  }\n  get maxHdcpLevel() {\n    return this._maxHdcpLevel;\n  }\n  set maxHdcpLevel(value) {\n    if (isHdcpLevel(value) && this._maxHdcpLevel !== value) {\n      this._maxHdcpLevel = value;\n      this.levelController.checkMaxAutoUpdated();\n    }\n  }\n\n  /**\n   * True when automatic level selection enabled\n   */\n  get autoLevelEnabled() {\n    return this.levelController.manualLevel === -1;\n  }\n\n  /**\n   * Level set manually (if any)\n   */\n  get manualLevel() {\n    return this.levelController.manualLevel;\n  }\n\n  /**\n   * min level selectable in auto mode according to config.minAutoBitrate\n   */\n  get minAutoLevel() {\n    const {\n      levels,\n      config: {\n        minAutoBitrate\n      }\n    } = this;\n    if (!levels) return 0;\n    const len = levels.length;\n    for (let i = 0; i < len; i++) {\n      if (levels[i].maxBitrate >= minAutoBitrate) {\n        return i;\n      }\n    }\n    return 0;\n  }\n\n  /**\n   * max level selectable in auto mode according to autoLevelCapping\n   */\n  get maxAutoLevel() {\n    const {\n      levels,\n      autoLevelCapping,\n      maxHdcpLevel\n    } = this;\n    let maxAutoLevel;\n    if (autoLevelCapping === -1 && levels != null && levels.length) {\n      maxAutoLevel = levels.length - 1;\n    } else {\n      maxAutoLevel = autoLevelCapping;\n    }\n    if (maxHdcpLevel) {\n      for (let i = maxAutoLevel; i--;) {\n        const hdcpLevel = levels[i].attrs['HDCP-LEVEL'];\n        if (hdcpLevel && hdcpLevel <= maxHdcpLevel) {\n          return i;\n        }\n      }\n    }\n    return maxAutoLevel;\n  }\n  get firstAutoLevel() {\n    return this.abrController.firstAutoLevel;\n  }\n\n  /**\n   * next automatically selected quality level\n   */\n  get nextAutoLevel() {\n    return this.abrController.nextAutoLevel;\n  }\n\n  /**\n   * this setter is used to force next auto level.\n   * this is useful to force a switch down in auto mode:\n   * in case of load error on level N, hls.js can set nextAutoLevel to N-1 for example)\n   * forced value is valid for one fragment. upon successful frag loading at forced level,\n   * this value will be resetted to -1 by ABR controller.\n   */\n  set nextAutoLevel(nextLevel) {\n    this.abrController.nextAutoLevel = nextLevel;\n  }\n\n  /**\n   * get the datetime value relative to media.currentTime for the active level Program Date Time if present\n   */\n  get playingDate() {\n    return this.streamController.currentProgramDateTime;\n  }\n  get mainForwardBufferInfo() {\n    return this.streamController.getMainFwdBufferInfo();\n  }\n  get maxBufferLength() {\n    return this.streamController.maxBufferLength;\n  }\n\n  /**\n   * Find and select the best matching audio track, making a level switch when a Group change is necessary.\n   * Updates `hls.config.audioPreference`. Returns the selected track, or null when no matching track is found.\n   */\n  setAudioOption(audioOption) {\n    var _this$audioTrackContr;\n    return ((_this$audioTrackContr = this.audioTrackController) == null ? void 0 : _this$audioTrackContr.setAudioOption(audioOption)) || null;\n  }\n  /**\n   * Find and select the best matching subtitle track, making a level switch when a Group change is necessary.\n   * Updates `hls.config.subtitlePreference`. Returns the selected track, or null when no matching track is found.\n   */\n  setSubtitleOption(subtitleOption) {\n    var _this$subtitleTrackCo;\n    return ((_this$subtitleTrackCo = this.subtitleTrackController) == null ? void 0 : _this$subtitleTrackCo.setSubtitleOption(subtitleOption)) || null;\n  }\n\n  /**\n   * Get the complete list of audio tracks across all media groups\n   */\n  get allAudioTracks() {\n    const audioTrackController = this.audioTrackController;\n    return audioTrackController ? audioTrackController.allAudioTracks : [];\n  }\n\n  /**\n   * Get the list of selectable audio tracks\n   */\n  get audioTracks() {\n    const audioTrackController = this.audioTrackController;\n    return audioTrackController ? audioTrackController.audioTracks : [];\n  }\n\n  /**\n   * index of the selected audio track (index in audio track lists)\n   */\n  get audioTrack() {\n    const audioTrackController = this.audioTrackController;\n    return audioTrackController ? audioTrackController.audioTrack : -1;\n  }\n\n  /**\n   * selects an audio track, based on its index in audio track lists\n   */\n  set audioTrack(audioTrackId) {\n    const audioTrackController = this.audioTrackController;\n    if (audioTrackController) {\n      audioTrackController.audioTrack = audioTrackId;\n    }\n  }\n\n  /**\n   * get the complete list of subtitle tracks across all media groups\n   */\n  get allSubtitleTracks() {\n    const subtitleTrackController = this.subtitleTrackController;\n    return subtitleTrackController ? subtitleTrackController.allSubtitleTracks : [];\n  }\n\n  /**\n   * get alternate subtitle tracks list from playlist\n   */\n  get subtitleTracks() {\n    const subtitleTrackController = this.subtitleTrackController;\n    return subtitleTrackController ? subtitleTrackController.subtitleTracks : [];\n  }\n\n  /**\n   * index of the selected subtitle track (index in subtitle track lists)\n   */\n  get subtitleTrack() {\n    const subtitleTrackController = this.subtitleTrackController;\n    return subtitleTrackController ? subtitleTrackController.subtitleTrack : -1;\n  }\n  get media() {\n    return this._media;\n  }\n\n  /**\n   * select an subtitle track, based on its index in subtitle track lists\n   */\n  set subtitleTrack(subtitleTrackId) {\n    const subtitleTrackController = this.subtitleTrackController;\n    if (subtitleTrackController) {\n      subtitleTrackController.subtitleTrack = subtitleTrackId;\n    }\n  }\n\n  /**\n   * Whether subtitle display is enabled or not\n   */\n  get subtitleDisplay() {\n    const subtitleTrackController = this.subtitleTrackController;\n    return subtitleTrackController ? subtitleTrackController.subtitleDisplay : false;\n  }\n\n  /**\n   * Enable/disable subtitle display rendering\n   */\n  set subtitleDisplay(value) {\n    const subtitleTrackController = this.subtitleTrackController;\n    if (subtitleTrackController) {\n      subtitleTrackController.subtitleDisplay = value;\n    }\n  }\n\n  /**\n   * get mode for Low-Latency HLS loading\n   */\n  get lowLatencyMode() {\n    return this.config.lowLatencyMode;\n  }\n\n  /**\n   * Enable/disable Low-Latency HLS part playlist and segment loading, and start live streams at playlist PART-HOLD-BACK rather than HOLD-BACK.\n   */\n  set lowLatencyMode(mode) {\n    this.config.lowLatencyMode = mode;\n  }\n\n  /**\n   * Position (in seconds) of live sync point (ie edge of live position minus safety delay defined by ```hls.config.liveSyncDuration```)\n   * @returns null prior to loading live Playlist\n   */\n  get liveSyncPosition() {\n    return this.latencyController.liveSyncPosition;\n  }\n\n  /**\n   * Estimated position (in seconds) of live edge (ie edge of live playlist plus time sync playlist advanced)\n   * @returns 0 before first playlist is loaded\n   */\n  get latency() {\n    return this.latencyController.latency;\n  }\n\n  /**\n   * maximum distance from the edge before the player seeks forward to ```hls.liveSyncPosition```\n   * configured using ```liveMaxLatencyDurationCount``` (multiple of target duration) or ```liveMaxLatencyDuration```\n   * @returns 0 before first playlist is loaded\n   */\n  get maxLatency() {\n    return this.latencyController.maxLatency;\n  }\n\n  /**\n   * target distance from the edge as calculated by the latency controller\n   */\n  get targetLatency() {\n    return this.latencyController.targetLatency;\n  }\n  set targetLatency(latency) {\n    this.latencyController.targetLatency = latency;\n  }\n\n  /**\n   * the rate at which the edge of the current live playlist is advancing or 1 if there is none\n   */\n  get drift() {\n    return this.latencyController.drift;\n  }\n\n  /**\n   * set to true when startLoad is called before MANIFEST_PARSED event\n   */\n  get forceStartLoad() {\n    return this.streamController.forceStartLoad;\n  }\n\n  /**\n   * ContentSteering pathways getter\n   */\n  get pathways() {\n    return this.levelController.pathways;\n  }\n\n  /**\n   * ContentSteering pathwayPriority getter/setter\n   */\n  get pathwayPriority() {\n    return this.levelController.pathwayPriority;\n  }\n  set pathwayPriority(pathwayPriority) {\n    this.levelController.pathwayPriority = pathwayPriority;\n  }\n\n  /**\n   * returns true when all SourceBuffers are buffered to the end\n   */\n  get bufferedToEnd() {\n    var _this$bufferControlle;\n    return !!((_this$bufferControlle = this.bufferController) != null && _this$bufferControlle.bufferedToEnd);\n  }\n\n  /**\n   * returns Interstitials Program Manager\n   */\n  get interstitialsManager() {\n    var _this$interstitialsCo;\n    return ((_this$interstitialsCo = this.interstitialsController) == null ? void 0 : _this$interstitialsCo.interstitialsManager) || null;\n  }\n\n  /**\n   * returns mediaCapabilities.decodingInfo for a variant/rendition\n   */\n  getMediaDecodingInfo(level, audioTracks = this.allAudioTracks) {\n    const audioTracksByGroup = getAudioTracksByGroup(audioTracks);\n    return getMediaDecodingInfoPromise(level, audioTracksByGroup, navigator.mediaCapabilities);\n  }\n}\nHls.defaultConfig = void 0;\n\n\n//# sourceMappingURL=hls.mjs.map\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/hls.js/dist/hls.mjs?\n}");

/***/ }),

/***/ "./node_modules/peerjs-js-binarypack/dist/binarypack.mjs":
/*!***************************************************************!*\
  !*** ./node_modules/peerjs-js-binarypack/dist/binarypack.mjs ***!
  \***************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Packer: () => (/* binding */ $0cfd7828ad59115f$export$b9ec4b114aa40074),\n/* harmony export */   pack: () => (/* binding */ $0cfd7828ad59115f$export$2a703dbb0cb35339),\n/* harmony export */   unpack: () => (/* binding */ $0cfd7828ad59115f$export$417857010dc9287f)\n/* harmony export */ });\nclass $e8379818650e2442$export$93654d4f2d6cd524 {\n    constructor(){\n        this.encoder = new TextEncoder();\n        this._pieces = [];\n        this._parts = [];\n    }\n    append_buffer(data) {\n        this.flush();\n        this._parts.push(data);\n    }\n    append(data) {\n        this._pieces.push(data);\n    }\n    flush() {\n        if (this._pieces.length > 0) {\n            const buf = new Uint8Array(this._pieces);\n            this._parts.push(buf);\n            this._pieces = [];\n        }\n    }\n    toArrayBuffer() {\n        const buffer = [];\n        for (const part of this._parts)buffer.push(part);\n        return $e8379818650e2442$var$concatArrayBuffers(buffer).buffer;\n    }\n}\nfunction $e8379818650e2442$var$concatArrayBuffers(bufs) {\n    let size = 0;\n    for (const buf of bufs)size += buf.byteLength;\n    const result = new Uint8Array(size);\n    let offset = 0;\n    for (const buf of bufs){\n        const view = new Uint8Array(buf.buffer, buf.byteOffset, buf.byteLength);\n        result.set(view, offset);\n        offset += buf.byteLength;\n    }\n    return result;\n}\n\n\nfunction $0cfd7828ad59115f$export$417857010dc9287f(data) {\n    const unpacker = new $0cfd7828ad59115f$var$Unpacker(data);\n    return unpacker.unpack();\n}\nfunction $0cfd7828ad59115f$export$2a703dbb0cb35339(data) {\n    const packer = new $0cfd7828ad59115f$export$b9ec4b114aa40074();\n    const res = packer.pack(data);\n    if (res instanceof Promise) return res.then(()=>packer.getBuffer());\n    return packer.getBuffer();\n}\nclass $0cfd7828ad59115f$var$Unpacker {\n    constructor(data){\n        this.index = 0;\n        this.dataBuffer = data;\n        this.dataView = new Uint8Array(this.dataBuffer);\n        this.length = this.dataBuffer.byteLength;\n    }\n    unpack() {\n        const type = this.unpack_uint8();\n        if (type < 0x80) return type;\n        else if ((type ^ 0xe0) < 0x20) return (type ^ 0xe0) - 0x20;\n        let size;\n        if ((size = type ^ 0xa0) <= 0x0f) return this.unpack_raw(size);\n        else if ((size = type ^ 0xb0) <= 0x0f) return this.unpack_string(size);\n        else if ((size = type ^ 0x90) <= 0x0f) return this.unpack_array(size);\n        else if ((size = type ^ 0x80) <= 0x0f) return this.unpack_map(size);\n        switch(type){\n            case 0xc0:\n                return null;\n            case 0xc1:\n                return undefined;\n            case 0xc2:\n                return false;\n            case 0xc3:\n                return true;\n            case 0xca:\n                return this.unpack_float();\n            case 0xcb:\n                return this.unpack_double();\n            case 0xcc:\n                return this.unpack_uint8();\n            case 0xcd:\n                return this.unpack_uint16();\n            case 0xce:\n                return this.unpack_uint32();\n            case 0xcf:\n                return this.unpack_uint64();\n            case 0xd0:\n                return this.unpack_int8();\n            case 0xd1:\n                return this.unpack_int16();\n            case 0xd2:\n                return this.unpack_int32();\n            case 0xd3:\n                return this.unpack_int64();\n            case 0xd4:\n                return undefined;\n            case 0xd5:\n                return undefined;\n            case 0xd6:\n                return undefined;\n            case 0xd7:\n                return undefined;\n            case 0xd8:\n                size = this.unpack_uint16();\n                return this.unpack_string(size);\n            case 0xd9:\n                size = this.unpack_uint32();\n                return this.unpack_string(size);\n            case 0xda:\n                size = this.unpack_uint16();\n                return this.unpack_raw(size);\n            case 0xdb:\n                size = this.unpack_uint32();\n                return this.unpack_raw(size);\n            case 0xdc:\n                size = this.unpack_uint16();\n                return this.unpack_array(size);\n            case 0xdd:\n                size = this.unpack_uint32();\n                return this.unpack_array(size);\n            case 0xde:\n                size = this.unpack_uint16();\n                return this.unpack_map(size);\n            case 0xdf:\n                size = this.unpack_uint32();\n                return this.unpack_map(size);\n        }\n    }\n    unpack_uint8() {\n        const byte = this.dataView[this.index] & 0xff;\n        this.index++;\n        return byte;\n    }\n    unpack_uint16() {\n        const bytes = this.read(2);\n        const uint16 = (bytes[0] & 0xff) * 256 + (bytes[1] & 0xff);\n        this.index += 2;\n        return uint16;\n    }\n    unpack_uint32() {\n        const bytes = this.read(4);\n        const uint32 = ((bytes[0] * 256 + bytes[1]) * 256 + bytes[2]) * 256 + bytes[3];\n        this.index += 4;\n        return uint32;\n    }\n    unpack_uint64() {\n        const bytes = this.read(8);\n        const uint64 = ((((((bytes[0] * 256 + bytes[1]) * 256 + bytes[2]) * 256 + bytes[3]) * 256 + bytes[4]) * 256 + bytes[5]) * 256 + bytes[6]) * 256 + bytes[7];\n        this.index += 8;\n        return uint64;\n    }\n    unpack_int8() {\n        const uint8 = this.unpack_uint8();\n        return uint8 < 0x80 ? uint8 : uint8 - 256;\n    }\n    unpack_int16() {\n        const uint16 = this.unpack_uint16();\n        return uint16 < 0x8000 ? uint16 : uint16 - 65536;\n    }\n    unpack_int32() {\n        const uint32 = this.unpack_uint32();\n        return uint32 < 2 ** 31 ? uint32 : uint32 - 2 ** 32;\n    }\n    unpack_int64() {\n        const uint64 = this.unpack_uint64();\n        return uint64 < 2 ** 63 ? uint64 : uint64 - 2 ** 64;\n    }\n    unpack_raw(size) {\n        if (this.length < this.index + size) throw new Error(`BinaryPackFailure: index is out of range ${this.index} ${size} ${this.length}`);\n        const buf = this.dataBuffer.slice(this.index, this.index + size);\n        this.index += size;\n        return buf;\n    }\n    unpack_string(size) {\n        const bytes = this.read(size);\n        let i = 0;\n        let str = \"\";\n        let c;\n        let code;\n        while(i < size){\n            c = bytes[i];\n            // The length of a UTF-8 sequence is specified in the first byte:\n            // 0xxxxxxx means length 1,\n            // 110xxxxx means length 2,\n            // 1110xxxx means length 3,\n            // 11110xxx means length 4.\n            // 10xxxxxx is for non-initial bytes.\n            if (c < 0xa0) {\n                // One-byte sequence: bits 0xxxxxxx\n                code = c;\n                i++;\n            } else if ((c ^ 0xc0) < 0x20) {\n                // Two-byte sequence: bits 110xxxxx 10xxxxxx\n                code = (c & 0x1f) << 6 | bytes[i + 1] & 0x3f;\n                i += 2;\n            } else if ((c ^ 0xe0) < 0x10) {\n                // Three-byte sequence: bits 1110xxxx 10xxxxxx 10xxxxxx\n                code = (c & 0x0f) << 12 | (bytes[i + 1] & 0x3f) << 6 | bytes[i + 2] & 0x3f;\n                i += 3;\n            } else {\n                // Four-byte sequence: bits 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx\n                code = (c & 0x07) << 18 | (bytes[i + 1] & 0x3f) << 12 | (bytes[i + 2] & 0x3f) << 6 | bytes[i + 3] & 0x3f;\n                i += 4;\n            }\n            str += String.fromCodePoint(code);\n        }\n        this.index += size;\n        return str;\n    }\n    unpack_array(size) {\n        const objects = new Array(size);\n        for(let i = 0; i < size; i++)objects[i] = this.unpack();\n        return objects;\n    }\n    unpack_map(size) {\n        const map = {};\n        for(let i = 0; i < size; i++){\n            const key = this.unpack();\n            map[key] = this.unpack();\n        }\n        return map;\n    }\n    unpack_float() {\n        const uint32 = this.unpack_uint32();\n        const sign = uint32 >> 31;\n        const exp = (uint32 >> 23 & 0xff) - 127;\n        const fraction = uint32 & 0x7fffff | 0x800000;\n        return (sign === 0 ? 1 : -1) * fraction * 2 ** (exp - 23);\n    }\n    unpack_double() {\n        const h32 = this.unpack_uint32();\n        const l32 = this.unpack_uint32();\n        const sign = h32 >> 31;\n        const exp = (h32 >> 20 & 0x7ff) - 1023;\n        const hfrac = h32 & 0xfffff | 0x100000;\n        const frac = hfrac * 2 ** (exp - 20) + l32 * 2 ** (exp - 52);\n        return (sign === 0 ? 1 : -1) * frac;\n    }\n    read(length) {\n        const j = this.index;\n        if (j + length <= this.length) return this.dataView.subarray(j, j + length);\n        else throw new Error(\"BinaryPackFailure: read index out of range\");\n    }\n}\nclass $0cfd7828ad59115f$export$b9ec4b114aa40074 {\n    getBuffer() {\n        return this._bufferBuilder.toArrayBuffer();\n    }\n    pack(value) {\n        if (typeof value === \"string\") this.pack_string(value);\n        else if (typeof value === \"number\") {\n            if (Math.floor(value) === value) this.pack_integer(value);\n            else this.pack_double(value);\n        } else if (typeof value === \"boolean\") {\n            if (value === true) this._bufferBuilder.append(0xc3);\n            else if (value === false) this._bufferBuilder.append(0xc2);\n        } else if (value === undefined) this._bufferBuilder.append(0xc0);\n        else if (typeof value === \"object\") {\n            if (value === null) this._bufferBuilder.append(0xc0);\n            else {\n                const constructor = value.constructor;\n                if (value instanceof Array) {\n                    const res = this.pack_array(value);\n                    if (res instanceof Promise) return res.then(()=>this._bufferBuilder.flush());\n                } else if (value instanceof ArrayBuffer) this.pack_bin(new Uint8Array(value));\n                else if (\"BYTES_PER_ELEMENT\" in value) {\n                    const v = value;\n                    this.pack_bin(new Uint8Array(v.buffer, v.byteOffset, v.byteLength));\n                } else if (value instanceof Date) this.pack_string(value.toString());\n                else if (value instanceof Blob) return value.arrayBuffer().then((buffer)=>{\n                    this.pack_bin(new Uint8Array(buffer));\n                    this._bufferBuilder.flush();\n                });\n                else if (constructor == Object || constructor.toString().startsWith(\"class\")) {\n                    const res = this.pack_object(value);\n                    if (res instanceof Promise) return res.then(()=>this._bufferBuilder.flush());\n                } else throw new Error(`Type \"${constructor.toString()}\" not yet supported`);\n            }\n        } else throw new Error(`Type \"${typeof value}\" not yet supported`);\n        this._bufferBuilder.flush();\n    }\n    pack_bin(blob) {\n        const length = blob.length;\n        if (length <= 0x0f) this.pack_uint8(0xa0 + length);\n        else if (length <= 0xffff) {\n            this._bufferBuilder.append(0xda);\n            this.pack_uint16(length);\n        } else if (length <= 0xffffffff) {\n            this._bufferBuilder.append(0xdb);\n            this.pack_uint32(length);\n        } else throw new Error(\"Invalid length\");\n        this._bufferBuilder.append_buffer(blob);\n    }\n    pack_string(str) {\n        const encoded = this._textEncoder.encode(str);\n        const length = encoded.length;\n        if (length <= 0x0f) this.pack_uint8(0xb0 + length);\n        else if (length <= 0xffff) {\n            this._bufferBuilder.append(0xd8);\n            this.pack_uint16(length);\n        } else if (length <= 0xffffffff) {\n            this._bufferBuilder.append(0xd9);\n            this.pack_uint32(length);\n        } else throw new Error(\"Invalid length\");\n        this._bufferBuilder.append_buffer(encoded);\n    }\n    pack_array(ary) {\n        const length = ary.length;\n        if (length <= 0x0f) this.pack_uint8(0x90 + length);\n        else if (length <= 0xffff) {\n            this._bufferBuilder.append(0xdc);\n            this.pack_uint16(length);\n        } else if (length <= 0xffffffff) {\n            this._bufferBuilder.append(0xdd);\n            this.pack_uint32(length);\n        } else throw new Error(\"Invalid length\");\n        const packNext = (index)=>{\n            if (index < length) {\n                const res = this.pack(ary[index]);\n                if (res instanceof Promise) return res.then(()=>packNext(index + 1));\n                return packNext(index + 1);\n            }\n        };\n        return packNext(0);\n    }\n    pack_integer(num) {\n        if (num >= -32 && num <= 0x7f) this._bufferBuilder.append(num & 0xff);\n        else if (num >= 0x00 && num <= 0xff) {\n            this._bufferBuilder.append(0xcc);\n            this.pack_uint8(num);\n        } else if (num >= -128 && num <= 0x7f) {\n            this._bufferBuilder.append(0xd0);\n            this.pack_int8(num);\n        } else if (num >= 0x0000 && num <= 0xffff) {\n            this._bufferBuilder.append(0xcd);\n            this.pack_uint16(num);\n        } else if (num >= -32768 && num <= 0x7fff) {\n            this._bufferBuilder.append(0xd1);\n            this.pack_int16(num);\n        } else if (num >= 0x00000000 && num <= 0xffffffff) {\n            this._bufferBuilder.append(0xce);\n            this.pack_uint32(num);\n        } else if (num >= -2147483648 && num <= 0x7fffffff) {\n            this._bufferBuilder.append(0xd2);\n            this.pack_int32(num);\n        } else if (num >= -9223372036854776000 && num <= 0x7fffffffffffffff) {\n            this._bufferBuilder.append(0xd3);\n            this.pack_int64(num);\n        } else if (num >= 0x0000000000000000 && num <= 0xffffffffffffffff) {\n            this._bufferBuilder.append(0xcf);\n            this.pack_uint64(num);\n        } else throw new Error(\"Invalid integer\");\n    }\n    pack_double(num) {\n        let sign = 0;\n        if (num < 0) {\n            sign = 1;\n            num = -num;\n        }\n        const exp = Math.floor(Math.log(num) / Math.LN2);\n        const frac0 = num / 2 ** exp - 1;\n        const frac1 = Math.floor(frac0 * 2 ** 52);\n        const b32 = 2 ** 32;\n        const h32 = sign << 31 | exp + 1023 << 20 | frac1 / b32 & 0x0fffff;\n        const l32 = frac1 % b32;\n        this._bufferBuilder.append(0xcb);\n        this.pack_int32(h32);\n        this.pack_int32(l32);\n    }\n    pack_object(obj) {\n        const keys = Object.keys(obj);\n        const length = keys.length;\n        if (length <= 0x0f) this.pack_uint8(0x80 + length);\n        else if (length <= 0xffff) {\n            this._bufferBuilder.append(0xde);\n            this.pack_uint16(length);\n        } else if (length <= 0xffffffff) {\n            this._bufferBuilder.append(0xdf);\n            this.pack_uint32(length);\n        } else throw new Error(\"Invalid length\");\n        const packNext = (index)=>{\n            if (index < keys.length) {\n                const prop = keys[index];\n                // eslint-disable-next-line no-prototype-builtins\n                if (obj.hasOwnProperty(prop)) {\n                    this.pack(prop);\n                    const res = this.pack(obj[prop]);\n                    if (res instanceof Promise) return res.then(()=>packNext(index + 1));\n                }\n                return packNext(index + 1);\n            }\n        };\n        return packNext(0);\n    }\n    pack_uint8(num) {\n        this._bufferBuilder.append(num);\n    }\n    pack_uint16(num) {\n        this._bufferBuilder.append(num >> 8);\n        this._bufferBuilder.append(num & 0xff);\n    }\n    pack_uint32(num) {\n        const n = num & 0xffffffff;\n        this._bufferBuilder.append((n & 0xff000000) >>> 24);\n        this._bufferBuilder.append((n & 0x00ff0000) >>> 16);\n        this._bufferBuilder.append((n & 0x0000ff00) >>> 8);\n        this._bufferBuilder.append(n & 0x000000ff);\n    }\n    pack_uint64(num) {\n        const high = num / 2 ** 32;\n        const low = num % 2 ** 32;\n        this._bufferBuilder.append((high & 0xff000000) >>> 24);\n        this._bufferBuilder.append((high & 0x00ff0000) >>> 16);\n        this._bufferBuilder.append((high & 0x0000ff00) >>> 8);\n        this._bufferBuilder.append(high & 0x000000ff);\n        this._bufferBuilder.append((low & 0xff000000) >>> 24);\n        this._bufferBuilder.append((low & 0x00ff0000) >>> 16);\n        this._bufferBuilder.append((low & 0x0000ff00) >>> 8);\n        this._bufferBuilder.append(low & 0x000000ff);\n    }\n    pack_int8(num) {\n        this._bufferBuilder.append(num & 0xff);\n    }\n    pack_int16(num) {\n        this._bufferBuilder.append((num & 0xff00) >> 8);\n        this._bufferBuilder.append(num & 0xff);\n    }\n    pack_int32(num) {\n        this._bufferBuilder.append(num >>> 24 & 0xff);\n        this._bufferBuilder.append((num & 0x00ff0000) >>> 16);\n        this._bufferBuilder.append((num & 0x0000ff00) >>> 8);\n        this._bufferBuilder.append(num & 0x000000ff);\n    }\n    pack_int64(num) {\n        const high = Math.floor(num / 2 ** 32);\n        const low = num % 2 ** 32;\n        this._bufferBuilder.append((high & 0xff000000) >>> 24);\n        this._bufferBuilder.append((high & 0x00ff0000) >>> 16);\n        this._bufferBuilder.append((high & 0x0000ff00) >>> 8);\n        this._bufferBuilder.append(high & 0x000000ff);\n        this._bufferBuilder.append((low & 0xff000000) >>> 24);\n        this._bufferBuilder.append((low & 0x00ff0000) >>> 16);\n        this._bufferBuilder.append((low & 0x0000ff00) >>> 8);\n        this._bufferBuilder.append(low & 0x000000ff);\n    }\n    constructor(){\n        this._bufferBuilder = new (0, $e8379818650e2442$export$93654d4f2d6cd524)();\n        this._textEncoder = new TextEncoder();\n    }\n}\n\n\n\n//# sourceMappingURL=binarypack.mjs.map\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/peerjs-js-binarypack/dist/binarypack.mjs?\n}");

/***/ }),

/***/ "./node_modules/peerjs/dist/bundler.mjs":
/*!**********************************************!*\
  !*** ./node_modules/peerjs/dist/bundler.mjs ***!
  \**********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   BaseConnectionErrorType: () => (/* binding */ $78455e22dea96b8c$export$7974935686149686),\n/* harmony export */   BufferedConnection: () => (/* binding */ $a229bedbcaa6ca23$export$ff7c9d4c11d94e8b),\n/* harmony export */   ConnectionType: () => (/* binding */ $78455e22dea96b8c$export$3157d57b4135e3bc),\n/* harmony export */   DataConnectionErrorType: () => (/* binding */ $78455e22dea96b8c$export$49ae800c114df41d),\n/* harmony export */   MsgPack: () => (/* binding */ $6e39230ab36396ad$export$80f5de1a66c4d624),\n/* harmony export */   MsgPackPeer: () => (/* binding */ $1e0aff16be2c328e$export$d72c7bf8eef50853),\n/* harmony export */   Peer: () => (/* binding */ $416260bce337df90$export$ecd1fc136c422448),\n/* harmony export */   PeerError: () => (/* binding */ $23779d1881157a18$export$98871882f492de82),\n/* harmony export */   PeerErrorType: () => (/* binding */ $78455e22dea96b8c$export$9547aaa2e39030ff),\n/* harmony export */   SerializationType: () => (/* binding */ $78455e22dea96b8c$export$89f507cf986a947),\n/* harmony export */   ServerMessageType: () => (/* binding */ $78455e22dea96b8c$export$adb4a1754da6f10d),\n/* harmony export */   SocketEventType: () => (/* binding */ $78455e22dea96b8c$export$3b5c4a4b6354f023),\n/* harmony export */   StreamConnection: () => (/* binding */ $20dbe68149d7aad9$export$72aa44612e2200cd),\n/* harmony export */   \"default\": () => (/* binding */ $dd0187d7f28e386f$export$2e2bcd8739ae039),\n/* harmony export */   util: () => (/* binding */ $4f4134156c446392$export$7debb50ef11d5e0b)\n/* harmony export */ });\n/* harmony import */ var peerjs_js_binarypack__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! peerjs-js-binarypack */ \"./node_modules/peerjs-js-binarypack/dist/binarypack.mjs\");\n/* harmony import */ var webrtc_adapter__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! webrtc-adapter */ \"./node_modules/webrtc-adapter/src/js/adapter_core.js\");\n/* harmony import */ var _msgpack_msgpack__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @msgpack/msgpack */ \"./node_modules/@msgpack/msgpack/dist.es5+esm/decodeAsync.mjs\");\n/* harmony import */ var _msgpack_msgpack__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! @msgpack/msgpack */ \"./node_modules/@msgpack/msgpack/dist.es5+esm/Encoder.mjs\");\n\n\n\n\n\nfunction $parcel$export(e, n, v, s) {\n  Object.defineProperty(e, n, {get: v, set: s, enumerable: true, configurable: true});\n}\nclass $fcbcc7538a6776d5$export$f1c5f4c9cb95390b {\n    constructor(){\n        this.chunkedMTU = 16300 // The original 60000 bytes setting does not work when sending data from Firefox to Chrome, which is \"cut off\" after 16384 bytes and delivered individually.\n        ;\n        // Binary stuff\n        this._dataCount = 1;\n        this.chunk = (blob)=>{\n            const chunks = [];\n            const size = blob.byteLength;\n            const total = Math.ceil(size / this.chunkedMTU);\n            let index = 0;\n            let start = 0;\n            while(start < size){\n                const end = Math.min(size, start + this.chunkedMTU);\n                const b = blob.slice(start, end);\n                const chunk = {\n                    __peerData: this._dataCount,\n                    n: index,\n                    data: b,\n                    total: total\n                };\n                chunks.push(chunk);\n                start = end;\n                index++;\n            }\n            this._dataCount++;\n            return chunks;\n        };\n    }\n}\nfunction $fcbcc7538a6776d5$export$52c89ebcdc4f53f2(bufs) {\n    let size = 0;\n    for (const buf of bufs)size += buf.byteLength;\n    const result = new Uint8Array(size);\n    let offset = 0;\n    for (const buf of bufs){\n        result.set(buf, offset);\n        offset += buf.byteLength;\n    }\n    return result;\n}\n\n\n\n\nconst $fb63e766cfafaab9$var$webRTCAdapter = //@ts-ignore\n(0, webrtc_adapter__WEBPACK_IMPORTED_MODULE_1__[\"default\"]).default || (0, webrtc_adapter__WEBPACK_IMPORTED_MODULE_1__[\"default\"]);\nconst $fb63e766cfafaab9$export$25be9502477c137d = new class {\n    isWebRTCSupported() {\n        return typeof RTCPeerConnection !== \"undefined\";\n    }\n    isBrowserSupported() {\n        const browser = this.getBrowser();\n        const version = this.getVersion();\n        const validBrowser = this.supportedBrowsers.includes(browser);\n        if (!validBrowser) return false;\n        if (browser === \"chrome\") return version >= this.minChromeVersion;\n        if (browser === \"firefox\") return version >= this.minFirefoxVersion;\n        if (browser === \"safari\") return !this.isIOS && version >= this.minSafariVersion;\n        return false;\n    }\n    getBrowser() {\n        return $fb63e766cfafaab9$var$webRTCAdapter.browserDetails.browser;\n    }\n    getVersion() {\n        return $fb63e766cfafaab9$var$webRTCAdapter.browserDetails.version || 0;\n    }\n    isUnifiedPlanSupported() {\n        const browser = this.getBrowser();\n        const version = $fb63e766cfafaab9$var$webRTCAdapter.browserDetails.version || 0;\n        if (browser === \"chrome\" && version < this.minChromeVersion) return false;\n        if (browser === \"firefox\" && version >= this.minFirefoxVersion) return true;\n        if (!window.RTCRtpTransceiver || !(\"currentDirection\" in RTCRtpTransceiver.prototype)) return false;\n        let tempPc;\n        let supported = false;\n        try {\n            tempPc = new RTCPeerConnection();\n            tempPc.addTransceiver(\"audio\");\n            supported = true;\n        } catch (e) {} finally{\n            if (tempPc) tempPc.close();\n        }\n        return supported;\n    }\n    toString() {\n        return `Supports:\n    browser:${this.getBrowser()}\n    version:${this.getVersion()}\n    isIOS:${this.isIOS}\n    isWebRTCSupported:${this.isWebRTCSupported()}\n    isBrowserSupported:${this.isBrowserSupported()}\n    isUnifiedPlanSupported:${this.isUnifiedPlanSupported()}`;\n    }\n    constructor(){\n        this.isIOS = typeof navigator !== \"undefined\" ? [\n            \"iPad\",\n            \"iPhone\",\n            \"iPod\"\n        ].includes(navigator.platform) : false;\n        this.supportedBrowsers = [\n            \"firefox\",\n            \"chrome\",\n            \"safari\"\n        ];\n        this.minFirefoxVersion = 59;\n        this.minChromeVersion = 72;\n        this.minSafariVersion = 605;\n    }\n}();\n\n\nconst $9a84a32bf0bf36bb$export$f35f128fd59ea256 = (id)=>{\n    // Allow empty ids\n    return !id || /^[A-Za-z0-9]+(?:[ _-][A-Za-z0-9]+)*$/.test(id);\n};\n\n\nconst $0e5fd1585784c252$export$4e61f672936bec77 = ()=>Math.random().toString(36).slice(2);\n\n\nconst $4f4134156c446392$var$DEFAULT_CONFIG = {\n    iceServers: [\n        {\n            urls: \"stun:stun.l.google.com:19302\"\n        },\n        {\n            urls: [\n                \"turn:eu-0.turn.peerjs.com:3478\",\n                \"turn:us-0.turn.peerjs.com:3478\"\n            ],\n            username: \"peerjs\",\n            credential: \"peerjsp\"\n        }\n    ],\n    sdpSemantics: \"unified-plan\"\n};\nclass $4f4134156c446392$export$f8f26dd395d7e1bd extends (0, $fcbcc7538a6776d5$export$f1c5f4c9cb95390b) {\n    noop() {}\n    blobToArrayBuffer(blob, cb) {\n        const fr = new FileReader();\n        fr.onload = function(evt) {\n            if (evt.target) cb(evt.target.result);\n        };\n        fr.readAsArrayBuffer(blob);\n        return fr;\n    }\n    binaryStringToArrayBuffer(binary) {\n        const byteArray = new Uint8Array(binary.length);\n        for(let i = 0; i < binary.length; i++)byteArray[i] = binary.charCodeAt(i) & 0xff;\n        return byteArray.buffer;\n    }\n    isSecure() {\n        return location.protocol === \"https:\";\n    }\n    constructor(...args){\n        super(...args);\n        this.CLOUD_HOST = \"0.peerjs.com\";\n        this.CLOUD_PORT = 443;\n        // Browsers that need chunking:\n        this.chunkedBrowsers = {\n            Chrome: 1,\n            chrome: 1\n        };\n        // Returns browser-agnostic default config\n        this.defaultConfig = $4f4134156c446392$var$DEFAULT_CONFIG;\n        this.browser = (0, $fb63e766cfafaab9$export$25be9502477c137d).getBrowser();\n        this.browserVersion = (0, $fb63e766cfafaab9$export$25be9502477c137d).getVersion();\n        this.pack = peerjs_js_binarypack__WEBPACK_IMPORTED_MODULE_0__.pack;\n        this.unpack = peerjs_js_binarypack__WEBPACK_IMPORTED_MODULE_0__.unpack;\n        /**\n\t * A hash of WebRTC features mapped to booleans that correspond to whether the feature is supported by the current browser.\n\t *\n\t * :::caution\n\t * Only the properties documented here are guaranteed to be present on `util.supports`\n\t * :::\n\t */ this.supports = function() {\n            const supported = {\n                browser: (0, $fb63e766cfafaab9$export$25be9502477c137d).isBrowserSupported(),\n                webRTC: (0, $fb63e766cfafaab9$export$25be9502477c137d).isWebRTCSupported(),\n                audioVideo: false,\n                data: false,\n                binaryBlob: false,\n                reliable: false\n            };\n            if (!supported.webRTC) return supported;\n            let pc;\n            try {\n                pc = new RTCPeerConnection($4f4134156c446392$var$DEFAULT_CONFIG);\n                supported.audioVideo = true;\n                let dc;\n                try {\n                    dc = pc.createDataChannel(\"_PEERJSTEST\", {\n                        ordered: true\n                    });\n                    supported.data = true;\n                    supported.reliable = !!dc.ordered;\n                    // Binary test\n                    try {\n                        dc.binaryType = \"blob\";\n                        supported.binaryBlob = !(0, $fb63e766cfafaab9$export$25be9502477c137d).isIOS;\n                    } catch (e) {}\n                } catch (e) {} finally{\n                    if (dc) dc.close();\n                }\n            } catch (e) {} finally{\n                if (pc) pc.close();\n            }\n            return supported;\n        }();\n        // Ensure alphanumeric ids\n        this.validateId = (0, $9a84a32bf0bf36bb$export$f35f128fd59ea256);\n        this.randomToken = (0, $0e5fd1585784c252$export$4e61f672936bec77);\n    }\n}\nconst $4f4134156c446392$export$7debb50ef11d5e0b = new $4f4134156c446392$export$f8f26dd395d7e1bd();\n\n\n\nconst $257947e92926277a$var$LOG_PREFIX = \"PeerJS: \";\nvar $257947e92926277a$export$243e62d78d3b544d;\n(function(LogLevel) {\n    /**\n\t * Prints no logs.\n\t */ LogLevel[LogLevel[\"Disabled\"] = 0] = \"Disabled\";\n    /**\n\t * Prints only errors.\n\t */ LogLevel[LogLevel[\"Errors\"] = 1] = \"Errors\";\n    /**\n\t * Prints errors and warnings.\n\t */ LogLevel[LogLevel[\"Warnings\"] = 2] = \"Warnings\";\n    /**\n\t * Prints all logs.\n\t */ LogLevel[LogLevel[\"All\"] = 3] = \"All\";\n})($257947e92926277a$export$243e62d78d3b544d || ($257947e92926277a$export$243e62d78d3b544d = {}));\nclass $257947e92926277a$var$Logger {\n    get logLevel() {\n        return this._logLevel;\n    }\n    set logLevel(logLevel) {\n        this._logLevel = logLevel;\n    }\n    log(...args) {\n        if (this._logLevel >= 3) this._print(3, ...args);\n    }\n    warn(...args) {\n        if (this._logLevel >= 2) this._print(2, ...args);\n    }\n    error(...args) {\n        if (this._logLevel >= 1) this._print(1, ...args);\n    }\n    setLogFunction(fn) {\n        this._print = fn;\n    }\n    _print(logLevel, ...rest) {\n        const copy = [\n            $257947e92926277a$var$LOG_PREFIX,\n            ...rest\n        ];\n        for(const i in copy)if (copy[i] instanceof Error) copy[i] = \"(\" + copy[i].name + \") \" + copy[i].message;\n        if (logLevel >= 3) console.log(...copy);\n        else if (logLevel >= 2) console.warn(\"WARNING\", ...copy);\n        else if (logLevel >= 1) console.error(\"ERROR\", ...copy);\n    }\n    constructor(){\n        this._logLevel = 0;\n    }\n}\nvar $257947e92926277a$export$2e2bcd8739ae039 = new $257947e92926277a$var$Logger();\n\n\nvar $c4dcfd1d1ea86647$exports = {};\n\"use strict\";\nvar $c4dcfd1d1ea86647$var$has = Object.prototype.hasOwnProperty, $c4dcfd1d1ea86647$var$prefix = \"~\";\n/**\n * Constructor to create a storage for our `EE` objects.\n * An `Events` instance is a plain object whose properties are event names.\n *\n * @constructor\n * @private\n */ function $c4dcfd1d1ea86647$var$Events() {}\n//\n// We try to not inherit from `Object.prototype`. In some engines creating an\n// instance in this way is faster than calling `Object.create(null)` directly.\n// If `Object.create(null)` is not supported we prefix the event names with a\n// character to make sure that the built-in object properties are not\n// overridden or used as an attack vector.\n//\nif (Object.create) {\n    $c4dcfd1d1ea86647$var$Events.prototype = Object.create(null);\n    //\n    // This hack is needed because the `__proto__` property is still inherited in\n    // some old browsers like Android 4, iPhone 5.1, Opera 11 and Safari 5.\n    //\n    if (!new $c4dcfd1d1ea86647$var$Events().__proto__) $c4dcfd1d1ea86647$var$prefix = false;\n}\n/**\n * Representation of a single event listener.\n *\n * @param {Function} fn The listener function.\n * @param {*} context The context to invoke the listener with.\n * @param {Boolean} [once=false] Specify if the listener is a one-time listener.\n * @constructor\n * @private\n */ function $c4dcfd1d1ea86647$var$EE(fn, context, once) {\n    this.fn = fn;\n    this.context = context;\n    this.once = once || false;\n}\n/**\n * Add a listener for a given event.\n *\n * @param {EventEmitter} emitter Reference to the `EventEmitter` instance.\n * @param {(String|Symbol)} event The event name.\n * @param {Function} fn The listener function.\n * @param {*} context The context to invoke the listener with.\n * @param {Boolean} once Specify if the listener is a one-time listener.\n * @returns {EventEmitter}\n * @private\n */ function $c4dcfd1d1ea86647$var$addListener(emitter, event, fn, context, once) {\n    if (typeof fn !== \"function\") throw new TypeError(\"The listener must be a function\");\n    var listener = new $c4dcfd1d1ea86647$var$EE(fn, context || emitter, once), evt = $c4dcfd1d1ea86647$var$prefix ? $c4dcfd1d1ea86647$var$prefix + event : event;\n    if (!emitter._events[evt]) emitter._events[evt] = listener, emitter._eventsCount++;\n    else if (!emitter._events[evt].fn) emitter._events[evt].push(listener);\n    else emitter._events[evt] = [\n        emitter._events[evt],\n        listener\n    ];\n    return emitter;\n}\n/**\n * Clear event by name.\n *\n * @param {EventEmitter} emitter Reference to the `EventEmitter` instance.\n * @param {(String|Symbol)} evt The Event name.\n * @private\n */ function $c4dcfd1d1ea86647$var$clearEvent(emitter, evt) {\n    if (--emitter._eventsCount === 0) emitter._events = new $c4dcfd1d1ea86647$var$Events();\n    else delete emitter._events[evt];\n}\n/**\n * Minimal `EventEmitter` interface that is molded against the Node.js\n * `EventEmitter` interface.\n *\n * @constructor\n * @public\n */ function $c4dcfd1d1ea86647$var$EventEmitter() {\n    this._events = new $c4dcfd1d1ea86647$var$Events();\n    this._eventsCount = 0;\n}\n/**\n * Return an array listing the events for which the emitter has registered\n * listeners.\n *\n * @returns {Array}\n * @public\n */ $c4dcfd1d1ea86647$var$EventEmitter.prototype.eventNames = function eventNames() {\n    var names = [], events, name;\n    if (this._eventsCount === 0) return names;\n    for(name in events = this._events)if ($c4dcfd1d1ea86647$var$has.call(events, name)) names.push($c4dcfd1d1ea86647$var$prefix ? name.slice(1) : name);\n    if (Object.getOwnPropertySymbols) return names.concat(Object.getOwnPropertySymbols(events));\n    return names;\n};\n/**\n * Return the listeners registered for a given event.\n *\n * @param {(String|Symbol)} event The event name.\n * @returns {Array} The registered listeners.\n * @public\n */ $c4dcfd1d1ea86647$var$EventEmitter.prototype.listeners = function listeners(event) {\n    var evt = $c4dcfd1d1ea86647$var$prefix ? $c4dcfd1d1ea86647$var$prefix + event : event, handlers = this._events[evt];\n    if (!handlers) return [];\n    if (handlers.fn) return [\n        handlers.fn\n    ];\n    for(var i = 0, l = handlers.length, ee = new Array(l); i < l; i++)ee[i] = handlers[i].fn;\n    return ee;\n};\n/**\n * Return the number of listeners listening to a given event.\n *\n * @param {(String|Symbol)} event The event name.\n * @returns {Number} The number of listeners.\n * @public\n */ $c4dcfd1d1ea86647$var$EventEmitter.prototype.listenerCount = function listenerCount(event) {\n    var evt = $c4dcfd1d1ea86647$var$prefix ? $c4dcfd1d1ea86647$var$prefix + event : event, listeners = this._events[evt];\n    if (!listeners) return 0;\n    if (listeners.fn) return 1;\n    return listeners.length;\n};\n/**\n * Calls each of the listeners registered for a given event.\n *\n * @param {(String|Symbol)} event The event name.\n * @returns {Boolean} `true` if the event had listeners, else `false`.\n * @public\n */ $c4dcfd1d1ea86647$var$EventEmitter.prototype.emit = function emit(event, a1, a2, a3, a4, a5) {\n    var evt = $c4dcfd1d1ea86647$var$prefix ? $c4dcfd1d1ea86647$var$prefix + event : event;\n    if (!this._events[evt]) return false;\n    var listeners = this._events[evt], len = arguments.length, args, i;\n    if (listeners.fn) {\n        if (listeners.once) this.removeListener(event, listeners.fn, undefined, true);\n        switch(len){\n            case 1:\n                return listeners.fn.call(listeners.context), true;\n            case 2:\n                return listeners.fn.call(listeners.context, a1), true;\n            case 3:\n                return listeners.fn.call(listeners.context, a1, a2), true;\n            case 4:\n                return listeners.fn.call(listeners.context, a1, a2, a3), true;\n            case 5:\n                return listeners.fn.call(listeners.context, a1, a2, a3, a4), true;\n            case 6:\n                return listeners.fn.call(listeners.context, a1, a2, a3, a4, a5), true;\n        }\n        for(i = 1, args = new Array(len - 1); i < len; i++)args[i - 1] = arguments[i];\n        listeners.fn.apply(listeners.context, args);\n    } else {\n        var length = listeners.length, j;\n        for(i = 0; i < length; i++){\n            if (listeners[i].once) this.removeListener(event, listeners[i].fn, undefined, true);\n            switch(len){\n                case 1:\n                    listeners[i].fn.call(listeners[i].context);\n                    break;\n                case 2:\n                    listeners[i].fn.call(listeners[i].context, a1);\n                    break;\n                case 3:\n                    listeners[i].fn.call(listeners[i].context, a1, a2);\n                    break;\n                case 4:\n                    listeners[i].fn.call(listeners[i].context, a1, a2, a3);\n                    break;\n                default:\n                    if (!args) for(j = 1, args = new Array(len - 1); j < len; j++)args[j - 1] = arguments[j];\n                    listeners[i].fn.apply(listeners[i].context, args);\n            }\n        }\n    }\n    return true;\n};\n/**\n * Add a listener for a given event.\n *\n * @param {(String|Symbol)} event The event name.\n * @param {Function} fn The listener function.\n * @param {*} [context=this] The context to invoke the listener with.\n * @returns {EventEmitter} `this`.\n * @public\n */ $c4dcfd1d1ea86647$var$EventEmitter.prototype.on = function on(event, fn, context) {\n    return $c4dcfd1d1ea86647$var$addListener(this, event, fn, context, false);\n};\n/**\n * Add a one-time listener for a given event.\n *\n * @param {(String|Symbol)} event The event name.\n * @param {Function} fn The listener function.\n * @param {*} [context=this] The context to invoke the listener with.\n * @returns {EventEmitter} `this`.\n * @public\n */ $c4dcfd1d1ea86647$var$EventEmitter.prototype.once = function once(event, fn, context) {\n    return $c4dcfd1d1ea86647$var$addListener(this, event, fn, context, true);\n};\n/**\n * Remove the listeners of a given event.\n *\n * @param {(String|Symbol)} event The event name.\n * @param {Function} fn Only remove the listeners that match this function.\n * @param {*} context Only remove the listeners that have this context.\n * @param {Boolean} once Only remove one-time listeners.\n * @returns {EventEmitter} `this`.\n * @public\n */ $c4dcfd1d1ea86647$var$EventEmitter.prototype.removeListener = function removeListener(event, fn, context, once) {\n    var evt = $c4dcfd1d1ea86647$var$prefix ? $c4dcfd1d1ea86647$var$prefix + event : event;\n    if (!this._events[evt]) return this;\n    if (!fn) {\n        $c4dcfd1d1ea86647$var$clearEvent(this, evt);\n        return this;\n    }\n    var listeners = this._events[evt];\n    if (listeners.fn) {\n        if (listeners.fn === fn && (!once || listeners.once) && (!context || listeners.context === context)) $c4dcfd1d1ea86647$var$clearEvent(this, evt);\n    } else {\n        for(var i = 0, events = [], length = listeners.length; i < length; i++)if (listeners[i].fn !== fn || once && !listeners[i].once || context && listeners[i].context !== context) events.push(listeners[i]);\n        //\n        // Reset the array, or remove it completely if we have no more listeners.\n        //\n        if (events.length) this._events[evt] = events.length === 1 ? events[0] : events;\n        else $c4dcfd1d1ea86647$var$clearEvent(this, evt);\n    }\n    return this;\n};\n/**\n * Remove all listeners, or those of the specified event.\n *\n * @param {(String|Symbol)} [event] The event name.\n * @returns {EventEmitter} `this`.\n * @public\n */ $c4dcfd1d1ea86647$var$EventEmitter.prototype.removeAllListeners = function removeAllListeners(event) {\n    var evt;\n    if (event) {\n        evt = $c4dcfd1d1ea86647$var$prefix ? $c4dcfd1d1ea86647$var$prefix + event : event;\n        if (this._events[evt]) $c4dcfd1d1ea86647$var$clearEvent(this, evt);\n    } else {\n        this._events = new $c4dcfd1d1ea86647$var$Events();\n        this._eventsCount = 0;\n    }\n    return this;\n};\n//\n// Alias methods names because people roll like that.\n//\n$c4dcfd1d1ea86647$var$EventEmitter.prototype.off = $c4dcfd1d1ea86647$var$EventEmitter.prototype.removeListener;\n$c4dcfd1d1ea86647$var$EventEmitter.prototype.addListener = $c4dcfd1d1ea86647$var$EventEmitter.prototype.on;\n//\n// Expose the prefix.\n//\n$c4dcfd1d1ea86647$var$EventEmitter.prefixed = $c4dcfd1d1ea86647$var$prefix;\n//\n// Allow `EventEmitter` to be imported as module namespace.\n//\n$c4dcfd1d1ea86647$var$EventEmitter.EventEmitter = $c4dcfd1d1ea86647$var$EventEmitter;\n$c4dcfd1d1ea86647$exports = $c4dcfd1d1ea86647$var$EventEmitter;\n\n\n\nvar $78455e22dea96b8c$exports = {};\n\n$parcel$export($78455e22dea96b8c$exports, \"ConnectionType\", () => $78455e22dea96b8c$export$3157d57b4135e3bc);\n$parcel$export($78455e22dea96b8c$exports, \"PeerErrorType\", () => $78455e22dea96b8c$export$9547aaa2e39030ff);\n$parcel$export($78455e22dea96b8c$exports, \"BaseConnectionErrorType\", () => $78455e22dea96b8c$export$7974935686149686);\n$parcel$export($78455e22dea96b8c$exports, \"DataConnectionErrorType\", () => $78455e22dea96b8c$export$49ae800c114df41d);\n$parcel$export($78455e22dea96b8c$exports, \"SerializationType\", () => $78455e22dea96b8c$export$89f507cf986a947);\n$parcel$export($78455e22dea96b8c$exports, \"SocketEventType\", () => $78455e22dea96b8c$export$3b5c4a4b6354f023);\n$parcel$export($78455e22dea96b8c$exports, \"ServerMessageType\", () => $78455e22dea96b8c$export$adb4a1754da6f10d);\nvar $78455e22dea96b8c$export$3157d57b4135e3bc;\n(function(ConnectionType) {\n    ConnectionType[\"Data\"] = \"data\";\n    ConnectionType[\"Media\"] = \"media\";\n})($78455e22dea96b8c$export$3157d57b4135e3bc || ($78455e22dea96b8c$export$3157d57b4135e3bc = {}));\nvar $78455e22dea96b8c$export$9547aaa2e39030ff;\n(function(PeerErrorType) {\n    /**\n\t * The client's browser does not support some or all WebRTC features that you are trying to use.\n\t */ PeerErrorType[\"BrowserIncompatible\"] = \"browser-incompatible\";\n    /**\n\t * You've already disconnected this peer from the server and can no longer make any new connections on it.\n\t */ PeerErrorType[\"Disconnected\"] = \"disconnected\";\n    /**\n\t * The ID passed into the Peer constructor contains illegal characters.\n\t */ PeerErrorType[\"InvalidID\"] = \"invalid-id\";\n    /**\n\t * The API key passed into the Peer constructor contains illegal characters or is not in the system (cloud server only).\n\t */ PeerErrorType[\"InvalidKey\"] = \"invalid-key\";\n    /**\n\t * Lost or cannot establish a connection to the signalling server.\n\t */ PeerErrorType[\"Network\"] = \"network\";\n    /**\n\t * The peer you're trying to connect to does not exist.\n\t */ PeerErrorType[\"PeerUnavailable\"] = \"peer-unavailable\";\n    /**\n\t * PeerJS is being used securely, but the cloud server does not support SSL. Use a custom PeerServer.\n\t */ PeerErrorType[\"SslUnavailable\"] = \"ssl-unavailable\";\n    /**\n\t * Unable to reach the server.\n\t */ PeerErrorType[\"ServerError\"] = \"server-error\";\n    /**\n\t * An error from the underlying socket.\n\t */ PeerErrorType[\"SocketError\"] = \"socket-error\";\n    /**\n\t * The underlying socket closed unexpectedly.\n\t */ PeerErrorType[\"SocketClosed\"] = \"socket-closed\";\n    /**\n\t * The ID passed into the Peer constructor is already taken.\n\t *\n\t * :::caution\n\t * This error is not fatal if your peer has open peer-to-peer connections.\n\t * This can happen if you attempt to {@apilink Peer.reconnect} a peer that has been disconnected from the server,\n\t * but its old ID has now been taken.\n\t * :::\n\t */ PeerErrorType[\"UnavailableID\"] = \"unavailable-id\";\n    /**\n\t * Native WebRTC errors.\n\t */ PeerErrorType[\"WebRTC\"] = \"webrtc\";\n})($78455e22dea96b8c$export$9547aaa2e39030ff || ($78455e22dea96b8c$export$9547aaa2e39030ff = {}));\nvar $78455e22dea96b8c$export$7974935686149686;\n(function(BaseConnectionErrorType) {\n    BaseConnectionErrorType[\"NegotiationFailed\"] = \"negotiation-failed\";\n    BaseConnectionErrorType[\"ConnectionClosed\"] = \"connection-closed\";\n})($78455e22dea96b8c$export$7974935686149686 || ($78455e22dea96b8c$export$7974935686149686 = {}));\nvar $78455e22dea96b8c$export$49ae800c114df41d;\n(function(DataConnectionErrorType) {\n    DataConnectionErrorType[\"NotOpenYet\"] = \"not-open-yet\";\n    DataConnectionErrorType[\"MessageToBig\"] = \"message-too-big\";\n})($78455e22dea96b8c$export$49ae800c114df41d || ($78455e22dea96b8c$export$49ae800c114df41d = {}));\nvar $78455e22dea96b8c$export$89f507cf986a947;\n(function(SerializationType) {\n    SerializationType[\"Binary\"] = \"binary\";\n    SerializationType[\"BinaryUTF8\"] = \"binary-utf8\";\n    SerializationType[\"JSON\"] = \"json\";\n    SerializationType[\"None\"] = \"raw\";\n})($78455e22dea96b8c$export$89f507cf986a947 || ($78455e22dea96b8c$export$89f507cf986a947 = {}));\nvar $78455e22dea96b8c$export$3b5c4a4b6354f023;\n(function(SocketEventType) {\n    SocketEventType[\"Message\"] = \"message\";\n    SocketEventType[\"Disconnected\"] = \"disconnected\";\n    SocketEventType[\"Error\"] = \"error\";\n    SocketEventType[\"Close\"] = \"close\";\n})($78455e22dea96b8c$export$3b5c4a4b6354f023 || ($78455e22dea96b8c$export$3b5c4a4b6354f023 = {}));\nvar $78455e22dea96b8c$export$adb4a1754da6f10d;\n(function(ServerMessageType) {\n    ServerMessageType[\"Heartbeat\"] = \"HEARTBEAT\";\n    ServerMessageType[\"Candidate\"] = \"CANDIDATE\";\n    ServerMessageType[\"Offer\"] = \"OFFER\";\n    ServerMessageType[\"Answer\"] = \"ANSWER\";\n    ServerMessageType[\"Open\"] = \"OPEN\";\n    ServerMessageType[\"Error\"] = \"ERROR\";\n    ServerMessageType[\"IdTaken\"] = \"ID-TAKEN\";\n    ServerMessageType[\"InvalidKey\"] = \"INVALID-KEY\";\n    ServerMessageType[\"Leave\"] = \"LEAVE\";\n    ServerMessageType[\"Expire\"] = \"EXPIRE\";\n})($78455e22dea96b8c$export$adb4a1754da6f10d || ($78455e22dea96b8c$export$adb4a1754da6f10d = {}));\n\n\nvar $f5f881ec4575f1fc$exports = {};\n$f5f881ec4575f1fc$exports = JSON.parse('{\"name\":\"peerjs\",\"version\":\"1.5.4\",\"keywords\":[\"peerjs\",\"webrtc\",\"p2p\",\"rtc\"],\"description\":\"PeerJS client\",\"homepage\":\"https://peerjs.com\",\"bugs\":{\"url\":\"https://github.com/peers/peerjs/issues\"},\"repository\":{\"type\":\"git\",\"url\":\"https://github.com/peers/peerjs\"},\"license\":\"MIT\",\"contributors\":[\"Michelle Bu <michelle@michellebu.com>\",\"afrokick <devbyru@gmail.com>\",\"ericz <really.ez@gmail.com>\",\"Jairo <kidandcat@gmail.com>\",\"Jonas Gloning <34194370+jonasgloning@users.noreply.github.com>\",\"Jairo Caro-Accino Viciana <jairo@galax.be>\",\"Carlos Caballero <carlos.caballero.gonzalez@gmail.com>\",\"hc <hheennrryy@gmail.com>\",\"Muhammad Asif <capripio@gmail.com>\",\"PrashoonB <prashoonbhattacharjee@gmail.com>\",\"Harsh Bardhan Mishra <47351025+HarshCasper@users.noreply.github.com>\",\"akotynski <aleksanderkotbury@gmail.com>\",\"lmb <i@lmb.io>\",\"Jairooo <jairocaro@msn.com>\",\"Moritz St\\xfcckler <moritz.stueckler@gmail.com>\",\"Simon <crydotsnakegithub@gmail.com>\",\"Denis Lukov <denismassters@gmail.com>\",\"Philipp Hancke <fippo@andyet.net>\",\"Hans Oksendahl <hansoksendahl@gmail.com>\",\"Jess <jessachandler@gmail.com>\",\"khankuan <khankuan@gmail.com>\",\"DUODVK <kurmanov.work@gmail.com>\",\"XiZhao <kwang1imsa@gmail.com>\",\"Matthias Lohr <matthias@lohr.me>\",\"=frank tree <=frnktrb@googlemail.com>\",\"Andre Eckardt <aeckardt@outlook.com>\",\"Chris Cowan <agentme49@gmail.com>\",\"Alex Chuev <alex@chuev.com>\",\"alxnull <alxnull@e.mail.de>\",\"Yemel Jardi <angel.jardi@gmail.com>\",\"Ben Parnell <benjaminparnell.94@gmail.com>\",\"Benny Lichtner <bennlich@gmail.com>\",\"fresheneesz <bitetrudpublic@gmail.com>\",\"bob.barstead@exaptive.com <bob.barstead@exaptive.com>\",\"chandika <chandika@gmail.com>\",\"emersion <contact@emersion.fr>\",\"Christopher Van <cvan@users.noreply.github.com>\",\"eddieherm <edhermoso@gmail.com>\",\"Eduardo Pinho <enet4mikeenet@gmail.com>\",\"Evandro Zanatta <ezanatta@tray.net.br>\",\"Gardner Bickford <gardner@users.noreply.github.com>\",\"Gian Luca <gianluca.cecchi@cynny.com>\",\"PatrickJS <github@gdi2290.com>\",\"jonnyf <github@jonathanfoss.co.uk>\",\"Hizkia Felix <hizkifw@gmail.com>\",\"Hristo Oskov <hristo.oskov@gmail.com>\",\"Isaac Madwed <i.madwed@gmail.com>\",\"Ilya Konanykhin <ilya.konanykhin@gmail.com>\",\"jasonbarry <jasbarry@me.com>\",\"Jonathan Burke <jonathan.burke.1311@googlemail.com>\",\"Josh Hamit <josh.hamit@gmail.com>\",\"Jordan Austin <jrax86@gmail.com>\",\"Joel Wetzell <jwetzell@yahoo.com>\",\"xizhao <kevin.wang@cloudera.com>\",\"Alberto Torres <kungfoobar@gmail.com>\",\"Jonathan Mayol <mayoljonathan@gmail.com>\",\"Jefferson Felix <me@jsfelix.dev>\",\"Rolf Erik Lekang <me@rolflekang.com>\",\"Kevin Mai-Husan Chia <mhchia@users.noreply.github.com>\",\"Pepijn de Vos <pepijndevos@gmail.com>\",\"JooYoung <qkdlql@naver.com>\",\"Tobias Speicher <rootcommander@gmail.com>\",\"Steve Blaurock <sblaurock@gmail.com>\",\"Kyrylo Shegeda <shegeda@ualberta.ca>\",\"Diwank Singh Tomer <singh@diwank.name>\",\"So\\u0308ren Balko <Soeren.Balko@gmail.com>\",\"Arpit Solanki <solankiarpit1997@gmail.com>\",\"Yuki Ito <yuki@gnnk.net>\",\"Artur Zayats <zag2art@gmail.com>\"],\"funding\":{\"type\":\"opencollective\",\"url\":\"https://opencollective.com/peer\"},\"collective\":{\"type\":\"opencollective\",\"url\":\"https://opencollective.com/peer\"},\"files\":[\"dist/*\"],\"sideEffects\":[\"lib/global.ts\",\"lib/supports.ts\"],\"main\":\"dist/bundler.cjs\",\"module\":\"dist/bundler.mjs\",\"browser-minified\":\"dist/peerjs.min.js\",\"browser-unminified\":\"dist/peerjs.js\",\"browser-minified-msgpack\":\"dist/serializer.msgpack.mjs\",\"types\":\"dist/types.d.ts\",\"engines\":{\"node\":\">= 14\"},\"targets\":{\"types\":{\"source\":\"lib/exports.ts\"},\"main\":{\"source\":\"lib/exports.ts\",\"sourceMap\":{\"inlineSources\":true}},\"module\":{\"source\":\"lib/exports.ts\",\"includeNodeModules\":[\"eventemitter3\"],\"sourceMap\":{\"inlineSources\":true}},\"browser-minified\":{\"context\":\"browser\",\"outputFormat\":\"global\",\"optimize\":true,\"engines\":{\"browsers\":\"chrome >= 83, edge >= 83, firefox >= 80, safari >= 15\"},\"source\":\"lib/global.ts\"},\"browser-unminified\":{\"context\":\"browser\",\"outputFormat\":\"global\",\"optimize\":false,\"engines\":{\"browsers\":\"chrome >= 83, edge >= 83, firefox >= 80, safari >= 15\"},\"source\":\"lib/global.ts\"},\"browser-minified-msgpack\":{\"context\":\"browser\",\"outputFormat\":\"esmodule\",\"isLibrary\":true,\"optimize\":true,\"engines\":{\"browsers\":\"chrome >= 83, edge >= 83, firefox >= 102, safari >= 15\"},\"source\":\"lib/dataconnection/StreamConnection/MsgPack.ts\"}},\"scripts\":{\"contributors\":\"git-authors-cli --print=false && prettier --write package.json && git add package.json package-lock.json && git commit -m \\\\\"chore(contributors): update and sort contributors list\\\\\"\",\"check\":\"tsc --noEmit && tsc -p e2e/tsconfig.json --noEmit\",\"watch\":\"parcel watch\",\"build\":\"rm -rf dist && parcel build\",\"prepublishOnly\":\"npm run build\",\"test\":\"jest\",\"test:watch\":\"jest --watch\",\"coverage\":\"jest --coverage --collectCoverageFrom=\\\\\"./lib/**\\\\\"\",\"format\":\"prettier --write .\",\"format:check\":\"prettier --check .\",\"semantic-release\":\"semantic-release\",\"e2e\":\"wdio run e2e/wdio.local.conf.ts\",\"e2e:bstack\":\"wdio run e2e/wdio.bstack.conf.ts\"},\"devDependencies\":{\"@parcel/config-default\":\"^2.9.3\",\"@parcel/packager-ts\":\"^2.9.3\",\"@parcel/transformer-typescript-tsc\":\"^2.9.3\",\"@parcel/transformer-typescript-types\":\"^2.9.3\",\"@semantic-release/changelog\":\"^6.0.1\",\"@semantic-release/git\":\"^10.0.1\",\"@swc/core\":\"^1.3.27\",\"@swc/jest\":\"^0.2.24\",\"@types/jasmine\":\"^4.3.4\",\"@wdio/browserstack-service\":\"^8.11.2\",\"@wdio/cli\":\"^8.11.2\",\"@wdio/globals\":\"^8.11.2\",\"@wdio/jasmine-framework\":\"^8.11.2\",\"@wdio/local-runner\":\"^8.11.2\",\"@wdio/spec-reporter\":\"^8.11.2\",\"@wdio/types\":\"^8.10.4\",\"http-server\":\"^14.1.1\",\"jest\":\"^29.3.1\",\"jest-environment-jsdom\":\"^29.3.1\",\"mock-socket\":\"^9.0.0\",\"parcel\":\"^2.9.3\",\"prettier\":\"^3.0.0\",\"semantic-release\":\"^21.0.0\",\"ts-node\":\"^10.9.1\",\"typescript\":\"^5.0.0\",\"wdio-geckodriver-service\":\"^5.0.1\"},\"dependencies\":{\"@msgpack/msgpack\":\"^2.8.0\",\"eventemitter3\":\"^4.0.7\",\"peerjs-js-binarypack\":\"^2.1.0\",\"webrtc-adapter\":\"^9.0.0\"},\"alias\":{\"process\":false,\"buffer\":false}}');\n\n\nclass $8f5bfa60836d261d$export$4798917dbf149b79 extends (0, $c4dcfd1d1ea86647$exports.EventEmitter) {\n    constructor(secure, host, port, path, key, pingInterval = 5000){\n        super();\n        this.pingInterval = pingInterval;\n        this._disconnected = true;\n        this._messagesQueue = [];\n        const wsProtocol = secure ? \"wss://\" : \"ws://\";\n        this._baseUrl = wsProtocol + host + \":\" + port + path + \"peerjs?key=\" + key;\n    }\n    start(id, token) {\n        this._id = id;\n        const wsUrl = `${this._baseUrl}&id=${id}&token=${token}`;\n        if (!!this._socket || !this._disconnected) return;\n        this._socket = new WebSocket(wsUrl + \"&version=\" + (0, $f5f881ec4575f1fc$exports.version));\n        this._disconnected = false;\n        this._socket.onmessage = (event)=>{\n            let data;\n            try {\n                data = JSON.parse(event.data);\n                (0, $257947e92926277a$export$2e2bcd8739ae039).log(\"Server message received:\", data);\n            } catch (e) {\n                (0, $257947e92926277a$export$2e2bcd8739ae039).log(\"Invalid server message\", event.data);\n                return;\n            }\n            this.emit((0, $78455e22dea96b8c$export$3b5c4a4b6354f023).Message, data);\n        };\n        this._socket.onclose = (event)=>{\n            if (this._disconnected) return;\n            (0, $257947e92926277a$export$2e2bcd8739ae039).log(\"Socket closed.\", event);\n            this._cleanup();\n            this._disconnected = true;\n            this.emit((0, $78455e22dea96b8c$export$3b5c4a4b6354f023).Disconnected);\n        };\n        // Take care of the queue of connections if necessary and make sure Peer knows\n        // socket is open.\n        this._socket.onopen = ()=>{\n            if (this._disconnected) return;\n            this._sendQueuedMessages();\n            (0, $257947e92926277a$export$2e2bcd8739ae039).log(\"Socket open\");\n            this._scheduleHeartbeat();\n        };\n    }\n    _scheduleHeartbeat() {\n        this._wsPingTimer = setTimeout(()=>{\n            this._sendHeartbeat();\n        }, this.pingInterval);\n    }\n    _sendHeartbeat() {\n        if (!this._wsOpen()) {\n            (0, $257947e92926277a$export$2e2bcd8739ae039).log(`Cannot send heartbeat, because socket closed`);\n            return;\n        }\n        const message = JSON.stringify({\n            type: (0, $78455e22dea96b8c$export$adb4a1754da6f10d).Heartbeat\n        });\n        this._socket.send(message);\n        this._scheduleHeartbeat();\n    }\n    /** Is the websocket currently open? */ _wsOpen() {\n        return !!this._socket && this._socket.readyState === 1;\n    }\n    /** Send queued messages. */ _sendQueuedMessages() {\n        //Create copy of queue and clear it,\n        //because send method push the message back to queue if smth will go wrong\n        const copiedQueue = [\n            ...this._messagesQueue\n        ];\n        this._messagesQueue = [];\n        for (const message of copiedQueue)this.send(message);\n    }\n    /** Exposed send for DC & Peer. */ send(data) {\n        if (this._disconnected) return;\n        // If we didn't get an ID yet, we can't yet send anything so we should queue\n        // up these messages.\n        if (!this._id) {\n            this._messagesQueue.push(data);\n            return;\n        }\n        if (!data.type) {\n            this.emit((0, $78455e22dea96b8c$export$3b5c4a4b6354f023).Error, \"Invalid message\");\n            return;\n        }\n        if (!this._wsOpen()) return;\n        const message = JSON.stringify(data);\n        this._socket.send(message);\n    }\n    close() {\n        if (this._disconnected) return;\n        this._cleanup();\n        this._disconnected = true;\n    }\n    _cleanup() {\n        if (this._socket) {\n            this._socket.onopen = this._socket.onmessage = this._socket.onclose = null;\n            this._socket.close();\n            this._socket = undefined;\n        }\n        clearTimeout(this._wsPingTimer);\n    }\n}\n\n\n\n\n\n\nclass $b82fb8fc0514bfc1$export$89e6bb5ad64bf4a {\n    constructor(connection){\n        this.connection = connection;\n    }\n    /** Returns a PeerConnection object set up correctly (for data, media). */ startConnection(options) {\n        const peerConnection = this._startPeerConnection();\n        // Set the connection's PC.\n        this.connection.peerConnection = peerConnection;\n        if (this.connection.type === (0, $78455e22dea96b8c$export$3157d57b4135e3bc).Media && options._stream) this._addTracksToConnection(options._stream, peerConnection);\n        // What do we need to do now?\n        if (options.originator) {\n            const dataConnection = this.connection;\n            const config = {\n                ordered: !!options.reliable\n            };\n            const dataChannel = peerConnection.createDataChannel(dataConnection.label, config);\n            dataConnection._initializeDataChannel(dataChannel);\n            this._makeOffer();\n        } else this.handleSDP(\"OFFER\", options.sdp);\n    }\n    /** Start a PC. */ _startPeerConnection() {\n        (0, $257947e92926277a$export$2e2bcd8739ae039).log(\"Creating RTCPeerConnection.\");\n        const peerConnection = new RTCPeerConnection(this.connection.provider.options.config);\n        this._setupListeners(peerConnection);\n        return peerConnection;\n    }\n    /** Set up various WebRTC listeners. */ _setupListeners(peerConnection) {\n        const peerId = this.connection.peer;\n        const connectionId = this.connection.connectionId;\n        const connectionType = this.connection.type;\n        const provider = this.connection.provider;\n        // ICE CANDIDATES.\n        (0, $257947e92926277a$export$2e2bcd8739ae039).log(\"Listening for ICE candidates.\");\n        peerConnection.onicecandidate = (evt)=>{\n            if (!evt.candidate || !evt.candidate.candidate) return;\n            (0, $257947e92926277a$export$2e2bcd8739ae039).log(`Received ICE candidates for ${peerId}:`, evt.candidate);\n            provider.socket.send({\n                type: (0, $78455e22dea96b8c$export$adb4a1754da6f10d).Candidate,\n                payload: {\n                    candidate: evt.candidate,\n                    type: connectionType,\n                    connectionId: connectionId\n                },\n                dst: peerId\n            });\n        };\n        peerConnection.oniceconnectionstatechange = ()=>{\n            switch(peerConnection.iceConnectionState){\n                case \"failed\":\n                    (0, $257947e92926277a$export$2e2bcd8739ae039).log(\"iceConnectionState is failed, closing connections to \" + peerId);\n                    this.connection.emitError((0, $78455e22dea96b8c$export$7974935686149686).NegotiationFailed, \"Negotiation of connection to \" + peerId + \" failed.\");\n                    this.connection.close();\n                    break;\n                case \"closed\":\n                    (0, $257947e92926277a$export$2e2bcd8739ae039).log(\"iceConnectionState is closed, closing connections to \" + peerId);\n                    this.connection.emitError((0, $78455e22dea96b8c$export$7974935686149686).ConnectionClosed, \"Connection to \" + peerId + \" closed.\");\n                    this.connection.close();\n                    break;\n                case \"disconnected\":\n                    (0, $257947e92926277a$export$2e2bcd8739ae039).log(\"iceConnectionState changed to disconnected on the connection with \" + peerId);\n                    break;\n                case \"completed\":\n                    peerConnection.onicecandidate = ()=>{};\n                    break;\n            }\n            this.connection.emit(\"iceStateChanged\", peerConnection.iceConnectionState);\n        };\n        // DATACONNECTION.\n        (0, $257947e92926277a$export$2e2bcd8739ae039).log(\"Listening for data channel\");\n        // Fired between offer and answer, so options should already be saved\n        // in the options hash.\n        peerConnection.ondatachannel = (evt)=>{\n            (0, $257947e92926277a$export$2e2bcd8739ae039).log(\"Received data channel\");\n            const dataChannel = evt.channel;\n            const connection = provider.getConnection(peerId, connectionId);\n            connection._initializeDataChannel(dataChannel);\n        };\n        // MEDIACONNECTION.\n        (0, $257947e92926277a$export$2e2bcd8739ae039).log(\"Listening for remote stream\");\n        peerConnection.ontrack = (evt)=>{\n            (0, $257947e92926277a$export$2e2bcd8739ae039).log(\"Received remote stream\");\n            const stream = evt.streams[0];\n            const connection = provider.getConnection(peerId, connectionId);\n            if (connection.type === (0, $78455e22dea96b8c$export$3157d57b4135e3bc).Media) {\n                const mediaConnection = connection;\n                this._addStreamToMediaConnection(stream, mediaConnection);\n            }\n        };\n    }\n    cleanup() {\n        (0, $257947e92926277a$export$2e2bcd8739ae039).log(\"Cleaning up PeerConnection to \" + this.connection.peer);\n        const peerConnection = this.connection.peerConnection;\n        if (!peerConnection) return;\n        this.connection.peerConnection = null;\n        //unsubscribe from all PeerConnection's events\n        peerConnection.onicecandidate = peerConnection.oniceconnectionstatechange = peerConnection.ondatachannel = peerConnection.ontrack = ()=>{};\n        const peerConnectionNotClosed = peerConnection.signalingState !== \"closed\";\n        let dataChannelNotClosed = false;\n        const dataChannel = this.connection.dataChannel;\n        if (dataChannel) dataChannelNotClosed = !!dataChannel.readyState && dataChannel.readyState !== \"closed\";\n        if (peerConnectionNotClosed || dataChannelNotClosed) peerConnection.close();\n    }\n    async _makeOffer() {\n        const peerConnection = this.connection.peerConnection;\n        const provider = this.connection.provider;\n        try {\n            const offer = await peerConnection.createOffer(this.connection.options.constraints);\n            (0, $257947e92926277a$export$2e2bcd8739ae039).log(\"Created offer.\");\n            if (this.connection.options.sdpTransform && typeof this.connection.options.sdpTransform === \"function\") offer.sdp = this.connection.options.sdpTransform(offer.sdp) || offer.sdp;\n            try {\n                await peerConnection.setLocalDescription(offer);\n                (0, $257947e92926277a$export$2e2bcd8739ae039).log(\"Set localDescription:\", offer, `for:${this.connection.peer}`);\n                let payload = {\n                    sdp: offer,\n                    type: this.connection.type,\n                    connectionId: this.connection.connectionId,\n                    metadata: this.connection.metadata\n                };\n                if (this.connection.type === (0, $78455e22dea96b8c$export$3157d57b4135e3bc).Data) {\n                    const dataConnection = this.connection;\n                    payload = {\n                        ...payload,\n                        label: dataConnection.label,\n                        reliable: dataConnection.reliable,\n                        serialization: dataConnection.serialization\n                    };\n                }\n                provider.socket.send({\n                    type: (0, $78455e22dea96b8c$export$adb4a1754da6f10d).Offer,\n                    payload: payload,\n                    dst: this.connection.peer\n                });\n            } catch (err) {\n                // TODO: investigate why _makeOffer is being called from the answer\n                if (err != \"OperationError: Failed to set local offer sdp: Called in wrong state: kHaveRemoteOffer\") {\n                    provider.emitError((0, $78455e22dea96b8c$export$9547aaa2e39030ff).WebRTC, err);\n                    (0, $257947e92926277a$export$2e2bcd8739ae039).log(\"Failed to setLocalDescription, \", err);\n                }\n            }\n        } catch (err_1) {\n            provider.emitError((0, $78455e22dea96b8c$export$9547aaa2e39030ff).WebRTC, err_1);\n            (0, $257947e92926277a$export$2e2bcd8739ae039).log(\"Failed to createOffer, \", err_1);\n        }\n    }\n    async _makeAnswer() {\n        const peerConnection = this.connection.peerConnection;\n        const provider = this.connection.provider;\n        try {\n            const answer = await peerConnection.createAnswer();\n            (0, $257947e92926277a$export$2e2bcd8739ae039).log(\"Created answer.\");\n            if (this.connection.options.sdpTransform && typeof this.connection.options.sdpTransform === \"function\") answer.sdp = this.connection.options.sdpTransform(answer.sdp) || answer.sdp;\n            try {\n                await peerConnection.setLocalDescription(answer);\n                (0, $257947e92926277a$export$2e2bcd8739ae039).log(`Set localDescription:`, answer, `for:${this.connection.peer}`);\n                provider.socket.send({\n                    type: (0, $78455e22dea96b8c$export$adb4a1754da6f10d).Answer,\n                    payload: {\n                        sdp: answer,\n                        type: this.connection.type,\n                        connectionId: this.connection.connectionId\n                    },\n                    dst: this.connection.peer\n                });\n            } catch (err) {\n                provider.emitError((0, $78455e22dea96b8c$export$9547aaa2e39030ff).WebRTC, err);\n                (0, $257947e92926277a$export$2e2bcd8739ae039).log(\"Failed to setLocalDescription, \", err);\n            }\n        } catch (err_1) {\n            provider.emitError((0, $78455e22dea96b8c$export$9547aaa2e39030ff).WebRTC, err_1);\n            (0, $257947e92926277a$export$2e2bcd8739ae039).log(\"Failed to create answer, \", err_1);\n        }\n    }\n    /** Handle an SDP. */ async handleSDP(type, sdp) {\n        sdp = new RTCSessionDescription(sdp);\n        const peerConnection = this.connection.peerConnection;\n        const provider = this.connection.provider;\n        (0, $257947e92926277a$export$2e2bcd8739ae039).log(\"Setting remote description\", sdp);\n        const self = this;\n        try {\n            await peerConnection.setRemoteDescription(sdp);\n            (0, $257947e92926277a$export$2e2bcd8739ae039).log(`Set remoteDescription:${type} for:${this.connection.peer}`);\n            if (type === \"OFFER\") await self._makeAnswer();\n        } catch (err) {\n            provider.emitError((0, $78455e22dea96b8c$export$9547aaa2e39030ff).WebRTC, err);\n            (0, $257947e92926277a$export$2e2bcd8739ae039).log(\"Failed to setRemoteDescription, \", err);\n        }\n    }\n    /** Handle a candidate. */ async handleCandidate(ice) {\n        (0, $257947e92926277a$export$2e2bcd8739ae039).log(`handleCandidate:`, ice);\n        try {\n            await this.connection.peerConnection.addIceCandidate(ice);\n            (0, $257947e92926277a$export$2e2bcd8739ae039).log(`Added ICE candidate for:${this.connection.peer}`);\n        } catch (err) {\n            this.connection.provider.emitError((0, $78455e22dea96b8c$export$9547aaa2e39030ff).WebRTC, err);\n            (0, $257947e92926277a$export$2e2bcd8739ae039).log(\"Failed to handleCandidate, \", err);\n        }\n    }\n    _addTracksToConnection(stream, peerConnection) {\n        (0, $257947e92926277a$export$2e2bcd8739ae039).log(`add tracks from stream ${stream.id} to peer connection`);\n        if (!peerConnection.addTrack) return (0, $257947e92926277a$export$2e2bcd8739ae039).error(`Your browser does't support RTCPeerConnection#addTrack. Ignored.`);\n        stream.getTracks().forEach((track)=>{\n            peerConnection.addTrack(track, stream);\n        });\n    }\n    _addStreamToMediaConnection(stream, mediaConnection) {\n        (0, $257947e92926277a$export$2e2bcd8739ae039).log(`add stream ${stream.id} to media connection ${mediaConnection.connectionId}`);\n        mediaConnection.addStream(stream);\n    }\n}\n\n\n\n\n\nclass $23779d1881157a18$export$6a678e589c8a4542 extends (0, $c4dcfd1d1ea86647$exports.EventEmitter) {\n    /**\n\t * Emits a typed error message.\n\t *\n\t * @internal\n\t */ emitError(type, err) {\n        (0, $257947e92926277a$export$2e2bcd8739ae039).error(\"Error:\", err);\n        // @ts-ignore\n        this.emit(\"error\", new $23779d1881157a18$export$98871882f492de82(`${type}`, err));\n    }\n}\nclass $23779d1881157a18$export$98871882f492de82 extends Error {\n    /**\n\t * @internal\n\t */ constructor(type, err){\n        if (typeof err === \"string\") super(err);\n        else {\n            super();\n            Object.assign(this, err);\n        }\n        this.type = type;\n    }\n}\n\n\nclass $5045192fc6d387ba$export$23a2a68283c24d80 extends (0, $23779d1881157a18$export$6a678e589c8a4542) {\n    /**\n\t * Whether the media connection is active (e.g. your call has been answered).\n\t * You can check this if you want to set a maximum wait time for a one-sided call.\n\t */ get open() {\n        return this._open;\n    }\n    constructor(/**\n\t\t * The ID of the peer on the other end of this connection.\n\t\t */ peer, provider, options){\n        super();\n        this.peer = peer;\n        this.provider = provider;\n        this.options = options;\n        this._open = false;\n        this.metadata = options.metadata;\n    }\n}\n\n\nclass $5c1d08c7c57da9a3$export$4a84e95a2324ac29 extends (0, $5045192fc6d387ba$export$23a2a68283c24d80) {\n    static #_ = this.ID_PREFIX = \"mc_\";\n    /**\n\t * For media connections, this is always 'media'.\n\t */ get type() {\n        return (0, $78455e22dea96b8c$export$3157d57b4135e3bc).Media;\n    }\n    get localStream() {\n        return this._localStream;\n    }\n    get remoteStream() {\n        return this._remoteStream;\n    }\n    constructor(peerId, provider, options){\n        super(peerId, provider, options);\n        this._localStream = this.options._stream;\n        this.connectionId = this.options.connectionId || $5c1d08c7c57da9a3$export$4a84e95a2324ac29.ID_PREFIX + (0, $4f4134156c446392$export$7debb50ef11d5e0b).randomToken();\n        this._negotiator = new (0, $b82fb8fc0514bfc1$export$89e6bb5ad64bf4a)(this);\n        if (this._localStream) this._negotiator.startConnection({\n            _stream: this._localStream,\n            originator: true\n        });\n    }\n    /** Called by the Negotiator when the DataChannel is ready. */ _initializeDataChannel(dc) {\n        this.dataChannel = dc;\n        this.dataChannel.onopen = ()=>{\n            (0, $257947e92926277a$export$2e2bcd8739ae039).log(`DC#${this.connectionId} dc connection success`);\n            this.emit(\"willCloseOnRemote\");\n        };\n        this.dataChannel.onclose = ()=>{\n            (0, $257947e92926277a$export$2e2bcd8739ae039).log(`DC#${this.connectionId} dc closed for:`, this.peer);\n            this.close();\n        };\n    }\n    addStream(remoteStream) {\n        (0, $257947e92926277a$export$2e2bcd8739ae039).log(\"Receiving stream\", remoteStream);\n        this._remoteStream = remoteStream;\n        super.emit(\"stream\", remoteStream); // Should we call this `open`?\n    }\n    /**\n\t * @internal\n\t */ handleMessage(message) {\n        const type = message.type;\n        const payload = message.payload;\n        switch(message.type){\n            case (0, $78455e22dea96b8c$export$adb4a1754da6f10d).Answer:\n                // Forward to negotiator\n                this._negotiator.handleSDP(type, payload.sdp);\n                this._open = true;\n                break;\n            case (0, $78455e22dea96b8c$export$adb4a1754da6f10d).Candidate:\n                this._negotiator.handleCandidate(payload.candidate);\n                break;\n            default:\n                (0, $257947e92926277a$export$2e2bcd8739ae039).warn(`Unrecognized message type:${type} from peer:${this.peer}`);\n                break;\n        }\n    }\n    /**\n     * When receiving a {@apilink PeerEvents | `call`} event on a peer, you can call\n     * `answer` on the media connection provided by the callback to accept the call\n     * and optionally send your own media stream.\n\n     *\n     * @param stream A WebRTC media stream.\n     * @param options\n     * @returns\n     */ answer(stream, options = {}) {\n        if (this._localStream) {\n            (0, $257947e92926277a$export$2e2bcd8739ae039).warn(\"Local stream already exists on this MediaConnection. Are you answering a call twice?\");\n            return;\n        }\n        this._localStream = stream;\n        if (options && options.sdpTransform) this.options.sdpTransform = options.sdpTransform;\n        this._negotiator.startConnection({\n            ...this.options._payload,\n            _stream: stream\n        });\n        // Retrieve lost messages stored because PeerConnection not set up.\n        const messages = this.provider._getMessages(this.connectionId);\n        for (const message of messages)this.handleMessage(message);\n        this._open = true;\n    }\n    /**\n\t * Exposed functionality for users.\n\t */ /**\n\t * Closes the media connection.\n\t */ close() {\n        if (this._negotiator) {\n            this._negotiator.cleanup();\n            this._negotiator = null;\n        }\n        this._localStream = null;\n        this._remoteStream = null;\n        if (this.provider) {\n            this.provider._removeConnection(this);\n            this.provider = null;\n        }\n        if (this.options && this.options._stream) this.options._stream = null;\n        if (!this.open) return;\n        this._open = false;\n        super.emit(\"close\");\n    }\n}\n\n\n\n\n\n\nclass $abf266641927cd89$export$2c4e825dc9120f87 {\n    constructor(_options){\n        this._options = _options;\n    }\n    _buildRequest(method) {\n        const protocol = this._options.secure ? \"https\" : \"http\";\n        const { host: host, port: port, path: path, key: key } = this._options;\n        const url = new URL(`${protocol}://${host}:${port}${path}${key}/${method}`);\n        // TODO: Why timestamp, why random?\n        url.searchParams.set(\"ts\", `${Date.now()}${Math.random()}`);\n        url.searchParams.set(\"version\", (0, $f5f881ec4575f1fc$exports.version));\n        return fetch(url.href, {\n            referrerPolicy: this._options.referrerPolicy\n        });\n    }\n    /** Get a unique ID from the server via XHR and initialize with it. */ async retrieveId() {\n        try {\n            const response = await this._buildRequest(\"id\");\n            if (response.status !== 200) throw new Error(`Error. Status:${response.status}`);\n            return response.text();\n        } catch (error) {\n            (0, $257947e92926277a$export$2e2bcd8739ae039).error(\"Error retrieving ID\", error);\n            let pathError = \"\";\n            if (this._options.path === \"/\" && this._options.host !== (0, $4f4134156c446392$export$7debb50ef11d5e0b).CLOUD_HOST) pathError = \" If you passed in a `path` to your self-hosted PeerServer, you'll also need to pass in that same path when creating a new Peer.\";\n            throw new Error(\"Could not get an ID from the server.\" + pathError);\n        }\n    }\n    /** @deprecated */ async listAllPeers() {\n        try {\n            const response = await this._buildRequest(\"peers\");\n            if (response.status !== 200) {\n                if (response.status === 401) {\n                    let helpfulError = \"\";\n                    if (this._options.host === (0, $4f4134156c446392$export$7debb50ef11d5e0b).CLOUD_HOST) helpfulError = \"It looks like you're using the cloud server. You can email team@peerjs.com to enable peer listing for your API key.\";\n                    else helpfulError = \"You need to enable `allow_discovery` on your self-hosted PeerServer to use this feature.\";\n                    throw new Error(\"It doesn't look like you have permission to list peers IDs. \" + helpfulError);\n                }\n                throw new Error(`Error. Status:${response.status}`);\n            }\n            return response.json();\n        } catch (error) {\n            (0, $257947e92926277a$export$2e2bcd8739ae039).error(\"Error retrieving list peers\", error);\n            throw new Error(\"Could not get list peers from the server.\" + error);\n        }\n    }\n}\n\n\n\n\n\n\n\n\n\n\nclass $6366c4ca161bc297$export$d365f7ad9d7df9c9 extends (0, $5045192fc6d387ba$export$23a2a68283c24d80) {\n    static #_ = this.ID_PREFIX = \"dc_\";\n    static #_2 = this.MAX_BUFFERED_AMOUNT = 8388608;\n    get type() {\n        return (0, $78455e22dea96b8c$export$3157d57b4135e3bc).Data;\n    }\n    constructor(peerId, provider, options){\n        super(peerId, provider, options);\n        this.connectionId = this.options.connectionId || $6366c4ca161bc297$export$d365f7ad9d7df9c9.ID_PREFIX + (0, $0e5fd1585784c252$export$4e61f672936bec77)();\n        this.label = this.options.label || this.connectionId;\n        this.reliable = !!this.options.reliable;\n        this._negotiator = new (0, $b82fb8fc0514bfc1$export$89e6bb5ad64bf4a)(this);\n        this._negotiator.startConnection(this.options._payload || {\n            originator: true,\n            reliable: this.reliable\n        });\n    }\n    /** Called by the Negotiator when the DataChannel is ready. */ _initializeDataChannel(dc) {\n        this.dataChannel = dc;\n        this.dataChannel.onopen = ()=>{\n            (0, $257947e92926277a$export$2e2bcd8739ae039).log(`DC#${this.connectionId} dc connection success`);\n            this._open = true;\n            this.emit(\"open\");\n        };\n        this.dataChannel.onmessage = (e)=>{\n            (0, $257947e92926277a$export$2e2bcd8739ae039).log(`DC#${this.connectionId} dc onmessage:`, e.data);\n        // this._handleDataMessage(e);\n        };\n        this.dataChannel.onclose = ()=>{\n            (0, $257947e92926277a$export$2e2bcd8739ae039).log(`DC#${this.connectionId} dc closed for:`, this.peer);\n            this.close();\n        };\n    }\n    /**\n\t * Exposed functionality for users.\n\t */ /** Allows user to close connection. */ close(options) {\n        if (options?.flush) {\n            this.send({\n                __peerData: {\n                    type: \"close\"\n                }\n            });\n            return;\n        }\n        if (this._negotiator) {\n            this._negotiator.cleanup();\n            this._negotiator = null;\n        }\n        if (this.provider) {\n            this.provider._removeConnection(this);\n            this.provider = null;\n        }\n        if (this.dataChannel) {\n            this.dataChannel.onopen = null;\n            this.dataChannel.onmessage = null;\n            this.dataChannel.onclose = null;\n            this.dataChannel = null;\n        }\n        if (!this.open) return;\n        this._open = false;\n        super.emit(\"close\");\n    }\n    /** Allows user to send data. */ send(data, chunked = false) {\n        if (!this.open) {\n            this.emitError((0, $78455e22dea96b8c$export$49ae800c114df41d).NotOpenYet, \"Connection is not open. You should listen for the `open` event before sending messages.\");\n            return;\n        }\n        return this._send(data, chunked);\n    }\n    async handleMessage(message) {\n        const payload = message.payload;\n        switch(message.type){\n            case (0, $78455e22dea96b8c$export$adb4a1754da6f10d).Answer:\n                await this._negotiator.handleSDP(message.type, payload.sdp);\n                break;\n            case (0, $78455e22dea96b8c$export$adb4a1754da6f10d).Candidate:\n                await this._negotiator.handleCandidate(payload.candidate);\n                break;\n            default:\n                (0, $257947e92926277a$export$2e2bcd8739ae039).warn(\"Unrecognized message type:\", message.type, \"from peer:\", this.peer);\n                break;\n        }\n    }\n}\n\n\nclass $a229bedbcaa6ca23$export$ff7c9d4c11d94e8b extends (0, $6366c4ca161bc297$export$d365f7ad9d7df9c9) {\n    get bufferSize() {\n        return this._bufferSize;\n    }\n    _initializeDataChannel(dc) {\n        super._initializeDataChannel(dc);\n        this.dataChannel.binaryType = \"arraybuffer\";\n        this.dataChannel.addEventListener(\"message\", (e)=>this._handleDataMessage(e));\n    }\n    _bufferedSend(msg) {\n        if (this._buffering || !this._trySend(msg)) {\n            this._buffer.push(msg);\n            this._bufferSize = this._buffer.length;\n        }\n    }\n    // Returns true if the send succeeds.\n    _trySend(msg) {\n        if (!this.open) return false;\n        if (this.dataChannel.bufferedAmount > (0, $6366c4ca161bc297$export$d365f7ad9d7df9c9).MAX_BUFFERED_AMOUNT) {\n            this._buffering = true;\n            setTimeout(()=>{\n                this._buffering = false;\n                this._tryBuffer();\n            }, 50);\n            return false;\n        }\n        try {\n            this.dataChannel.send(msg);\n        } catch (e) {\n            (0, $257947e92926277a$export$2e2bcd8739ae039).error(`DC#:${this.connectionId} Error when sending:`, e);\n            this._buffering = true;\n            this.close();\n            return false;\n        }\n        return true;\n    }\n    // Try to send the first message in the buffer.\n    _tryBuffer() {\n        if (!this.open) return;\n        if (this._buffer.length === 0) return;\n        const msg = this._buffer[0];\n        if (this._trySend(msg)) {\n            this._buffer.shift();\n            this._bufferSize = this._buffer.length;\n            this._tryBuffer();\n        }\n    }\n    close(options) {\n        if (options?.flush) {\n            this.send({\n                __peerData: {\n                    type: \"close\"\n                }\n            });\n            return;\n        }\n        this._buffer = [];\n        this._bufferSize = 0;\n        super.close();\n    }\n    constructor(...args){\n        super(...args);\n        this._buffer = [];\n        this._bufferSize = 0;\n        this._buffering = false;\n    }\n}\n\n\n\n\nclass $9fcfddb3ae148f88$export$f0a5a64d5bb37108 extends (0, $a229bedbcaa6ca23$export$ff7c9d4c11d94e8b) {\n    close(options) {\n        super.close(options);\n        this._chunkedData = {};\n    }\n    constructor(peerId, provider, options){\n        super(peerId, provider, options);\n        this.chunker = new (0, $fcbcc7538a6776d5$export$f1c5f4c9cb95390b)();\n        this.serialization = (0, $78455e22dea96b8c$export$89f507cf986a947).Binary;\n        this._chunkedData = {};\n    }\n    // Handles a DataChannel message.\n    _handleDataMessage({ data: data }) {\n        const deserializedData = (0, peerjs_js_binarypack__WEBPACK_IMPORTED_MODULE_0__.unpack)(data);\n        // PeerJS specific message\n        const peerData = deserializedData[\"__peerData\"];\n        if (peerData) {\n            if (peerData.type === \"close\") {\n                this.close();\n                return;\n            }\n            // Chunked data -- piece things back together.\n            // @ts-ignore\n            this._handleChunk(deserializedData);\n            return;\n        }\n        this.emit(\"data\", deserializedData);\n    }\n    _handleChunk(data) {\n        const id = data.__peerData;\n        const chunkInfo = this._chunkedData[id] || {\n            data: [],\n            count: 0,\n            total: data.total\n        };\n        chunkInfo.data[data.n] = new Uint8Array(data.data);\n        chunkInfo.count++;\n        this._chunkedData[id] = chunkInfo;\n        if (chunkInfo.total === chunkInfo.count) {\n            // Clean up before making the recursive call to `_handleDataMessage`.\n            delete this._chunkedData[id];\n            // We've received all the chunks--time to construct the complete data.\n            // const data = new Blob(chunkInfo.data);\n            const data = (0, $fcbcc7538a6776d5$export$52c89ebcdc4f53f2)(chunkInfo.data);\n            this._handleDataMessage({\n                data: data\n            });\n        }\n    }\n    _send(data, chunked) {\n        const blob = (0, peerjs_js_binarypack__WEBPACK_IMPORTED_MODULE_0__.pack)(data);\n        if (blob instanceof Promise) return this._send_blob(blob);\n        if (!chunked && blob.byteLength > this.chunker.chunkedMTU) {\n            this._sendChunks(blob);\n            return;\n        }\n        this._bufferedSend(blob);\n    }\n    async _send_blob(blobPromise) {\n        const blob = await blobPromise;\n        if (blob.byteLength > this.chunker.chunkedMTU) {\n            this._sendChunks(blob);\n            return;\n        }\n        this._bufferedSend(blob);\n    }\n    _sendChunks(blob) {\n        const blobs = this.chunker.chunk(blob);\n        (0, $257947e92926277a$export$2e2bcd8739ae039).log(`DC#${this.connectionId} Try to send ${blobs.length} chunks...`);\n        for (const blob of blobs)this.send(blob, true);\n    }\n}\n\n\n\n\nclass $bbaee3f15f714663$export$6f88fe47d32c9c94 extends (0, $a229bedbcaa6ca23$export$ff7c9d4c11d94e8b) {\n    _handleDataMessage({ data: data }) {\n        super.emit(\"data\", data);\n    }\n    _send(data, _chunked) {\n        this._bufferedSend(data);\n    }\n    constructor(...args){\n        super(...args);\n        this.serialization = (0, $78455e22dea96b8c$export$89f507cf986a947).None;\n    }\n}\n\n\n\n\n\nclass $817f931e3f9096cf$export$48880ac635f47186 extends (0, $a229bedbcaa6ca23$export$ff7c9d4c11d94e8b) {\n    // Handles a DataChannel message.\n    _handleDataMessage({ data: data }) {\n        const deserializedData = this.parse(this.decoder.decode(data));\n        // PeerJS specific message\n        const peerData = deserializedData[\"__peerData\"];\n        if (peerData && peerData.type === \"close\") {\n            this.close();\n            return;\n        }\n        this.emit(\"data\", deserializedData);\n    }\n    _send(data, _chunked) {\n        const encodedData = this.encoder.encode(this.stringify(data));\n        if (encodedData.byteLength >= (0, $4f4134156c446392$export$7debb50ef11d5e0b).chunkedMTU) {\n            this.emitError((0, $78455e22dea96b8c$export$49ae800c114df41d).MessageToBig, \"Message too big for JSON channel\");\n            return;\n        }\n        this._bufferedSend(encodedData);\n    }\n    constructor(...args){\n        super(...args);\n        this.serialization = (0, $78455e22dea96b8c$export$89f507cf986a947).JSON;\n        this.encoder = new TextEncoder();\n        this.decoder = new TextDecoder();\n        this.stringify = JSON.stringify;\n        this.parse = JSON.parse;\n    }\n}\n\n\n\nclass $416260bce337df90$var$PeerOptions {\n}\nclass $416260bce337df90$export$ecd1fc136c422448 extends (0, $23779d1881157a18$export$6a678e589c8a4542) {\n    static #_ = this.DEFAULT_KEY = \"peerjs\";\n    /**\n\t * The brokering ID of this peer\n\t *\n\t * If no ID was specified in {@apilink Peer | the constructor},\n\t * this will be `undefined` until the {@apilink PeerEvents | `open`} event is emitted.\n\t */ get id() {\n        return this._id;\n    }\n    get options() {\n        return this._options;\n    }\n    get open() {\n        return this._open;\n    }\n    /**\n\t * @internal\n\t */ get socket() {\n        return this._socket;\n    }\n    /**\n\t * A hash of all connections associated with this peer, keyed by the remote peer's ID.\n\t * @deprecated\n\t * Return type will change from Object to Map<string,[]>\n\t */ get connections() {\n        const plainConnections = Object.create(null);\n        for (const [k, v] of this._connections)plainConnections[k] = v;\n        return plainConnections;\n    }\n    /**\n\t * true if this peer and all of its connections can no longer be used.\n\t */ get destroyed() {\n        return this._destroyed;\n    }\n    /**\n\t * false if there is an active connection to the PeerServer.\n\t */ get disconnected() {\n        return this._disconnected;\n    }\n    constructor(id, options){\n        super();\n        this._serializers = {\n            raw: (0, $bbaee3f15f714663$export$6f88fe47d32c9c94),\n            json: (0, $817f931e3f9096cf$export$48880ac635f47186),\n            binary: (0, $9fcfddb3ae148f88$export$f0a5a64d5bb37108),\n            \"binary-utf8\": (0, $9fcfddb3ae148f88$export$f0a5a64d5bb37108),\n            default: (0, $9fcfddb3ae148f88$export$f0a5a64d5bb37108)\n        };\n        this._id = null;\n        this._lastServerId = null;\n        // States.\n        this._destroyed = false // Connections have been killed\n        ;\n        this._disconnected = false // Connection to PeerServer killed but P2P connections still active\n        ;\n        this._open = false // Sockets and such are not yet open.\n        ;\n        this._connections = new Map() // All connections for this peer.\n        ;\n        this._lostMessages = new Map() // src => [list of messages]\n        ;\n        let userId;\n        // Deal with overloading\n        if (id && id.constructor == Object) options = id;\n        else if (id) userId = id.toString();\n        // Configurize options\n        options = {\n            debug: 0,\n            host: (0, $4f4134156c446392$export$7debb50ef11d5e0b).CLOUD_HOST,\n            port: (0, $4f4134156c446392$export$7debb50ef11d5e0b).CLOUD_PORT,\n            path: \"/\",\n            key: $416260bce337df90$export$ecd1fc136c422448.DEFAULT_KEY,\n            token: (0, $4f4134156c446392$export$7debb50ef11d5e0b).randomToken(),\n            config: (0, $4f4134156c446392$export$7debb50ef11d5e0b).defaultConfig,\n            referrerPolicy: \"strict-origin-when-cross-origin\",\n            serializers: {},\n            ...options\n        };\n        this._options = options;\n        this._serializers = {\n            ...this._serializers,\n            ...this.options.serializers\n        };\n        // Detect relative URL host.\n        if (this._options.host === \"/\") this._options.host = window.location.hostname;\n        // Set path correctly.\n        if (this._options.path) {\n            if (this._options.path[0] !== \"/\") this._options.path = \"/\" + this._options.path;\n            if (this._options.path[this._options.path.length - 1] !== \"/\") this._options.path += \"/\";\n        }\n        // Set whether we use SSL to same as current host\n        if (this._options.secure === undefined && this._options.host !== (0, $4f4134156c446392$export$7debb50ef11d5e0b).CLOUD_HOST) this._options.secure = (0, $4f4134156c446392$export$7debb50ef11d5e0b).isSecure();\n        else if (this._options.host == (0, $4f4134156c446392$export$7debb50ef11d5e0b).CLOUD_HOST) this._options.secure = true;\n        // Set a custom log function if present\n        if (this._options.logFunction) (0, $257947e92926277a$export$2e2bcd8739ae039).setLogFunction(this._options.logFunction);\n        (0, $257947e92926277a$export$2e2bcd8739ae039).logLevel = this._options.debug || 0;\n        this._api = new (0, $abf266641927cd89$export$2c4e825dc9120f87)(options);\n        this._socket = this._createServerConnection();\n        // Sanity checks\n        // Ensure WebRTC supported\n        if (!(0, $4f4134156c446392$export$7debb50ef11d5e0b).supports.audioVideo && !(0, $4f4134156c446392$export$7debb50ef11d5e0b).supports.data) {\n            this._delayedAbort((0, $78455e22dea96b8c$export$9547aaa2e39030ff).BrowserIncompatible, \"The current browser does not support WebRTC\");\n            return;\n        }\n        // Ensure alphanumeric id\n        if (!!userId && !(0, $4f4134156c446392$export$7debb50ef11d5e0b).validateId(userId)) {\n            this._delayedAbort((0, $78455e22dea96b8c$export$9547aaa2e39030ff).InvalidID, `ID \"${userId}\" is invalid`);\n            return;\n        }\n        if (userId) this._initialize(userId);\n        else this._api.retrieveId().then((id)=>this._initialize(id)).catch((error)=>this._abort((0, $78455e22dea96b8c$export$9547aaa2e39030ff).ServerError, error));\n    }\n    _createServerConnection() {\n        const socket = new (0, $8f5bfa60836d261d$export$4798917dbf149b79)(this._options.secure, this._options.host, this._options.port, this._options.path, this._options.key, this._options.pingInterval);\n        socket.on((0, $78455e22dea96b8c$export$3b5c4a4b6354f023).Message, (data)=>{\n            this._handleMessage(data);\n        });\n        socket.on((0, $78455e22dea96b8c$export$3b5c4a4b6354f023).Error, (error)=>{\n            this._abort((0, $78455e22dea96b8c$export$9547aaa2e39030ff).SocketError, error);\n        });\n        socket.on((0, $78455e22dea96b8c$export$3b5c4a4b6354f023).Disconnected, ()=>{\n            if (this.disconnected) return;\n            this.emitError((0, $78455e22dea96b8c$export$9547aaa2e39030ff).Network, \"Lost connection to server.\");\n            this.disconnect();\n        });\n        socket.on((0, $78455e22dea96b8c$export$3b5c4a4b6354f023).Close, ()=>{\n            if (this.disconnected) return;\n            this._abort((0, $78455e22dea96b8c$export$9547aaa2e39030ff).SocketClosed, \"Underlying socket is already closed.\");\n        });\n        return socket;\n    }\n    /** Initialize a connection with the server. */ _initialize(id) {\n        this._id = id;\n        this.socket.start(id, this._options.token);\n    }\n    /** Handles messages from the server. */ _handleMessage(message) {\n        const type = message.type;\n        const payload = message.payload;\n        const peerId = message.src;\n        switch(type){\n            case (0, $78455e22dea96b8c$export$adb4a1754da6f10d).Open:\n                this._lastServerId = this.id;\n                this._open = true;\n                this.emit(\"open\", this.id);\n                break;\n            case (0, $78455e22dea96b8c$export$adb4a1754da6f10d).Error:\n                this._abort((0, $78455e22dea96b8c$export$9547aaa2e39030ff).ServerError, payload.msg);\n                break;\n            case (0, $78455e22dea96b8c$export$adb4a1754da6f10d).IdTaken:\n                this._abort((0, $78455e22dea96b8c$export$9547aaa2e39030ff).UnavailableID, `ID \"${this.id}\" is taken`);\n                break;\n            case (0, $78455e22dea96b8c$export$adb4a1754da6f10d).InvalidKey:\n                this._abort((0, $78455e22dea96b8c$export$9547aaa2e39030ff).InvalidKey, `API KEY \"${this._options.key}\" is invalid`);\n                break;\n            case (0, $78455e22dea96b8c$export$adb4a1754da6f10d).Leave:\n                (0, $257947e92926277a$export$2e2bcd8739ae039).log(`Received leave message from ${peerId}`);\n                this._cleanupPeer(peerId);\n                this._connections.delete(peerId);\n                break;\n            case (0, $78455e22dea96b8c$export$adb4a1754da6f10d).Expire:\n                this.emitError((0, $78455e22dea96b8c$export$9547aaa2e39030ff).PeerUnavailable, `Could not connect to peer ${peerId}`);\n                break;\n            case (0, $78455e22dea96b8c$export$adb4a1754da6f10d).Offer:\n                {\n                    // we should consider switching this to CALL/CONNECT, but this is the least breaking option.\n                    const connectionId = payload.connectionId;\n                    let connection = this.getConnection(peerId, connectionId);\n                    if (connection) {\n                        connection.close();\n                        (0, $257947e92926277a$export$2e2bcd8739ae039).warn(`Offer received for existing Connection ID:${connectionId}`);\n                    }\n                    // Create a new connection.\n                    if (payload.type === (0, $78455e22dea96b8c$export$3157d57b4135e3bc).Media) {\n                        const mediaConnection = new (0, $5c1d08c7c57da9a3$export$4a84e95a2324ac29)(peerId, this, {\n                            connectionId: connectionId,\n                            _payload: payload,\n                            metadata: payload.metadata\n                        });\n                        connection = mediaConnection;\n                        this._addConnection(peerId, connection);\n                        this.emit(\"call\", mediaConnection);\n                    } else if (payload.type === (0, $78455e22dea96b8c$export$3157d57b4135e3bc).Data) {\n                        const dataConnection = new this._serializers[payload.serialization](peerId, this, {\n                            connectionId: connectionId,\n                            _payload: payload,\n                            metadata: payload.metadata,\n                            label: payload.label,\n                            serialization: payload.serialization,\n                            reliable: payload.reliable\n                        });\n                        connection = dataConnection;\n                        this._addConnection(peerId, connection);\n                        this.emit(\"connection\", dataConnection);\n                    } else {\n                        (0, $257947e92926277a$export$2e2bcd8739ae039).warn(`Received malformed connection type:${payload.type}`);\n                        return;\n                    }\n                    // Find messages.\n                    const messages = this._getMessages(connectionId);\n                    for (const message of messages)connection.handleMessage(message);\n                    break;\n                }\n            default:\n                {\n                    if (!payload) {\n                        (0, $257947e92926277a$export$2e2bcd8739ae039).warn(`You received a malformed message from ${peerId} of type ${type}`);\n                        return;\n                    }\n                    const connectionId = payload.connectionId;\n                    const connection = this.getConnection(peerId, connectionId);\n                    if (connection && connection.peerConnection) // Pass it on.\n                    connection.handleMessage(message);\n                    else if (connectionId) // Store for possible later use\n                    this._storeMessage(connectionId, message);\n                    else (0, $257947e92926277a$export$2e2bcd8739ae039).warn(\"You received an unrecognized message:\", message);\n                    break;\n                }\n        }\n    }\n    /** Stores messages without a set up connection, to be claimed later. */ _storeMessage(connectionId, message) {\n        if (!this._lostMessages.has(connectionId)) this._lostMessages.set(connectionId, []);\n        this._lostMessages.get(connectionId).push(message);\n    }\n    /**\n\t * Retrieve messages from lost message store\n\t * @internal\n\t */ //TODO Change it to private\n    _getMessages(connectionId) {\n        const messages = this._lostMessages.get(connectionId);\n        if (messages) {\n            this._lostMessages.delete(connectionId);\n            return messages;\n        }\n        return [];\n    }\n    /**\n\t * Connects to the remote peer specified by id and returns a data connection.\n\t * @param peer The brokering ID of the remote peer (their {@apilink Peer.id}).\n\t * @param options for specifying details about Peer Connection\n\t */ connect(peer, options = {}) {\n        options = {\n            serialization: \"default\",\n            ...options\n        };\n        if (this.disconnected) {\n            (0, $257947e92926277a$export$2e2bcd8739ae039).warn(\"You cannot connect to a new Peer because you called .disconnect() on this Peer and ended your connection with the server. You can create a new Peer to reconnect, or call reconnect on this peer if you believe its ID to still be available.\");\n            this.emitError((0, $78455e22dea96b8c$export$9547aaa2e39030ff).Disconnected, \"Cannot connect to new Peer after disconnecting from server.\");\n            return;\n        }\n        const dataConnection = new this._serializers[options.serialization](peer, this, options);\n        this._addConnection(peer, dataConnection);\n        return dataConnection;\n    }\n    /**\n\t * Calls the remote peer specified by id and returns a media connection.\n\t * @param peer The brokering ID of the remote peer (their peer.id).\n\t * @param stream The caller's media stream\n\t * @param options Metadata associated with the connection, passed in by whoever initiated the connection.\n\t */ call(peer, stream, options = {}) {\n        if (this.disconnected) {\n            (0, $257947e92926277a$export$2e2bcd8739ae039).warn(\"You cannot connect to a new Peer because you called .disconnect() on this Peer and ended your connection with the server. You can create a new Peer to reconnect.\");\n            this.emitError((0, $78455e22dea96b8c$export$9547aaa2e39030ff).Disconnected, \"Cannot connect to new Peer after disconnecting from server.\");\n            return;\n        }\n        if (!stream) {\n            (0, $257947e92926277a$export$2e2bcd8739ae039).error(\"To call a peer, you must provide a stream from your browser's `getUserMedia`.\");\n            return;\n        }\n        const mediaConnection = new (0, $5c1d08c7c57da9a3$export$4a84e95a2324ac29)(peer, this, {\n            ...options,\n            _stream: stream\n        });\n        this._addConnection(peer, mediaConnection);\n        return mediaConnection;\n    }\n    /** Add a data/media connection to this peer. */ _addConnection(peerId, connection) {\n        (0, $257947e92926277a$export$2e2bcd8739ae039).log(`add connection ${connection.type}:${connection.connectionId} to peerId:${peerId}`);\n        if (!this._connections.has(peerId)) this._connections.set(peerId, []);\n        this._connections.get(peerId).push(connection);\n    }\n    //TODO should be private\n    _removeConnection(connection) {\n        const connections = this._connections.get(connection.peer);\n        if (connections) {\n            const index = connections.indexOf(connection);\n            if (index !== -1) connections.splice(index, 1);\n        }\n        //remove from lost messages\n        this._lostMessages.delete(connection.connectionId);\n    }\n    /** Retrieve a data/media connection for this peer. */ getConnection(peerId, connectionId) {\n        const connections = this._connections.get(peerId);\n        if (!connections) return null;\n        for (const connection of connections){\n            if (connection.connectionId === connectionId) return connection;\n        }\n        return null;\n    }\n    _delayedAbort(type, message) {\n        setTimeout(()=>{\n            this._abort(type, message);\n        }, 0);\n    }\n    /**\n\t * Emits an error message and destroys the Peer.\n\t * The Peer is not destroyed if it's in a disconnected state, in which case\n\t * it retains its disconnected state and its existing connections.\n\t */ _abort(type, message) {\n        (0, $257947e92926277a$export$2e2bcd8739ae039).error(\"Aborting!\");\n        this.emitError(type, message);\n        if (!this._lastServerId) this.destroy();\n        else this.disconnect();\n    }\n    /**\n\t * Destroys the Peer: closes all active connections as well as the connection\n\t * to the server.\n\t *\n\t * :::caution\n\t * This cannot be undone; the respective peer object will no longer be able\n\t * to create or receive any connections, its ID will be forfeited on the server,\n\t * and all of its data and media connections will be closed.\n\t * :::\n\t */ destroy() {\n        if (this.destroyed) return;\n        (0, $257947e92926277a$export$2e2bcd8739ae039).log(`Destroy peer with ID:${this.id}`);\n        this.disconnect();\n        this._cleanup();\n        this._destroyed = true;\n        this.emit(\"close\");\n    }\n    /** Disconnects every connection on this peer. */ _cleanup() {\n        for (const peerId of this._connections.keys()){\n            this._cleanupPeer(peerId);\n            this._connections.delete(peerId);\n        }\n        this.socket.removeAllListeners();\n    }\n    /** Closes all connections to this peer. */ _cleanupPeer(peerId) {\n        const connections = this._connections.get(peerId);\n        if (!connections) return;\n        for (const connection of connections)connection.close();\n    }\n    /**\n\t * Disconnects the Peer's connection to the PeerServer. Does not close any\n\t *  active connections.\n\t * Warning: The peer can no longer create or accept connections after being\n\t *  disconnected. It also cannot reconnect to the server.\n\t */ disconnect() {\n        if (this.disconnected) return;\n        const currentId = this.id;\n        (0, $257947e92926277a$export$2e2bcd8739ae039).log(`Disconnect peer with ID:${currentId}`);\n        this._disconnected = true;\n        this._open = false;\n        this.socket.close();\n        this._lastServerId = currentId;\n        this._id = null;\n        this.emit(\"disconnected\", currentId);\n    }\n    /** Attempts to reconnect with the same ID.\n\t *\n\t * Only {@apilink Peer.disconnect | disconnected peers} can be reconnected.\n\t * Destroyed peers cannot be reconnected.\n\t * If the connection fails (as an example, if the peer's old ID is now taken),\n\t * the peer's existing connections will not close, but any associated errors events will fire.\n\t */ reconnect() {\n        if (this.disconnected && !this.destroyed) {\n            (0, $257947e92926277a$export$2e2bcd8739ae039).log(`Attempting reconnection to server with ID ${this._lastServerId}`);\n            this._disconnected = false;\n            this._initialize(this._lastServerId);\n        } else if (this.destroyed) throw new Error(\"This peer cannot reconnect to the server. It has already been destroyed.\");\n        else if (!this.disconnected && !this.open) // Do nothing. We're still connecting the first time.\n        (0, $257947e92926277a$export$2e2bcd8739ae039).error(\"In a hurry? We're still trying to make the initial connection!\");\n        else throw new Error(`Peer ${this.id} cannot reconnect because it is not disconnected from the server!`);\n    }\n    /**\n\t * Get a list of available peer IDs. If you're running your own server, you'll\n\t * want to set allow_discovery: true in the PeerServer options. If you're using\n\t * the cloud server, email team@peerjs.com to get the functionality enabled for\n\t * your key.\n\t */ listAllPeers(cb = (_)=>{}) {\n        this._api.listAllPeers().then((peers)=>cb(peers)).catch((error)=>this._abort((0, $78455e22dea96b8c$export$9547aaa2e39030ff).ServerError, error));\n    }\n}\n\n\n\n\n\n\nclass $20dbe68149d7aad9$export$72aa44612e2200cd extends (0, $6366c4ca161bc297$export$d365f7ad9d7df9c9) {\n    constructor(peerId, provider, options){\n        super(peerId, provider, {\n            ...options,\n            reliable: true\n        });\n        this._CHUNK_SIZE = 32768;\n        this._splitStream = new TransformStream({\n            transform: (chunk, controller)=>{\n                for(let split = 0; split < chunk.length; split += this._CHUNK_SIZE)controller.enqueue(chunk.subarray(split, split + this._CHUNK_SIZE));\n            }\n        });\n        this._rawSendStream = new WritableStream({\n            write: async (chunk, controller)=>{\n                const openEvent = new Promise((resolve)=>this.dataChannel.addEventListener(\"bufferedamountlow\", resolve, {\n                        once: true\n                    }));\n                // if we can send the chunk now, send it\n                // if not, we wait until at least half of the sending buffer is free again\n                await (this.dataChannel.bufferedAmount <= (0, $6366c4ca161bc297$export$d365f7ad9d7df9c9).MAX_BUFFERED_AMOUNT - chunk.byteLength || openEvent);\n                // TODO: what can go wrong here?\n                try {\n                    this.dataChannel.send(chunk);\n                } catch (e) {\n                    (0, $257947e92926277a$export$2e2bcd8739ae039).error(`DC#:${this.connectionId} Error when sending:`, e);\n                    controller.error(e);\n                    this.close();\n                }\n            }\n        });\n        this.writer = this._splitStream.writable.getWriter();\n        this._rawReadStream = new ReadableStream({\n            start: (controller)=>{\n                this.once(\"open\", ()=>{\n                    this.dataChannel.addEventListener(\"message\", (e)=>{\n                        controller.enqueue(e.data);\n                    });\n                });\n            }\n        });\n        this._splitStream.readable.pipeTo(this._rawSendStream);\n    }\n    _initializeDataChannel(dc) {\n        super._initializeDataChannel(dc);\n        this.dataChannel.binaryType = \"arraybuffer\";\n        this.dataChannel.bufferedAmountLowThreshold = (0, $6366c4ca161bc297$export$d365f7ad9d7df9c9).MAX_BUFFERED_AMOUNT / 2;\n    }\n}\n\n\nclass $6e39230ab36396ad$export$80f5de1a66c4d624 extends (0, $20dbe68149d7aad9$export$72aa44612e2200cd) {\n    constructor(peerId, provider, options){\n        super(peerId, provider, options);\n        this.serialization = \"MsgPack\";\n        this._encoder = new (0, _msgpack_msgpack__WEBPACK_IMPORTED_MODULE_3__.Encoder)();\n        (async ()=>{\n            for await (const msg of (0, _msgpack_msgpack__WEBPACK_IMPORTED_MODULE_2__.decodeMultiStream)(this._rawReadStream)){\n                // @ts-ignore\n                if (msg.__peerData?.type === \"close\") {\n                    this.close();\n                    return;\n                }\n                this.emit(\"data\", msg);\n            }\n        })();\n    }\n    _send(data) {\n        return this.writer.write(this._encoder.encode(data));\n    }\n}\n\n\nclass $1e0aff16be2c328e$export$d72c7bf8eef50853 extends (0, $416260bce337df90$export$ecd1fc136c422448) {\n    constructor(...args){\n        super(...args);\n        this._serializers = {\n            MsgPack: $6e39230ab36396ad$export$80f5de1a66c4d624,\n            default: (0, $6e39230ab36396ad$export$80f5de1a66c4d624)\n        };\n    }\n}\n\n\n\n\n\n\n\nvar $dd0187d7f28e386f$export$2e2bcd8739ae039 = (0, $416260bce337df90$export$ecd1fc136c422448);\n\n\n\n//# sourceMappingURL=bundler.mjs.map\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/peerjs/dist/bundler.mjs?\n}");

/***/ }),

/***/ "./node_modules/sdp/sdp.js":
/*!*********************************!*\
  !*** ./node_modules/sdp/sdp.js ***!
  \*********************************/
/***/ ((module) => {

"use strict";
eval("{/* eslint-env node */\n\n\n// SDP helpers.\nconst SDPUtils = {};\n\n// Generate an alphanumeric identifier for cname or mids.\n// TODO: use UUIDs instead? https://gist.github.com/jed/982883\nSDPUtils.generateIdentifier = function() {\n  return Math.random().toString(36).substring(2, 12);\n};\n\n// The RTCP CNAME used by all peerconnections from the same JS.\nSDPUtils.localCName = SDPUtils.generateIdentifier();\n\n// Splits SDP into lines, dealing with both CRLF and LF.\nSDPUtils.splitLines = function(blob) {\n  return blob.trim().split('\\n').map(line => line.trim());\n};\n// Splits SDP into sessionpart and mediasections. Ensures CRLF.\nSDPUtils.splitSections = function(blob) {\n  const parts = blob.split('\\nm=');\n  return parts.map((part, index) => (index > 0 ?\n    'm=' + part : part).trim() + '\\r\\n');\n};\n\n// Returns the session description.\nSDPUtils.getDescription = function(blob) {\n  const sections = SDPUtils.splitSections(blob);\n  return sections && sections[0];\n};\n\n// Returns the individual media sections.\nSDPUtils.getMediaSections = function(blob) {\n  const sections = SDPUtils.splitSections(blob);\n  sections.shift();\n  return sections;\n};\n\n// Returns lines that start with a certain prefix.\nSDPUtils.matchPrefix = function(blob, prefix) {\n  return SDPUtils.splitLines(blob).filter(line => line.indexOf(prefix) === 0);\n};\n\n// Parses an ICE candidate line. Sample input:\n// candidate:702786350 2 udp 41819902 8.8.8.8 60769 typ relay raddr 8.8.8.8\n// rport 55996\"\n// Input can be prefixed with a=.\nSDPUtils.parseCandidate = function(line) {\n  let parts;\n  // Parse both variants.\n  if (line.indexOf('a=candidate:') === 0) {\n    parts = line.substring(12).split(' ');\n  } else {\n    parts = line.substring(10).split(' ');\n  }\n\n  const candidate = {\n    foundation: parts[0],\n    component: {1: 'rtp', 2: 'rtcp'}[parts[1]] || parts[1],\n    protocol: parts[2].toLowerCase(),\n    priority: parseInt(parts[3], 10),\n    ip: parts[4],\n    address: parts[4], // address is an alias for ip.\n    port: parseInt(parts[5], 10),\n    // skip parts[6] == 'typ'\n    type: parts[7],\n  };\n\n  for (let i = 8; i < parts.length; i += 2) {\n    switch (parts[i]) {\n      case 'raddr':\n        candidate.relatedAddress = parts[i + 1];\n        break;\n      case 'rport':\n        candidate.relatedPort = parseInt(parts[i + 1], 10);\n        break;\n      case 'tcptype':\n        candidate.tcpType = parts[i + 1];\n        break;\n      case 'ufrag':\n        candidate.ufrag = parts[i + 1]; // for backward compatibility.\n        candidate.usernameFragment = parts[i + 1];\n        break;\n      default: // extension handling, in particular ufrag. Don't overwrite.\n        if (candidate[parts[i]] === undefined) {\n          candidate[parts[i]] = parts[i + 1];\n        }\n        break;\n    }\n  }\n  return candidate;\n};\n\n// Translates a candidate object into SDP candidate attribute.\n// This does not include the a= prefix!\nSDPUtils.writeCandidate = function(candidate) {\n  const sdp = [];\n  sdp.push(candidate.foundation);\n\n  const component = candidate.component;\n  if (component === 'rtp') {\n    sdp.push(1);\n  } else if (component === 'rtcp') {\n    sdp.push(2);\n  } else {\n    sdp.push(component);\n  }\n  sdp.push(candidate.protocol.toUpperCase());\n  sdp.push(candidate.priority);\n  sdp.push(candidate.address || candidate.ip);\n  sdp.push(candidate.port);\n\n  const type = candidate.type;\n  sdp.push('typ');\n  sdp.push(type);\n  if (type !== 'host' && candidate.relatedAddress &&\n      candidate.relatedPort) {\n    sdp.push('raddr');\n    sdp.push(candidate.relatedAddress);\n    sdp.push('rport');\n    sdp.push(candidate.relatedPort);\n  }\n  if (candidate.tcpType && candidate.protocol.toLowerCase() === 'tcp') {\n    sdp.push('tcptype');\n    sdp.push(candidate.tcpType);\n  }\n  if (candidate.usernameFragment || candidate.ufrag) {\n    sdp.push('ufrag');\n    sdp.push(candidate.usernameFragment || candidate.ufrag);\n  }\n  return 'candidate:' + sdp.join(' ');\n};\n\n// Parses an ice-options line, returns an array of option tags.\n// Sample input:\n// a=ice-options:foo bar\nSDPUtils.parseIceOptions = function(line) {\n  return line.substring(14).split(' ');\n};\n\n// Parses a rtpmap line, returns RTCRtpCoddecParameters. Sample input:\n// a=rtpmap:111 opus/48000/2\nSDPUtils.parseRtpMap = function(line) {\n  let parts = line.substring(9).split(' ');\n  const parsed = {\n    payloadType: parseInt(parts.shift(), 10), // was: id\n  };\n\n  parts = parts[0].split('/');\n\n  parsed.name = parts[0];\n  parsed.clockRate = parseInt(parts[1], 10); // was: clockrate\n  parsed.channels = parts.length === 3 ? parseInt(parts[2], 10) : 1;\n  // legacy alias, got renamed back to channels in ORTC.\n  parsed.numChannels = parsed.channels;\n  return parsed;\n};\n\n// Generates a rtpmap line from RTCRtpCodecCapability or\n// RTCRtpCodecParameters.\nSDPUtils.writeRtpMap = function(codec) {\n  let pt = codec.payloadType;\n  if (codec.preferredPayloadType !== undefined) {\n    pt = codec.preferredPayloadType;\n  }\n  const channels = codec.channels || codec.numChannels || 1;\n  return 'a=rtpmap:' + pt + ' ' + codec.name + '/' + codec.clockRate +\n      (channels !== 1 ? '/' + channels : '') + '\\r\\n';\n};\n\n// Parses a extmap line (headerextension from RFC 5285). Sample input:\n// a=extmap:2 urn:ietf:params:rtp-hdrext:toffset\n// a=extmap:2/sendonly urn:ietf:params:rtp-hdrext:toffset\nSDPUtils.parseExtmap = function(line) {\n  const parts = line.substring(9).split(' ');\n  return {\n    id: parseInt(parts[0], 10),\n    direction: parts[0].indexOf('/') > 0 ? parts[0].split('/')[1] : 'sendrecv',\n    uri: parts[1],\n    attributes: parts.slice(2).join(' '),\n  };\n};\n\n// Generates an extmap line from RTCRtpHeaderExtensionParameters or\n// RTCRtpHeaderExtension.\nSDPUtils.writeExtmap = function(headerExtension) {\n  return 'a=extmap:' + (headerExtension.id || headerExtension.preferredId) +\n      (headerExtension.direction && headerExtension.direction !== 'sendrecv'\n        ? '/' + headerExtension.direction\n        : '') +\n      ' ' + headerExtension.uri +\n      (headerExtension.attributes ? ' ' + headerExtension.attributes : '') +\n      '\\r\\n';\n};\n\n// Parses a fmtp line, returns dictionary. Sample input:\n// a=fmtp:96 vbr=on;cng=on\n// Also deals with vbr=on; cng=on\nSDPUtils.parseFmtp = function(line) {\n  const parsed = {};\n  let kv;\n  const parts = line.substring(line.indexOf(' ') + 1).split(';');\n  for (let j = 0; j < parts.length; j++) {\n    kv = parts[j].trim().split('=');\n    parsed[kv[0].trim()] = kv[1];\n  }\n  return parsed;\n};\n\n// Generates a fmtp line from RTCRtpCodecCapability or RTCRtpCodecParameters.\nSDPUtils.writeFmtp = function(codec) {\n  let line = '';\n  let pt = codec.payloadType;\n  if (codec.preferredPayloadType !== undefined) {\n    pt = codec.preferredPayloadType;\n  }\n  if (codec.parameters && Object.keys(codec.parameters).length) {\n    const params = [];\n    Object.keys(codec.parameters).forEach(param => {\n      if (codec.parameters[param] !== undefined) {\n        params.push(param + '=' + codec.parameters[param]);\n      } else {\n        params.push(param);\n      }\n    });\n    line += 'a=fmtp:' + pt + ' ' + params.join(';') + '\\r\\n';\n  }\n  return line;\n};\n\n// Parses a rtcp-fb line, returns RTCPRtcpFeedback object. Sample input:\n// a=rtcp-fb:98 nack rpsi\nSDPUtils.parseRtcpFb = function(line) {\n  const parts = line.substring(line.indexOf(' ') + 1).split(' ');\n  return {\n    type: parts.shift(),\n    parameter: parts.join(' '),\n  };\n};\n\n// Generate a=rtcp-fb lines from RTCRtpCodecCapability or RTCRtpCodecParameters.\nSDPUtils.writeRtcpFb = function(codec) {\n  let lines = '';\n  let pt = codec.payloadType;\n  if (codec.preferredPayloadType !== undefined) {\n    pt = codec.preferredPayloadType;\n  }\n  if (codec.rtcpFeedback && codec.rtcpFeedback.length) {\n    // FIXME: special handling for trr-int?\n    codec.rtcpFeedback.forEach(fb => {\n      lines += 'a=rtcp-fb:' + pt + ' ' + fb.type +\n      (fb.parameter && fb.parameter.length ? ' ' + fb.parameter : '') +\n          '\\r\\n';\n    });\n  }\n  return lines;\n};\n\n// Parses a RFC 5576 ssrc media attribute. Sample input:\n// a=ssrc:3735928559 cname:something\nSDPUtils.parseSsrcMedia = function(line) {\n  const sp = line.indexOf(' ');\n  const parts = {\n    ssrc: parseInt(line.substring(7, sp), 10),\n  };\n  const colon = line.indexOf(':', sp);\n  if (colon > -1) {\n    parts.attribute = line.substring(sp + 1, colon);\n    parts.value = line.substring(colon + 1);\n  } else {\n    parts.attribute = line.substring(sp + 1);\n  }\n  return parts;\n};\n\n// Parse a ssrc-group line (see RFC 5576). Sample input:\n// a=ssrc-group:semantics 12 34\nSDPUtils.parseSsrcGroup = function(line) {\n  const parts = line.substring(13).split(' ');\n  return {\n    semantics: parts.shift(),\n    ssrcs: parts.map(ssrc => parseInt(ssrc, 10)),\n  };\n};\n\n// Extracts the MID (RFC 5888) from a media section.\n// Returns the MID or undefined if no mid line was found.\nSDPUtils.getMid = function(mediaSection) {\n  const mid = SDPUtils.matchPrefix(mediaSection, 'a=mid:')[0];\n  if (mid) {\n    return mid.substring(6);\n  }\n};\n\n// Parses a fingerprint line for DTLS-SRTP.\nSDPUtils.parseFingerprint = function(line) {\n  const parts = line.substring(14).split(' ');\n  return {\n    algorithm: parts[0].toLowerCase(), // algorithm is case-sensitive in Edge.\n    value: parts[1].toUpperCase(), // the definition is upper-case in RFC 4572.\n  };\n};\n\n// Extracts DTLS parameters from SDP media section or sessionpart.\n// FIXME: for consistency with other functions this should only\n//   get the fingerprint line as input. See also getIceParameters.\nSDPUtils.getDtlsParameters = function(mediaSection, sessionpart) {\n  const lines = SDPUtils.matchPrefix(mediaSection + sessionpart,\n    'a=fingerprint:');\n  // Note: a=setup line is ignored since we use the 'auto' role in Edge.\n  return {\n    role: 'auto',\n    fingerprints: lines.map(SDPUtils.parseFingerprint),\n  };\n};\n\n// Serializes DTLS parameters to SDP.\nSDPUtils.writeDtlsParameters = function(params, setupType) {\n  let sdp = 'a=setup:' + setupType + '\\r\\n';\n  params.fingerprints.forEach(fp => {\n    sdp += 'a=fingerprint:' + fp.algorithm + ' ' + fp.value + '\\r\\n';\n  });\n  return sdp;\n};\n\n// Parses a=crypto lines into\n//   https://rawgit.com/aboba/edgertc/master/msortc-rs4.html#dictionary-rtcsrtpsdesparameters-members\nSDPUtils.parseCryptoLine = function(line) {\n  const parts = line.substring(9).split(' ');\n  return {\n    tag: parseInt(parts[0], 10),\n    cryptoSuite: parts[1],\n    keyParams: parts[2],\n    sessionParams: parts.slice(3),\n  };\n};\n\nSDPUtils.writeCryptoLine = function(parameters) {\n  return 'a=crypto:' + parameters.tag + ' ' +\n    parameters.cryptoSuite + ' ' +\n    (typeof parameters.keyParams === 'object'\n      ? SDPUtils.writeCryptoKeyParams(parameters.keyParams)\n      : parameters.keyParams) +\n    (parameters.sessionParams ? ' ' + parameters.sessionParams.join(' ') : '') +\n    '\\r\\n';\n};\n\n// Parses the crypto key parameters into\n//   https://rawgit.com/aboba/edgertc/master/msortc-rs4.html#rtcsrtpkeyparam*\nSDPUtils.parseCryptoKeyParams = function(keyParams) {\n  if (keyParams.indexOf('inline:') !== 0) {\n    return null;\n  }\n  const parts = keyParams.substring(7).split('|');\n  return {\n    keyMethod: 'inline',\n    keySalt: parts[0],\n    lifeTime: parts[1],\n    mkiValue: parts[2] ? parts[2].split(':')[0] : undefined,\n    mkiLength: parts[2] ? parts[2].split(':')[1] : undefined,\n  };\n};\n\nSDPUtils.writeCryptoKeyParams = function(keyParams) {\n  return keyParams.keyMethod + ':'\n    + keyParams.keySalt +\n    (keyParams.lifeTime ? '|' + keyParams.lifeTime : '') +\n    (keyParams.mkiValue && keyParams.mkiLength\n      ? '|' + keyParams.mkiValue + ':' + keyParams.mkiLength\n      : '');\n};\n\n// Extracts all SDES parameters.\nSDPUtils.getCryptoParameters = function(mediaSection, sessionpart) {\n  const lines = SDPUtils.matchPrefix(mediaSection + sessionpart,\n    'a=crypto:');\n  return lines.map(SDPUtils.parseCryptoLine);\n};\n\n// Parses ICE information from SDP media section or sessionpart.\n// FIXME: for consistency with other functions this should only\n//   get the ice-ufrag and ice-pwd lines as input.\nSDPUtils.getIceParameters = function(mediaSection, sessionpart) {\n  const ufrag = SDPUtils.matchPrefix(mediaSection + sessionpart,\n    'a=ice-ufrag:')[0];\n  const pwd = SDPUtils.matchPrefix(mediaSection + sessionpart,\n    'a=ice-pwd:')[0];\n  if (!(ufrag && pwd)) {\n    return null;\n  }\n  return {\n    usernameFragment: ufrag.substring(12),\n    password: pwd.substring(10),\n  };\n};\n\n// Serializes ICE parameters to SDP.\nSDPUtils.writeIceParameters = function(params) {\n  let sdp = 'a=ice-ufrag:' + params.usernameFragment + '\\r\\n' +\n      'a=ice-pwd:' + params.password + '\\r\\n';\n  if (params.iceLite) {\n    sdp += 'a=ice-lite\\r\\n';\n  }\n  return sdp;\n};\n\n// Parses the SDP media section and returns RTCRtpParameters.\nSDPUtils.parseRtpParameters = function(mediaSection) {\n  const description = {\n    codecs: [],\n    headerExtensions: [],\n    fecMechanisms: [],\n    rtcp: [],\n  };\n  const lines = SDPUtils.splitLines(mediaSection);\n  const mline = lines[0].split(' ');\n  description.profile = mline[2];\n  for (let i = 3; i < mline.length; i++) { // find all codecs from mline[3..]\n    const pt = mline[i];\n    const rtpmapline = SDPUtils.matchPrefix(\n      mediaSection, 'a=rtpmap:' + pt + ' ')[0];\n    if (rtpmapline) {\n      const codec = SDPUtils.parseRtpMap(rtpmapline);\n      const fmtps = SDPUtils.matchPrefix(\n        mediaSection, 'a=fmtp:' + pt + ' ');\n      // Only the first a=fmtp:<pt> is considered.\n      codec.parameters = fmtps.length ? SDPUtils.parseFmtp(fmtps[0]) : {};\n      codec.rtcpFeedback = SDPUtils.matchPrefix(\n        mediaSection, 'a=rtcp-fb:' + pt + ' ')\n        .map(SDPUtils.parseRtcpFb);\n      description.codecs.push(codec);\n      // parse FEC mechanisms from rtpmap lines.\n      switch (codec.name.toUpperCase()) {\n        case 'RED':\n        case 'ULPFEC':\n          description.fecMechanisms.push(codec.name.toUpperCase());\n          break;\n        default: // only RED and ULPFEC are recognized as FEC mechanisms.\n          break;\n      }\n    }\n  }\n  SDPUtils.matchPrefix(mediaSection, 'a=extmap:').forEach(line => {\n    description.headerExtensions.push(SDPUtils.parseExtmap(line));\n  });\n  const wildcardRtcpFb = SDPUtils.matchPrefix(mediaSection, 'a=rtcp-fb:* ')\n    .map(SDPUtils.parseRtcpFb);\n  description.codecs.forEach(codec => {\n    wildcardRtcpFb.forEach(fb=> {\n      const duplicate = codec.rtcpFeedback.find(existingFeedback => {\n        return existingFeedback.type === fb.type &&\n          existingFeedback.parameter === fb.parameter;\n      });\n      if (!duplicate) {\n        codec.rtcpFeedback.push(fb);\n      }\n    });\n  });\n  // FIXME: parse rtcp.\n  return description;\n};\n\n// Generates parts of the SDP media section describing the capabilities /\n// parameters.\nSDPUtils.writeRtpDescription = function(kind, caps) {\n  let sdp = '';\n\n  // Build the mline.\n  sdp += 'm=' + kind + ' ';\n  sdp += caps.codecs.length > 0 ? '9' : '0'; // reject if no codecs.\n  sdp += ' ' + (caps.profile || 'UDP/TLS/RTP/SAVPF') + ' ';\n  sdp += caps.codecs.map(codec => {\n    if (codec.preferredPayloadType !== undefined) {\n      return codec.preferredPayloadType;\n    }\n    return codec.payloadType;\n  }).join(' ') + '\\r\\n';\n\n  sdp += 'c=IN IP4 0.0.0.0\\r\\n';\n  sdp += 'a=rtcp:9 IN IP4 0.0.0.0\\r\\n';\n\n  // Add a=rtpmap lines for each codec. Also fmtp and rtcp-fb.\n  caps.codecs.forEach(codec => {\n    sdp += SDPUtils.writeRtpMap(codec);\n    sdp += SDPUtils.writeFmtp(codec);\n    sdp += SDPUtils.writeRtcpFb(codec);\n  });\n  let maxptime = 0;\n  caps.codecs.forEach(codec => {\n    if (codec.maxptime > maxptime) {\n      maxptime = codec.maxptime;\n    }\n  });\n  if (maxptime > 0) {\n    sdp += 'a=maxptime:' + maxptime + '\\r\\n';\n  }\n\n  if (caps.headerExtensions) {\n    caps.headerExtensions.forEach(extension => {\n      sdp += SDPUtils.writeExtmap(extension);\n    });\n  }\n  // FIXME: write fecMechanisms.\n  return sdp;\n};\n\n// Parses the SDP media section and returns an array of\n// RTCRtpEncodingParameters.\nSDPUtils.parseRtpEncodingParameters = function(mediaSection) {\n  const encodingParameters = [];\n  const description = SDPUtils.parseRtpParameters(mediaSection);\n  const hasRed = description.fecMechanisms.indexOf('RED') !== -1;\n  const hasUlpfec = description.fecMechanisms.indexOf('ULPFEC') !== -1;\n\n  // filter a=ssrc:... cname:, ignore PlanB-msid\n  const ssrcs = SDPUtils.matchPrefix(mediaSection, 'a=ssrc:')\n    .map(line => SDPUtils.parseSsrcMedia(line))\n    .filter(parts => parts.attribute === 'cname');\n  const primarySsrc = ssrcs.length > 0 && ssrcs[0].ssrc;\n  let secondarySsrc;\n\n  const flows = SDPUtils.matchPrefix(mediaSection, 'a=ssrc-group:FID')\n    .map(line => {\n      const parts = line.substring(17).split(' ');\n      return parts.map(part => parseInt(part, 10));\n    });\n  if (flows.length > 0 && flows[0].length > 1 && flows[0][0] === primarySsrc) {\n    secondarySsrc = flows[0][1];\n  }\n\n  description.codecs.forEach(codec => {\n    if (codec.name.toUpperCase() === 'RTX' && codec.parameters.apt) {\n      let encParam = {\n        ssrc: primarySsrc,\n        codecPayloadType: parseInt(codec.parameters.apt, 10),\n      };\n      if (primarySsrc && secondarySsrc) {\n        encParam.rtx = {ssrc: secondarySsrc};\n      }\n      encodingParameters.push(encParam);\n      if (hasRed) {\n        encParam = JSON.parse(JSON.stringify(encParam));\n        encParam.fec = {\n          ssrc: primarySsrc,\n          mechanism: hasUlpfec ? 'red+ulpfec' : 'red',\n        };\n        encodingParameters.push(encParam);\n      }\n    }\n  });\n  if (encodingParameters.length === 0 && primarySsrc) {\n    encodingParameters.push({\n      ssrc: primarySsrc,\n    });\n  }\n\n  // we support both b=AS and b=TIAS but interpret AS as TIAS.\n  let bandwidth = SDPUtils.matchPrefix(mediaSection, 'b=');\n  if (bandwidth.length) {\n    if (bandwidth[0].indexOf('b=TIAS:') === 0) {\n      bandwidth = parseInt(bandwidth[0].substring(7), 10);\n    } else if (bandwidth[0].indexOf('b=AS:') === 0) {\n      // use formula from JSEP to convert b=AS to TIAS value.\n      bandwidth = parseInt(bandwidth[0].substring(5), 10) * 1000 * 0.95\n          - (50 * 40 * 8);\n    } else {\n      bandwidth = undefined;\n    }\n    encodingParameters.forEach(params => {\n      params.maxBitrate = bandwidth;\n    });\n  }\n  return encodingParameters;\n};\n\n// parses http://draft.ortc.org/#rtcrtcpparameters*\nSDPUtils.parseRtcpParameters = function(mediaSection) {\n  const rtcpParameters = {};\n\n  // Gets the first SSRC. Note that with RTX there might be multiple\n  // SSRCs.\n  const remoteSsrc = SDPUtils.matchPrefix(mediaSection, 'a=ssrc:')\n    .map(line => SDPUtils.parseSsrcMedia(line))\n    .filter(obj => obj.attribute === 'cname')[0];\n  if (remoteSsrc) {\n    rtcpParameters.cname = remoteSsrc.value;\n    rtcpParameters.ssrc = remoteSsrc.ssrc;\n  }\n\n  // Edge uses the compound attribute instead of reducedSize\n  // compound is !reducedSize\n  const rsize = SDPUtils.matchPrefix(mediaSection, 'a=rtcp-rsize');\n  rtcpParameters.reducedSize = rsize.length > 0;\n  rtcpParameters.compound = rsize.length === 0;\n\n  // parses the rtcp-mux attrbute.\n  // Note that Edge does not support unmuxed RTCP.\n  const mux = SDPUtils.matchPrefix(mediaSection, 'a=rtcp-mux');\n  rtcpParameters.mux = mux.length > 0;\n\n  return rtcpParameters;\n};\n\nSDPUtils.writeRtcpParameters = function(rtcpParameters) {\n  let sdp = '';\n  if (rtcpParameters.reducedSize) {\n    sdp += 'a=rtcp-rsize\\r\\n';\n  }\n  if (rtcpParameters.mux) {\n    sdp += 'a=rtcp-mux\\r\\n';\n  }\n  if (rtcpParameters.ssrc !== undefined && rtcpParameters.cname) {\n    sdp += 'a=ssrc:' + rtcpParameters.ssrc +\n      ' cname:' + rtcpParameters.cname + '\\r\\n';\n  }\n  return sdp;\n};\n\n\n// parses either a=msid: or a=ssrc:... msid lines and returns\n// the id of the MediaStream and MediaStreamTrack.\nSDPUtils.parseMsid = function(mediaSection) {\n  let parts;\n  const spec = SDPUtils.matchPrefix(mediaSection, 'a=msid:');\n  if (spec.length === 1) {\n    parts = spec[0].substring(7).split(' ');\n    return {stream: parts[0], track: parts[1]};\n  }\n  const planB = SDPUtils.matchPrefix(mediaSection, 'a=ssrc:')\n    .map(line => SDPUtils.parseSsrcMedia(line))\n    .filter(msidParts => msidParts.attribute === 'msid');\n  if (planB.length > 0) {\n    parts = planB[0].value.split(' ');\n    return {stream: parts[0], track: parts[1]};\n  }\n};\n\n// SCTP\n// parses draft-ietf-mmusic-sctp-sdp-26 first and falls back\n// to draft-ietf-mmusic-sctp-sdp-05\nSDPUtils.parseSctpDescription = function(mediaSection) {\n  const mline = SDPUtils.parseMLine(mediaSection);\n  const maxSizeLine = SDPUtils.matchPrefix(mediaSection, 'a=max-message-size:');\n  let maxMessageSize;\n  if (maxSizeLine.length > 0) {\n    maxMessageSize = parseInt(maxSizeLine[0].substring(19), 10);\n  }\n  if (isNaN(maxMessageSize)) {\n    maxMessageSize = 65536;\n  }\n  const sctpPort = SDPUtils.matchPrefix(mediaSection, 'a=sctp-port:');\n  if (sctpPort.length > 0) {\n    return {\n      port: parseInt(sctpPort[0].substring(12), 10),\n      protocol: mline.fmt,\n      maxMessageSize,\n    };\n  }\n  const sctpMapLines = SDPUtils.matchPrefix(mediaSection, 'a=sctpmap:');\n  if (sctpMapLines.length > 0) {\n    const parts = sctpMapLines[0]\n      .substring(10)\n      .split(' ');\n    return {\n      port: parseInt(parts[0], 10),\n      protocol: parts[1],\n      maxMessageSize,\n    };\n  }\n};\n\n// SCTP\n// outputs the draft-ietf-mmusic-sctp-sdp-26 version that all browsers\n// support by now receiving in this format, unless we originally parsed\n// as the draft-ietf-mmusic-sctp-sdp-05 format (indicated by the m-line\n// protocol of DTLS/SCTP -- without UDP/ or TCP/)\nSDPUtils.writeSctpDescription = function(media, sctp) {\n  let output = [];\n  if (media.protocol !== 'DTLS/SCTP') {\n    output = [\n      'm=' + media.kind + ' 9 ' + media.protocol + ' ' + sctp.protocol + '\\r\\n',\n      'c=IN IP4 0.0.0.0\\r\\n',\n      'a=sctp-port:' + sctp.port + '\\r\\n',\n    ];\n  } else {\n    output = [\n      'm=' + media.kind + ' 9 ' + media.protocol + ' ' + sctp.port + '\\r\\n',\n      'c=IN IP4 0.0.0.0\\r\\n',\n      'a=sctpmap:' + sctp.port + ' ' + sctp.protocol + ' 65535\\r\\n',\n    ];\n  }\n  if (sctp.maxMessageSize !== undefined) {\n    output.push('a=max-message-size:' + sctp.maxMessageSize + '\\r\\n');\n  }\n  return output.join('');\n};\n\n// Generate a session ID for SDP.\n// https://tools.ietf.org/html/draft-ietf-rtcweb-jsep-20#section-5.2.1\n// recommends using a cryptographically random +ve 64-bit value\n// but right now this should be acceptable and within the right range\nSDPUtils.generateSessionId = function() {\n  return Math.random().toString().substr(2, 22);\n};\n\n// Write boiler plate for start of SDP\n// sessId argument is optional - if not supplied it will\n// be generated randomly\n// sessVersion is optional and defaults to 2\n// sessUser is optional and defaults to 'thisisadapterortc'\nSDPUtils.writeSessionBoilerplate = function(sessId, sessVer, sessUser) {\n  let sessionId;\n  const version = sessVer !== undefined ? sessVer : 2;\n  if (sessId) {\n    sessionId = sessId;\n  } else {\n    sessionId = SDPUtils.generateSessionId();\n  }\n  const user = sessUser || 'thisisadapterortc';\n  // FIXME: sess-id should be an NTP timestamp.\n  return 'v=0\\r\\n' +\n      'o=' + user + ' ' + sessionId + ' ' + version +\n        ' IN IP4 127.0.0.1\\r\\n' +\n      's=-\\r\\n' +\n      't=0 0\\r\\n';\n};\n\n// Gets the direction from the mediaSection or the sessionpart.\nSDPUtils.getDirection = function(mediaSection, sessionpart) {\n  // Look for sendrecv, sendonly, recvonly, inactive, default to sendrecv.\n  const lines = SDPUtils.splitLines(mediaSection);\n  for (let i = 0; i < lines.length; i++) {\n    switch (lines[i]) {\n      case 'a=sendrecv':\n      case 'a=sendonly':\n      case 'a=recvonly':\n      case 'a=inactive':\n        return lines[i].substring(2);\n      default:\n        // FIXME: What should happen here?\n    }\n  }\n  if (sessionpart) {\n    return SDPUtils.getDirection(sessionpart);\n  }\n  return 'sendrecv';\n};\n\nSDPUtils.getKind = function(mediaSection) {\n  const lines = SDPUtils.splitLines(mediaSection);\n  const mline = lines[0].split(' ');\n  return mline[0].substring(2);\n};\n\nSDPUtils.isRejected = function(mediaSection) {\n  return mediaSection.split(' ', 2)[1] === '0';\n};\n\nSDPUtils.parseMLine = function(mediaSection) {\n  const lines = SDPUtils.splitLines(mediaSection);\n  const parts = lines[0].substring(2).split(' ');\n  return {\n    kind: parts[0],\n    port: parseInt(parts[1], 10),\n    protocol: parts[2],\n    fmt: parts.slice(3).join(' '),\n  };\n};\n\nSDPUtils.parseOLine = function(mediaSection) {\n  const line = SDPUtils.matchPrefix(mediaSection, 'o=')[0];\n  const parts = line.substring(2).split(' ');\n  return {\n    username: parts[0],\n    sessionId: parts[1],\n    sessionVersion: parseInt(parts[2], 10),\n    netType: parts[3],\n    addressType: parts[4],\n    address: parts[5],\n  };\n};\n\n// a very naive interpretation of a valid SDP.\nSDPUtils.isValidSDP = function(blob) {\n  if (typeof blob !== 'string' || blob.length === 0) {\n    return false;\n  }\n  const lines = SDPUtils.splitLines(blob);\n  for (let i = 0; i < lines.length; i++) {\n    if (lines[i].length < 2 || lines[i].charAt(1) !== '=') {\n      return false;\n    }\n    // TODO: check the modifier a bit more.\n  }\n  return true;\n};\n\n// Expose public methods.\nif (true) {\n  module.exports = SDPUtils;\n}\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/sdp/sdp.js?\n}");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/native.js":
/*!******************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/native.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nconst randomUUID = typeof crypto !== 'undefined' && crypto.randomUUID && crypto.randomUUID.bind(crypto);\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ({\n  randomUUID\n});\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/uuid/dist/esm-browser/native.js?\n}");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/regex.js":
/*!*****************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/regex.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (/^(?:[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}|00000000-0000-0000-0000-000000000000)$/i);\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/uuid/dist/esm-browser/regex.js?\n}");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/rng.js":
/*!***************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/rng.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ rng)\n/* harmony export */ });\n// Unique ID creation requires a high quality random # generator. In the browser we therefore\n// require the crypto API and do not support built-in fallback to lower quality random number\n// generators (like Math.random()).\nlet getRandomValues;\nconst rnds8 = new Uint8Array(16);\nfunction rng() {\n  // lazy load so that environments that need to polyfill have a chance to do so\n  if (!getRandomValues) {\n    // getRandomValues needs to be invoked in a context where \"this\" is a Crypto implementation.\n    getRandomValues = typeof crypto !== 'undefined' && crypto.getRandomValues && crypto.getRandomValues.bind(crypto);\n\n    if (!getRandomValues) {\n      throw new Error('crypto.getRandomValues() not supported. See https://github.com/uuidjs/uuid#getrandomvalues-not-supported');\n    }\n  }\n\n  return getRandomValues(rnds8);\n}\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/uuid/dist/esm-browser/rng.js?\n}");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/stringify.js":
/*!*********************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/stringify.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__),\n/* harmony export */   unsafeStringify: () => (/* binding */ unsafeStringify)\n/* harmony export */ });\n/* harmony import */ var _validate_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./validate.js */ \"./node_modules/uuid/dist/esm-browser/validate.js\");\n\n/**\n * Convert array of 16 byte values to UUID string format of the form:\n * XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\n */\n\nconst byteToHex = [];\n\nfor (let i = 0; i < 256; ++i) {\n  byteToHex.push((i + 0x100).toString(16).slice(1));\n}\n\nfunction unsafeStringify(arr, offset = 0) {\n  // Note: Be careful editing this code!  It's been tuned for performance\n  // and works in ways you may not expect. See https://github.com/uuidjs/uuid/pull/434\n  return byteToHex[arr[offset + 0]] + byteToHex[arr[offset + 1]] + byteToHex[arr[offset + 2]] + byteToHex[arr[offset + 3]] + '-' + byteToHex[arr[offset + 4]] + byteToHex[arr[offset + 5]] + '-' + byteToHex[arr[offset + 6]] + byteToHex[arr[offset + 7]] + '-' + byteToHex[arr[offset + 8]] + byteToHex[arr[offset + 9]] + '-' + byteToHex[arr[offset + 10]] + byteToHex[arr[offset + 11]] + byteToHex[arr[offset + 12]] + byteToHex[arr[offset + 13]] + byteToHex[arr[offset + 14]] + byteToHex[arr[offset + 15]];\n}\n\nfunction stringify(arr, offset = 0) {\n  const uuid = unsafeStringify(arr, offset); // Consistency check for valid UUID.  If this throws, it's likely due to one\n  // of the following:\n  // - One or more input array values don't map to a hex octet (leading to\n  // \"undefined\" in the uuid)\n  // - Invalid input values for the RFC `version` or `variant` fields\n\n  if (!(0,_validate_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(uuid)) {\n    throw TypeError('Stringified UUID is invalid');\n  }\n\n  return uuid;\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (stringify);\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/uuid/dist/esm-browser/stringify.js?\n}");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/v4.js":
/*!**************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/v4.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _native_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./native.js */ \"./node_modules/uuid/dist/esm-browser/native.js\");\n/* harmony import */ var _rng_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./rng.js */ \"./node_modules/uuid/dist/esm-browser/rng.js\");\n/* harmony import */ var _stringify_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./stringify.js */ \"./node_modules/uuid/dist/esm-browser/stringify.js\");\n\n\n\n\nfunction v4(options, buf, offset) {\n  if (_native_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].randomUUID && !buf && !options) {\n    return _native_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].randomUUID();\n  }\n\n  options = options || {};\n  const rnds = options.random || (options.rng || _rng_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(); // Per 4.4, set bits for version and `clock_seq_hi_and_reserved`\n\n  rnds[6] = rnds[6] & 0x0f | 0x40;\n  rnds[8] = rnds[8] & 0x3f | 0x80; // Copy bytes to buffer, if provided\n\n  if (buf) {\n    offset = offset || 0;\n\n    for (let i = 0; i < 16; ++i) {\n      buf[offset + i] = rnds[i];\n    }\n\n    return buf;\n  }\n\n  return (0,_stringify_js__WEBPACK_IMPORTED_MODULE_2__.unsafeStringify)(rnds);\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (v4);\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/uuid/dist/esm-browser/v4.js?\n}");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/validate.js":
/*!********************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/validate.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _regex_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./regex.js */ \"./node_modules/uuid/dist/esm-browser/regex.js\");\n\n\nfunction validate(uuid) {\n  return typeof uuid === 'string' && _regex_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].test(uuid);\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (validate);\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/uuid/dist/esm-browser/validate.js?\n}");

/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/adapter_core.js":
/*!************************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/adapter_core.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _adapter_factory_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./adapter_factory.js */ \"./node_modules/webrtc-adapter/src/js/adapter_factory.js\");\n/*\n *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.\n *\n *  Use of this source code is governed by a BSD-style license\n *  that can be found in the LICENSE file in the root of the source\n *  tree.\n */\n/* eslint-env node */\n\n\n\n\n\nconst adapter =\n  (0,_adapter_factory_js__WEBPACK_IMPORTED_MODULE_0__.adapterFactory)({window: typeof window === 'undefined' ? undefined : window});\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (adapter);\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/webrtc-adapter/src/js/adapter_core.js?\n}");

/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/adapter_factory.js":
/*!***************************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/adapter_factory.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   adapterFactory: () => (/* binding */ adapterFactory)\n/* harmony export */ });\n/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./utils */ \"./node_modules/webrtc-adapter/src/js/utils.js\");\n/* harmony import */ var _chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./chrome/chrome_shim */ \"./node_modules/webrtc-adapter/src/js/chrome/chrome_shim.js\");\n/* harmony import */ var _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./firefox/firefox_shim */ \"./node_modules/webrtc-adapter/src/js/firefox/firefox_shim.js\");\n/* harmony import */ var _safari_safari_shim__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./safari/safari_shim */ \"./node_modules/webrtc-adapter/src/js/safari/safari_shim.js\");\n/* harmony import */ var _common_shim__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./common_shim */ \"./node_modules/webrtc-adapter/src/js/common_shim.js\");\n/* harmony import */ var sdp__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! sdp */ \"./node_modules/sdp/sdp.js\");\n/* harmony import */ var sdp__WEBPACK_IMPORTED_MODULE_5___default = /*#__PURE__*/__webpack_require__.n(sdp__WEBPACK_IMPORTED_MODULE_5__);\n/*\n *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.\n *\n *  Use of this source code is governed by a BSD-style license\n *  that can be found in the LICENSE file in the root of the source\n *  tree.\n */\n\n\n// Browser shims.\n\n\n\n\n\n\n// Shimming starts here.\nfunction adapterFactory({window} = {}, options = {\n  shimChrome: true,\n  shimFirefox: true,\n  shimSafari: true,\n}) {\n  // Utils.\n  const logging = _utils__WEBPACK_IMPORTED_MODULE_0__.log;\n  const browserDetails = _utils__WEBPACK_IMPORTED_MODULE_0__.detectBrowser(window);\n\n  const adapter = {\n    browserDetails,\n    commonShim: _common_shim__WEBPACK_IMPORTED_MODULE_4__,\n    extractVersion: _utils__WEBPACK_IMPORTED_MODULE_0__.extractVersion,\n    disableLog: _utils__WEBPACK_IMPORTED_MODULE_0__.disableLog,\n    disableWarnings: _utils__WEBPACK_IMPORTED_MODULE_0__.disableWarnings,\n    // Expose sdp as a convenience. For production apps include directly.\n    sdp: sdp__WEBPACK_IMPORTED_MODULE_5__,\n  };\n\n  // Shim browser if found.\n  switch (browserDetails.browser) {\n    case 'chrome':\n      if (!_chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__ || !_chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__.shimPeerConnection ||\n          !options.shimChrome) {\n        logging('Chrome shim is not included in this adapter release.');\n        return adapter;\n      }\n      if (browserDetails.version === null) {\n        logging('Chrome shim can not determine version, not shimming.');\n        return adapter;\n      }\n      logging('adapter.js shimming chrome.');\n      // Export to the adapter global object visible in the browser.\n      adapter.browserShim = _chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__;\n\n      // Must be called before shimPeerConnection.\n      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimAddIceCandidateNullOrEmpty(window, browserDetails);\n      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimParameterlessSetLocalDescription(window, browserDetails);\n\n      _chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__.shimGetUserMedia(window, browserDetails);\n      _chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__.shimMediaStream(window, browserDetails);\n      _chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__.shimPeerConnection(window, browserDetails);\n      _chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__.shimOnTrack(window, browserDetails);\n      _chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__.shimAddTrackRemoveTrack(window, browserDetails);\n      _chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__.shimGetSendersWithDtmf(window, browserDetails);\n      _chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__.shimSenderReceiverGetStats(window, browserDetails);\n      _chrome_chrome_shim__WEBPACK_IMPORTED_MODULE_1__.fixNegotiationNeeded(window, browserDetails);\n\n      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimRTCIceCandidate(window, browserDetails);\n      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimRTCIceCandidateRelayProtocol(window, browserDetails);\n      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimConnectionState(window, browserDetails);\n      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimMaxMessageSize(window, browserDetails);\n      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimSendThrowTypeError(window, browserDetails);\n      _common_shim__WEBPACK_IMPORTED_MODULE_4__.removeExtmapAllowMixed(window, browserDetails);\n      break;\n    case 'firefox':\n      if (!_firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_2__ || !_firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_2__.shimPeerConnection ||\n          !options.shimFirefox) {\n        logging('Firefox shim is not included in this adapter release.');\n        return adapter;\n      }\n      logging('adapter.js shimming firefox.');\n      // Export to the adapter global object visible in the browser.\n      adapter.browserShim = _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_2__;\n\n      // Must be called before shimPeerConnection.\n      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimAddIceCandidateNullOrEmpty(window, browserDetails);\n      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimParameterlessSetLocalDescription(window, browserDetails);\n\n      _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_2__.shimGetUserMedia(window, browserDetails);\n      _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_2__.shimPeerConnection(window, browserDetails);\n      _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_2__.shimOnTrack(window, browserDetails);\n      _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_2__.shimRemoveStream(window, browserDetails);\n      _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_2__.shimSenderGetStats(window, browserDetails);\n      _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_2__.shimReceiverGetStats(window, browserDetails);\n      _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_2__.shimRTCDataChannel(window, browserDetails);\n      _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_2__.shimAddTransceiver(window, browserDetails);\n      _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_2__.shimGetParameters(window, browserDetails);\n      _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_2__.shimCreateOffer(window, browserDetails);\n      _firefox_firefox_shim__WEBPACK_IMPORTED_MODULE_2__.shimCreateAnswer(window, browserDetails);\n\n      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimRTCIceCandidate(window, browserDetails);\n      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimConnectionState(window, browserDetails);\n      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimMaxMessageSize(window, browserDetails);\n      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimSendThrowTypeError(window, browserDetails);\n      break;\n    case 'safari':\n      if (!_safari_safari_shim__WEBPACK_IMPORTED_MODULE_3__ || !options.shimSafari) {\n        logging('Safari shim is not included in this adapter release.');\n        return adapter;\n      }\n      logging('adapter.js shimming safari.');\n      // Export to the adapter global object visible in the browser.\n      adapter.browserShim = _safari_safari_shim__WEBPACK_IMPORTED_MODULE_3__;\n\n      // Must be called before shimCallbackAPI.\n      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimAddIceCandidateNullOrEmpty(window, browserDetails);\n      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimParameterlessSetLocalDescription(window, browserDetails);\n\n      _safari_safari_shim__WEBPACK_IMPORTED_MODULE_3__.shimRTCIceServerUrls(window, browserDetails);\n      _safari_safari_shim__WEBPACK_IMPORTED_MODULE_3__.shimCreateOfferLegacy(window, browserDetails);\n      _safari_safari_shim__WEBPACK_IMPORTED_MODULE_3__.shimCallbacksAPI(window, browserDetails);\n      _safari_safari_shim__WEBPACK_IMPORTED_MODULE_3__.shimLocalStreamsAPI(window, browserDetails);\n      _safari_safari_shim__WEBPACK_IMPORTED_MODULE_3__.shimRemoteStreamsAPI(window, browserDetails);\n      _safari_safari_shim__WEBPACK_IMPORTED_MODULE_3__.shimTrackEventTransceiver(window, browserDetails);\n      _safari_safari_shim__WEBPACK_IMPORTED_MODULE_3__.shimGetUserMedia(window, browserDetails);\n      _safari_safari_shim__WEBPACK_IMPORTED_MODULE_3__.shimAudioContext(window, browserDetails);\n\n      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimRTCIceCandidate(window, browserDetails);\n      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimRTCIceCandidateRelayProtocol(window, browserDetails);\n      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimMaxMessageSize(window, browserDetails);\n      _common_shim__WEBPACK_IMPORTED_MODULE_4__.shimSendThrowTypeError(window, browserDetails);\n      _common_shim__WEBPACK_IMPORTED_MODULE_4__.removeExtmapAllowMixed(window, browserDetails);\n      break;\n    default:\n      logging('Unsupported browser!');\n      break;\n  }\n\n  return adapter;\n}\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/webrtc-adapter/src/js/adapter_factory.js?\n}");

/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/chrome/chrome_shim.js":
/*!******************************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/chrome/chrome_shim.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   fixNegotiationNeeded: () => (/* binding */ fixNegotiationNeeded),\n/* harmony export */   shimAddTrackRemoveTrack: () => (/* binding */ shimAddTrackRemoveTrack),\n/* harmony export */   shimAddTrackRemoveTrackWithNative: () => (/* binding */ shimAddTrackRemoveTrackWithNative),\n/* harmony export */   shimGetSendersWithDtmf: () => (/* binding */ shimGetSendersWithDtmf),\n/* harmony export */   shimGetUserMedia: () => (/* reexport safe */ _getusermedia__WEBPACK_IMPORTED_MODULE_1__.shimGetUserMedia),\n/* harmony export */   shimMediaStream: () => (/* binding */ shimMediaStream),\n/* harmony export */   shimOnTrack: () => (/* binding */ shimOnTrack),\n/* harmony export */   shimPeerConnection: () => (/* binding */ shimPeerConnection),\n/* harmony export */   shimSenderReceiverGetStats: () => (/* binding */ shimSenderReceiverGetStats)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils.js */ \"./node_modules/webrtc-adapter/src/js/utils.js\");\n/* harmony import */ var _getusermedia__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./getusermedia */ \"./node_modules/webrtc-adapter/src/js/chrome/getusermedia.js\");\n/*\n *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.\n *\n *  Use of this source code is governed by a BSD-style license\n *  that can be found in the LICENSE file in the root of the source\n *  tree.\n */\n/* eslint-env node */\n\n\n\n\n\nfunction shimMediaStream(window) {\n  window.MediaStream = window.MediaStream || window.webkitMediaStream;\n}\n\nfunction shimOnTrack(window) {\n  if (typeof window === 'object' && window.RTCPeerConnection && !('ontrack' in\n      window.RTCPeerConnection.prototype)) {\n    Object.defineProperty(window.RTCPeerConnection.prototype, 'ontrack', {\n      get() {\n        return this._ontrack;\n      },\n      set(f) {\n        if (this._ontrack) {\n          this.removeEventListener('track', this._ontrack);\n        }\n        this.addEventListener('track', this._ontrack = f);\n      },\n      enumerable: true,\n      configurable: true\n    });\n    const origSetRemoteDescription =\n        window.RTCPeerConnection.prototype.setRemoteDescription;\n    window.RTCPeerConnection.prototype.setRemoteDescription =\n      function setRemoteDescription() {\n        if (!this._ontrackpoly) {\n          this._ontrackpoly = (e) => {\n            // onaddstream does not fire when a track is added to an existing\n            // stream. But stream.onaddtrack is implemented so we use that.\n            e.stream.addEventListener('addtrack', te => {\n              let receiver;\n              if (window.RTCPeerConnection.prototype.getReceivers) {\n                receiver = this.getReceivers()\n                  .find(r => r.track && r.track.id === te.track.id);\n              } else {\n                receiver = {track: te.track};\n              }\n\n              const event = new Event('track');\n              event.track = te.track;\n              event.receiver = receiver;\n              event.transceiver = {receiver};\n              event.streams = [e.stream];\n              this.dispatchEvent(event);\n            });\n            e.stream.getTracks().forEach(track => {\n              let receiver;\n              if (window.RTCPeerConnection.prototype.getReceivers) {\n                receiver = this.getReceivers()\n                  .find(r => r.track && r.track.id === track.id);\n              } else {\n                receiver = {track};\n              }\n              const event = new Event('track');\n              event.track = track;\n              event.receiver = receiver;\n              event.transceiver = {receiver};\n              event.streams = [e.stream];\n              this.dispatchEvent(event);\n            });\n          };\n          this.addEventListener('addstream', this._ontrackpoly);\n        }\n        return origSetRemoteDescription.apply(this, arguments);\n      };\n  } else {\n    // even if RTCRtpTransceiver is in window, it is only used and\n    // emitted in unified-plan. Unfortunately this means we need\n    // to unconditionally wrap the event.\n    _utils_js__WEBPACK_IMPORTED_MODULE_0__.wrapPeerConnectionEvent(window, 'track', e => {\n      if (!e.transceiver) {\n        Object.defineProperty(e, 'transceiver',\n          {value: {receiver: e.receiver}});\n      }\n      return e;\n    });\n  }\n}\n\nfunction shimGetSendersWithDtmf(window) {\n  // Overrides addTrack/removeTrack, depends on shimAddTrackRemoveTrack.\n  if (typeof window === 'object' && window.RTCPeerConnection &&\n      !('getSenders' in window.RTCPeerConnection.prototype) &&\n      'createDTMFSender' in window.RTCPeerConnection.prototype) {\n    const shimSenderWithDtmf = function(pc, track) {\n      return {\n        track,\n        get dtmf() {\n          if (this._dtmf === undefined) {\n            if (track.kind === 'audio') {\n              this._dtmf = pc.createDTMFSender(track);\n            } else {\n              this._dtmf = null;\n            }\n          }\n          return this._dtmf;\n        },\n        _pc: pc\n      };\n    };\n\n    // augment addTrack when getSenders is not available.\n    if (!window.RTCPeerConnection.prototype.getSenders) {\n      window.RTCPeerConnection.prototype.getSenders = function getSenders() {\n        this._senders = this._senders || [];\n        return this._senders.slice(); // return a copy of the internal state.\n      };\n      const origAddTrack = window.RTCPeerConnection.prototype.addTrack;\n      window.RTCPeerConnection.prototype.addTrack =\n        function addTrack(track, stream) {\n          let sender = origAddTrack.apply(this, arguments);\n          if (!sender) {\n            sender = shimSenderWithDtmf(this, track);\n            this._senders.push(sender);\n          }\n          return sender;\n        };\n\n      const origRemoveTrack = window.RTCPeerConnection.prototype.removeTrack;\n      window.RTCPeerConnection.prototype.removeTrack =\n        function removeTrack(sender) {\n          origRemoveTrack.apply(this, arguments);\n          const idx = this._senders.indexOf(sender);\n          if (idx !== -1) {\n            this._senders.splice(idx, 1);\n          }\n        };\n    }\n    const origAddStream = window.RTCPeerConnection.prototype.addStream;\n    window.RTCPeerConnection.prototype.addStream = function addStream(stream) {\n      this._senders = this._senders || [];\n      origAddStream.apply(this, [stream]);\n      stream.getTracks().forEach(track => {\n        this._senders.push(shimSenderWithDtmf(this, track));\n      });\n    };\n\n    const origRemoveStream = window.RTCPeerConnection.prototype.removeStream;\n    window.RTCPeerConnection.prototype.removeStream =\n      function removeStream(stream) {\n        this._senders = this._senders || [];\n        origRemoveStream.apply(this, [stream]);\n\n        stream.getTracks().forEach(track => {\n          const sender = this._senders.find(s => s.track === track);\n          if (sender) { // remove sender\n            this._senders.splice(this._senders.indexOf(sender), 1);\n          }\n        });\n      };\n  } else if (typeof window === 'object' && window.RTCPeerConnection &&\n             'getSenders' in window.RTCPeerConnection.prototype &&\n             'createDTMFSender' in window.RTCPeerConnection.prototype &&\n             window.RTCRtpSender &&\n             !('dtmf' in window.RTCRtpSender.prototype)) {\n    const origGetSenders = window.RTCPeerConnection.prototype.getSenders;\n    window.RTCPeerConnection.prototype.getSenders = function getSenders() {\n      const senders = origGetSenders.apply(this, []);\n      senders.forEach(sender => sender._pc = this);\n      return senders;\n    };\n\n    Object.defineProperty(window.RTCRtpSender.prototype, 'dtmf', {\n      get() {\n        if (this._dtmf === undefined) {\n          if (this.track.kind === 'audio') {\n            this._dtmf = this._pc.createDTMFSender(this.track);\n          } else {\n            this._dtmf = null;\n          }\n        }\n        return this._dtmf;\n      }\n    });\n  }\n}\n\nfunction shimSenderReceiverGetStats(window) {\n  if (!(typeof window === 'object' && window.RTCPeerConnection &&\n      window.RTCRtpSender && window.RTCRtpReceiver)) {\n    return;\n  }\n\n  // shim sender stats.\n  if (!('getStats' in window.RTCRtpSender.prototype)) {\n    const origGetSenders = window.RTCPeerConnection.prototype.getSenders;\n    if (origGetSenders) {\n      window.RTCPeerConnection.prototype.getSenders = function getSenders() {\n        const senders = origGetSenders.apply(this, []);\n        senders.forEach(sender => sender._pc = this);\n        return senders;\n      };\n    }\n\n    const origAddTrack = window.RTCPeerConnection.prototype.addTrack;\n    if (origAddTrack) {\n      window.RTCPeerConnection.prototype.addTrack = function addTrack() {\n        const sender = origAddTrack.apply(this, arguments);\n        sender._pc = this;\n        return sender;\n      };\n    }\n    window.RTCRtpSender.prototype.getStats = function getStats() {\n      const sender = this;\n      return this._pc.getStats().then(result =>\n        /* Note: this will include stats of all senders that\n         *   send a track with the same id as sender.track as\n         *   it is not possible to identify the RTCRtpSender.\n         */\n        _utils_js__WEBPACK_IMPORTED_MODULE_0__.filterStats(result, sender.track, true));\n    };\n  }\n\n  // shim receiver stats.\n  if (!('getStats' in window.RTCRtpReceiver.prototype)) {\n    const origGetReceivers = window.RTCPeerConnection.prototype.getReceivers;\n    if (origGetReceivers) {\n      window.RTCPeerConnection.prototype.getReceivers =\n        function getReceivers() {\n          const receivers = origGetReceivers.apply(this, []);\n          receivers.forEach(receiver => receiver._pc = this);\n          return receivers;\n        };\n    }\n    _utils_js__WEBPACK_IMPORTED_MODULE_0__.wrapPeerConnectionEvent(window, 'track', e => {\n      e.receiver._pc = e.srcElement;\n      return e;\n    });\n    window.RTCRtpReceiver.prototype.getStats = function getStats() {\n      const receiver = this;\n      return this._pc.getStats().then(result =>\n        _utils_js__WEBPACK_IMPORTED_MODULE_0__.filterStats(result, receiver.track, false));\n    };\n  }\n\n  if (!('getStats' in window.RTCRtpSender.prototype &&\n      'getStats' in window.RTCRtpReceiver.prototype)) {\n    return;\n  }\n\n  // shim RTCPeerConnection.getStats(track).\n  const origGetStats = window.RTCPeerConnection.prototype.getStats;\n  window.RTCPeerConnection.prototype.getStats = function getStats() {\n    if (arguments.length > 0 &&\n        arguments[0] instanceof window.MediaStreamTrack) {\n      const track = arguments[0];\n      let sender;\n      let receiver;\n      let err;\n      this.getSenders().forEach(s => {\n        if (s.track === track) {\n          if (sender) {\n            err = true;\n          } else {\n            sender = s;\n          }\n        }\n      });\n      this.getReceivers().forEach(r => {\n        if (r.track === track) {\n          if (receiver) {\n            err = true;\n          } else {\n            receiver = r;\n          }\n        }\n        return r.track === track;\n      });\n      if (err || (sender && receiver)) {\n        return Promise.reject(new DOMException(\n          'There are more than one sender or receiver for the track.',\n          'InvalidAccessError'));\n      } else if (sender) {\n        return sender.getStats();\n      } else if (receiver) {\n        return receiver.getStats();\n      }\n      return Promise.reject(new DOMException(\n        'There is no sender or receiver for the track.',\n        'InvalidAccessError'));\n    }\n    return origGetStats.apply(this, arguments);\n  };\n}\n\nfunction shimAddTrackRemoveTrackWithNative(window) {\n  // shim addTrack/removeTrack with native variants in order to make\n  // the interactions with legacy getLocalStreams behave as in other browsers.\n  // Keeps a mapping stream.id => [stream, rtpsenders...]\n  window.RTCPeerConnection.prototype.getLocalStreams =\n    function getLocalStreams() {\n      this._shimmedLocalStreams = this._shimmedLocalStreams || {};\n      return Object.keys(this._shimmedLocalStreams)\n        .map(streamId => this._shimmedLocalStreams[streamId][0]);\n    };\n\n  const origAddTrack = window.RTCPeerConnection.prototype.addTrack;\n  window.RTCPeerConnection.prototype.addTrack =\n    function addTrack(track, stream) {\n      if (!stream) {\n        return origAddTrack.apply(this, arguments);\n      }\n      this._shimmedLocalStreams = this._shimmedLocalStreams || {};\n\n      const sender = origAddTrack.apply(this, arguments);\n      if (!this._shimmedLocalStreams[stream.id]) {\n        this._shimmedLocalStreams[stream.id] = [stream, sender];\n      } else if (this._shimmedLocalStreams[stream.id].indexOf(sender) === -1) {\n        this._shimmedLocalStreams[stream.id].push(sender);\n      }\n      return sender;\n    };\n\n  const origAddStream = window.RTCPeerConnection.prototype.addStream;\n  window.RTCPeerConnection.prototype.addStream = function addStream(stream) {\n    this._shimmedLocalStreams = this._shimmedLocalStreams || {};\n\n    stream.getTracks().forEach(track => {\n      const alreadyExists = this.getSenders().find(s => s.track === track);\n      if (alreadyExists) {\n        throw new DOMException('Track already exists.',\n          'InvalidAccessError');\n      }\n    });\n    const existingSenders = this.getSenders();\n    origAddStream.apply(this, arguments);\n    const newSenders = this.getSenders()\n      .filter(newSender => existingSenders.indexOf(newSender) === -1);\n    this._shimmedLocalStreams[stream.id] = [stream].concat(newSenders);\n  };\n\n  const origRemoveStream = window.RTCPeerConnection.prototype.removeStream;\n  window.RTCPeerConnection.prototype.removeStream =\n    function removeStream(stream) {\n      this._shimmedLocalStreams = this._shimmedLocalStreams || {};\n      delete this._shimmedLocalStreams[stream.id];\n      return origRemoveStream.apply(this, arguments);\n    };\n\n  const origRemoveTrack = window.RTCPeerConnection.prototype.removeTrack;\n  window.RTCPeerConnection.prototype.removeTrack =\n    function removeTrack(sender) {\n      this._shimmedLocalStreams = this._shimmedLocalStreams || {};\n      if (sender) {\n        Object.keys(this._shimmedLocalStreams).forEach(streamId => {\n          const idx = this._shimmedLocalStreams[streamId].indexOf(sender);\n          if (idx !== -1) {\n            this._shimmedLocalStreams[streamId].splice(idx, 1);\n          }\n          if (this._shimmedLocalStreams[streamId].length === 1) {\n            delete this._shimmedLocalStreams[streamId];\n          }\n        });\n      }\n      return origRemoveTrack.apply(this, arguments);\n    };\n}\n\nfunction shimAddTrackRemoveTrack(window, browserDetails) {\n  if (!window.RTCPeerConnection) {\n    return;\n  }\n  // shim addTrack and removeTrack.\n  if (window.RTCPeerConnection.prototype.addTrack &&\n      browserDetails.version >= 65) {\n    return shimAddTrackRemoveTrackWithNative(window);\n  }\n\n  // also shim pc.getLocalStreams when addTrack is shimmed\n  // to return the original streams.\n  const origGetLocalStreams = window.RTCPeerConnection.prototype\n    .getLocalStreams;\n  window.RTCPeerConnection.prototype.getLocalStreams =\n    function getLocalStreams() {\n      const nativeStreams = origGetLocalStreams.apply(this);\n      this._reverseStreams = this._reverseStreams || {};\n      return nativeStreams.map(stream => this._reverseStreams[stream.id]);\n    };\n\n  const origAddStream = window.RTCPeerConnection.prototype.addStream;\n  window.RTCPeerConnection.prototype.addStream = function addStream(stream) {\n    this._streams = this._streams || {};\n    this._reverseStreams = this._reverseStreams || {};\n\n    stream.getTracks().forEach(track => {\n      const alreadyExists = this.getSenders().find(s => s.track === track);\n      if (alreadyExists) {\n        throw new DOMException('Track already exists.',\n          'InvalidAccessError');\n      }\n    });\n    // Add identity mapping for consistency with addTrack.\n    // Unless this is being used with a stream from addTrack.\n    if (!this._reverseStreams[stream.id]) {\n      const newStream = new window.MediaStream(stream.getTracks());\n      this._streams[stream.id] = newStream;\n      this._reverseStreams[newStream.id] = stream;\n      stream = newStream;\n    }\n    origAddStream.apply(this, [stream]);\n  };\n\n  const origRemoveStream = window.RTCPeerConnection.prototype.removeStream;\n  window.RTCPeerConnection.prototype.removeStream =\n    function removeStream(stream) {\n      this._streams = this._streams || {};\n      this._reverseStreams = this._reverseStreams || {};\n\n      origRemoveStream.apply(this, [(this._streams[stream.id] || stream)]);\n      delete this._reverseStreams[(this._streams[stream.id] ?\n        this._streams[stream.id].id : stream.id)];\n      delete this._streams[stream.id];\n    };\n\n  window.RTCPeerConnection.prototype.addTrack =\n    function addTrack(track, stream) {\n      if (this.signalingState === 'closed') {\n        throw new DOMException(\n          'The RTCPeerConnection\\'s signalingState is \\'closed\\'.',\n          'InvalidStateError');\n      }\n      const streams = [].slice.call(arguments, 1);\n      if (streams.length !== 1 ||\n          !streams[0].getTracks().find(t => t === track)) {\n        // this is not fully correct but all we can manage without\n        // [[associated MediaStreams]] internal slot.\n        throw new DOMException(\n          'The adapter.js addTrack polyfill only supports a single ' +\n          ' stream which is associated with the specified track.',\n          'NotSupportedError');\n      }\n\n      const alreadyExists = this.getSenders().find(s => s.track === track);\n      if (alreadyExists) {\n        throw new DOMException('Track already exists.',\n          'InvalidAccessError');\n      }\n\n      this._streams = this._streams || {};\n      this._reverseStreams = this._reverseStreams || {};\n      const oldStream = this._streams[stream.id];\n      if (oldStream) {\n        // this is using odd Chrome behaviour, use with caution:\n        // https://bugs.chromium.org/p/webrtc/issues/detail?id=7815\n        // Note: we rely on the high-level addTrack/dtmf shim to\n        // create the sender with a dtmf sender.\n        oldStream.addTrack(track);\n\n        // Trigger ONN async.\n        Promise.resolve().then(() => {\n          this.dispatchEvent(new Event('negotiationneeded'));\n        });\n      } else {\n        const newStream = new window.MediaStream([track]);\n        this._streams[stream.id] = newStream;\n        this._reverseStreams[newStream.id] = stream;\n        this.addStream(newStream);\n      }\n      return this.getSenders().find(s => s.track === track);\n    };\n\n  // replace the internal stream id with the external one and\n  // vice versa.\n  function replaceInternalStreamId(pc, description) {\n    let sdp = description.sdp;\n    Object.keys(pc._reverseStreams || []).forEach(internalId => {\n      const externalStream = pc._reverseStreams[internalId];\n      const internalStream = pc._streams[externalStream.id];\n      sdp = sdp.replace(new RegExp(internalStream.id, 'g'),\n        externalStream.id);\n    });\n    return new RTCSessionDescription({\n      type: description.type,\n      sdp\n    });\n  }\n  function replaceExternalStreamId(pc, description) {\n    let sdp = description.sdp;\n    Object.keys(pc._reverseStreams || []).forEach(internalId => {\n      const externalStream = pc._reverseStreams[internalId];\n      const internalStream = pc._streams[externalStream.id];\n      sdp = sdp.replace(new RegExp(externalStream.id, 'g'),\n        internalStream.id);\n    });\n    return new RTCSessionDescription({\n      type: description.type,\n      sdp\n    });\n  }\n  ['createOffer', 'createAnswer'].forEach(function(method) {\n    const nativeMethod = window.RTCPeerConnection.prototype[method];\n    const methodObj = {[method]() {\n      const args = arguments;\n      const isLegacyCall = arguments.length &&\n          typeof arguments[0] === 'function';\n      if (isLegacyCall) {\n        return nativeMethod.apply(this, [\n          (description) => {\n            const desc = replaceInternalStreamId(this, description);\n            args[0].apply(null, [desc]);\n          },\n          (err) => {\n            if (args[1]) {\n              args[1].apply(null, err);\n            }\n          }, arguments[2]\n        ]);\n      }\n      return nativeMethod.apply(this, arguments)\n        .then(description => replaceInternalStreamId(this, description));\n    }};\n    window.RTCPeerConnection.prototype[method] = methodObj[method];\n  });\n\n  const origSetLocalDescription =\n      window.RTCPeerConnection.prototype.setLocalDescription;\n  window.RTCPeerConnection.prototype.setLocalDescription =\n    function setLocalDescription() {\n      if (!arguments.length || !arguments[0].type) {\n        return origSetLocalDescription.apply(this, arguments);\n      }\n      arguments[0] = replaceExternalStreamId(this, arguments[0]);\n      return origSetLocalDescription.apply(this, arguments);\n    };\n\n  // TODO: mangle getStats: https://w3c.github.io/webrtc-stats/#dom-rtcmediastreamstats-streamidentifier\n\n  const origLocalDescription = Object.getOwnPropertyDescriptor(\n    window.RTCPeerConnection.prototype, 'localDescription');\n  Object.defineProperty(window.RTCPeerConnection.prototype,\n    'localDescription', {\n      get() {\n        const description = origLocalDescription.get.apply(this);\n        if (description.type === '') {\n          return description;\n        }\n        return replaceInternalStreamId(this, description);\n      }\n    });\n\n  window.RTCPeerConnection.prototype.removeTrack =\n    function removeTrack(sender) {\n      if (this.signalingState === 'closed') {\n        throw new DOMException(\n          'The RTCPeerConnection\\'s signalingState is \\'closed\\'.',\n          'InvalidStateError');\n      }\n      // We can not yet check for sender instanceof RTCRtpSender\n      // since we shim RTPSender. So we check if sender._pc is set.\n      if (!sender._pc) {\n        throw new DOMException('Argument 1 of RTCPeerConnection.removeTrack ' +\n            'does not implement interface RTCRtpSender.', 'TypeError');\n      }\n      const isLocal = sender._pc === this;\n      if (!isLocal) {\n        throw new DOMException('Sender was not created by this connection.',\n          'InvalidAccessError');\n      }\n\n      // Search for the native stream the senders track belongs to.\n      this._streams = this._streams || {};\n      let stream;\n      Object.keys(this._streams).forEach(streamid => {\n        const hasTrack = this._streams[streamid].getTracks()\n          .find(track => sender.track === track);\n        if (hasTrack) {\n          stream = this._streams[streamid];\n        }\n      });\n\n      if (stream) {\n        if (stream.getTracks().length === 1) {\n          // if this is the last track of the stream, remove the stream. This\n          // takes care of any shimmed _senders.\n          this.removeStream(this._reverseStreams[stream.id]);\n        } else {\n          // relying on the same odd chrome behaviour as above.\n          stream.removeTrack(sender.track);\n        }\n        this.dispatchEvent(new Event('negotiationneeded'));\n      }\n    };\n}\n\nfunction shimPeerConnection(window, browserDetails) {\n  if (!window.RTCPeerConnection && window.webkitRTCPeerConnection) {\n    // very basic support for old versions.\n    window.RTCPeerConnection = window.webkitRTCPeerConnection;\n  }\n  if (!window.RTCPeerConnection) {\n    return;\n  }\n\n  // shim implicit creation of RTCSessionDescription/RTCIceCandidate\n  if (browserDetails.version < 53) {\n    ['setLocalDescription', 'setRemoteDescription', 'addIceCandidate']\n      .forEach(function(method) {\n        const nativeMethod = window.RTCPeerConnection.prototype[method];\n        const methodObj = {[method]() {\n          arguments[0] = new ((method === 'addIceCandidate') ?\n            window.RTCIceCandidate :\n            window.RTCSessionDescription)(arguments[0]);\n          return nativeMethod.apply(this, arguments);\n        }};\n        window.RTCPeerConnection.prototype[method] = methodObj[method];\n      });\n  }\n}\n\n// Attempt to fix ONN in plan-b mode.\nfunction fixNegotiationNeeded(window, browserDetails) {\n  _utils_js__WEBPACK_IMPORTED_MODULE_0__.wrapPeerConnectionEvent(window, 'negotiationneeded', e => {\n    const pc = e.target;\n    if (browserDetails.version < 72 || (pc.getConfiguration &&\n        pc.getConfiguration().sdpSemantics === 'plan-b')) {\n      if (pc.signalingState !== 'stable') {\n        return;\n      }\n    }\n    return e;\n  });\n}\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/webrtc-adapter/src/js/chrome/chrome_shim.js?\n}");

/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/chrome/getusermedia.js":
/*!*******************************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/chrome/getusermedia.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   shimGetUserMedia: () => (/* binding */ shimGetUserMedia)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils.js */ \"./node_modules/webrtc-adapter/src/js/utils.js\");\n/*\n *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.\n *\n *  Use of this source code is governed by a BSD-style license\n *  that can be found in the LICENSE file in the root of the source\n *  tree.\n */\n/* eslint-env node */\n\n\nconst logging = _utils_js__WEBPACK_IMPORTED_MODULE_0__.log;\n\nfunction shimGetUserMedia(window, browserDetails) {\n  const navigator = window && window.navigator;\n\n  if (!navigator.mediaDevices) {\n    return;\n  }\n\n  const constraintsToChrome_ = function(c) {\n    if (typeof c !== 'object' || c.mandatory || c.optional) {\n      return c;\n    }\n    const cc = {};\n    Object.keys(c).forEach(key => {\n      if (key === 'require' || key === 'advanced' || key === 'mediaSource') {\n        return;\n      }\n      const r = (typeof c[key] === 'object') ? c[key] : {ideal: c[key]};\n      if (r.exact !== undefined && typeof r.exact === 'number') {\n        r.min = r.max = r.exact;\n      }\n      const oldname_ = function(prefix, name) {\n        if (prefix) {\n          return prefix + name.charAt(0).toUpperCase() + name.slice(1);\n        }\n        return (name === 'deviceId') ? 'sourceId' : name;\n      };\n      if (r.ideal !== undefined) {\n        cc.optional = cc.optional || [];\n        let oc = {};\n        if (typeof r.ideal === 'number') {\n          oc[oldname_('min', key)] = r.ideal;\n          cc.optional.push(oc);\n          oc = {};\n          oc[oldname_('max', key)] = r.ideal;\n          cc.optional.push(oc);\n        } else {\n          oc[oldname_('', key)] = r.ideal;\n          cc.optional.push(oc);\n        }\n      }\n      if (r.exact !== undefined && typeof r.exact !== 'number') {\n        cc.mandatory = cc.mandatory || {};\n        cc.mandatory[oldname_('', key)] = r.exact;\n      } else {\n        ['min', 'max'].forEach(mix => {\n          if (r[mix] !== undefined) {\n            cc.mandatory = cc.mandatory || {};\n            cc.mandatory[oldname_(mix, key)] = r[mix];\n          }\n        });\n      }\n    });\n    if (c.advanced) {\n      cc.optional = (cc.optional || []).concat(c.advanced);\n    }\n    return cc;\n  };\n\n  const shimConstraints_ = function(constraints, func) {\n    if (browserDetails.version >= 61) {\n      return func(constraints);\n    }\n    constraints = JSON.parse(JSON.stringify(constraints));\n    if (constraints && typeof constraints.audio === 'object') {\n      const remap = function(obj, a, b) {\n        if (a in obj && !(b in obj)) {\n          obj[b] = obj[a];\n          delete obj[a];\n        }\n      };\n      constraints = JSON.parse(JSON.stringify(constraints));\n      remap(constraints.audio, 'autoGainControl', 'googAutoGainControl');\n      remap(constraints.audio, 'noiseSuppression', 'googNoiseSuppression');\n      constraints.audio = constraintsToChrome_(constraints.audio);\n    }\n    if (constraints && typeof constraints.video === 'object') {\n      // Shim facingMode for mobile & surface pro.\n      let face = constraints.video.facingMode;\n      face = face && ((typeof face === 'object') ? face : {ideal: face});\n      const getSupportedFacingModeLies = browserDetails.version < 66;\n\n      if ((face && (face.exact === 'user' || face.exact === 'environment' ||\n                    face.ideal === 'user' || face.ideal === 'environment')) &&\n          !(navigator.mediaDevices.getSupportedConstraints &&\n            navigator.mediaDevices.getSupportedConstraints().facingMode &&\n            !getSupportedFacingModeLies)) {\n        delete constraints.video.facingMode;\n        let matches;\n        if (face.exact === 'environment' || face.ideal === 'environment') {\n          matches = ['back', 'rear'];\n        } else if (face.exact === 'user' || face.ideal === 'user') {\n          matches = ['front'];\n        }\n        if (matches) {\n          // Look for matches in label, or use last cam for back (typical).\n          return navigator.mediaDevices.enumerateDevices()\n            .then(devices => {\n              devices = devices.filter(d => d.kind === 'videoinput');\n              let dev = devices.find(d => matches.some(match =>\n                d.label.toLowerCase().includes(match)));\n              if (!dev && devices.length && matches.includes('back')) {\n                dev = devices[devices.length - 1]; // more likely the back cam\n              }\n              if (dev) {\n                constraints.video.deviceId = face.exact\n                  ? {exact: dev.deviceId}\n                  : {ideal: dev.deviceId};\n              }\n              constraints.video = constraintsToChrome_(constraints.video);\n              logging('chrome: ' + JSON.stringify(constraints));\n              return func(constraints);\n            });\n        }\n      }\n      constraints.video = constraintsToChrome_(constraints.video);\n    }\n    logging('chrome: ' + JSON.stringify(constraints));\n    return func(constraints);\n  };\n\n  const shimError_ = function(e) {\n    if (browserDetails.version >= 64) {\n      return e;\n    }\n    return {\n      name: {\n        PermissionDeniedError: 'NotAllowedError',\n        PermissionDismissedError: 'NotAllowedError',\n        InvalidStateError: 'NotAllowedError',\n        DevicesNotFoundError: 'NotFoundError',\n        ConstraintNotSatisfiedError: 'OverconstrainedError',\n        TrackStartError: 'NotReadableError',\n        MediaDeviceFailedDueToShutdown: 'NotAllowedError',\n        MediaDeviceKillSwitchOn: 'NotAllowedError',\n        TabCaptureError: 'AbortError',\n        ScreenCaptureError: 'AbortError',\n        DeviceCaptureError: 'AbortError'\n      }[e.name] || e.name,\n      message: e.message,\n      constraint: e.constraint || e.constraintName,\n      toString() {\n        return this.name + (this.message && ': ') + this.message;\n      }\n    };\n  };\n\n  const getUserMedia_ = function(constraints, onSuccess, onError) {\n    shimConstraints_(constraints, c => {\n      navigator.webkitGetUserMedia(c, onSuccess, e => {\n        if (onError) {\n          onError(shimError_(e));\n        }\n      });\n    });\n  };\n  navigator.getUserMedia = getUserMedia_.bind(navigator);\n\n  // Even though Chrome 45 has navigator.mediaDevices and a getUserMedia\n  // function which returns a Promise, it does not accept spec-style\n  // constraints.\n  if (navigator.mediaDevices.getUserMedia) {\n    const origGetUserMedia = navigator.mediaDevices.getUserMedia.\n      bind(navigator.mediaDevices);\n    navigator.mediaDevices.getUserMedia = function(cs) {\n      return shimConstraints_(cs, c => origGetUserMedia(c).then(stream => {\n        if (c.audio && !stream.getAudioTracks().length ||\n            c.video && !stream.getVideoTracks().length) {\n          stream.getTracks().forEach(track => {\n            track.stop();\n          });\n          throw new DOMException('', 'NotFoundError');\n        }\n        return stream;\n      }, e => Promise.reject(shimError_(e))));\n    };\n  }\n}\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/webrtc-adapter/src/js/chrome/getusermedia.js?\n}");

/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/common_shim.js":
/*!***********************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/common_shim.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   removeExtmapAllowMixed: () => (/* binding */ removeExtmapAllowMixed),\n/* harmony export */   shimAddIceCandidateNullOrEmpty: () => (/* binding */ shimAddIceCandidateNullOrEmpty),\n/* harmony export */   shimConnectionState: () => (/* binding */ shimConnectionState),\n/* harmony export */   shimMaxMessageSize: () => (/* binding */ shimMaxMessageSize),\n/* harmony export */   shimParameterlessSetLocalDescription: () => (/* binding */ shimParameterlessSetLocalDescription),\n/* harmony export */   shimRTCIceCandidate: () => (/* binding */ shimRTCIceCandidate),\n/* harmony export */   shimRTCIceCandidateRelayProtocol: () => (/* binding */ shimRTCIceCandidateRelayProtocol),\n/* harmony export */   shimSendThrowTypeError: () => (/* binding */ shimSendThrowTypeError)\n/* harmony export */ });\n/* harmony import */ var sdp__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! sdp */ \"./node_modules/sdp/sdp.js\");\n/* harmony import */ var sdp__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(sdp__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./utils */ \"./node_modules/webrtc-adapter/src/js/utils.js\");\n/*\n *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.\n *\n *  Use of this source code is governed by a BSD-style license\n *  that can be found in the LICENSE file in the root of the source\n *  tree.\n */\n/* eslint-env node */\n\n\n\n\n\nfunction shimRTCIceCandidate(window) {\n  // foundation is arbitrarily chosen as an indicator for full support for\n  // https://w3c.github.io/webrtc-pc/#rtcicecandidate-interface\n  if (!window.RTCIceCandidate || (window.RTCIceCandidate && 'foundation' in\n      window.RTCIceCandidate.prototype)) {\n    return;\n  }\n\n  const NativeRTCIceCandidate = window.RTCIceCandidate;\n  window.RTCIceCandidate = function RTCIceCandidate(args) {\n    // Remove the a= which shouldn't be part of the candidate string.\n    if (typeof args === 'object' && args.candidate &&\n        args.candidate.indexOf('a=') === 0) {\n      args = JSON.parse(JSON.stringify(args));\n      args.candidate = args.candidate.substring(2);\n    }\n\n    if (args.candidate && args.candidate.length) {\n      // Augment the native candidate with the parsed fields.\n      const nativeCandidate = new NativeRTCIceCandidate(args);\n      const parsedCandidate = sdp__WEBPACK_IMPORTED_MODULE_0___default().parseCandidate(args.candidate);\n      for (const key in parsedCandidate) {\n        if (!(key in nativeCandidate)) {\n          Object.defineProperty(nativeCandidate, key,\n            {value: parsedCandidate[key]});\n        }\n      }\n\n      // Override serializer to not serialize the extra attributes.\n      nativeCandidate.toJSON = function toJSON() {\n        return {\n          candidate: nativeCandidate.candidate,\n          sdpMid: nativeCandidate.sdpMid,\n          sdpMLineIndex: nativeCandidate.sdpMLineIndex,\n          usernameFragment: nativeCandidate.usernameFragment,\n        };\n      };\n      return nativeCandidate;\n    }\n    return new NativeRTCIceCandidate(args);\n  };\n  window.RTCIceCandidate.prototype = NativeRTCIceCandidate.prototype;\n\n  // Hook up the augmented candidate in onicecandidate and\n  // addEventListener('icecandidate', ...)\n  _utils__WEBPACK_IMPORTED_MODULE_1__.wrapPeerConnectionEvent(window, 'icecandidate', e => {\n    if (e.candidate) {\n      Object.defineProperty(e, 'candidate', {\n        value: new window.RTCIceCandidate(e.candidate),\n        writable: 'false'\n      });\n    }\n    return e;\n  });\n}\n\nfunction shimRTCIceCandidateRelayProtocol(window) {\n  if (!window.RTCIceCandidate || (window.RTCIceCandidate && 'relayProtocol' in\n      window.RTCIceCandidate.prototype)) {\n    return;\n  }\n\n  // Hook up the augmented candidate in onicecandidate and\n  // addEventListener('icecandidate', ...)\n  _utils__WEBPACK_IMPORTED_MODULE_1__.wrapPeerConnectionEvent(window, 'icecandidate', e => {\n    if (e.candidate) {\n      const parsedCandidate = sdp__WEBPACK_IMPORTED_MODULE_0___default().parseCandidate(e.candidate.candidate);\n      if (parsedCandidate.type === 'relay') {\n        // This is a libwebrtc-specific mapping of local type preference\n        // to relayProtocol.\n        e.candidate.relayProtocol = {\n          0: 'tls',\n          1: 'tcp',\n          2: 'udp',\n        }[parsedCandidate.priority >> 24];\n      }\n    }\n    return e;\n  });\n}\n\nfunction shimMaxMessageSize(window, browserDetails) {\n  if (!window.RTCPeerConnection) {\n    return;\n  }\n\n  if (!('sctp' in window.RTCPeerConnection.prototype)) {\n    Object.defineProperty(window.RTCPeerConnection.prototype, 'sctp', {\n      get() {\n        return typeof this._sctp === 'undefined' ? null : this._sctp;\n      }\n    });\n  }\n\n  const sctpInDescription = function(description) {\n    if (!description || !description.sdp) {\n      return false;\n    }\n    const sections = sdp__WEBPACK_IMPORTED_MODULE_0___default().splitSections(description.sdp);\n    sections.shift();\n    return sections.some(mediaSection => {\n      const mLine = sdp__WEBPACK_IMPORTED_MODULE_0___default().parseMLine(mediaSection);\n      return mLine && mLine.kind === 'application'\n          && mLine.protocol.indexOf('SCTP') !== -1;\n    });\n  };\n\n  const getRemoteFirefoxVersion = function(description) {\n    // TODO: Is there a better solution for detecting Firefox?\n    const match = description.sdp.match(/mozilla...THIS_IS_SDPARTA-(\\d+)/);\n    if (match === null || match.length < 2) {\n      return -1;\n    }\n    const version = parseInt(match[1], 10);\n    // Test for NaN (yes, this is ugly)\n    return version !== version ? -1 : version;\n  };\n\n  const getCanSendMaxMessageSize = function(remoteIsFirefox) {\n    // Every implementation we know can send at least 64 KiB.\n    // Note: Although Chrome is technically able to send up to 256 KiB, the\n    //       data does not reach the other peer reliably.\n    //       See: https://bugs.chromium.org/p/webrtc/issues/detail?id=8419\n    let canSendMaxMessageSize = 65536;\n    if (browserDetails.browser === 'firefox') {\n      if (browserDetails.version < 57) {\n        if (remoteIsFirefox === -1) {\n          // FF < 57 will send in 16 KiB chunks using the deprecated PPID\n          // fragmentation.\n          canSendMaxMessageSize = 16384;\n        } else {\n          // However, other FF (and RAWRTC) can reassemble PPID-fragmented\n          // messages. Thus, supporting ~2 GiB when sending.\n          canSendMaxMessageSize = 2147483637;\n        }\n      } else if (browserDetails.version < 60) {\n        // Currently, all FF >= 57 will reset the remote maximum message size\n        // to the default value when a data channel is created at a later\n        // stage. :(\n        // See: https://bugzilla.mozilla.org/show_bug.cgi?id=1426831\n        canSendMaxMessageSize =\n          browserDetails.version === 57 ? 65535 : 65536;\n      } else {\n        // FF >= 60 supports sending ~2 GiB\n        canSendMaxMessageSize = 2147483637;\n      }\n    }\n    return canSendMaxMessageSize;\n  };\n\n  const getMaxMessageSize = function(description, remoteIsFirefox) {\n    // Note: 65536 bytes is the default value from the SDP spec. Also,\n    //       every implementation we know supports receiving 65536 bytes.\n    let maxMessageSize = 65536;\n\n    // FF 57 has a slightly incorrect default remote max message size, so\n    // we need to adjust it here to avoid a failure when sending.\n    // See: https://bugzilla.mozilla.org/show_bug.cgi?id=1425697\n    if (browserDetails.browser === 'firefox'\n         && browserDetails.version === 57) {\n      maxMessageSize = 65535;\n    }\n\n    const match = sdp__WEBPACK_IMPORTED_MODULE_0___default().matchPrefix(description.sdp,\n      'a=max-message-size:');\n    if (match.length > 0) {\n      maxMessageSize = parseInt(match[0].substring(19), 10);\n    } else if (browserDetails.browser === 'firefox' &&\n                remoteIsFirefox !== -1) {\n      // If the maximum message size is not present in the remote SDP and\n      // both local and remote are Firefox, the remote peer can receive\n      // ~2 GiB.\n      maxMessageSize = 2147483637;\n    }\n    return maxMessageSize;\n  };\n\n  const origSetRemoteDescription =\n      window.RTCPeerConnection.prototype.setRemoteDescription;\n  window.RTCPeerConnection.prototype.setRemoteDescription =\n    function setRemoteDescription() {\n      this._sctp = null;\n      // Chrome decided to not expose .sctp in plan-b mode.\n      // As usual, adapter.js has to do an 'ugly worakaround'\n      // to cover up the mess.\n      if (browserDetails.browser === 'chrome' && browserDetails.version >= 76) {\n        const {sdpSemantics} = this.getConfiguration();\n        if (sdpSemantics === 'plan-b') {\n          Object.defineProperty(this, 'sctp', {\n            get() {\n              return typeof this._sctp === 'undefined' ? null : this._sctp;\n            },\n            enumerable: true,\n            configurable: true,\n          });\n        }\n      }\n\n      if (sctpInDescription(arguments[0])) {\n        // Check if the remote is FF.\n        const isFirefox = getRemoteFirefoxVersion(arguments[0]);\n\n        // Get the maximum message size the local peer is capable of sending\n        const canSendMMS = getCanSendMaxMessageSize(isFirefox);\n\n        // Get the maximum message size of the remote peer.\n        const remoteMMS = getMaxMessageSize(arguments[0], isFirefox);\n\n        // Determine final maximum message size\n        let maxMessageSize;\n        if (canSendMMS === 0 && remoteMMS === 0) {\n          maxMessageSize = Number.POSITIVE_INFINITY;\n        } else if (canSendMMS === 0 || remoteMMS === 0) {\n          maxMessageSize = Math.max(canSendMMS, remoteMMS);\n        } else {\n          maxMessageSize = Math.min(canSendMMS, remoteMMS);\n        }\n\n        // Create a dummy RTCSctpTransport object and the 'maxMessageSize'\n        // attribute.\n        const sctp = {};\n        Object.defineProperty(sctp, 'maxMessageSize', {\n          get() {\n            return maxMessageSize;\n          }\n        });\n        this._sctp = sctp;\n      }\n\n      return origSetRemoteDescription.apply(this, arguments);\n    };\n}\n\nfunction shimSendThrowTypeError(window) {\n  if (!(window.RTCPeerConnection &&\n      'createDataChannel' in window.RTCPeerConnection.prototype)) {\n    return;\n  }\n\n  // Note: Although Firefox >= 57 has a native implementation, the maximum\n  //       message size can be reset for all data channels at a later stage.\n  //       See: https://bugzilla.mozilla.org/show_bug.cgi?id=1426831\n\n  function wrapDcSend(dc, pc) {\n    const origDataChannelSend = dc.send;\n    dc.send = function send() {\n      const data = arguments[0];\n      const length = data.length || data.size || data.byteLength;\n      if (dc.readyState === 'open' &&\n          pc.sctp && length > pc.sctp.maxMessageSize) {\n        throw new TypeError('Message too large (can send a maximum of ' +\n          pc.sctp.maxMessageSize + ' bytes)');\n      }\n      return origDataChannelSend.apply(dc, arguments);\n    };\n  }\n  const origCreateDataChannel =\n    window.RTCPeerConnection.prototype.createDataChannel;\n  window.RTCPeerConnection.prototype.createDataChannel =\n    function createDataChannel() {\n      const dataChannel = origCreateDataChannel.apply(this, arguments);\n      wrapDcSend(dataChannel, this);\n      return dataChannel;\n    };\n  _utils__WEBPACK_IMPORTED_MODULE_1__.wrapPeerConnectionEvent(window, 'datachannel', e => {\n    wrapDcSend(e.channel, e.target);\n    return e;\n  });\n}\n\n\n/* shims RTCConnectionState by pretending it is the same as iceConnectionState.\n * See https://bugs.chromium.org/p/webrtc/issues/detail?id=6145#c12\n * for why this is a valid hack in Chrome. In Firefox it is slightly incorrect\n * since DTLS failures would be hidden. See\n * https://bugzilla.mozilla.org/show_bug.cgi?id=1265827\n * for the Firefox tracking bug.\n */\nfunction shimConnectionState(window) {\n  if (!window.RTCPeerConnection ||\n      'connectionState' in window.RTCPeerConnection.prototype) {\n    return;\n  }\n  const proto = window.RTCPeerConnection.prototype;\n  Object.defineProperty(proto, 'connectionState', {\n    get() {\n      return {\n        completed: 'connected',\n        checking: 'connecting'\n      }[this.iceConnectionState] || this.iceConnectionState;\n    },\n    enumerable: true,\n    configurable: true\n  });\n  Object.defineProperty(proto, 'onconnectionstatechange', {\n    get() {\n      return this._onconnectionstatechange || null;\n    },\n    set(cb) {\n      if (this._onconnectionstatechange) {\n        this.removeEventListener('connectionstatechange',\n          this._onconnectionstatechange);\n        delete this._onconnectionstatechange;\n      }\n      if (cb) {\n        this.addEventListener('connectionstatechange',\n          this._onconnectionstatechange = cb);\n      }\n    },\n    enumerable: true,\n    configurable: true\n  });\n\n  ['setLocalDescription', 'setRemoteDescription'].forEach((method) => {\n    const origMethod = proto[method];\n    proto[method] = function() {\n      if (!this._connectionstatechangepoly) {\n        this._connectionstatechangepoly = e => {\n          const pc = e.target;\n          if (pc._lastConnectionState !== pc.connectionState) {\n            pc._lastConnectionState = pc.connectionState;\n            const newEvent = new Event('connectionstatechange', e);\n            pc.dispatchEvent(newEvent);\n          }\n          return e;\n        };\n        this.addEventListener('iceconnectionstatechange',\n          this._connectionstatechangepoly);\n      }\n      return origMethod.apply(this, arguments);\n    };\n  });\n}\n\nfunction removeExtmapAllowMixed(window, browserDetails) {\n  /* remove a=extmap-allow-mixed for webrtc.org < M71 */\n  if (!window.RTCPeerConnection) {\n    return;\n  }\n  if (browserDetails.browser === 'chrome' && browserDetails.version >= 71) {\n    return;\n  }\n  if (browserDetails.browser === 'safari' && browserDetails.version >= 605) {\n    return;\n  }\n  const nativeSRD = window.RTCPeerConnection.prototype.setRemoteDescription;\n  window.RTCPeerConnection.prototype.setRemoteDescription =\n  function setRemoteDescription(desc) {\n    if (desc && desc.sdp && desc.sdp.indexOf('\\na=extmap-allow-mixed') !== -1) {\n      const sdp = desc.sdp.split('\\n').filter((line) => {\n        return line.trim() !== 'a=extmap-allow-mixed';\n      }).join('\\n');\n      // Safari enforces read-only-ness of RTCSessionDescription fields.\n      if (window.RTCSessionDescription &&\n          desc instanceof window.RTCSessionDescription) {\n        arguments[0] = new window.RTCSessionDescription({\n          type: desc.type,\n          sdp,\n        });\n      } else {\n        desc.sdp = sdp;\n      }\n    }\n    return nativeSRD.apply(this, arguments);\n  };\n}\n\nfunction shimAddIceCandidateNullOrEmpty(window, browserDetails) {\n  // Support for addIceCandidate(null or undefined)\n  // as well as addIceCandidate({candidate: \"\", ...})\n  // https://bugs.chromium.org/p/chromium/issues/detail?id=978582\n  // Note: must be called before other polyfills which change the signature.\n  if (!(window.RTCPeerConnection && window.RTCPeerConnection.prototype)) {\n    return;\n  }\n  const nativeAddIceCandidate =\n      window.RTCPeerConnection.prototype.addIceCandidate;\n  if (!nativeAddIceCandidate || nativeAddIceCandidate.length === 0) {\n    return;\n  }\n  window.RTCPeerConnection.prototype.addIceCandidate =\n    function addIceCandidate() {\n      if (!arguments[0]) {\n        if (arguments[1]) {\n          arguments[1].apply(null);\n        }\n        return Promise.resolve();\n      }\n      // Firefox 68+ emits and processes {candidate: \"\", ...}, ignore\n      // in older versions.\n      // Native support for ignoring exists for Chrome M77+.\n      // Safari ignores as well, exact version unknown but works in the same\n      // version that also ignores addIceCandidate(null).\n      if (((browserDetails.browser === 'chrome' && browserDetails.version < 78)\n           || (browserDetails.browser === 'firefox'\n               && browserDetails.version < 68)\n           || (browserDetails.browser === 'safari'))\n          && arguments[0] && arguments[0].candidate === '') {\n        return Promise.resolve();\n      }\n      return nativeAddIceCandidate.apply(this, arguments);\n    };\n}\n\n// Note: Make sure to call this ahead of APIs that modify\n// setLocalDescription.length\nfunction shimParameterlessSetLocalDescription(window, browserDetails) {\n  if (!(window.RTCPeerConnection && window.RTCPeerConnection.prototype)) {\n    return;\n  }\n  const nativeSetLocalDescription =\n      window.RTCPeerConnection.prototype.setLocalDescription;\n  if (!nativeSetLocalDescription || nativeSetLocalDescription.length === 0) {\n    return;\n  }\n  window.RTCPeerConnection.prototype.setLocalDescription =\n    function setLocalDescription() {\n      let desc = arguments[0] || {};\n      if (typeof desc !== 'object' || (desc.type && desc.sdp)) {\n        return nativeSetLocalDescription.apply(this, arguments);\n      }\n      // The remaining steps should technically happen when SLD comes off the\n      // RTCPeerConnection's operations chain (not ahead of going on it), but\n      // this is too difficult to shim. Instead, this shim only covers the\n      // common case where the operations chain is empty. This is imperfect, but\n      // should cover many cases. Rationale: Even if we can't reduce the glare\n      // window to zero on imperfect implementations, there's value in tapping\n      // into the perfect negotiation pattern that several browsers support.\n      desc = {type: desc.type, sdp: desc.sdp};\n      if (!desc.type) {\n        switch (this.signalingState) {\n          case 'stable':\n          case 'have-local-offer':\n          case 'have-remote-pranswer':\n            desc.type = 'offer';\n            break;\n          default:\n            desc.type = 'answer';\n            break;\n        }\n      }\n      if (desc.sdp || (desc.type !== 'offer' && desc.type !== 'answer')) {\n        return nativeSetLocalDescription.apply(this, [desc]);\n      }\n      const func = desc.type === 'offer' ? this.createOffer : this.createAnswer;\n      return func.apply(this)\n        .then(d => nativeSetLocalDescription.apply(this, [d]));\n    };\n}\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/webrtc-adapter/src/js/common_shim.js?\n}");

/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/firefox/firefox_shim.js":
/*!********************************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/firefox/firefox_shim.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   shimAddTransceiver: () => (/* binding */ shimAddTransceiver),\n/* harmony export */   shimCreateAnswer: () => (/* binding */ shimCreateAnswer),\n/* harmony export */   shimCreateOffer: () => (/* binding */ shimCreateOffer),\n/* harmony export */   shimGetDisplayMedia: () => (/* reexport safe */ _getdisplaymedia__WEBPACK_IMPORTED_MODULE_2__.shimGetDisplayMedia),\n/* harmony export */   shimGetParameters: () => (/* binding */ shimGetParameters),\n/* harmony export */   shimGetUserMedia: () => (/* reexport safe */ _getusermedia__WEBPACK_IMPORTED_MODULE_1__.shimGetUserMedia),\n/* harmony export */   shimOnTrack: () => (/* binding */ shimOnTrack),\n/* harmony export */   shimPeerConnection: () => (/* binding */ shimPeerConnection),\n/* harmony export */   shimRTCDataChannel: () => (/* binding */ shimRTCDataChannel),\n/* harmony export */   shimReceiverGetStats: () => (/* binding */ shimReceiverGetStats),\n/* harmony export */   shimRemoveStream: () => (/* binding */ shimRemoveStream),\n/* harmony export */   shimSenderGetStats: () => (/* binding */ shimSenderGetStats)\n/* harmony export */ });\n/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils */ \"./node_modules/webrtc-adapter/src/js/utils.js\");\n/* harmony import */ var _getusermedia__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./getusermedia */ \"./node_modules/webrtc-adapter/src/js/firefox/getusermedia.js\");\n/* harmony import */ var _getdisplaymedia__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./getdisplaymedia */ \"./node_modules/webrtc-adapter/src/js/firefox/getdisplaymedia.js\");\n/*\n *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.\n *\n *  Use of this source code is governed by a BSD-style license\n *  that can be found in the LICENSE file in the root of the source\n *  tree.\n */\n/* eslint-env node */\n\n\n\n\n\n\nfunction shimOnTrack(window) {\n  if (typeof window === 'object' && window.RTCTrackEvent &&\n      ('receiver' in window.RTCTrackEvent.prototype) &&\n      !('transceiver' in window.RTCTrackEvent.prototype)) {\n    Object.defineProperty(window.RTCTrackEvent.prototype, 'transceiver', {\n      get() {\n        return {receiver: this.receiver};\n      }\n    });\n  }\n}\n\nfunction shimPeerConnection(window, browserDetails) {\n  if (typeof window !== 'object' ||\n      !(window.RTCPeerConnection || window.mozRTCPeerConnection)) {\n    return; // probably media.peerconnection.enabled=false in about:config\n  }\n  if (!window.RTCPeerConnection && window.mozRTCPeerConnection) {\n    // very basic support for old versions.\n    window.RTCPeerConnection = window.mozRTCPeerConnection;\n  }\n\n  if (browserDetails.version < 53) {\n    // shim away need for obsolete RTCIceCandidate/RTCSessionDescription.\n    ['setLocalDescription', 'setRemoteDescription', 'addIceCandidate']\n      .forEach(function(method) {\n        const nativeMethod = window.RTCPeerConnection.prototype[method];\n        const methodObj = {[method]() {\n          arguments[0] = new ((method === 'addIceCandidate') ?\n            window.RTCIceCandidate :\n            window.RTCSessionDescription)(arguments[0]);\n          return nativeMethod.apply(this, arguments);\n        }};\n        window.RTCPeerConnection.prototype[method] = methodObj[method];\n      });\n  }\n\n  const modernStatsTypes = {\n    inboundrtp: 'inbound-rtp',\n    outboundrtp: 'outbound-rtp',\n    candidatepair: 'candidate-pair',\n    localcandidate: 'local-candidate',\n    remotecandidate: 'remote-candidate'\n  };\n\n  const nativeGetStats = window.RTCPeerConnection.prototype.getStats;\n  window.RTCPeerConnection.prototype.getStats = function getStats() {\n    const [selector, onSucc, onErr] = arguments;\n    return nativeGetStats.apply(this, [selector || null])\n      .then(stats => {\n        if (browserDetails.version < 53 && !onSucc) {\n          // Shim only promise getStats with spec-hyphens in type names\n          // Leave callback version alone; misc old uses of forEach before Map\n          try {\n            stats.forEach(stat => {\n              stat.type = modernStatsTypes[stat.type] || stat.type;\n            });\n          } catch (e) {\n            if (e.name !== 'TypeError') {\n              throw e;\n            }\n            // Avoid TypeError: \"type\" is read-only, in old versions. 34-43ish\n            stats.forEach((stat, i) => {\n              stats.set(i, Object.assign({}, stat, {\n                type: modernStatsTypes[stat.type] || stat.type\n              }));\n            });\n          }\n        }\n        return stats;\n      })\n      .then(onSucc, onErr);\n  };\n}\n\nfunction shimSenderGetStats(window) {\n  if (!(typeof window === 'object' && window.RTCPeerConnection &&\n      window.RTCRtpSender)) {\n    return;\n  }\n  if (window.RTCRtpSender && 'getStats' in window.RTCRtpSender.prototype) {\n    return;\n  }\n  const origGetSenders = window.RTCPeerConnection.prototype.getSenders;\n  if (origGetSenders) {\n    window.RTCPeerConnection.prototype.getSenders = function getSenders() {\n      const senders = origGetSenders.apply(this, []);\n      senders.forEach(sender => sender._pc = this);\n      return senders;\n    };\n  }\n\n  const origAddTrack = window.RTCPeerConnection.prototype.addTrack;\n  if (origAddTrack) {\n    window.RTCPeerConnection.prototype.addTrack = function addTrack() {\n      const sender = origAddTrack.apply(this, arguments);\n      sender._pc = this;\n      return sender;\n    };\n  }\n  window.RTCRtpSender.prototype.getStats = function getStats() {\n    return this.track ? this._pc.getStats(this.track) :\n      Promise.resolve(new Map());\n  };\n}\n\nfunction shimReceiverGetStats(window) {\n  if (!(typeof window === 'object' && window.RTCPeerConnection &&\n      window.RTCRtpSender)) {\n    return;\n  }\n  if (window.RTCRtpSender && 'getStats' in window.RTCRtpReceiver.prototype) {\n    return;\n  }\n  const origGetReceivers = window.RTCPeerConnection.prototype.getReceivers;\n  if (origGetReceivers) {\n    window.RTCPeerConnection.prototype.getReceivers = function getReceivers() {\n      const receivers = origGetReceivers.apply(this, []);\n      receivers.forEach(receiver => receiver._pc = this);\n      return receivers;\n    };\n  }\n  _utils__WEBPACK_IMPORTED_MODULE_0__.wrapPeerConnectionEvent(window, 'track', e => {\n    e.receiver._pc = e.srcElement;\n    return e;\n  });\n  window.RTCRtpReceiver.prototype.getStats = function getStats() {\n    return this._pc.getStats(this.track);\n  };\n}\n\nfunction shimRemoveStream(window) {\n  if (!window.RTCPeerConnection ||\n      'removeStream' in window.RTCPeerConnection.prototype) {\n    return;\n  }\n  window.RTCPeerConnection.prototype.removeStream =\n    function removeStream(stream) {\n      _utils__WEBPACK_IMPORTED_MODULE_0__.deprecated('removeStream', 'removeTrack');\n      this.getSenders().forEach(sender => {\n        if (sender.track && stream.getTracks().includes(sender.track)) {\n          this.removeTrack(sender);\n        }\n      });\n    };\n}\n\nfunction shimRTCDataChannel(window) {\n  // rename DataChannel to RTCDataChannel (native fix in FF60):\n  // https://bugzilla.mozilla.org/show_bug.cgi?id=1173851\n  if (window.DataChannel && !window.RTCDataChannel) {\n    window.RTCDataChannel = window.DataChannel;\n  }\n}\n\nfunction shimAddTransceiver(window) {\n  // https://github.com/webrtcHacks/adapter/issues/998#issuecomment-516921647\n  // Firefox ignores the init sendEncodings options passed to addTransceiver\n  // https://bugzilla.mozilla.org/show_bug.cgi?id=1396918\n  if (!(typeof window === 'object' && window.RTCPeerConnection)) {\n    return;\n  }\n  const origAddTransceiver = window.RTCPeerConnection.prototype.addTransceiver;\n  if (origAddTransceiver) {\n    window.RTCPeerConnection.prototype.addTransceiver =\n      function addTransceiver() {\n        this.setParametersPromises = [];\n        // WebIDL input coercion and validation\n        let sendEncodings = arguments[1] && arguments[1].sendEncodings;\n        if (sendEncodings === undefined) {\n          sendEncodings = [];\n        }\n        sendEncodings = [...sendEncodings];\n        const shouldPerformCheck = sendEncodings.length > 0;\n        if (shouldPerformCheck) {\n          // If sendEncodings params are provided, validate grammar\n          sendEncodings.forEach((encodingParam) => {\n            if ('rid' in encodingParam) {\n              const ridRegex = /^[a-z0-9]{0,16}$/i;\n              if (!ridRegex.test(encodingParam.rid)) {\n                throw new TypeError('Invalid RID value provided.');\n              }\n            }\n            if ('scaleResolutionDownBy' in encodingParam) {\n              if (!(parseFloat(encodingParam.scaleResolutionDownBy) >= 1.0)) {\n                throw new RangeError('scale_resolution_down_by must be >= 1.0');\n              }\n            }\n            if ('maxFramerate' in encodingParam) {\n              if (!(parseFloat(encodingParam.maxFramerate) >= 0)) {\n                throw new RangeError('max_framerate must be >= 0.0');\n              }\n            }\n          });\n        }\n        const transceiver = origAddTransceiver.apply(this, arguments);\n        if (shouldPerformCheck) {\n          // Check if the init options were applied. If not we do this in an\n          // asynchronous way and save the promise reference in a global object.\n          // This is an ugly hack, but at the same time is way more robust than\n          // checking the sender parameters before and after the createOffer\n          // Also note that after the createoffer we are not 100% sure that\n          // the params were asynchronously applied so we might miss the\n          // opportunity to recreate offer.\n          const {sender} = transceiver;\n          const params = sender.getParameters();\n          if (!('encodings' in params) ||\n              // Avoid being fooled by patched getParameters() below.\n              (params.encodings.length === 1 &&\n               Object.keys(params.encodings[0]).length === 0)) {\n            params.encodings = sendEncodings;\n            sender.sendEncodings = sendEncodings;\n            this.setParametersPromises.push(sender.setParameters(params)\n              .then(() => {\n                delete sender.sendEncodings;\n              }).catch(() => {\n                delete sender.sendEncodings;\n              })\n            );\n          }\n        }\n        return transceiver;\n      };\n  }\n}\n\nfunction shimGetParameters(window) {\n  if (!(typeof window === 'object' && window.RTCRtpSender)) {\n    return;\n  }\n  const origGetParameters = window.RTCRtpSender.prototype.getParameters;\n  if (origGetParameters) {\n    window.RTCRtpSender.prototype.getParameters =\n      function getParameters() {\n        const params = origGetParameters.apply(this, arguments);\n        if (!('encodings' in params)) {\n          params.encodings = [].concat(this.sendEncodings || [{}]);\n        }\n        return params;\n      };\n  }\n}\n\nfunction shimCreateOffer(window) {\n  // https://github.com/webrtcHacks/adapter/issues/998#issuecomment-516921647\n  // Firefox ignores the init sendEncodings options passed to addTransceiver\n  // https://bugzilla.mozilla.org/show_bug.cgi?id=1396918\n  if (!(typeof window === 'object' && window.RTCPeerConnection)) {\n    return;\n  }\n  const origCreateOffer = window.RTCPeerConnection.prototype.createOffer;\n  window.RTCPeerConnection.prototype.createOffer = function createOffer() {\n    if (this.setParametersPromises && this.setParametersPromises.length) {\n      return Promise.all(this.setParametersPromises)\n        .then(() => {\n          return origCreateOffer.apply(this, arguments);\n        })\n        .finally(() => {\n          this.setParametersPromises = [];\n        });\n    }\n    return origCreateOffer.apply(this, arguments);\n  };\n}\n\nfunction shimCreateAnswer(window) {\n  // https://github.com/webrtcHacks/adapter/issues/998#issuecomment-516921647\n  // Firefox ignores the init sendEncodings options passed to addTransceiver\n  // https://bugzilla.mozilla.org/show_bug.cgi?id=1396918\n  if (!(typeof window === 'object' && window.RTCPeerConnection)) {\n    return;\n  }\n  const origCreateAnswer = window.RTCPeerConnection.prototype.createAnswer;\n  window.RTCPeerConnection.prototype.createAnswer = function createAnswer() {\n    if (this.setParametersPromises && this.setParametersPromises.length) {\n      return Promise.all(this.setParametersPromises)\n        .then(() => {\n          return origCreateAnswer.apply(this, arguments);\n        })\n        .finally(() => {\n          this.setParametersPromises = [];\n        });\n    }\n    return origCreateAnswer.apply(this, arguments);\n  };\n}\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/webrtc-adapter/src/js/firefox/firefox_shim.js?\n}");

/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/firefox/getdisplaymedia.js":
/*!***********************************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/firefox/getdisplaymedia.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   shimGetDisplayMedia: () => (/* binding */ shimGetDisplayMedia)\n/* harmony export */ });\n/*\n *  Copyright (c) 2018 The adapter.js project authors. All Rights Reserved.\n *\n *  Use of this source code is governed by a BSD-style license\n *  that can be found in the LICENSE file in the root of the source\n *  tree.\n */\n/* eslint-env node */\n\n\nfunction shimGetDisplayMedia(window, preferredMediaSource) {\n  if (window.navigator.mediaDevices &&\n    'getDisplayMedia' in window.navigator.mediaDevices) {\n    return;\n  }\n  if (!(window.navigator.mediaDevices)) {\n    return;\n  }\n  window.navigator.mediaDevices.getDisplayMedia =\n    function getDisplayMedia(constraints) {\n      if (!(constraints && constraints.video)) {\n        const err = new DOMException('getDisplayMedia without video ' +\n            'constraints is undefined');\n        err.name = 'NotFoundError';\n        // from https://heycam.github.io/webidl/#idl-DOMException-error-names\n        err.code = 8;\n        return Promise.reject(err);\n      }\n      if (constraints.video === true) {\n        constraints.video = {mediaSource: preferredMediaSource};\n      } else {\n        constraints.video.mediaSource = preferredMediaSource;\n      }\n      return window.navigator.mediaDevices.getUserMedia(constraints);\n    };\n}\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/webrtc-adapter/src/js/firefox/getdisplaymedia.js?\n}");

/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/firefox/getusermedia.js":
/*!********************************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/firefox/getusermedia.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   shimGetUserMedia: () => (/* binding */ shimGetUserMedia)\n/* harmony export */ });\n/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils */ \"./node_modules/webrtc-adapter/src/js/utils.js\");\n/*\n *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.\n *\n *  Use of this source code is governed by a BSD-style license\n *  that can be found in the LICENSE file in the root of the source\n *  tree.\n */\n/* eslint-env node */\n\n\n\n\nfunction shimGetUserMedia(window, browserDetails) {\n  const navigator = window && window.navigator;\n  const MediaStreamTrack = window && window.MediaStreamTrack;\n\n  navigator.getUserMedia = function(constraints, onSuccess, onError) {\n    // Replace Firefox 44+'s deprecation warning with unprefixed version.\n    _utils__WEBPACK_IMPORTED_MODULE_0__.deprecated('navigator.getUserMedia',\n      'navigator.mediaDevices.getUserMedia');\n    navigator.mediaDevices.getUserMedia(constraints).then(onSuccess, onError);\n  };\n\n  if (!(browserDetails.version > 55 &&\n      'autoGainControl' in navigator.mediaDevices.getSupportedConstraints())) {\n    const remap = function(obj, a, b) {\n      if (a in obj && !(b in obj)) {\n        obj[b] = obj[a];\n        delete obj[a];\n      }\n    };\n\n    const nativeGetUserMedia = navigator.mediaDevices.getUserMedia.\n      bind(navigator.mediaDevices);\n    navigator.mediaDevices.getUserMedia = function(c) {\n      if (typeof c === 'object' && typeof c.audio === 'object') {\n        c = JSON.parse(JSON.stringify(c));\n        remap(c.audio, 'autoGainControl', 'mozAutoGainControl');\n        remap(c.audio, 'noiseSuppression', 'mozNoiseSuppression');\n      }\n      return nativeGetUserMedia(c);\n    };\n\n    if (MediaStreamTrack && MediaStreamTrack.prototype.getSettings) {\n      const nativeGetSettings = MediaStreamTrack.prototype.getSettings;\n      MediaStreamTrack.prototype.getSettings = function() {\n        const obj = nativeGetSettings.apply(this, arguments);\n        remap(obj, 'mozAutoGainControl', 'autoGainControl');\n        remap(obj, 'mozNoiseSuppression', 'noiseSuppression');\n        return obj;\n      };\n    }\n\n    if (MediaStreamTrack && MediaStreamTrack.prototype.applyConstraints) {\n      const nativeApplyConstraints =\n        MediaStreamTrack.prototype.applyConstraints;\n      MediaStreamTrack.prototype.applyConstraints = function(c) {\n        if (this.kind === 'audio' && typeof c === 'object') {\n          c = JSON.parse(JSON.stringify(c));\n          remap(c, 'autoGainControl', 'mozAutoGainControl');\n          remap(c, 'noiseSuppression', 'mozNoiseSuppression');\n        }\n        return nativeApplyConstraints.apply(this, [c]);\n      };\n    }\n  }\n}\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/webrtc-adapter/src/js/firefox/getusermedia.js?\n}");

/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/safari/safari_shim.js":
/*!******************************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/safari/safari_shim.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   shimAudioContext: () => (/* binding */ shimAudioContext),\n/* harmony export */   shimCallbacksAPI: () => (/* binding */ shimCallbacksAPI),\n/* harmony export */   shimConstraints: () => (/* binding */ shimConstraints),\n/* harmony export */   shimCreateOfferLegacy: () => (/* binding */ shimCreateOfferLegacy),\n/* harmony export */   shimGetUserMedia: () => (/* binding */ shimGetUserMedia),\n/* harmony export */   shimLocalStreamsAPI: () => (/* binding */ shimLocalStreamsAPI),\n/* harmony export */   shimRTCIceServerUrls: () => (/* binding */ shimRTCIceServerUrls),\n/* harmony export */   shimRemoteStreamsAPI: () => (/* binding */ shimRemoteStreamsAPI),\n/* harmony export */   shimTrackEventTransceiver: () => (/* binding */ shimTrackEventTransceiver)\n/* harmony export */ });\n/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils */ \"./node_modules/webrtc-adapter/src/js/utils.js\");\n/*\n *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.\n *\n *  Use of this source code is governed by a BSD-style license\n *  that can be found in the LICENSE file in the root of the source\n *  tree.\n */\n\n\n\nfunction shimLocalStreamsAPI(window) {\n  if (typeof window !== 'object' || !window.RTCPeerConnection) {\n    return;\n  }\n  if (!('getLocalStreams' in window.RTCPeerConnection.prototype)) {\n    window.RTCPeerConnection.prototype.getLocalStreams =\n      function getLocalStreams() {\n        if (!this._localStreams) {\n          this._localStreams = [];\n        }\n        return this._localStreams;\n      };\n  }\n  if (!('addStream' in window.RTCPeerConnection.prototype)) {\n    const _addTrack = window.RTCPeerConnection.prototype.addTrack;\n    window.RTCPeerConnection.prototype.addStream = function addStream(stream) {\n      if (!this._localStreams) {\n        this._localStreams = [];\n      }\n      if (!this._localStreams.includes(stream)) {\n        this._localStreams.push(stream);\n      }\n      // Try to emulate Chrome's behaviour of adding in audio-video order.\n      // Safari orders by track id.\n      stream.getAudioTracks().forEach(track => _addTrack.call(this, track,\n        stream));\n      stream.getVideoTracks().forEach(track => _addTrack.call(this, track,\n        stream));\n    };\n\n    window.RTCPeerConnection.prototype.addTrack =\n      function addTrack(track, ...streams) {\n        if (streams) {\n          streams.forEach((stream) => {\n            if (!this._localStreams) {\n              this._localStreams = [stream];\n            } else if (!this._localStreams.includes(stream)) {\n              this._localStreams.push(stream);\n            }\n          });\n        }\n        return _addTrack.apply(this, arguments);\n      };\n  }\n  if (!('removeStream' in window.RTCPeerConnection.prototype)) {\n    window.RTCPeerConnection.prototype.removeStream =\n      function removeStream(stream) {\n        if (!this._localStreams) {\n          this._localStreams = [];\n        }\n        const index = this._localStreams.indexOf(stream);\n        if (index === -1) {\n          return;\n        }\n        this._localStreams.splice(index, 1);\n        const tracks = stream.getTracks();\n        this.getSenders().forEach(sender => {\n          if (tracks.includes(sender.track)) {\n            this.removeTrack(sender);\n          }\n        });\n      };\n  }\n}\n\nfunction shimRemoteStreamsAPI(window) {\n  if (typeof window !== 'object' || !window.RTCPeerConnection) {\n    return;\n  }\n  if (!('getRemoteStreams' in window.RTCPeerConnection.prototype)) {\n    window.RTCPeerConnection.prototype.getRemoteStreams =\n      function getRemoteStreams() {\n        return this._remoteStreams ? this._remoteStreams : [];\n      };\n  }\n  if (!('onaddstream' in window.RTCPeerConnection.prototype)) {\n    Object.defineProperty(window.RTCPeerConnection.prototype, 'onaddstream', {\n      get() {\n        return this._onaddstream;\n      },\n      set(f) {\n        if (this._onaddstream) {\n          this.removeEventListener('addstream', this._onaddstream);\n          this.removeEventListener('track', this._onaddstreampoly);\n        }\n        this.addEventListener('addstream', this._onaddstream = f);\n        this.addEventListener('track', this._onaddstreampoly = (e) => {\n          e.streams.forEach(stream => {\n            if (!this._remoteStreams) {\n              this._remoteStreams = [];\n            }\n            if (this._remoteStreams.includes(stream)) {\n              return;\n            }\n            this._remoteStreams.push(stream);\n            const event = new Event('addstream');\n            event.stream = stream;\n            this.dispatchEvent(event);\n          });\n        });\n      }\n    });\n    const origSetRemoteDescription =\n      window.RTCPeerConnection.prototype.setRemoteDescription;\n    window.RTCPeerConnection.prototype.setRemoteDescription =\n      function setRemoteDescription() {\n        const pc = this;\n        if (!this._onaddstreampoly) {\n          this.addEventListener('track', this._onaddstreampoly = function(e) {\n            e.streams.forEach(stream => {\n              if (!pc._remoteStreams) {\n                pc._remoteStreams = [];\n              }\n              if (pc._remoteStreams.indexOf(stream) >= 0) {\n                return;\n              }\n              pc._remoteStreams.push(stream);\n              const event = new Event('addstream');\n              event.stream = stream;\n              pc.dispatchEvent(event);\n            });\n          });\n        }\n        return origSetRemoteDescription.apply(pc, arguments);\n      };\n  }\n}\n\nfunction shimCallbacksAPI(window) {\n  if (typeof window !== 'object' || !window.RTCPeerConnection) {\n    return;\n  }\n  const prototype = window.RTCPeerConnection.prototype;\n  const origCreateOffer = prototype.createOffer;\n  const origCreateAnswer = prototype.createAnswer;\n  const setLocalDescription = prototype.setLocalDescription;\n  const setRemoteDescription = prototype.setRemoteDescription;\n  const addIceCandidate = prototype.addIceCandidate;\n\n  prototype.createOffer =\n    function createOffer(successCallback, failureCallback) {\n      const options = (arguments.length >= 2) ? arguments[2] : arguments[0];\n      const promise = origCreateOffer.apply(this, [options]);\n      if (!failureCallback) {\n        return promise;\n      }\n      promise.then(successCallback, failureCallback);\n      return Promise.resolve();\n    };\n\n  prototype.createAnswer =\n    function createAnswer(successCallback, failureCallback) {\n      const options = (arguments.length >= 2) ? arguments[2] : arguments[0];\n      const promise = origCreateAnswer.apply(this, [options]);\n      if (!failureCallback) {\n        return promise;\n      }\n      promise.then(successCallback, failureCallback);\n      return Promise.resolve();\n    };\n\n  let withCallback = function(description, successCallback, failureCallback) {\n    const promise = setLocalDescription.apply(this, [description]);\n    if (!failureCallback) {\n      return promise;\n    }\n    promise.then(successCallback, failureCallback);\n    return Promise.resolve();\n  };\n  prototype.setLocalDescription = withCallback;\n\n  withCallback = function(description, successCallback, failureCallback) {\n    const promise = setRemoteDescription.apply(this, [description]);\n    if (!failureCallback) {\n      return promise;\n    }\n    promise.then(successCallback, failureCallback);\n    return Promise.resolve();\n  };\n  prototype.setRemoteDescription = withCallback;\n\n  withCallback = function(candidate, successCallback, failureCallback) {\n    const promise = addIceCandidate.apply(this, [candidate]);\n    if (!failureCallback) {\n      return promise;\n    }\n    promise.then(successCallback, failureCallback);\n    return Promise.resolve();\n  };\n  prototype.addIceCandidate = withCallback;\n}\n\nfunction shimGetUserMedia(window) {\n  const navigator = window && window.navigator;\n\n  if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {\n    // shim not needed in Safari 12.1\n    const mediaDevices = navigator.mediaDevices;\n    const _getUserMedia = mediaDevices.getUserMedia.bind(mediaDevices);\n    navigator.mediaDevices.getUserMedia = (constraints) => {\n      return _getUserMedia(shimConstraints(constraints));\n    };\n  }\n\n  if (!navigator.getUserMedia && navigator.mediaDevices &&\n    navigator.mediaDevices.getUserMedia) {\n    navigator.getUserMedia = function getUserMedia(constraints, cb, errcb) {\n      navigator.mediaDevices.getUserMedia(constraints)\n        .then(cb, errcb);\n    }.bind(navigator);\n  }\n}\n\nfunction shimConstraints(constraints) {\n  if (constraints && constraints.video !== undefined) {\n    return Object.assign({},\n      constraints,\n      {video: _utils__WEBPACK_IMPORTED_MODULE_0__.compactObject(constraints.video)}\n    );\n  }\n\n  return constraints;\n}\n\nfunction shimRTCIceServerUrls(window) {\n  if (!window.RTCPeerConnection) {\n    return;\n  }\n  // migrate from non-spec RTCIceServer.url to RTCIceServer.urls\n  const OrigPeerConnection = window.RTCPeerConnection;\n  window.RTCPeerConnection =\n    function RTCPeerConnection(pcConfig, pcConstraints) {\n      if (pcConfig && pcConfig.iceServers) {\n        const newIceServers = [];\n        for (let i = 0; i < pcConfig.iceServers.length; i++) {\n          let server = pcConfig.iceServers[i];\n          if (server.urls === undefined && server.url) {\n            _utils__WEBPACK_IMPORTED_MODULE_0__.deprecated('RTCIceServer.url', 'RTCIceServer.urls');\n            server = JSON.parse(JSON.stringify(server));\n            server.urls = server.url;\n            delete server.url;\n            newIceServers.push(server);\n          } else {\n            newIceServers.push(pcConfig.iceServers[i]);\n          }\n        }\n        pcConfig.iceServers = newIceServers;\n      }\n      return new OrigPeerConnection(pcConfig, pcConstraints);\n    };\n  window.RTCPeerConnection.prototype = OrigPeerConnection.prototype;\n  // wrap static methods. Currently just generateCertificate.\n  if ('generateCertificate' in OrigPeerConnection) {\n    Object.defineProperty(window.RTCPeerConnection, 'generateCertificate', {\n      get() {\n        return OrigPeerConnection.generateCertificate;\n      }\n    });\n  }\n}\n\nfunction shimTrackEventTransceiver(window) {\n  // Add event.transceiver member over deprecated event.receiver\n  if (typeof window === 'object' && window.RTCTrackEvent &&\n      'receiver' in window.RTCTrackEvent.prototype &&\n      !('transceiver' in window.RTCTrackEvent.prototype)) {\n    Object.defineProperty(window.RTCTrackEvent.prototype, 'transceiver', {\n      get() {\n        return {receiver: this.receiver};\n      }\n    });\n  }\n}\n\nfunction shimCreateOfferLegacy(window) {\n  const origCreateOffer = window.RTCPeerConnection.prototype.createOffer;\n  window.RTCPeerConnection.prototype.createOffer =\n    function createOffer(offerOptions) {\n      if (offerOptions) {\n        if (typeof offerOptions.offerToReceiveAudio !== 'undefined') {\n          // support bit values\n          offerOptions.offerToReceiveAudio =\n            !!offerOptions.offerToReceiveAudio;\n        }\n        const audioTransceiver = this.getTransceivers().find(transceiver =>\n          transceiver.receiver.track.kind === 'audio');\n        if (offerOptions.offerToReceiveAudio === false && audioTransceiver) {\n          if (audioTransceiver.direction === 'sendrecv') {\n            if (audioTransceiver.setDirection) {\n              audioTransceiver.setDirection('sendonly');\n            } else {\n              audioTransceiver.direction = 'sendonly';\n            }\n          } else if (audioTransceiver.direction === 'recvonly') {\n            if (audioTransceiver.setDirection) {\n              audioTransceiver.setDirection('inactive');\n            } else {\n              audioTransceiver.direction = 'inactive';\n            }\n          }\n        } else if (offerOptions.offerToReceiveAudio === true &&\n            !audioTransceiver) {\n          this.addTransceiver('audio', {direction: 'recvonly'});\n        }\n\n        if (typeof offerOptions.offerToReceiveVideo !== 'undefined') {\n          // support bit values\n          offerOptions.offerToReceiveVideo =\n            !!offerOptions.offerToReceiveVideo;\n        }\n        const videoTransceiver = this.getTransceivers().find(transceiver =>\n          transceiver.receiver.track.kind === 'video');\n        if (offerOptions.offerToReceiveVideo === false && videoTransceiver) {\n          if (videoTransceiver.direction === 'sendrecv') {\n            if (videoTransceiver.setDirection) {\n              videoTransceiver.setDirection('sendonly');\n            } else {\n              videoTransceiver.direction = 'sendonly';\n            }\n          } else if (videoTransceiver.direction === 'recvonly') {\n            if (videoTransceiver.setDirection) {\n              videoTransceiver.setDirection('inactive');\n            } else {\n              videoTransceiver.direction = 'inactive';\n            }\n          }\n        } else if (offerOptions.offerToReceiveVideo === true &&\n            !videoTransceiver) {\n          this.addTransceiver('video', {direction: 'recvonly'});\n        }\n      }\n      return origCreateOffer.apply(this, arguments);\n    };\n}\n\nfunction shimAudioContext(window) {\n  if (typeof window !== 'object' || window.AudioContext) {\n    return;\n  }\n  window.AudioContext = window.webkitAudioContext;\n}\n\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/webrtc-adapter/src/js/safari/safari_shim.js?\n}");

/***/ }),

/***/ "./node_modules/webrtc-adapter/src/js/utils.js":
/*!*****************************************************!*\
  !*** ./node_modules/webrtc-adapter/src/js/utils.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   compactObject: () => (/* binding */ compactObject),\n/* harmony export */   deprecated: () => (/* binding */ deprecated),\n/* harmony export */   detectBrowser: () => (/* binding */ detectBrowser),\n/* harmony export */   disableLog: () => (/* binding */ disableLog),\n/* harmony export */   disableWarnings: () => (/* binding */ disableWarnings),\n/* harmony export */   extractVersion: () => (/* binding */ extractVersion),\n/* harmony export */   filterStats: () => (/* binding */ filterStats),\n/* harmony export */   log: () => (/* binding */ log),\n/* harmony export */   walkStats: () => (/* binding */ walkStats),\n/* harmony export */   wrapPeerConnectionEvent: () => (/* binding */ wrapPeerConnectionEvent)\n/* harmony export */ });\n/*\n *  Copyright (c) 2016 The WebRTC project authors. All Rights Reserved.\n *\n *  Use of this source code is governed by a BSD-style license\n *  that can be found in the LICENSE file in the root of the source\n *  tree.\n */\n/* eslint-env node */\n\n\nlet logDisabled_ = true;\nlet deprecationWarnings_ = true;\n\n/**\n * Extract browser version out of the provided user agent string.\n *\n * @param {!string} uastring userAgent string.\n * @param {!string} expr Regular expression used as match criteria.\n * @param {!number} pos position in the version string to be returned.\n * @return {!number} browser version.\n */\nfunction extractVersion(uastring, expr, pos) {\n  const match = uastring.match(expr);\n  return match && match.length >= pos && parseInt(match[pos], 10);\n}\n\n// Wraps the peerconnection event eventNameToWrap in a function\n// which returns the modified event object (or false to prevent\n// the event).\nfunction wrapPeerConnectionEvent(window, eventNameToWrap, wrapper) {\n  if (!window.RTCPeerConnection) {\n    return;\n  }\n  const proto = window.RTCPeerConnection.prototype;\n  const nativeAddEventListener = proto.addEventListener;\n  proto.addEventListener = function(nativeEventName, cb) {\n    if (nativeEventName !== eventNameToWrap) {\n      return nativeAddEventListener.apply(this, arguments);\n    }\n    const wrappedCallback = (e) => {\n      const modifiedEvent = wrapper(e);\n      if (modifiedEvent) {\n        if (cb.handleEvent) {\n          cb.handleEvent(modifiedEvent);\n        } else {\n          cb(modifiedEvent);\n        }\n      }\n    };\n    this._eventMap = this._eventMap || {};\n    if (!this._eventMap[eventNameToWrap]) {\n      this._eventMap[eventNameToWrap] = new Map();\n    }\n    this._eventMap[eventNameToWrap].set(cb, wrappedCallback);\n    return nativeAddEventListener.apply(this, [nativeEventName,\n      wrappedCallback]);\n  };\n\n  const nativeRemoveEventListener = proto.removeEventListener;\n  proto.removeEventListener = function(nativeEventName, cb) {\n    if (nativeEventName !== eventNameToWrap || !this._eventMap\n        || !this._eventMap[eventNameToWrap]) {\n      return nativeRemoveEventListener.apply(this, arguments);\n    }\n    if (!this._eventMap[eventNameToWrap].has(cb)) {\n      return nativeRemoveEventListener.apply(this, arguments);\n    }\n    const unwrappedCb = this._eventMap[eventNameToWrap].get(cb);\n    this._eventMap[eventNameToWrap].delete(cb);\n    if (this._eventMap[eventNameToWrap].size === 0) {\n      delete this._eventMap[eventNameToWrap];\n    }\n    if (Object.keys(this._eventMap).length === 0) {\n      delete this._eventMap;\n    }\n    return nativeRemoveEventListener.apply(this, [nativeEventName,\n      unwrappedCb]);\n  };\n\n  Object.defineProperty(proto, 'on' + eventNameToWrap, {\n    get() {\n      return this['_on' + eventNameToWrap];\n    },\n    set(cb) {\n      if (this['_on' + eventNameToWrap]) {\n        this.removeEventListener(eventNameToWrap,\n          this['_on' + eventNameToWrap]);\n        delete this['_on' + eventNameToWrap];\n      }\n      if (cb) {\n        this.addEventListener(eventNameToWrap,\n          this['_on' + eventNameToWrap] = cb);\n      }\n    },\n    enumerable: true,\n    configurable: true\n  });\n}\n\nfunction disableLog(bool) {\n  if (typeof bool !== 'boolean') {\n    return new Error('Argument type: ' + typeof bool +\n        '. Please use a boolean.');\n  }\n  logDisabled_ = bool;\n  return (bool) ? 'adapter.js logging disabled' :\n    'adapter.js logging enabled';\n}\n\n/**\n * Disable or enable deprecation warnings\n * @param {!boolean} bool set to true to disable warnings.\n */\nfunction disableWarnings(bool) {\n  if (typeof bool !== 'boolean') {\n    return new Error('Argument type: ' + typeof bool +\n        '. Please use a boolean.');\n  }\n  deprecationWarnings_ = !bool;\n  return 'adapter.js deprecation warnings ' + (bool ? 'disabled' : 'enabled');\n}\n\nfunction log() {\n  if (typeof window === 'object') {\n    if (logDisabled_) {\n      return;\n    }\n    if (typeof console !== 'undefined' && typeof console.log === 'function') {\n      console.log.apply(console, arguments);\n    }\n  }\n}\n\n/**\n * Shows a deprecation warning suggesting the modern and spec-compatible API.\n */\nfunction deprecated(oldMethod, newMethod) {\n  if (!deprecationWarnings_) {\n    return;\n  }\n  console.warn(oldMethod + ' is deprecated, please use ' + newMethod +\n      ' instead.');\n}\n\n/**\n * Browser detector.\n *\n * @return {object} result containing browser and version\n *     properties.\n */\nfunction detectBrowser(window) {\n  // Returned result object.\n  const result = {browser: null, version: null};\n\n  // Fail early if it's not a browser\n  if (typeof window === 'undefined' || !window.navigator ||\n      !window.navigator.userAgent) {\n    result.browser = 'Not a browser.';\n    return result;\n  }\n\n  const {navigator} = window;\n\n  // Prefer navigator.userAgentData.\n  if (navigator.userAgentData && navigator.userAgentData.brands) {\n    const chromium = navigator.userAgentData.brands.find((brand) => {\n      return brand.brand === 'Chromium';\n    });\n    if (chromium) {\n      return {browser: 'chrome', version: parseInt(chromium.version, 10)};\n    }\n  }\n\n  if (navigator.mozGetUserMedia) { // Firefox.\n    result.browser = 'firefox';\n    result.version = extractVersion(navigator.userAgent,\n      /Firefox\\/(\\d+)\\./, 1);\n  } else if (navigator.webkitGetUserMedia ||\n      (window.isSecureContext === false && window.webkitRTCPeerConnection)) {\n    // Chrome, Chromium, Webview, Opera.\n    // Version matches Chrome/WebRTC version.\n    // Chrome 74 removed webkitGetUserMedia on http as well so we need the\n    // more complicated fallback to webkitRTCPeerConnection.\n    result.browser = 'chrome';\n    result.version = extractVersion(navigator.userAgent,\n      /Chrom(e|ium)\\/(\\d+)\\./, 2);\n  } else if (window.RTCPeerConnection &&\n      navigator.userAgent.match(/AppleWebKit\\/(\\d+)\\./)) { // Safari.\n    result.browser = 'safari';\n    result.version = extractVersion(navigator.userAgent,\n      /AppleWebKit\\/(\\d+)\\./, 1);\n    result.supportsUnifiedPlan = window.RTCRtpTransceiver &&\n        'currentDirection' in window.RTCRtpTransceiver.prototype;\n  } else { // Default fallthrough: not supported.\n    result.browser = 'Not a supported browser.';\n    return result;\n  }\n\n  return result;\n}\n\n/**\n * Checks if something is an object.\n *\n * @param {*} val The something you want to check.\n * @return true if val is an object, false otherwise.\n */\nfunction isObject(val) {\n  return Object.prototype.toString.call(val) === '[object Object]';\n}\n\n/**\n * Remove all empty objects and undefined values\n * from a nested object -- an enhanced and vanilla version\n * of Lodash's `compact`.\n */\nfunction compactObject(data) {\n  if (!isObject(data)) {\n    return data;\n  }\n\n  return Object.keys(data).reduce(function(accumulator, key) {\n    const isObj = isObject(data[key]);\n    const value = isObj ? compactObject(data[key]) : data[key];\n    const isEmptyObject = isObj && !Object.keys(value).length;\n    if (value === undefined || isEmptyObject) {\n      return accumulator;\n    }\n    return Object.assign(accumulator, {[key]: value});\n  }, {});\n}\n\n/* iterates the stats graph recursively. */\nfunction walkStats(stats, base, resultSet) {\n  if (!base || resultSet.has(base.id)) {\n    return;\n  }\n  resultSet.set(base.id, base);\n  Object.keys(base).forEach(name => {\n    if (name.endsWith('Id')) {\n      walkStats(stats, stats.get(base[name]), resultSet);\n    } else if (name.endsWith('Ids')) {\n      base[name].forEach(id => {\n        walkStats(stats, stats.get(id), resultSet);\n      });\n    }\n  });\n}\n\n/* filter getStats for a sender/receiver track. */\nfunction filterStats(result, track, outbound) {\n  const streamStatsType = outbound ? 'outbound-rtp' : 'inbound-rtp';\n  const filteredResult = new Map();\n  if (track === null) {\n    return filteredResult;\n  }\n  const trackStats = [];\n  result.forEach(value => {\n    if (value.type === 'track' &&\n        value.trackIdentifier === track.id) {\n      trackStats.push(value);\n    }\n  });\n  trackStats.forEach(trackStat => {\n    result.forEach(stats => {\n      if (stats.type === streamStatsType && stats.trackId === trackStat.id) {\n        walkStats(result, stats, filteredResult);\n      }\n    });\n  });\n  return filteredResult;\n}\n\n\n\n//# sourceURL=webpack://html-peer-viewer/./node_modules/webrtc-adapter/src/js/utils.js?\n}");

/***/ }),

/***/ "./src/Entry.ts":
/*!**********************!*\
  !*** ./src/Entry.ts ***!
  \**********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   CONFIG: () => (/* binding */ CONFIG)\n/* harmony export */ });\n/* harmony import */ var _record_Snaphots__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./record/Snaphots */ \"./src/record/Snaphots.ts\");\n/* harmony import */ var _motion_MotionDetector__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./motion/MotionDetector */ \"./src/motion/MotionDetector.ts\");\n/* harmony import */ var _utils_Events__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./utils/Events */ \"./src/utils/Events.ts\");\n/* harmony import */ var _network_StreamProvider__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./network/StreamProvider */ \"./src/network/StreamProvider.ts\");\n/* harmony import */ var _view_View__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./view/View */ \"./src/view/View.ts\");\n/* harmony import */ var _utils_Console__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./utils/Console */ \"./src/utils/Console.ts\");\n/* harmony import */ var _network_RestService__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./network/RestService */ \"./src/network/RestService.ts\");\n/* harmony import */ var _auth_Authentification__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./auth/Authentification */ \"./src/auth/Authentification.ts\");\n/* harmony import */ var _view_Controls__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./view/Controls */ \"./src/view/Controls.ts\");\n/* harmony import */ var _utils_Sounds__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./utils/Sounds */ \"./src/utils/Sounds.ts\");\n/* harmony import */ var _utils_Utils__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./utils/Utils */ \"./src/utils/Utils.ts\");\n/* harmony import */ var _view_Matrix__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./view/Matrix */ \"./src/view/Matrix.ts\");\n/* harmony import */ var _store_Model__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./store/Model */ \"./src/store/Model.ts\");\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\r\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\r\n    return new (P || (P = Promise))(function (resolve, reject) {\r\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\r\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\r\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\r\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\r\n    });\r\n};\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nconst CONFIG = {\r\n    BACKEND_URL: 'https://nodejs-http-server.onrender.com',\r\n    DEFAULT_CAMERA: 'camera',\r\n    INTRO_VIDEO_URL: './videos/solars.mp4'\r\n};\r\nconst route = () => { var _a; return (_a = window.location.search) === null || _a === void 0 ? void 0 : _a.substring(1); };\r\nclass Entry {\r\n    constructor() {\r\n        this.initialize_tmp = () => __awaiter(this, void 0, void 0, function* () {\r\n            const vid = new YourClass();\r\n            vid.initialize();\r\n            setTimeout(() => vid.initWebRTC(), 1000);\r\n        });\r\n        this.initializeAuth = () => __awaiter(this, void 0, void 0, function* () {\r\n            _utils_Utils__WEBPACK_IMPORTED_MODULE_10__.tryResizeWindow();\r\n            yield _utils_Console__WEBPACK_IMPORTED_MODULE_5__[\"default\"].initialize();\r\n            yield _auth_Authentification__WEBPACK_IMPORTED_MODULE_7__[\"default\"].initialize();\r\n            _auth_Authentification__WEBPACK_IMPORTED_MODULE_7__[\"default\"].addEventListener(_utils_Events__WEBPACK_IMPORTED_MODULE_2__.NETWORK_AUTH_SUCCESS, () => this.initializeView());\r\n        });\r\n        this.initializeView = () => __awaiter(this, void 0, void 0, function* () {\r\n            yield _view_View__WEBPACK_IMPORTED_MODULE_4__[\"default\"].initialize();\r\n            _view_View__WEBPACK_IMPORTED_MODULE_4__[\"default\"].addEventListener(_utils_Events__WEBPACK_IMPORTED_MODULE_2__.USER_PROCEEDED, () => this.initializeRoutes());\r\n        });\r\n        this.initializeRoutes = () => __awaiter(this, void 0, void 0, function* () {\r\n            switch (route()) {\r\n                case ('mix'): {\r\n                    this.initializeIntegratedComponents();\r\n                    break;\r\n                }\r\n                case ('proxy'): {\r\n                    this.initializeProxyComponents();\r\n                    break;\r\n                }\r\n                case ('low'): {\r\n                    this.initializeComponentsLow();\r\n                    break;\r\n                }\r\n                case ('check'): {\r\n                    this.initializeCheckComponents();\r\n                    break;\r\n                }\r\n                default: {\r\n                    this.initializeComponents();\r\n                    break;\r\n                }\r\n            }\r\n        });\r\n        this.initializeCheckComponents = () => __awaiter(this, void 0, void 0, function* () {\r\n            const initializeCheckStream = () => __awaiter(this, void 0, void 0, function* () {\r\n                console.log('[Entry] initializeRemoteStream importing streamer...');\r\n                const { Streamer } = yield System.import('https://html-peer-streamer.onrender.com/index.js');\r\n                const ipCameraConfigProxy = {\r\n                    name: 'security-camera',\r\n                    url: 'https://nodejs-http-server.onrender.com/api/webrtc/camera/',\r\n                    type: 'webrtc',\r\n                    quality: '' //StreamQuality.HIGH\r\n                };\r\n                const streamer = new Streamer();\r\n                console.log('[Entry] initializeRemoteStream streamer imported. created instance. initializing...');\r\n                const { peerId, primaryStream, streams, qualities, stats, cameraInfo, cameraHash } = yield streamer.initialize({ ipCamera: ipCameraConfigProxy });\r\n                // debugger;\r\n                return { primaryStream, streams };\r\n            });\r\n            const { primaryStream, streams } = yield initializeCheckStream();\r\n            console.log('[Entry] initializeIntegratedComponents initializing StreamProvider...');\r\n            yield _network_StreamProvider__WEBPACK_IMPORTED_MODULE_3__[\"default\"].initialize(true, streams);\r\n            console.log('[Entry] initializeIntegratedComponents displaying stream');\r\n            _view_View__WEBPACK_IMPORTED_MODULE_4__[\"default\"].displayStream((this.stream = primaryStream));\r\n            _view_Controls__WEBPACK_IMPORTED_MODULE_8__[\"default\"].setVisible(true);\r\n            yield this.initializeCommonComponents();\r\n        });\r\n        this.initializeRemoteStream = () => __awaiter(this, void 0, void 0, function* () {\r\n            console.log('[Entry] initializeRemoteStream importing streamer...');\r\n            const { Streamer } = yield System.import('https://html-peer-streamer.onrender.com/index.js');\r\n            const streamer = new Streamer();\r\n            console.log('[Entry] initializeRemoteStream streamer imported. created instance. initializing...');\r\n            const { peerId, primaryStream, streams, qualities, stats, cameraInfo, cameraHash } = yield streamer.initialize();\r\n            // debugger;\r\n            return { primaryStream, streams };\r\n        });\r\n        this.initializeProxyComponents = () => __awaiter(this, void 0, void 0, function* () {\r\n            const { primaryStream, streams } = yield this.initializeRemoteStream();\r\n            console.log('[Entry] initializeIntegratedComponents initializing StreamProvider...');\r\n            yield _network_StreamProvider__WEBPACK_IMPORTED_MODULE_3__[\"default\"].initialize(true, streams);\r\n            console.log('[Entry] initializeIntegratedComponents displaying stream');\r\n            _view_View__WEBPACK_IMPORTED_MODULE_4__[\"default\"].displayStream((this.stream = primaryStream));\r\n        });\r\n        this.initializeIntegratedComponents = () => __awaiter(this, void 0, void 0, function* () {\r\n            const { primaryStream, streams } = yield this.initializeRemoteStream();\r\n            console.log('[Entry] initializeIntegratedComponents initializing StreamProvider...');\r\n            yield _network_StreamProvider__WEBPACK_IMPORTED_MODULE_3__[\"default\"].initialize(true, streams);\r\n            console.log('[Entry] initializeIntegratedComponents displaying stream');\r\n            _view_View__WEBPACK_IMPORTED_MODULE_4__[\"default\"].displayStream((this.stream = primaryStream));\r\n            _view_Controls__WEBPACK_IMPORTED_MODULE_8__[\"default\"].setVisible(true);\r\n            yield this.initializeCommonComponents();\r\n        });\r\n        this.initializeComponents = () => __awaiter(this, void 0, void 0, function* () {\r\n            yield _network_StreamProvider__WEBPACK_IMPORTED_MODULE_3__[\"default\"].initialize();\r\n            _utils_Events__WEBPACK_IMPORTED_MODULE_2__[\"default\"].addEventListener(_utils_Events__WEBPACK_IMPORTED_MODULE_2__.STREAM_RECEIVED, (data) => {\r\n                _view_View__WEBPACK_IMPORTED_MODULE_4__[\"default\"].displayStream(data.stream);\r\n                _utils_Sounds__WEBPACK_IMPORTED_MODULE_9__[\"default\"].playStream(data.stream);\r\n                _view_Controls__WEBPACK_IMPORTED_MODULE_8__[\"default\"].setVisible(true);\r\n            });\r\n            yield this.initializeCommonComponents();\r\n        });\r\n        this.initializeComponentsLow = () => __awaiter(this, void 0, void 0, function* () {\r\n            _store_Model__WEBPACK_IMPORTED_MODULE_12__[\"default\"].motionDetectorEnabled = false;\r\n            _store_Model__WEBPACK_IMPORTED_MODULE_12__[\"default\"].colorCurvesEnabled = true;\r\n            _store_Model__WEBPACK_IMPORTED_MODULE_12__[\"default\"].prefferedStreamQuality = 'low';\r\n            yield _network_StreamProvider__WEBPACK_IMPORTED_MODULE_3__[\"default\"].initialize();\r\n            _utils_Events__WEBPACK_IMPORTED_MODULE_2__[\"default\"].addEventListener(_utils_Events__WEBPACK_IMPORTED_MODULE_2__.STREAM_RECEIVED, (data) => {\r\n                _view_View__WEBPACK_IMPORTED_MODULE_4__[\"default\"].displayStream(data.stream);\r\n                _motion_MotionDetector__WEBPACK_IMPORTED_MODULE_1__[\"default\"].initialize();\r\n            });\r\n        });\r\n        this.initializeCommonComponents = () => __awaiter(this, void 0, void 0, function* () {\r\n            yield _network_RestService__WEBPACK_IMPORTED_MODULE_6__[\"default\"].initialize();\r\n            yield _record_Snaphots__WEBPACK_IMPORTED_MODULE_0__[\"default\"].initialize();\r\n            yield _motion_MotionDetector__WEBPACK_IMPORTED_MODULE_1__[\"default\"].initialize();\r\n            yield _utils_Sounds__WEBPACK_IMPORTED_MODULE_9__[\"default\"].initialize();\r\n            yield _view_Matrix__WEBPACK_IMPORTED_MODULE_11__[\"default\"].initialize();\r\n            yield _utils_Console__WEBPACK_IMPORTED_MODULE_5__[\"default\"].initialize();\r\n        });\r\n        _store_Model__WEBPACK_IMPORTED_MODULE_12__[\"default\"].initialize();\r\n        if (window.location.search.includes('%')) {\r\n            this.initialize_tmp();\r\n        }\r\n        else {\r\n            switch (route()) {\r\n                case ('show'): {\r\n                    this.initializeView();\r\n                    break;\r\n                }\r\n                default: {\r\n                    this.initializeAuth();\r\n                    break;\r\n                }\r\n            }\r\n        }\r\n    }\r\n}\r\nclass YourClass {\r\n    constructor() {\r\n    }\r\n    initWebRTC() {\r\n        return __awaiter(this, void 0, void 0, function* () {\r\n            return this.simpleWebRTCMediaMTX();\r\n        });\r\n    }\r\n    simpleWebRTCMediaMTX() {\r\n        return __awaiter(this, void 0, void 0, function* () {\r\n            const video = document.createElement('video');\r\n            video.autoplay = true;\r\n            video.muted = true;\r\n            video.playsInline = true;\r\n            video.controls = false; //    -  true\r\n            video.style.cssText = `\r\n      position: fixed;\r\n      width: 50%;\r\n      height: 50%;\r\n      top: 0;\r\n      left: 0;\r\n      border: 3px solid #167bff;\r\n      background: #000;\r\n      object-fit: cover;\r\n      z-index: 1000;\r\n      opacity: 0;\r\n      transition: opacity 0.5s ease;\r\n    `;\r\n            document.body.appendChild(video);\r\n            const serverUrl = 'https://nodejs-http-server.onrender.com/api/webrtc/camera/';\r\n            console.log('   WebRTC:', serverUrl);\r\n            try {\r\n                const pc = new RTCPeerConnection();\r\n                pc.addTransceiver('video', { direction: 'recvonly' });\r\n                const offer = yield pc.createOffer();\r\n                yield pc.setLocalDescription(offer);\r\n                const response = yield fetch(serverUrl, {\r\n                    method: 'POST',\r\n                    headers: { 'Content-Type': 'application/sdp' },\r\n                    body: offer.sdp\r\n                });\r\n                if (!response.ok) {\r\n                    throw new Error(`HTTP ${response.status}: ${yield response.text()}`);\r\n                }\r\n                let answerSdp = yield response.text();\r\n                //  SDP answer  \r\n                if (!answerSdp.includes('ice-ufrag')) {\r\n                    const localSdp = pc.localDescription.sdp;\r\n                    const ufragMatch = localSdp.match(/a=ice-ufrag:(\\S+)/);\r\n                    const pwdMatch = localSdp.match(/a=ice-pwd:(\\S+)/);\r\n                    if (ufragMatch && pwdMatch) {\r\n                        answerSdp += `\\r\\na=ice-ufrag:${ufragMatch[1]}\\r\\na=ice-pwd:${pwdMatch[1]}`;\r\n                    }\r\n                }\r\n                yield pc.setRemoteDescription({\r\n                    type: 'answer',\r\n                    sdp: answerSdp\r\n                });\r\n                console.log(' WebRTC  ');\r\n                //     \r\n                pc.ontrack = (event) => {\r\n                    if (event.track.kind === 'video') {\r\n                        console.log(' WebRTC  !');\r\n                        video.srcObject = new MediaStream([event.track]);\r\n                        setTimeout(() => {\r\n                            video.style.opacity = '1';\r\n                        }, 100);\r\n                    }\r\n                };\r\n                // Fallback \r\n                setTimeout(() => {\r\n                    var _a;\r\n                    if (!video.srcObject) {\r\n                        const receivers = pc.getReceivers();\r\n                        const videoTrack = (_a = receivers.find(r => { var _a; return ((_a = r.track) === null || _a === void 0 ? void 0 : _a.kind) === 'video'; })) === null || _a === void 0 ? void 0 : _a.track;\r\n                        if (videoTrack) {\r\n                            video.srcObject = new MediaStream([videoTrack]);\r\n                            video.style.opacity = '1';\r\n                        }\r\n                    }\r\n                }, 3000);\r\n                return video;\r\n            }\r\n            catch (error) {\r\n                console.error('  WebRTC:', error);\r\n                video.remove();\r\n                throw error;\r\n            }\r\n        });\r\n    }\r\n    createWebRTCExperience(options) {\r\n        return __awaiter(this, void 0, void 0, function* () {\r\n            const body = document.body;\r\n            body.style.overflow = 'hidden';\r\n            document.querySelector('picture').style.opacity = '0.5'; // 1.   \r\n            const introVideoUrl = './videos/solars1.mp4';\r\n            console.log('  :', introVideoUrl);\r\n            const preloadVideo = document.createElement('video');\r\n            //preloadVideo.style.display = 'none';\r\n            preloadVideo.preload = 'auto';\r\n            preloadVideo.src = introVideoUrl;\r\n            //    \r\n            yield new Promise((resolve) => {\r\n                const onCanPlayThrough = () => {\r\n                    console.log('   ');\r\n                    preloadVideo.removeEventListener('canplaythrough', onCanPlayThrough);\r\n                    resolve();\r\n                };\r\n                preloadVideo.addEventListener('canplaythrough', onCanPlayThrough);\r\n                if (preloadVideo.readyState >= 4) {\r\n                    console.log('   ');\r\n                    resolve();\r\n                }\r\n            });\r\n            // 2.     \r\n            const introVideo = document.createElement('video');\r\n            introVideo.src = introVideoUrl;\r\n            introVideo.autoplay = true;\r\n            introVideo.muted = true;\r\n            introVideo.loop = true;\r\n            introVideo.controls = false;\r\n            introVideo.playsInline = true;\r\n            Object.assign(introVideo.style, {\r\n                width: '100%',\r\n                height: '100%',\r\n                objectFit: 'cover',\r\n                position: 'fixed',\r\n                top: '0',\r\n                left: '0',\r\n                zIndex: '1',\r\n                opacity: '0.4'\r\n            });\r\n            body.appendChild(introVideo);\r\n            // 3.    WebRTC \r\n            const webrtcContainer = document.createElement('div');\r\n            const webrtcOpts = (options === null || options === void 0 ? void 0 : options.webrtcOptions) || {};\r\n            const position = webrtcOpts.position || 'top-left';\r\n            const borderColor = webrtcOpts.borderColor || '#00ff00';\r\n            let top = '0', left = '0', right = 'auto', bottom = 'auto';\r\n            switch (position) {\r\n                case 'top-right':\r\n                    top = '0';\r\n                    left = 'auto';\r\n                    right = '0';\r\n                    break;\r\n                case 'bottom-left':\r\n                    top = 'auto';\r\n                    left = '0';\r\n                    bottom = '0';\r\n                    break;\r\n                case 'bottom-right':\r\n                    top = 'auto';\r\n                    left = 'auto';\r\n                    right = '0';\r\n                    bottom = '0';\r\n                    break;\r\n            }\r\n            Object.assign(webrtcContainer.style, {\r\n                position: 'fixed',\r\n                top, left, right, bottom,\r\n                width: webrtcOpts.width || '50%',\r\n                height: webrtcOpts.height || '50%',\r\n                zIndex: '2',\r\n                display: 'none',\r\n                opacity: '0',\r\n                transition: 'opacity 0.5s ease'\r\n            });\r\n        });\r\n    }\r\n    initialize() {\r\n        return __awaiter(this, void 0, void 0, function* () {\r\n            //  WebRTC  HLS\r\n            yield this.createWebRTCExperience({\r\n                introVideoUrl: './videos/solars1.mp4',\r\n                cameraName: 'camera',\r\n                webrtcOptions: {\r\n                    width: '50%',\r\n                    height: '50%',\r\n                    position: 'top-left',\r\n                    showAfterIntro: true,\r\n                    borderColor: '#4CAF50' //  \r\n                }\r\n            }).catch(console.error);\r\n        });\r\n    }\r\n    // ==========   WebRTC    ==========\r\n    quickStartWebRTC() {\r\n        return __awaiter(this, void 0, void 0, function* () {\r\n            try {\r\n                const video = yield this.simpleWebRTCMediaMTX();\r\n                console.log(' WebRTC    quick start');\r\n                return video;\r\n            }\r\n            catch (error) {\r\n                console.error('  :', error);\r\n                return null;\r\n            }\r\n        });\r\n    }\r\n}\r\nnew Entry();\r\n\n\n//# sourceURL=webpack://html-peer-viewer/./src/Entry.ts?\n}");

/***/ }),

/***/ "./src/auth/Authentification.ts":
/*!**************************************!*\
  !*** ./src/auth/Authentification.ts ***!
  \**************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _network_RestService__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../network/RestService */ \"./src/network/RestService.ts\");\n/* harmony import */ var _utils_Events__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/Events */ \"./src/utils/Events.ts\");\n/* harmony import */ var bcrypt_ts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! bcrypt-ts */ \"./node_modules/bcrypt-ts/dist/browser.mjs\");\n/* harmony import */ var _view_Pincode__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../view/Pincode */ \"./src/view/Pincode.ts\");\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\r\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\r\n    return new (P || (P = Promise))(function (resolve, reject) {\r\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\r\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\r\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\r\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\r\n    });\r\n};\r\n\r\n\r\n//import * as tf from '@tensorflow/tfjs';\r\n//import * as bcrypt from 'bcrypt';\r\n\r\n\r\nclass Authentification extends _utils_Events__WEBPACK_IMPORTED_MODULE_1__.EventHandler {\r\n    constructor() {\r\n        super();\r\n        // private _url = './model_0/model.json';\r\n        // private _buffer: any;\r\n        this.initialize = () => __awaiter(this, void 0, void 0, function* () {\r\n            this._authenticate();\r\n            return this;\r\n        });\r\n        this._authenticate = () => __awaiter(this, void 0, void 0, function* () {\r\n            const pinhash = localStorage.getItem('pinhash');\r\n            const validate = (hash) => __awaiter(this, void 0, void 0, function* () { return !!((yield _network_RestService__WEBPACK_IMPORTED_MODULE_0__[\"default\"].validatePinhash(hash)).result); });\r\n            const queryPinControl = () => __awaiter(this, void 0, void 0, function* () {\r\n                _view_Pincode__WEBPACK_IMPORTED_MODULE_3__[\"default\"].initialize();\r\n                _view_Pincode__WEBPACK_IMPORTED_MODULE_3__[\"default\"].addEventListener(_utils_Events__WEBPACK_IMPORTED_MODULE_1__.CONSOLE_EXECUTE_COMMAND, (pin) => __awaiter(this, void 0, void 0, function* () {\r\n                    _view_Pincode__WEBPACK_IMPORTED_MODULE_3__[\"default\"].hide();\r\n                    this.showLoadingView();\r\n                    const salt = (0,bcrypt_ts__WEBPACK_IMPORTED_MODULE_2__.genSaltSync)(10);\r\n                    const hash = (0,bcrypt_ts__WEBPACK_IMPORTED_MODULE_2__.hashSync)(pin, salt);\r\n                    const result = yield validate(hash);\r\n                    if (result) {\r\n                        localStorage.setItem('pinhash', hash);\r\n                        this.showSuccessView();\r\n                        this.dispatchEvent(_utils_Events__WEBPACK_IMPORTED_MODULE_1__.NETWORK_AUTH_SUCCESS, null);\r\n                    }\r\n                    else {\r\n                        this.showDefaultView();\r\n                    }\r\n                }));\r\n            });\r\n            if (pinhash) {\r\n                const result = yield validate(pinhash);\r\n                if (result) {\r\n                    this.showSuccessView();\r\n                    this.dispatchEvent(_utils_Events__WEBPACK_IMPORTED_MODULE_1__.NETWORK_AUTH_SUCCESS, null);\r\n                }\r\n                else {\r\n                    queryPinControl();\r\n                }\r\n            }\r\n            else {\r\n                queryPinControl();\r\n            }\r\n        });\r\n        this.showLoadingView = () => {\r\n            document.querySelectorAll(\"img\")[0].src = \"./images/eye_0_2.png\";\r\n        };\r\n        this.showSuccessView = () => {\r\n            setTimeout(() => { document.querySelectorAll(\"img\")[0].src = \"./images/eye_0_3.png\"; }, 300);\r\n        };\r\n        this.showDefaultView = () => {\r\n            document.querySelectorAll(\"img\")[0].src = \"./images/eye_0.png\";\r\n        };\r\n    }\r\n}\r\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (new Authentification());\r\n\n\n//# sourceURL=webpack://html-peer-viewer/./src/auth/Authentification.ts?\n}");

/***/ }),

/***/ "./src/motion/MotionDetector.ts":
/*!**************************************!*\
  !*** ./src/motion/MotionDetector.ts ***!
  \**************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   MotionDetector: () => (/* binding */ MotionDetector),\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _utils_Events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/Events */ \"./src/utils/Events.ts\");\n/* harmony import */ var _utils_Constants__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/Constants */ \"./src/utils/Constants.ts\");\n/* harmony import */ var _utils_Utils__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/Utils */ \"./src/utils/Utils.ts\");\n/* harmony import */ var _view_Matrix__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../view/Matrix */ \"./src/view/Matrix.ts\");\n/* harmony import */ var _store_Model__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../store/Model */ \"./src/store/Model.ts\");\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\r\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\r\n    return new (P || (P = Promise))(function (resolve, reject) {\r\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\r\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\r\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\r\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\r\n    });\r\n};\r\n\r\n\r\n\r\n\r\n\r\nclass MotionDetector {\r\n    constructor() {\r\n        this._checkpoint = {\r\n            size: _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.MOTION_DETECT_CHECKPOINT_SIZE,\r\n            coefs: [0.66, 0.33],\r\n            canvas: null,\r\n            context: function () {\r\n                return this.canvas.getContext('2d', { willReadFrequently: true });\r\n            }\r\n        };\r\n        this._shiftpoint = {\r\n            size: _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.MOTION_DETECT_CHECKPOINT_SIZE,\r\n            coefs: [0.96, 0.96],\r\n            canvas: null,\r\n            context: function () {\r\n                return this.canvas.getContext('2d', { willReadFrequently: true });\r\n            }\r\n        };\r\n        this._values = new DeltaValues();\r\n        this.initialize = () => __awaiter(this, void 0, void 0, function* () {\r\n            this._viewport = document.querySelector(\"video\");\r\n            _utils_Events__WEBPACK_IMPORTED_MODULE_0__[\"default\"].addEventListener(_utils_Events__WEBPACK_IMPORTED_MODULE_0__.STREAM_SWITCHED, () => this._values = new DeltaValues());\r\n            this.startDetector();\r\n        });\r\n        this.startDetector = () => __awaiter(this, void 0, void 0, function* () {\r\n            this._container = document.getElementById(\"view-page\");\r\n            this.aimview();\r\n            this._label = document.createElement(\"label\");\r\n            this._container.appendChild(this._label);\r\n            this._label.style.setProperty('position', 'absolute');\r\n            this._label.style.setProperty('top', '3%');\r\n            this._label.style.setProperty('left', '13%');\r\n            this._label.style.setProperty('font-size', '34px');\r\n            this._label.style.setProperty('font-family', 'Courier New');\r\n            this._label.style.setProperty('font-weight', 'bold');\r\n            this._label.style.setProperty('color', '#00ff30');\r\n            this._label.style.setProperty('visibility', 'hidden');\r\n            this._graphic = document.createElement(\"canvas\");\r\n            this._container.appendChild(this._graphic);\r\n            //  this._graphic.width = '100%';\r\n            //  this._graphic.height = '40%';\r\n            this._graphic.style.setProperty(\"pointer-events\", \"none\");\r\n            this._graphic.style.setProperty('position', 'absolute');\r\n            this._graphic.style.setProperty('bottom', '0%');\r\n            this._graphic.style.setProperty('left', '0%');\r\n            this._graphic.style.setProperty('height', '40%');\r\n            this._graphic.style.setProperty('width', '100%');\r\n            this._graphic.style.setProperty('display', 'none');\r\n            //this._graphic.style.setProperty('image-rendering', 'pixelated');\r\n            const handleColorCurvesVisibility = (value = _store_Model__WEBPACK_IMPORTED_MODULE_4__[\"default\"].colorCurvesEnabled) => {\r\n                const propValue = value ? 'block' : 'none';\r\n                this._graphic.style.setProperty('display', propValue);\r\n                this._label.style.setProperty('display', propValue);\r\n            };\r\n            _utils_Events__WEBPACK_IMPORTED_MODULE_0__[\"default\"].addEventListener(_utils_Events__WEBPACK_IMPORTED_MODULE_0__.COLOR_CURVES_STATE_CHANGED, (value) => {\r\n                handleColorCurvesVisibility(value);\r\n            });\r\n            handleColorCurvesVisibility();\r\n            this._viewport.requestVideoFrameCallback(this.onVideoEnterFrame);\r\n        });\r\n        this.aimview = () => {\r\n            this._checkpoint.canvas = document.createElement(\"canvas\"); //this._container.appendChild(this._points.canvas);         \r\n            this._checkpoint.canvas.width = this._checkpoint.size;\r\n            this._checkpoint.canvas.height = this._checkpoint.size;\r\n            this._checkpoint.context().globalCompositeOperation = \"difference\";\r\n            this._shiftpoint.canvas = document.createElement(\"canvas\"); //this._container.appendChild(this._points.canvas);         \r\n            this._shiftpoint.canvas.width = this._shiftpoint.size;\r\n            this._shiftpoint.canvas.height = this._shiftpoint.size;\r\n            this._shiftpoint.context().globalCompositeOperation = \"difference\";\r\n        };\r\n        this.onVideoEnterFrame = (...args) => {\r\n            this.drawCheckpoint();\r\n            this.analyzeVideoFrame();\r\n        };\r\n        this.drawCheckpoint = () => {\r\n            const size = this._checkpoint.size;\r\n            const context = this._checkpoint.context();\r\n            context.clearRect(0, 0, size, size);\r\n            return context.drawImage(this._viewport, this._width * this._checkpoint.coefs[0], this._height * this._checkpoint.coefs[1], size, size, 0, 0, size, size);\r\n        };\r\n        this.analyzeVideoFrame = () => {\r\n            const getPointData = (point) => {\r\n                const image = point.context().getImageData(0, 0, point.size, point.size);\r\n                const rgb = _utils_Utils__WEBPACK_IMPORTED_MODULE_2__.getRgb(image);\r\n                const hsv = _utils_Utils__WEBPACK_IMPORTED_MODULE_2__.rbgToHsv(rgb);\r\n                return hsv;\r\n            };\r\n            const data = getPointData(this._checkpoint);\r\n            let timeout = 0;\r\n            if (_store_Model__WEBPACK_IMPORTED_MODULE_4__[\"default\"].motionDetectorEnabled) {\r\n                timeout = this.analyzeDeltaValues(data);\r\n            }\r\n            this._values.add(data);\r\n            if (_store_Model__WEBPACK_IMPORTED_MODULE_4__[\"default\"].colorCurvesEnabled) {\r\n                this.trace();\r\n            }\r\n            setTimeout(() => this._viewport.requestVideoFrameCallback(this.onVideoEnterFrame), timeout);\r\n        };\r\n        this.analyzeDeltaValues = (value) => {\r\n            const current = value.h;\r\n            const previous = this._values.hue.last;\r\n            const average = this._values.hue.average;\r\n            let timeout = 0;\r\n            if (Math.abs(current - average) > _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.MOTION_DETECT_PIXEL_COEF &&\r\n                Math.abs(previous - average) > _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.MOTION_DETECT_PIXEL_COEF) {\r\n                timeout = _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.MOTION_DETECT_DELAY;\r\n                _view_Matrix__WEBPACK_IMPORTED_MODULE_3__[\"default\"].hide();\r\n                _utils_Events__WEBPACK_IMPORTED_MODULE_0__[\"default\"].dispatchEvent(_utils_Events__WEBPACK_IMPORTED_MODULE_0__.MOTION_DETECTION_STARTED, value);\r\n            }\r\n            //setTimeout(() => this._viewport.requestVideoFrameCallback(this.onVideoEnterFrame), timeout);\r\n            return timeout;\r\n        };\r\n        this.trace = () => {\r\n            this.drawDeltaGraphics(this._values.hue, \"rgb(0, 255, 0, 1)\", true, -100);\r\n            // this.drawDeltaGraphics(this._values.saturation,\"rgb(0, 188, 188, 1)\", false, 50);\r\n            // this.drawDeltaGraphics(this._values.brightness, \"rgb(255, 255, 255, 1)\", false, 30);\r\n        };\r\n        this.drawDeltaGraphics = (values, color, clear = false, adjust = 0, fillArea = true, smoothCurve = false // Enable bezier smoothing\r\n        ) => {\r\n            const ctx = this._graphic.getContext('2d', { willReadFrequently: true });\r\n            if (clear) {\r\n                ctx.clearRect(0, 0, this._width, this._height);\r\n            }\r\n            if (!(values === null || values === void 0 ? void 0 : values.cached) || values.cached.length < 2) {\r\n                return;\r\n            }\r\n            const BOTTOM_Y = 500;\r\n            const points = values.cached.map((y, x) => ({ x, y: y + adjust }));\r\n            // Draw filled area\r\n            if (fillArea) {\r\n                ctx.fillStyle = \"rgb(0, 255, 0, 0.15)\";\r\n                ctx.beginPath();\r\n                if (smoothCurve && points.length > 2) {\r\n                    // Draw smooth curve for fill\r\n                    this.drawSmoothCurve(ctx, points);\r\n                }\r\n                else {\r\n                    // Draw straight lines\r\n                    ctx.moveTo(points[0].x, points[0].y);\r\n                    for (let i = 1; i < points.length; i++) {\r\n                        ctx.lineTo(points[i].x, points[i].y);\r\n                    }\r\n                }\r\n                // Close the path to create fill area\r\n                ctx.lineTo(points[points.length - 1].x, BOTTOM_Y);\r\n                ctx.lineTo(points[0].x, BOTTOM_Y);\r\n                ctx.closePath();\r\n                ctx.fill();\r\n            }\r\n            // Draw the curve line\r\n            ctx.lineWidth = 1.5;\r\n            ctx.lineCap = 'round';\r\n            ctx.lineJoin = 'round';\r\n            ctx.strokeStyle = color;\r\n            ctx.beginPath();\r\n            if (smoothCurve && points.length > 2) {\r\n                // Draw smooth curve\r\n                this.drawSmoothCurve(ctx, points);\r\n            }\r\n            else {\r\n                // Draw straight lines\r\n                ctx.moveTo(points[0].x, points[0].y);\r\n                for (let i = 1; i < points.length; i++) {\r\n                    ctx.lineTo(points[i].x, points[i].y);\r\n                }\r\n            }\r\n            ctx.stroke();\r\n        };\r\n        // Helper for drawing smooth bezier curves\r\n        this.drawSmoothCurve = (ctx, points) => {\r\n            if (points.length < 2)\r\n                return;\r\n            // Move to first point\r\n            ctx.moveTo(points[0].x, points[0].y);\r\n            if (points.length === 2) {\r\n                // Just draw a line if only 2 points\r\n                ctx.lineTo(points[1].x, points[1].y);\r\n                return;\r\n            }\r\n            // Draw bezier curves for smoother line\r\n            for (let i = 1; i < points.length - 1; i++) {\r\n                const xc = (points[i].x + points[i + 1].x) / 2;\r\n                const yc = (points[i].y + points[i + 1].y) / 2;\r\n                // Quadratic bezier curve\r\n                ctx.quadraticCurveTo(points[i].x, points[i].y, xc, yc);\r\n            }\r\n            // Curve through the last two points\r\n            ctx.quadraticCurveTo(points[points.length - 1].x, points[points.length - 1].y, points[points.length - 1].x, points[points.length - 1].y);\r\n        };\r\n    }\r\n    get _width() { return this._viewport.videoWidth; }\r\n    get _height() { return this._viewport.videoHeight; }\r\n}\r\nclass DeltaValues {\r\n    constructor() {\r\n        this._h = new DeltaValue();\r\n        this._s = new DeltaValue();\r\n        this._v = new DeltaValue();\r\n        this.add = (value) => {\r\n            this._h.add(value.h);\r\n            // this._s.add(value.s);\r\n            // this._v.add(value.v);\r\n        };\r\n    }\r\n    get hue() { return this._h; }\r\n    get saturation() { return this._s; }\r\n    get brightness() { return this._v; }\r\n}\r\nclass DeltaValue {\r\n    constructor() {\r\n        this._values = {\r\n            cached: [] = [],\r\n            average: Number,\r\n        };\r\n        this.size = _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.MOTION_DETECT_HEAP_SIZE * 3;\r\n        this.add = (value) => {\r\n            this._values.cached.push(value);\r\n            this.updateCached();\r\n            this.updateAverage();\r\n        };\r\n        this.updateAverage = () => {\r\n            this._values.average = this._values.cached.length ? this._values.cached.reduce((previous, current) => previous + current) / this._values.cached.length : 0;\r\n        };\r\n        this.updateCached = () => {\r\n            if (this._values.cached.length > this.size) {\r\n                this._values.cached.shift();\r\n            }\r\n        };\r\n    }\r\n    get average() {\r\n        return this._values.average;\r\n    }\r\n    get cached() {\r\n        return this._values.cached;\r\n    }\r\n    get length() {\r\n        return this._values.cached.length;\r\n    }\r\n    get last() {\r\n        return this.cached.length ?\r\n            this.cached[this.cached.length - 1] : undefined;\r\n    }\r\n}\r\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (new MotionDetector());\r\n\n\n//# sourceURL=webpack://html-peer-viewer/./src/motion/MotionDetector.ts?\n}");

/***/ }),

/***/ "./src/network/RestService.ts":
/*!************************************!*\
  !*** ./src/network/RestService.ts ***!
  \************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   RestService: () => (/* binding */ RestService),\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _utils_Events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/Events */ \"./src/utils/Events.ts\");\n/* harmony import */ var axios__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! axios */ \"./node_modules/axios/lib/axios.js\");\n/* harmony import */ var _utils_Utils__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/Utils */ \"./src/utils/Utils.ts\");\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\r\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\r\n    return new (P || (P = Promise))(function (resolve, reject) {\r\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\r\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\r\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\r\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\r\n    });\r\n};\r\n\r\n\r\n\r\nclass RestService {\r\n    //private TIME_ZONE: string = 'Europe/Kyiv';\r\n    constructor() {\r\n        this.SERVER_URL = 'https://nodejs-http-server.onrender.com/';\r\n        this.initialize = () => __awaiter(this, void 0, void 0, function* () {\r\n            _utils_Events__WEBPACK_IMPORTED_MODULE_0__[\"default\"].addEventListener(_utils_Events__WEBPACK_IMPORTED_MODULE_0__.SNAPSHOT_SEND_HOMIE, (data) => this.sendSnaphot(data));\r\n        });\r\n        this.sendSnaphot = (snapshot) => {\r\n            // const name: string = new Date().toLocaleString('ua-UA', { timeZone: this.TIME_ZONE })\r\n            //  .replace(/:/g, '.').replace(', ', '-') + '.png';\r\n            const name = (0,_utils_Utils__WEBPACK_IMPORTED_MODULE_2__.generateSortableFileName)() + '.png';\r\n            (0,axios__WEBPACK_IMPORTED_MODULE_1__[\"default\"])({\r\n                method: 'post',\r\n                url: this.SERVER_URL + 'snapshot',\r\n                data: { file: snapshot, name: name, pin: localStorage.getItem('pinhash') }\r\n            });\r\n        };\r\n        this.getSnapshot = (month, name) => __awaiter(this, void 0, void 0, function* () {\r\n            const response = yield axios__WEBPACK_IMPORTED_MODULE_1__[\"default\"].get(this.SERVER_URL + 'snapshot', {\r\n                params: {\r\n                    month: month,\r\n                    name: name,\r\n                    pin: localStorage.getItem('pinhash')\r\n                }\r\n            });\r\n            const url = 'data:image/png;base64,'.concat(response.data);\r\n            return url;\r\n        });\r\n        this.deleteSnapshot = (month, name) => __awaiter(this, void 0, void 0, function* () {\r\n            const response = yield axios__WEBPACK_IMPORTED_MODULE_1__[\"default\"].get(this.SERVER_URL + 'delsnapshot', {\r\n                params: {\r\n                    month: month,\r\n                    name: name,\r\n                    pin: localStorage.getItem('pinhash')\r\n                }\r\n            });\r\n            return response.data;\r\n        });\r\n        this.getFilesList = () => {\r\n            return axios__WEBPACK_IMPORTED_MODULE_1__[\"default\"].get(this.SERVER_URL + 'lsall', {\r\n                params: {\r\n                    pin: localStorage.getItem('pinhash')\r\n                }\r\n            });\r\n        };\r\n        this.validatePrediction = (prediction) => __awaiter(this, void 0, void 0, function* () {\r\n            const response = yield axios__WEBPACK_IMPORTED_MODULE_1__[\"default\"].get(this.SERVER_URL + 'valprediction', {\r\n                params: {\r\n                    prediction: prediction,\r\n                    pin: localStorage.getItem('pinhash')\r\n                }\r\n            });\r\n            return response.data;\r\n        });\r\n        this.validatePinhash = (hash) => __awaiter(this, void 0, void 0, function* () {\r\n            const response = yield axios__WEBPACK_IMPORTED_MODULE_1__[\"default\"].get(this.SERVER_URL + 'login', {\r\n                params: {\r\n                    pin: hash,\r\n                }\r\n            });\r\n            return response.data;\r\n        });\r\n        this.updateAudioVolume = (volume) => __awaiter(this, void 0, void 0, function* () {\r\n            (0,axios__WEBPACK_IMPORTED_MODULE_1__[\"default\"])({\r\n                method: 'post',\r\n                url: this.SERVER_URL + 'setvolume',\r\n                data: { volume: volume }\r\n            });\r\n        });\r\n        this.getAudioVolume = () => __awaiter(this, void 0, void 0, function* () {\r\n            const response = yield axios__WEBPACK_IMPORTED_MODULE_1__[\"default\"].get(this.SERVER_URL + 'getvolume', {\r\n                params: {\r\n                    pin: localStorage.getItem('pinhash')\r\n                }\r\n            });\r\n            return response.data;\r\n        });\r\n        this.addPeerId = (id) => __awaiter(this, void 0, void 0, function* () {\r\n            (0,axios__WEBPACK_IMPORTED_MODULE_1__[\"default\"])({\r\n                method: 'post',\r\n                url: this.SERVER_URL + 'addpeerid',\r\n                data: { id: id }\r\n            });\r\n        });\r\n        this.removePeerId = (id) => __awaiter(this, void 0, void 0, function* () {\r\n            (0,axios__WEBPACK_IMPORTED_MODULE_1__[\"default\"])({\r\n                method: 'post',\r\n                url: this.SERVER_URL + 'removepeerid',\r\n                data: { id: id }\r\n            });\r\n        });\r\n        this.getPeersIds = () => __awaiter(this, void 0, void 0, function* () {\r\n            return axios__WEBPACK_IMPORTED_MODULE_1__[\"default\"].get(this.SERVER_URL + 'getpeersids', {\r\n                params: {\r\n                    pin: localStorage.getItem('pinhash')\r\n                }\r\n            });\r\n        });\r\n        this.heartBeat = (peerId) => __awaiter(this, void 0, void 0, function* () {\r\n            return (0,axios__WEBPACK_IMPORTED_MODULE_1__[\"default\"])({\r\n                method: 'post',\r\n                url: this.SERVER_URL + 'heartbeat',\r\n                data: { id: peerId },\r\n                //signal: AbortSignal.timeout(5000)\r\n            });\r\n        });\r\n    }\r\n}\r\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (new RestService());\r\n\n\n//# sourceURL=webpack://html-peer-viewer/./src/network/RestService.ts?\n}");

/***/ }),

/***/ "./src/network/StreamProvider.ts":
/*!***************************************!*\
  !*** ./src/network/StreamProvider.ts ***!
  \***************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   StreamProvider: () => (/* binding */ StreamProvider),\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _utils_Events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/Events */ \"./src/utils/Events.ts\");\n/* harmony import */ var peerjs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! peerjs */ \"./node_modules/peerjs/dist/bundler.mjs\");\n/* harmony import */ var uuid__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! uuid */ \"./node_modules/uuid/dist/esm-browser/v4.js\");\n/* harmony import */ var _RestService__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./RestService */ \"./src/network/RestService.ts\");\n/* harmony import */ var _store_Model__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../store/Model */ \"./src/store/Model.ts\");\n/* harmony import */ var _view_View__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../view/View */ \"./src/view/View.ts\");\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\r\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\r\n    return new (P || (P = Promise))(function (resolve, reject) {\r\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\r\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\r\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\r\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\r\n    });\r\n};\r\n\r\n\r\n\r\n\r\n\r\n\r\nconst id = (device = !!screen.orientation ? \"static-\" : \"mobile-\") => device + uuid__WEBPACK_IMPORTED_MODULE_2__[\"default\"]();\r\nclass StreamProvider {\r\n    constructor() {\r\n        this._streamers = new Map();\r\n        this._index = 0;\r\n        this._peer = null;\r\n        this._activeStreamerId = null;\r\n        this._isInitialized = false;\r\n        this._isNetworkOffline = false;\r\n        this._reconnectTimeout = null;\r\n        this._streamCleanupTimeouts = new Map();\r\n        this._peerReconnectAttempts = 0;\r\n        this.MAX_RECONNECT_ATTEMPTS = 10;\r\n        this.RECONNECT_DELAY = 3000;\r\n        this.initialize = (local = false, streams = undefined) => __awaiter(this, void 0, void 0, function* () {\r\n            if (local) {\r\n                this._streams = streams;\r\n                this.initializeLocalStream();\r\n            }\r\n            else {\r\n                yield this.initializePeerStream();\r\n            }\r\n            this._isInitialized = true;\r\n            return this;\r\n        });\r\n        this.switchStreamQuality = (quality) => {\r\n            if (this._streams) {\r\n                _view_View__WEBPACK_IMPORTED_MODULE_5__[\"default\"].displayStream(this._streams.get(quality));\r\n            }\r\n        };\r\n        this.getNextStream = () => {\r\n            const activeStreamers = Array.from(this._streamers.values()).filter(s => s.stream);\r\n            if (activeStreamers.length === 0) {\r\n                _utils_Events__WEBPACK_IMPORTED_MODULE_0__[\"default\"].dispatchEvent(_utils_Events__WEBPACK_IMPORTED_MODULE_0__.NO_STREAMS_AVAILABLE);\r\n                return null;\r\n            }\r\n            if (this._index >= activeStreamers.length - 1) {\r\n                this._index = 0;\r\n            }\r\n            else {\r\n                this._index = this._index + 1;\r\n            }\r\n            const streamer = activeStreamers[this._index];\r\n            this._activeStreamerId = (streamer === null || streamer === void 0 ? void 0 : streamer.id) || null;\r\n            return (streamer === null || streamer === void 0 ? void 0 : streamer.stream) || null;\r\n        };\r\n        this.switchToStreamer = (streamerId) => {\r\n            const streamer = this._streamers.get(streamerId);\r\n            if (streamer === null || streamer === void 0 ? void 0 : streamer.stream) {\r\n                this._activeStreamerId = streamerId;\r\n                return streamer.stream;\r\n            }\r\n            return null;\r\n        };\r\n        this.getActiveStreamerId = () => {\r\n            return this._activeStreamerId;\r\n        };\r\n        this.getAllStreamers = () => {\r\n            return Array.from(this._streamers.entries()).map(([id, streamer]) => ({\r\n                id,\r\n                hasStream: !!streamer.stream\r\n            }));\r\n        };\r\n        this.triggerReconnect = () => {\r\n            console.log('[StreamProvider] Manual reconnect triggered');\r\n            this.reconnectPeer();\r\n        };\r\n        this.getAllPeersIds = () => __awaiter(this, void 0, void 0, function* () {\r\n            var _a;\r\n            try {\r\n                if (this._isNetworkOffline) {\r\n                    console.log('[StreamProvider] Network offline, skipping peer list fetch');\r\n                    return;\r\n                }\r\n                const response = yield _RestService__WEBPACK_IMPORTED_MODULE_3__[\"default\"].getPeersIds();\r\n                const peerIds = ((_a = response.data) === null || _a === void 0 ? void 0 : _a.data) || [];\r\n                _store_Model__WEBPACK_IMPORTED_MODULE_4__[\"default\"].streamersTotalCount = peerIds.length;\r\n                // Remove streamers that no longer exist\r\n                const currentIds = new Set(peerIds);\r\n                for (const [id, streamer] of this._streamers) {\r\n                    if (!currentIds.has(id)) {\r\n                        this.handleStreamLost(id, 'streamer_removed_from_server');\r\n                    }\r\n                }\r\n                // Add new streamers\r\n                peerIds.forEach((id) => {\r\n                    if (!this._streamers.has(id)) {\r\n                        this._streamers.set(id, new Streamer(id));\r\n                    }\r\n                });\r\n            }\r\n            catch (error) {\r\n                console.error('[StreamProvider] Failed to get peer IDs:', error);\r\n            }\r\n        });\r\n        this.handleNetworkOnline = () => {\r\n            console.log('[StreamProvider] Network is back online');\r\n            this._isNetworkOffline = false;\r\n            _utils_Events__WEBPACK_IMPORTED_MODULE_0__[\"default\"].dispatchEvent(_utils_Events__WEBPACK_IMPORTED_MODULE_0__.NETWORK_ONLINE);\r\n            // Reset reconnect attempts\r\n            this._peerReconnectAttempts = 0;\r\n            // Clear any pending reconnect\r\n            if (this._reconnectTimeout) {\r\n                clearTimeout(this._reconnectTimeout);\r\n                this._reconnectTimeout = null;\r\n            }\r\n            // Reconnect immediately\r\n            this.reconnectPeer();\r\n        };\r\n        this.handleNetworkOffline = () => {\r\n            console.log('[StreamProvider] Network went offline');\r\n            this._isNetworkOffline = true;\r\n            _utils_Events__WEBPACK_IMPORTED_MODULE_0__[\"default\"].dispatchEvent(_utils_Events__WEBPACK_IMPORTED_MODULE_0__.NETWORK_OFFLINE);\r\n            // Clear all streams immediately\r\n            this.clearAllStreams('network_offline');\r\n        };\r\n        this.clearAllStreams = (reason) => {\r\n            console.log(`[StreamProvider] Clearing all streams due to: ${reason}`);\r\n            // Clear active stream first\r\n            if (this._activeStreamerId) {\r\n                const activeStreamer = this._streamers.get(this._activeStreamerId);\r\n                if (activeStreamer === null || activeStreamer === void 0 ? void 0 : activeStreamer.stream) {\r\n                    _utils_Events__WEBPACK_IMPORTED_MODULE_0__[\"default\"].dispatchEvent(_utils_Events__WEBPACK_IMPORTED_MODULE_0__.STREAM_LOST, {\r\n                        streamerId: this._activeStreamerId,\r\n                        reason,\r\n                        timestamp: Date.now()\r\n                    });\r\n                }\r\n            }\r\n            // Clear all streams\r\n            this._streamers.forEach(streamer => {\r\n                if (streamer.stream) {\r\n                    this.cleanupStream(streamer.id);\r\n                }\r\n            });\r\n        };\r\n        this.cleanupStream = (streamerId) => {\r\n            const streamer = this._streamers.get(streamerId);\r\n            if (!streamer)\r\n                return;\r\n            // Clear any existing cleanup timeout\r\n            const existingTimeout = this._streamCleanupTimeouts.get(streamerId);\r\n            if (existingTimeout) {\r\n                clearTimeout(existingTimeout);\r\n                this._streamCleanupTimeouts.delete(streamerId);\r\n            }\r\n            // Schedule immediate cleanup\r\n            const cleanupTimeout = setTimeout(() => {\r\n                if (streamer.stream) {\r\n                    console.log(`[StreamProvider] Cleaning up stream for ${streamerId}`);\r\n                    // Stop all tracks\r\n                    streamer.stream.getTracks().forEach(track => {\r\n                        track.stop();\r\n                        if (streamer.stream) {\r\n                            streamer.stream.removeTrack(track);\r\n                        }\r\n                    });\r\n                    // Set stream to null\r\n                    streamer.stream = null;\r\n                    // Dispatch generic stream lost event\r\n                    _utils_Events__WEBPACK_IMPORTED_MODULE_0__[\"default\"].dispatchEvent(_utils_Events__WEBPACK_IMPORTED_MODULE_0__.STREAM_LOST_GENERIC, {\r\n                        streamerId,\r\n                        reason: 'cleanup',\r\n                        timestamp: Date.now()\r\n                    });\r\n                    this._streamCleanupTimeouts.delete(streamerId);\r\n                }\r\n            }, 0);\r\n            this._streamCleanupTimeouts.set(streamerId, cleanupTimeout);\r\n        };\r\n        this.initializePeerStream = () => __awaiter(this, void 0, void 0, function* () {\r\n            console.log('[StreamProvider] Initializing peer stream');\r\n            yield this.getAllPeersIds();\r\n            this.startPeerListRefresh();\r\n            this.createPeer();\r\n        });\r\n        this.createPeer = () => {\r\n            console.log('[StreamProvider] Creating new peer instance');\r\n            // Clean up old peer if exists\r\n            this.destroyPeer();\r\n            const params = {\r\n                host: \"nodejs-peer-server.onrender.com\",\r\n                path: \"/peer\",\r\n                secure: true,\r\n                config: {\r\n                    iceServers: [\r\n                        { urls: 'stun:stun.l.google.com:19302' },\r\n                        { urls: 'stun:global.stun.twilio.com:3478' }\r\n                    ]\r\n                }\r\n            };\r\n            this._peer = new peerjs__WEBPACK_IMPORTED_MODULE_1__.Peer(id(), params);\r\n            this.setupPeerEventHandlers();\r\n        };\r\n        this.destroyPeer = () => {\r\n            if (this._peer) {\r\n                console.log('[StreamProvider] Destroying old peer');\r\n                // Remove all listeners\r\n                this._peer.off('open');\r\n                this._peer.off('disconnected');\r\n                this._peer.off('close');\r\n                this._peer.off('error');\r\n                this._peer.off('call');\r\n                // Destroy peer\r\n                try {\r\n                    this._peer.disconnect();\r\n                    this._peer.destroy();\r\n                }\r\n                catch (error) {\r\n                    console.error('[StreamProvider] Error destroying peer:', error);\r\n                }\r\n                this._peer = null;\r\n            }\r\n            // Clear reconnect timeout\r\n            if (this._reconnectTimeout) {\r\n                clearTimeout(this._reconnectTimeout);\r\n                this._reconnectTimeout = null;\r\n            }\r\n        };\r\n        this.setupPeerEventHandlers = () => {\r\n            if (!this._peer)\r\n                return;\r\n            this._peer.on('open', () => {\r\n                console.log('[StreamProvider] Peer connected with ID:', this._peer.id);\r\n                this._peerReconnectAttempts = 0;\r\n                _utils_Events__WEBPACK_IMPORTED_MODULE_0__[\"default\"].dispatchEvent(_utils_Events__WEBPACK_IMPORTED_MODULE_0__.PEER_CONNECTED, { peerId: this._peer.id });\r\n                // Connect to all streamers\r\n                this.connectToAllStreamers();\r\n                // Set up call handler\r\n                this.setupCallHandler();\r\n            });\r\n            this._peer.on('disconnected', () => {\r\n                console.log('[StreamProvider] Peer disconnected');\r\n                _utils_Events__WEBPACK_IMPORTED_MODULE_0__[\"default\"].dispatchEvent(_utils_Events__WEBPACK_IMPORTED_MODULE_0__.PEER_DISCONNECTED);\r\n                this.clearAllStreams('peer_disconnected');\r\n                this.reconnectPeer();\r\n            });\r\n            this._peer.on('close', () => {\r\n                console.log('[StreamProvider] Peer connection closed');\r\n                _utils_Events__WEBPACK_IMPORTED_MODULE_0__[\"default\"].dispatchEvent(_utils_Events__WEBPACK_IMPORTED_MODULE_0__.PEER_CLOSED);\r\n                this.clearAllStreams('peer_closed');\r\n                this.reconnectPeer();\r\n            });\r\n            this._peer.on('error', (error) => {\r\n                console.error('[StreamProvider] Peer error:', error.type, error.message);\r\n                if (error.type === 'network') {\r\n                    this.clearAllStreams('network_error');\r\n                }\r\n                _utils_Events__WEBPACK_IMPORTED_MODULE_0__[\"default\"].dispatchEvent(_utils_Events__WEBPACK_IMPORTED_MODULE_0__.PEER_ERROR, error);\r\n                this.reconnectPeer();\r\n            });\r\n        };\r\n        this.setupCallHandler = () => {\r\n            if (!this._peer)\r\n                return;\r\n            this._peer.on('call', (call) => {\r\n                console.log('[StreamProvider] Incoming call from:', call.peer);\r\n                call.on('stream', (stream) => {\r\n                    console.log('[StreamProvider] Stream received from:', call.peer);\r\n                    const streamer = this._streamers.get(call.peer);\r\n                    if (streamer) {\r\n                        // Clean up old stream first\r\n                        //this.cleanupStream(call.peer);\r\n                        // Set new stream\r\n                        streamer.setStream(stream);\r\n                        // Dispatch STREAM_RECEIVED event\r\n                        console.log('[StreamProvider] Dispatching STREAM_RECEIVED for:', call.peer);\r\n                        _utils_Events__WEBPACK_IMPORTED_MODULE_0__[\"default\"].dispatchEvent(_utils_Events__WEBPACK_IMPORTED_MODULE_0__.STREAM_RECEIVED, {\r\n                            streamerId: call.peer,\r\n                            stream: stream,\r\n                            timestamp: Date.now()\r\n                        });\r\n                        // If this is the active streamer, also dispatch active stream received\r\n                        if (this._activeStreamerId === call.peer) {\r\n                            _utils_Events__WEBPACK_IMPORTED_MODULE_0__[\"default\"].dispatchEvent(_utils_Events__WEBPACK_IMPORTED_MODULE_0__.ACTIVE_STREAM_RECEIVED, {\r\n                                streamerId: call.peer,\r\n                                stream: stream,\r\n                                timestamp: Date.now()\r\n                            });\r\n                        }\r\n                    }\r\n                    else {\r\n                        console.error('[StreamProvider] Received stream for unknown streamer:', call.peer);\r\n                    }\r\n                });\r\n                call.on('close', () => {\r\n                    console.log('[StreamProvider] Call closed from:', call.peer);\r\n                    this.handleStreamLost(call.peer, 'call_closed');\r\n                });\r\n                call.on('error', (error) => {\r\n                    console.error('[StreamProvider] Call error from:', call.peer, error);\r\n                    this.handleStreamLost(call.peer, 'call_error');\r\n                });\r\n                // Answer the call\r\n                call.answer(null);\r\n            });\r\n        };\r\n        this.connectToAllStreamers = () => {\r\n            if (!this._peer)\r\n                return;\r\n            const streamerIds = Array.from(this._streamers.keys());\r\n            console.log(`[StreamProvider] Connecting to ${streamerIds.length} streamers`);\r\n            streamerIds.forEach((streamerId, index) => {\r\n                setTimeout(() => {\r\n                    this.connectToStreamer(streamerId);\r\n                }, index * 500); // Stagger connections\r\n            });\r\n        };\r\n        this.connectToStreamer = (streamerId) => {\r\n            if (!this._peer) {\r\n                console.log('[StreamProvider] No peer available for connection');\r\n                return;\r\n            }\r\n            try {\r\n                console.log(`[StreamProvider] Connecting to streamer: ${streamerId}`);\r\n                const connection = this._peer.connect(streamerId, {\r\n                    reliable: true,\r\n                    serialization: 'json'\r\n                });\r\n                connection === null || connection === void 0 ? void 0 : connection.on('open', () => {\r\n                    console.log(`[StreamProvider] Connected to streamer: ${streamerId}`);\r\n                    connection.send({ type: 'custom-media-stream-request', quality: _store_Model__WEBPACK_IMPORTED_MODULE_4__[\"default\"].prefferedStreamQuality });\r\n                });\r\n                connection === null || connection === void 0 ? void 0 : connection.on('close', () => {\r\n                    console.log(`[StreamProvider] Connection closed to streamer: ${streamerId}`);\r\n                    this.handleStreamLost(streamerId, 'connection_closed');\r\n                });\r\n                connection === null || connection === void 0 ? void 0 : connection.on('error', (error) => {\r\n                    console.error(`[StreamProvider] Connection error to streamer: ${streamerId}`, error);\r\n                    this.handleStreamLost(streamerId, 'connection_error');\r\n                });\r\n            }\r\n            catch (error) {\r\n                console.error(`[StreamProvider] Failed to connect to streamer: ${streamerId}`, error);\r\n                this.handleStreamLost(streamerId, 'connection_failed');\r\n            }\r\n        };\r\n        this.handleStreamLost = (streamerId, reason) => {\r\n            console.log(`[StreamProvider] Stream lost from ${streamerId}, reason: ${reason}`);\r\n            // Clean up the stream\r\n            this.cleanupStream(streamerId);\r\n            // If this is the active streamer, dispatch STREAM_LOST event\r\n            if (this._activeStreamerId === streamerId) {\r\n                _utils_Events__WEBPACK_IMPORTED_MODULE_0__[\"default\"].dispatchEvent(_utils_Events__WEBPACK_IMPORTED_MODULE_0__.STREAM_LOST, {\r\n                    streamerId,\r\n                    reason,\r\n                    timestamp: Date.now()\r\n                });\r\n                // Try to switch to another stream\r\n                const nextStream = this.getNextStream();\r\n                if (nextStream) {\r\n                    _utils_Events__WEBPACK_IMPORTED_MODULE_0__[\"default\"].dispatchEvent(_utils_Events__WEBPACK_IMPORTED_MODULE_0__.STREAM_SWITCHED, {\r\n                        from: streamerId,\r\n                        to: this._activeStreamerId,\r\n                        stream: nextStream\r\n                    });\r\n                }\r\n            }\r\n        };\r\n        this.reconnectPeer = () => {\r\n            // Clear any existing timeout\r\n            if (this._reconnectTimeout) {\r\n                clearTimeout(this._reconnectTimeout);\r\n                this._reconnectTimeout = null;\r\n            }\r\n            // Check max attempts\r\n            if (this._peerReconnectAttempts >= this.MAX_RECONNECT_ATTEMPTS) {\r\n                console.error('[StreamProvider] Max reconnect attempts reached');\r\n                _utils_Events__WEBPACK_IMPORTED_MODULE_0__[\"default\"].dispatchEvent(_utils_Events__WEBPACK_IMPORTED_MODULE_0__.PEER_RECONNECT_FAILED);\r\n                _utils_Events__WEBPACK_IMPORTED_MODULE_0__[\"default\"].dispatchEvent(_utils_Events__WEBPACK_IMPORTED_MODULE_0__.MANUAL_RECONNECT_REQUIRED);\r\n                return;\r\n            }\r\n            this._peerReconnectAttempts++;\r\n            // Calculate delay with exponential backoff, capped at 30 seconds\r\n            const delay = Math.min(this.RECONNECT_DELAY * Math.pow(1.5, this._peerReconnectAttempts - 1), 30000);\r\n            console.log(`[StreamProvider] Will recreate peer in ${delay}ms (attempt ${this._peerReconnectAttempts})`);\r\n            this._reconnectTimeout = setTimeout(() => {\r\n                console.log('[StreamProvider] Recreating peer...');\r\n                this.createPeer();\r\n            }, delay);\r\n        };\r\n        this.startPeerListRefresh = () => {\r\n            // Refresh peer list every 30 seconds\r\n            setInterval(() => __awaiter(this, void 0, void 0, function* () {\r\n                try {\r\n                    yield this.getAllPeersIds();\r\n                    console.log('[StreamProvider] Refreshed peer list');\r\n                    // If peer is connected, connect to new streamers\r\n                    if (this._peer) {\r\n                        const streamerIds = Array.from(this._streamers.keys());\r\n                        streamerIds.forEach(streamerId => {\r\n                            const streamer = this._streamers.get(streamerId);\r\n                            if (streamer && !streamer.stream) {\r\n                                this.connectToStreamer(streamerId);\r\n                            }\r\n                        });\r\n                    }\r\n                }\r\n                catch (error) {\r\n                    console.error('[StreamProvider] Failed to refresh peer list:', error);\r\n                }\r\n            }), 30000);\r\n        };\r\n        this.initializeLocalStream = () => {\r\n            this.startPeerListRefresh();\r\n            _utils_Events__WEBPACK_IMPORTED_MODULE_0__[\"default\"].dispatchEvent(_utils_Events__WEBPACK_IMPORTED_MODULE_0__.STREAM_RECEIVED);\r\n        };\r\n        this.destroy = () => {\r\n            console.log('[StreamProvider] Destroying...');\r\n            // Remove network listeners\r\n            window.removeEventListener('online', this.handleNetworkOnline);\r\n            window.removeEventListener('offline', this.handleNetworkOffline);\r\n            // Clear all timeouts\r\n            if (this._reconnectTimeout) {\r\n                clearTimeout(this._reconnectTimeout);\r\n                this._reconnectTimeout = null;\r\n            }\r\n            this._streamCleanupTimeouts.forEach(timeout => clearTimeout(timeout));\r\n            this._streamCleanupTimeouts.clear();\r\n            // Clear all streams\r\n            this._streamers.forEach(streamer => {\r\n                if (streamer.stream) {\r\n                    streamer.stream.getTracks().forEach(track => track.stop());\r\n                    streamer.stream = null;\r\n                }\r\n            });\r\n            this._streamers.clear();\r\n            // Destroy peer\r\n            this.destroyPeer();\r\n            console.log('[StreamProvider] Destroyed');\r\n        };\r\n        window.addEventListener('online', this.handleNetworkOnline.bind(this));\r\n        window.addEventListener('offline', this.handleNetworkOffline.bind(this));\r\n        window.onbeforeunload = () => this.destroy();\r\n        window.onpagehide = () => this.destroy();\r\n    }\r\n}\r\nclass Streamer {\r\n    get pending() {\r\n        return !this.stream;\r\n    }\r\n    constructor(id) {\r\n        this.stream = null;\r\n        this.setStream = (stream) => {\r\n            // Clean up old stream if exists\r\n            if (this.stream) {\r\n                this.stream.getTracks().forEach(track => track.stop());\r\n            }\r\n            this.stream = stream;\r\n            // Set up track ended listeners\r\n            stream.getTracks().forEach(track => {\r\n                track.onended = () => {\r\n                    console.log(`[Streamer ${this.id}] Track ended`);\r\n                    this.stream = null;\r\n                };\r\n            });\r\n            return stream;\r\n        };\r\n        this.id = id;\r\n    }\r\n}\r\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (new StreamProvider());\r\n\n\n//# sourceURL=webpack://html-peer-viewer/./src/network/StreamProvider.ts?\n}");

/***/ }),

/***/ "./src/record/Snaphots.ts":
/*!********************************!*\
  !*** ./src/record/Snaphots.ts ***!
  \********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _tweenjs_tween_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @tweenjs/tween.js */ \"./node_modules/@tweenjs/tween.js/dist/tween.esm.js\");\n/* harmony import */ var _utils_Constants__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/Constants */ \"./src/utils/Constants.ts\");\n/* harmony import */ var _utils_Utils__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/Utils */ \"./src/utils/Utils.ts\");\n/* harmony import */ var _view_Controls__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../view/Controls */ \"./src/view/Controls.ts\");\n/* harmony import */ var file_saver__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! file-saver */ \"./node_modules/file-saver/dist/FileSaver.min.js\");\n/* harmony import */ var file_saver__WEBPACK_IMPORTED_MODULE_4___default = /*#__PURE__*/__webpack_require__.n(file_saver__WEBPACK_IMPORTED_MODULE_4__);\n/* harmony import */ var _network_StreamProvider__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../network/StreamProvider */ \"./src/network/StreamProvider.ts\");\n/* harmony import */ var _utils_MobileUtils__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../utils/MobileUtils */ \"./src/utils/MobileUtils.ts\");\n/* harmony import */ var _utils_Events__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../utils/Events */ \"./src/utils/Events.ts\");\n/* harmony import */ var _utils_HlsUtil__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../utils/HlsUtil */ \"./src/utils/HlsUtil.ts\");\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\r\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\r\n    return new (P || (P = Promise))(function (resolve, reject) {\r\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\r\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\r\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\r\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\r\n    });\r\n};\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nclass Snaphots {\r\n    constructor() {\r\n        this._count = 0;\r\n        this.initialize = () => __awaiter(this, void 0, void 0, function* () {\r\n            this._container = document.getElementById(\"view-page\");\r\n            this._viewport = document.querySelector(\"video\");\r\n            this._viewport.addEventListener(\"click\", this.onViewportClick);\r\n            _utils_MobileUtils__WEBPACK_IMPORTED_MODULE_6__[\"default\"].on(document).addEventListener(_utils_Events__WEBPACK_IMPORTED_MODULE_7__.MOBILE_SWIPE_RIGHT, this.onViewportClick);\r\n            //   this._viewport.addEventListener(\"touchstart\", this.onViewportClick);\r\n            this._snapsaver = document.createElement(\"canvas\");\r\n            this._container.appendChild(this._snapsaver);\r\n            this._snapsaver.style.setProperty('position', 'absolute');\r\n            this._snapsaver.addEventListener(\"click\", this.onViewportClick);\r\n            // this._snapsaver.addEventListener(\"touchstart\", this.onViewportClick);\r\n            this._snapsaver.style.setProperty('transform', 'translate(' + 0 + 'px,' + 0 + 'px)' + 'scale(' + 1 + ',' + 1 + ')');\r\n            let context = this._snapsaver.getContext('2d', { willReadFrequently: true });\r\n            context.clearRect(0, 0, _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.VIDEO_WIDTH, _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.VIDEO_HEIGHT);\r\n            this._snapshot = document.createElement(\"canvas\");\r\n            this._container.appendChild(this._snapshot);\r\n            this._snapshot.style.setProperty('position', 'absolute');\r\n            this._snapshot.width = _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.SNAP_WIDTH;\r\n            this._snapshot.height = _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.SNAP_HEIGHT;\r\n            this._snapshot.getContext('2d', { willReadFrequently: true }).globalAlpha = 0;\r\n            this._snapshot.getContext('2d').beginPath();\r\n            this._snapshot.getContext('2d').lineWidth = \"0\";\r\n            this._snapshot.getContext('2d').strokeStyle = \"black\";\r\n            this._snapshot.getContext('2d').rect(0, 0, _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.SNAP_WIDTH, _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.SNAP_HEIGHT);\r\n            this._snapshot.getContext('2d').stroke();\r\n            //this._snapshot.onclick = () => this.viewSnapshotCollection();\r\n            this._proxy = document.createElement(\"canvas\");\r\n            this.createBufferCanvas();\r\n            _utils_Events__WEBPACK_IMPORTED_MODULE_7__[\"default\"].addEventListener(_utils_Events__WEBPACK_IMPORTED_MODULE_7__.MOTION_DETECTION_STARTED, (data) => this.create('', false, data));\r\n            requestAnimationFrame(this.tick);\r\n        });\r\n        this.createBufferCanvas = () => {\r\n            try {\r\n                this._buffer = new OffscreenCanvas(_utils_Constants__WEBPACK_IMPORTED_MODULE_1__.VIDEO_WIDTH * _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.SNAP_COUNT, _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.VIDEO_HEIGHT * _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.SNAP_COUNT);\r\n            }\r\n            catch (error) {\r\n                this._buffer = document.createElement(\"canvas\");\r\n            }\r\n            this._buffer.width = _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.VIDEO_WIDTH * _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.SNAP_COUNT;\r\n            this._buffer.height = _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.VIDEO_HEIGHT * _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.SNAP_COUNT;\r\n            this._buffer.getContext('2d', { willReadFrequently: true }).beginPath();\r\n            this._buffer.getContext('2d').lineWidth = 1;\r\n            this._buffer.getContext('2d').strokeStyle = \"black\";\r\n            this._buffer.getContext('2d').rect(0, 0, _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.VIDEO_WIDTH * 5, _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.VIDEO_HEIGHT * 5);\r\n            this._buffer.getContext('2d').stroke();\r\n        };\r\n        this.create = (source = '', send = false, data = null) => {\r\n            this.createSnaphot(this.drawCanvasFromVideo(this._proxy, this._viewport, source, data), send);\r\n        };\r\n        this.onViewportClick = (event) => {\r\n            this.switchStreams();\r\n            //this.createSnaphot(this.drawCanvasFromVideo(this._proxy, this._viewport, \"manual\"), true);\r\n        };\r\n        this.switchStreams = () => {\r\n            _utils_Events__WEBPACK_IMPORTED_MODULE_7__[\"default\"].dispatchEvent(_utils_Events__WEBPACK_IMPORTED_MODULE_7__.STREAM_SWITCHED);\r\n            const stream = _network_StreamProvider__WEBPACK_IMPORTED_MODULE_5__[\"default\"].getNextStream();\r\n            if (!stream) {\r\n                new _utils_HlsUtil__WEBPACK_IMPORTED_MODULE_8__.HlsUtil();\r\n            }\r\n            else {\r\n                const viewport = document.querySelector(\"video\");\r\n                viewport.srcObject = stream; //;\r\n            }\r\n        };\r\n        this.createSnaphot = (source, send) => {\r\n            if (this.playing)\r\n                this._tween.stop();\r\n            const x = (this._count % _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.SNAP_COUNT) * _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.VIDEO_WIDTH;\r\n            const y = Math.floor(this._count / _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.SNAP_COUNT) * _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.VIDEO_HEIGHT;\r\n            this._buffer.getContext('2d', { willReadFrequently: true }).drawImage(source, x, y, _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.VIDEO_WIDTH, _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.VIDEO_HEIGHT);\r\n            this._snapsaver.style.setProperty('display', 'inline');\r\n            this._snapsaver.width = this.w;\r\n            this._snapsaver.height = this.h;\r\n            this._snapsaver.getContext('2d', { willReadFrequently: true }).globalAlpha = _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.SNAP_SAVER_OPACITY;\r\n            this._snapsaver.getContext('2d').drawImage(source, 0, 0, this.w, this.h);\r\n            this.startSaverTween(this.w, this.h);\r\n        };\r\n        this.startSaverTween = (w, h) => {\r\n            const ini = { scaleX: 1, scaleY: 1, x: 0, y: 0 };\r\n            const end = { scaleX: _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.SNAP_WIDTH / w, scaleY: _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.SNAP_HEIGHT / h, x: this._viewport.getBoundingClientRect().left - this._viewport.offsetLeft - this._viewport.offsetParent.offsetLeft + (this.w - _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.SNAP_WIDTH) / 2, y: -(h - _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.SNAP_HEIGHT) / 2 }; //TODO simplify this !!!!!\r\n            this._tween = new _tweenjs_tween_js__WEBPACK_IMPORTED_MODULE_0__.Tween(ini)\r\n                .to({ scaleX: end.scaleX, scaleY: end.scaleY, x: end.x, y: end.y }, 333)\r\n                .easing(_tweenjs_tween_js__WEBPACK_IMPORTED_MODULE_0__.Easing.Linear.None)\r\n                .onUpdate(() => this._snapsaver.style.setProperty('transform', 'translate(' + ini.x + 'px,' + ini.y + 'px)' +\r\n                'scale(' + ini.scaleX + ',' + ini.scaleY + ')'))\r\n                .onComplete(() => this.onSaverTweenComplete())\r\n                .onStop(() => this.onSaverTweenComplete())\r\n                .start();\r\n        };\r\n        this.onSaverTweenComplete = () => {\r\n            this._snapshot.style.setProperty('transform', 'translate(' + String(this._viewport.getBoundingClientRect().left - this._viewport.offsetLeft - this._viewport.offsetParent.offsetLeft + (this.w - _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.SNAP_WIDTH) / 2) + 'px,' + String(-(this.h - _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.SNAP_HEIGHT) / 2) + 'px)' + 'scale(' + 1 + ',' + 1 + ')'); //TODO simplify this !!!!!\r\n            this._snapshot.getContext('2d', { willReadFrequently: true }).globalAlpha = 1;\r\n            this._snapshot.getContext('2d').clearRect(0, 0, _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.SNAP_WIDTH + 1, _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.SNAP_HEIGHT) + 1;\r\n            this._snapshot.getContext('2d').drawImage(this._snapsaver, 0, 0, _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.SNAP_WIDTH, _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.SNAP_HEIGHT);\r\n            this._snapshot.getContext('2d').beginPath();\r\n            this._snapshot.getContext('2d').lineWidth = \"1\";\r\n            this._snapshot.getContext('2d').strokeStyle = \"black\";\r\n            this._snapshot.getContext('2d').rect(0, 0, _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.SNAP_WIDTH, _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.SNAP_HEIGHT);\r\n            this._snapshot.getContext('2d').stroke();\r\n            this._snapsaver.style.setProperty('transform', 'translate(' + 0 + 'px,' + 0 + 'px)' + 'scale(' + 1 + ',' + 1 + ')');\r\n            this._snapsaver.style.setProperty('display', 'none');\r\n            this._snapsaver.getContext('2d', { willReadFrequently: true }).clearRect(0, 0, _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.VIDEO_WIDTH, _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.VIDEO_HEIGHT);\r\n            document.getElementById(\"snaps-button\").innerHTML = String(++this._count);\r\n            if (this._count === _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.SNAP_COUNT * _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.SNAP_COUNT)\r\n                this.flushBuffer();\r\n        };\r\n        this.flushBuffer = () => {\r\n            this.dispatchSendEvent();\r\n            this._buffer.getContext('2d', { willReadFrequently: true }).clearRect(0, 0, _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.VIDEO_WIDTH * _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.SNAP_COUNT, _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.VIDEO_HEIGHT * _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.SNAP_COUNT);\r\n            this._buffer.width = _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.VIDEO_WIDTH * _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.SNAP_COUNT;\r\n            this._buffer.height = _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.VIDEO_HEIGHT * _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.SNAP_COUNT;\r\n            document.getElementById(\"snaps-button\").innerHTML = String(this._count = 0);\r\n        };\r\n        this.viewSnapshotCollection = () => __awaiter(this, void 0, void 0, function* () {\r\n            this.bufferToDataUrl((data) => {\r\n                const tab = window.open();\r\n                tab.document.body.style.width = tab.document.body.style.height = '100%';\r\n                tab.document.body.style.overflow = 'hidden';\r\n                tab.document.body.innerHTML =\r\n                    '<div width=\"100%\" height=\"100%\">' + '<img src=\"' + data + '\" width=\"' + _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.VIDEO_WIDTH + 'px\" height=\"' + _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.VIDEO_HEIGHT + 'px\">' + '</div>';\r\n            });\r\n        });\r\n        this.bufferToDataUrl = (callback) => {\r\n            this._buffer.convertToBlob().then((value) => {\r\n                if (_view_Controls__WEBPACK_IMPORTED_MODULE_3__[\"default\"] === null || _view_Controls__WEBPACK_IMPORTED_MODULE_3__[\"default\"] === void 0 ? void 0 : _view_Controls__WEBPACK_IMPORTED_MODULE_3__[\"default\"].localSaveEnabled) {\r\n                    const name = new Date().toISOString().split('T')[0] + ' ' + new Date().toTimeString().split(' ')[0];\r\n                    file_saver__WEBPACK_IMPORTED_MODULE_4___default().saveAs(value, name.toString() + '.png');\r\n                }\r\n                const reader = new FileReader();\r\n                const file = new File([value], '_.png', { type: 'image/png' });\r\n                reader.onload = (result) => { var _a; return callback((_a = result === null || result === void 0 ? void 0 : result.target) === null || _a === void 0 ? void 0 : _a.result); };\r\n                reader.readAsDataURL(file);\r\n            });\r\n        };\r\n        this.dispatchSendEvent = () => {\r\n            this.bufferToDataUrl((data) => _utils_Events__WEBPACK_IMPORTED_MODULE_7__[\"default\"].dispatchEvent(_utils_Events__WEBPACK_IMPORTED_MODULE_7__.SNAPSHOT_SEND_HOMIE, data));\r\n        };\r\n        this.tick = (time) => {\r\n            requestAnimationFrame(this.tick);\r\n            _tweenjs_tween_js__WEBPACK_IMPORTED_MODULE_0__.update(time);\r\n        };\r\n    }\r\n    get w() { return this._viewport.getBoundingClientRect().width; }\r\n    get h() { return this._viewport.getBoundingClientRect().height; }\r\n    get playing() { var _a; return !!((_a = this._tween) === null || _a === void 0 ? void 0 : _a.isPlaying); }\r\n    ;\r\n    drawCanvasFromVideo(canvas, video, source, data = null) {\r\n        const w = canvas.width = video.getBoundingClientRect().width;\r\n        const h = canvas.height = video.getBoundingClientRect().height;\r\n        const context = canvas.getContext('2d', { willReadFrequently: true });\r\n        context === null || context === void 0 ? void 0 : context.clearRect(0, 0, w, h);\r\n        context === null || context === void 0 ? void 0 : context.drawImage(video, 0, 0, w, h);\r\n        _utils_Utils__WEBPACK_IMPORTED_MODULE_2__.addTimeStamp(canvas);\r\n        _utils_Utils__WEBPACK_IMPORTED_MODULE_2__.addSourceStamp(canvas, source);\r\n        _utils_Utils__WEBPACK_IMPORTED_MODULE_2__.addDataStamp(canvas, data);\r\n        return canvas;\r\n    }\r\n    ;\r\n}\r\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (new Snaphots());\r\n\n\n//# sourceURL=webpack://html-peer-viewer/./src/record/Snaphots.ts?\n}");

/***/ }),

/***/ "./src/store/Model.ts":
/*!****************************!*\
  !*** ./src/store/Model.ts ***!
  \****************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Model: () => (/* binding */ Model),\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _utils_Events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/Events */ \"./src/utils/Events.ts\");\n\r\nclass Model {\r\n    get motionDetectorEnabled() {\r\n        return this._motionDetectorEnabled;\r\n    }\r\n    set motionDetectorEnabled(value) {\r\n        if (this._motionDetectorEnabled !== value) {\r\n            this._motionDetectorEnabled = value;\r\n            _utils_Events__WEBPACK_IMPORTED_MODULE_0__[\"default\"].dispatchEvent(_utils_Events__WEBPACK_IMPORTED_MODULE_0__.MOTION_DETECTOR_STATE_CHANGED, value);\r\n        }\r\n    }\r\n    get matrixScreenEnabled() {\r\n        return this._matrixScreenEnabled;\r\n    }\r\n    set matrixScreenEnabled(value) {\r\n        if (this._matrixScreenEnabled !== value) {\r\n            this._matrixScreenEnabled = value;\r\n            _utils_Events__WEBPACK_IMPORTED_MODULE_0__[\"default\"].dispatchEvent(_utils_Events__WEBPACK_IMPORTED_MODULE_0__.MATRIX_SCREEN_STATE_CHANGED, value);\r\n        }\r\n    }\r\n    get colorCurvesEnabled() {\r\n        return this._colorCurvesEnabled;\r\n    }\r\n    set colorCurvesEnabled(value) {\r\n        if (this._colorCurvesEnabled !== value) {\r\n            this._colorCurvesEnabled = value;\r\n            _utils_Events__WEBPACK_IMPORTED_MODULE_0__[\"default\"].dispatchEvent(_utils_Events__WEBPACK_IMPORTED_MODULE_0__.COLOR_CURVES_STATE_CHANGED, value);\r\n        }\r\n    }\r\n    get streamersTotalCount() {\r\n        return this._streamersTotalCount;\r\n    }\r\n    set streamersTotalCount(value) {\r\n        if (this._streamersTotalCount !== value) {\r\n            this._streamersTotalCount = value;\r\n            _utils_Events__WEBPACK_IMPORTED_MODULE_0__[\"default\"].dispatchEvent(_utils_Events__WEBPACK_IMPORTED_MODULE_0__.STREAMS_COUNT_CHANGED, value);\r\n        }\r\n    }\r\n    get prefferedStreamQuality() {\r\n        return this._prefferedStreamQuality;\r\n    }\r\n    set prefferedStreamQuality(value) {\r\n        if (this._prefferedStreamQuality !== value) {\r\n            this._prefferedStreamQuality = value;\r\n        }\r\n    }\r\n    constructor() {\r\n        this.initialize = () => {\r\n        };\r\n        this._motionDetectorEnabled = true;\r\n        this._matrixScreenEnabled = false;\r\n        this._colorCurvesEnabled = false;\r\n        this._streamersTotalCount = 0;\r\n        this._prefferedStreamQuality = 'high';\r\n    }\r\n}\r\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (new Model());\r\n\n\n//# sourceURL=webpack://html-peer-viewer/./src/store/Model.ts?\n}");

/***/ }),

/***/ "./src/utils/Console.ts":
/*!******************************!*\
  !*** ./src/utils/Console.ts ***!
  \******************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _Events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Events */ \"./src/utils/Events.ts\");\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\r\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\r\n    return new (P || (P = Promise))(function (resolve, reject) {\r\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\r\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\r\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\r\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\r\n    });\r\n};\r\n\r\nclass Console extends _Events__WEBPACK_IMPORTED_MODULE_0__.EventHandler {\r\n    constructor() {\r\n        super();\r\n        this._value = '';\r\n        this.initialize = () => __awaiter(this, void 0, void 0, function* () {\r\n            const viewport = document.getElementById(\"entry-page\");\r\n            this._console = document.createElement(\"textarea\");\r\n            viewport.appendChild(this._console);\r\n            this._console.style.setProperty('position', 'absolute');\r\n            this._console.style.setProperty('top', '45%');\r\n            this._console.style.setProperty('left', '30%');\r\n            this._console.style.setProperty('width', '40%');\r\n            this._console.style.setProperty('background-color', 'black');\r\n            this._console.style.setProperty('font-size', '48px');\r\n            this._console.style.setProperty('text-align', 'center');\r\n            // this._console.style.setProperty('vertical-align', 'middle');\r\n            // this._console.style.setProperty('line-height', '30%');\r\n            this._console.style.setProperty('font-family', 'Courier New');\r\n            this._console.style.setProperty('font-weight', 'bold');\r\n            this._console.style.setProperty('color', 'green');\r\n            this._console.style.setProperty('overflow', 'hidden');\r\n            this._console.focus();\r\n            this._console.value = '>';\r\n            this._console.setSelectionRange(1, 1);\r\n            this._console.style.setProperty('display', 'none');\r\n            document.onkeydown = (event) => {\r\n                if (Number.isInteger(Number(event.key))) {\r\n                    this._value += String(event.key);\r\n                }\r\n                switch (event.key) {\r\n                    case 'q': {\r\n                        this.switchVisibility();\r\n                        break;\r\n                    }\r\n                    case 'Enter': {\r\n                        this.executeCommand(String(this._value));\r\n                        break;\r\n                    }\r\n                }\r\n                if (this._console.value.length > 1) {\r\n                    this._console.value = '>' + '*'.repeat(this._console.value.length - 1);\r\n                }\r\n            };\r\n        });\r\n        this.switchVisibility = () => {\r\n            this._console.style.setProperty('display', { inline: 'none', none: 'inline' }[String(this._console.style.getPropertyValue('display'))]);\r\n        };\r\n        this.executeCommand = (command) => {\r\n            /*switch (command) {\r\n                case 'trace': {\r\n                    this.dispatchEvent(Events.CHANGE_TRACE_VISIBILITY, null);\r\n                    break;\r\n                }\r\n                default: {\r\n                    this.dispatchEvent(Events.CONSOLE_EXECUTE_COMMAND, command);\r\n                    break;\r\n                }\r\n            }*/\r\n            //this._console.value = '>';\r\n            //this.switchVisibility();\r\n            /* let symbolMap: Map<String, String> =  Object.entries({\r\n                 '':''\r\n             });*/\r\n        };\r\n    }\r\n}\r\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (new Console());\r\n\n\n//# sourceURL=webpack://html-peer-viewer/./src/utils/Console.ts?\n}");

/***/ }),

/***/ "./src/utils/Constants.ts":
/*!********************************!*\
  !*** ./src/utils/Constants.ts ***!
  \********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   FACE_DETECT_INTERVAL_ACTIVE: () => (/* binding */ FACE_DETECT_INTERVAL_ACTIVE),\n/* harmony export */   FACE_DETECT_INTERVAL_LAZY: () => (/* binding */ FACE_DETECT_INTERVAL_LAZY),\n/* harmony export */   FACE_DETECT_INTERVAL_WORKTIME: () => (/* binding */ FACE_DETECT_INTERVAL_WORKTIME),\n/* harmony export */   MATRIX_COOLDOWN_DELAY: () => (/* binding */ MATRIX_COOLDOWN_DELAY),\n/* harmony export */   MATRIX_FONT_SIZE: () => (/* binding */ MATRIX_FONT_SIZE),\n/* harmony export */   MAYBE: () => (/* binding */ MAYBE),\n/* harmony export */   MOTION_DETECT_CHECKPOINT_SIZE: () => (/* binding */ MOTION_DETECT_CHECKPOINT_SIZE),\n/* harmony export */   MOTION_DETECT_DELAY: () => (/* binding */ MOTION_DETECT_DELAY),\n/* harmony export */   MOTION_DETECT_HEAP_SIZE: () => (/* binding */ MOTION_DETECT_HEAP_SIZE),\n/* harmony export */   MOTION_DETECT_IMAGE_COEF: () => (/* binding */ MOTION_DETECT_IMAGE_COEF),\n/* harmony export */   MOTION_DETECT_INTERVAL: () => (/* binding */ MOTION_DETECT_INTERVAL),\n/* harmony export */   MOTION_DETECT_PIXEL_COEF: () => (/* binding */ MOTION_DETECT_PIXEL_COEF),\n/* harmony export */   PINCODE_CHAR_LENGTH: () => (/* binding */ PINCODE_CHAR_LENGTH),\n/* harmony export */   SNAP_COUNT: () => (/* binding */ SNAP_COUNT),\n/* harmony export */   SNAP_HEIGHT: () => (/* binding */ SNAP_HEIGHT),\n/* harmony export */   SNAP_SAVER_OPACITY: () => (/* binding */ SNAP_SAVER_OPACITY),\n/* harmony export */   SNAP_WIDTH: () => (/* binding */ SNAP_WIDTH),\n/* harmony export */   SOUND_PLAY_TIME: () => (/* binding */ SOUND_PLAY_TIME),\n/* harmony export */   VIDEO_HEIGHT: () => (/* binding */ VIDEO_HEIGHT),\n/* harmony export */   VIDEO_WIDTH: () => (/* binding */ VIDEO_WIDTH)\n/* harmony export */ });\nconst VIDEO_WIDTH = 1280 / 1.2;\r\nconst VIDEO_HEIGHT = 720 / 1.2;\r\nconst SNAP_WIDTH = 444;\r\nconst SNAP_HEIGHT = 248;\r\nconst SNAP_COUNT = 5;\r\nconst SNAP_SAVER_OPACITY = 0.8;\r\nconst FACE_DETECT_INTERVAL_ACTIVE = 111;\r\nconst FACE_DETECT_INTERVAL_LAZY = 555;\r\nconst FACE_DETECT_INTERVAL_WORKTIME = 11111;\r\nconst MOTION_DETECT_INTERVAL = 3.33;\r\nconst MOTION_DETECT_DELAY = 7777;\r\nconst MOTION_DETECT_PIXEL_COEF = 44;\r\nconst MOTION_DETECT_IMAGE_COEF = 0.05;\r\nconst MOTION_DETECT_HEAP_SIZE = 100;\r\nconst MOTION_DETECT_CHECKPOINT_SIZE = 44;\r\nconst PINCODE_CHAR_LENGTH = 4;\r\nconst MATRIX_COOLDOWN_DELAY = 77777;\r\nconst MATRIX_FONT_SIZE = 24;\r\nconst SOUND_PLAY_TIME = 11;\r\nconst MAYBE = 4;\r\n\n\n//# sourceURL=webpack://html-peer-viewer/./src/utils/Constants.ts?\n}");

/***/ }),

/***/ "./src/utils/Events.ts":
/*!*****************************!*\
  !*** ./src/utils/Events.ts ***!
  \*****************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   ACTIVE_STREAM_RECEIVED: () => (/* binding */ ACTIVE_STREAM_RECEIVED),\n/* harmony export */   CHANGE_TRACE_VISIBILITY: () => (/* binding */ CHANGE_TRACE_VISIBILITY),\n/* harmony export */   COLOR_CURVES_STATE_CHANGED: () => (/* binding */ COLOR_CURVES_STATE_CHANGED),\n/* harmony export */   CONSOLE_EXECUTE_COMMAND: () => (/* binding */ CONSOLE_EXECUTE_COMMAND),\n/* harmony export */   EventHandler: () => (/* binding */ EventHandler),\n/* harmony export */   FACE_DETECTED: () => (/* binding */ FACE_DETECTED),\n/* harmony export */   FACE_RECOGNIZED: () => (/* binding */ FACE_RECOGNIZED),\n/* harmony export */   MANUAL_RECONNECT_REQUIRED: () => (/* binding */ MANUAL_RECONNECT_REQUIRED),\n/* harmony export */   MATRIX_SCREEN_STATE_CHANGED: () => (/* binding */ MATRIX_SCREEN_STATE_CHANGED),\n/* harmony export */   MOBILE_SWIPE_RIGHT: () => (/* binding */ MOBILE_SWIPE_RIGHT),\n/* harmony export */   MOTION_DETECTED: () => (/* binding */ MOTION_DETECTED),\n/* harmony export */   MOTION_DETECTION_FINISHED: () => (/* binding */ MOTION_DETECTION_FINISHED),\n/* harmony export */   MOTION_DETECTION_STARTED: () => (/* binding */ MOTION_DETECTION_STARTED),\n/* harmony export */   MOTION_DETECTOR_STATE_CHANGED: () => (/* binding */ MOTION_DETECTOR_STATE_CHANGED),\n/* harmony export */   NETWORK_AUTH_SUCCESS: () => (/* binding */ NETWORK_AUTH_SUCCESS),\n/* harmony export */   NETWORK_FOLDERS_LOAD_END: () => (/* binding */ NETWORK_FOLDERS_LOAD_END),\n/* harmony export */   NETWORK_OFFLINE: () => (/* binding */ NETWORK_OFFLINE),\n/* harmony export */   NETWORK_ONLINE: () => (/* binding */ NETWORK_ONLINE),\n/* harmony export */   NETWORK_SNAPSHOT_LOAD_END: () => (/* binding */ NETWORK_SNAPSHOT_LOAD_END),\n/* harmony export */   NETWORK_SNAPSHOT_LOAD_START: () => (/* binding */ NETWORK_SNAPSHOT_LOAD_START),\n/* harmony export */   NO_STREAMS_AVAILABLE: () => (/* binding */ NO_STREAMS_AVAILABLE),\n/* harmony export */   PEER_CLOSED: () => (/* binding */ PEER_CLOSED),\n/* harmony export */   PEER_CONNECTED: () => (/* binding */ PEER_CONNECTED),\n/* harmony export */   PEER_DISCONNECTED: () => (/* binding */ PEER_DISCONNECTED),\n/* harmony export */   PEER_ERROR: () => (/* binding */ PEER_ERROR),\n/* harmony export */   PEER_RECONNECT_FAILED: () => (/* binding */ PEER_RECONNECT_FAILED),\n/* harmony export */   SNAPSHOT_SEND_HOMIE: () => (/* binding */ SNAPSHOT_SEND_HOMIE),\n/* harmony export */   STREAMS_COUNT_CHANGED: () => (/* binding */ STREAMS_COUNT_CHANGED),\n/* harmony export */   STREAM_BALANCED: () => (/* binding */ STREAM_BALANCED),\n/* harmony export */   STREAM_LOST: () => (/* binding */ STREAM_LOST),\n/* harmony export */   STREAM_LOST_GENERIC: () => (/* binding */ STREAM_LOST_GENERIC),\n/* harmony export */   STREAM_RECEIVED: () => (/* binding */ STREAM_RECEIVED),\n/* harmony export */   STREAM_SWITCHED: () => (/* binding */ STREAM_SWITCHED),\n/* harmony export */   USER_PROCEEDED: () => (/* binding */ USER_PROCEEDED),\n/* harmony export */   VOLUME_ADJUST_SPREAD: () => (/* binding */ VOLUME_ADJUST_SPREAD),\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nclass EventHandler {\r\n    constructor() {\r\n        this.events = {};\r\n        this.dispatchEvent = (eventName, data = null) => {\r\n            const event = this.events[eventName];\r\n            if (event) {\r\n                const handlers = [...event];\r\n                handlers.forEach((handler) => {\r\n                    handler.call(null, data);\r\n                });\r\n            }\r\n        };\r\n    }\r\n    addEventListener(eventName, handler) {\r\n        if (!this.events[eventName]) {\r\n            this.events[eventName] = [];\r\n        }\r\n        return this.events[eventName].push(handler);\r\n    }\r\n    addSingleEventListener(eventName, handler) {\r\n        const onceHandler = (data) => {\r\n            handler.call(null, data);\r\n            this.removeSpecificEventListener(eventName, onceHandler);\r\n        };\r\n        return this.addEventListener(eventName, onceHandler);\r\n    }\r\n    removeSpecificEventListener(eventName, handlerToRemove) {\r\n        if (!this.events[eventName]) {\r\n            return false;\r\n        }\r\n        const index = this.events[eventName].findIndex(handler => handler === handlerToRemove);\r\n        if (index !== -1) {\r\n            this.events[eventName].splice(index, 1);\r\n            return true;\r\n        }\r\n        return false;\r\n    }\r\n    removeEventListener(eventName) {\r\n        return delete this.events[eventName];\r\n    }\r\n}\r\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (new EventHandler());\r\nconst USER_PROCEEDED = 'user_proceeded';\r\nconst STREAM_RECEIVED = 'stream_received';\r\nconst STREAM_BALANCED = 'stream_balanced';\r\nconst ACTIVE_STREAM_RECEIVED = 'active_stream_received';\r\nconst STREAMS_COUNT_CHANGED = 'streams_count_changed';\r\nconst STREAM_LOST = 'stream_lost';\r\nconst STREAM_LOST_GENERIC = 'stream_lost_generic';\r\nconst STREAM_SWITCHED = 'stream_switched';\r\nconst PEER_CONNECTED = 'peer_connected';\r\nconst PEER_DISCONNECTED = 'peer_disconnected';\r\nconst PEER_CLOSED = 'peer_closed';\r\nconst PEER_ERROR = 'peer_error';\r\nconst PEER_RECONNECT_FAILED = 'peer_reconnect_failed';\r\nconst NO_STREAMS_AVAILABLE = 'no_streams_available';\r\nconst NETWORK_ONLINE = 'network_online';\r\nconst NETWORK_OFFLINE = 'network_offline';\r\nconst MANUAL_RECONNECT_REQUIRED = 'manual_reconnect_required';\r\nconst FACE_DETECTED = 'face_detected';\r\nconst FACE_RECOGNIZED = 'face_recognized';\r\nconst MOTION_DETECTOR_STATE_CHANGED = 'motion_detector_state_changed';\r\nconst MOTION_DETECTED = 'motion_detected';\r\nconst MOTION_DETECTION_STARTED = 'motion_detection_started';\r\nconst MOTION_DETECTION_FINISHED = 'motion_detection_finished';\r\nconst SNAPSHOT_SEND_HOMIE = 'snapshot_send_homie';\r\nconst CHANGE_TRACE_VISIBILITY = 'change_trace_visibility';\r\nconst NETWORK_FOLDERS_LOAD_END = 'network_folders_loaded';\r\nconst NETWORK_SNAPSHOT_LOAD_START = 'network_snapshot_load_start';\r\nconst NETWORK_SNAPSHOT_LOAD_END = 'network_snapshot_load_end';\r\nconst NETWORK_AUTH_SUCCESS = 'network_auth_success';\r\nconst CONSOLE_EXECUTE_COMMAND = 'console_execute_command';\r\nconst VOLUME_ADJUST_SPREAD = 'volume_adjust_spread';\r\nconst MOBILE_SWIPE_RIGHT = 'mobile_swipe_right';\r\nconst MATRIX_SCREEN_STATE_CHANGED = 'matrix_screen_state_changed';\r\nconst COLOR_CURVES_STATE_CHANGED = 'color_curves_state_changed';\r\n\n\n//# sourceURL=webpack://html-peer-viewer/./src/utils/Events.ts?\n}");

/***/ }),

/***/ "./src/utils/HlsUtil.ts":
/*!******************************!*\
  !*** ./src/utils/HlsUtil.ts ***!
  \******************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   HlsUtil: () => (/* binding */ HlsUtil)\n/* harmony export */ });\n/* harmony import */ var hls_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! hls.js */ \"./node_modules/hls.js/dist/hls.mjs\");\n\r\nclass HlsUtil {\r\n    constructor() {\r\n        this.tryWebRTC = () => {\r\n            const pc = new RTCPeerConnection();\r\n            pc.ontrack = e => {\r\n                this.video.srcObject = e.streams[0];\r\n                console.log(' Using WebRTC');\r\n            };\r\n            pc.addTransceiver('video', { direction: 'recvonly' });\r\n            pc.createOffer().then(offer => {\r\n                pc.setLocalDescription(offer);\r\n                return fetch(HlsUtil.STREAM_URL + 'whip', {\r\n                    method: 'POST',\r\n                    body: offer.sdp,\r\n                    headers: { 'Content-Type': 'application/sdp' }\r\n                });\r\n            }).then(r => {\r\n                if (r.ok)\r\n                    return r.text();\r\n                throw new Error('WebRTC failed');\r\n            }).then(answer => {\r\n                pc.setRemoteDescription({ type: 'answer', sdp: answer });\r\n            }).catch(() => {\r\n                // Fallback to HLS\r\n                this.tryHls();\r\n            });\r\n        };\r\n        this.tryHls = () => {\r\n            if (hls_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isSupported()) {\r\n                this.video.srcObject = null;\r\n                const hls = new hls_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"]();\r\n                hls.loadSource(HlsUtil.STREAM_URL + 'index.m3u8');\r\n                hls.attachMedia(this.video);\r\n            }\r\n            else if (this.video.canPlayType('application/vnd.apple.mpegurl')) {\r\n                this.video.src = HlsUtil.STREAM_URL + 'index.m3u8';\r\n                console.log(' Using native HLS');\r\n            }\r\n            else {\r\n                // Final fallback: MJPEG\r\n                this.video.style.display = 'none';\r\n                const img = document.createElement('img');\r\n                img.src = HlsUtil.STREAM_URL + 'mjpeg';\r\n                document.body.appendChild(img);\r\n            }\r\n        };\r\n        this.video = document.querySelector(\"video\");\r\n        this.tryHls();\r\n    }\r\n}\r\nHlsUtil.STREAM_URL = 'https://195.137.244.53:8888/camera/';\r\n\n\n//# sourceURL=webpack://html-peer-viewer/./src/utils/HlsUtil.ts?\n}");

/***/ }),

/***/ "./src/utils/MobileUtils.ts":
/*!**********************************!*\
  !*** ./src/utils/MobileUtils.ts ***!
  \**********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   MobileUtils: () => (/* binding */ MobileUtils),\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _Events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Events */ \"./src/utils/Events.ts\");\n\r\nclass MobileUtils extends _Events__WEBPACK_IMPORTED_MODULE_0__.EventHandler {\r\n    constructor() {\r\n        super();\r\n        this.on = (element) => {\r\n            let touchstartX = 0;\r\n            let touchendX = 0;\r\n            const checkDirection = () => {\r\n                if (touchendX < touchstartX)\r\n                    this.dispatchEvent(_Events__WEBPACK_IMPORTED_MODULE_0__.MOBILE_SWIPE_RIGHT);\r\n            };\r\n            element.addEventListener('touchstart', (event) => {\r\n                touchstartX = event.changedTouches[0].screenX;\r\n            });\r\n            element.addEventListener('touchend', (event) => {\r\n                touchendX = event.changedTouches[0].screenX;\r\n                checkDirection();\r\n            });\r\n            return this;\r\n        };\r\n    }\r\n}\r\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (new MobileUtils());\r\n\n\n//# sourceURL=webpack://html-peer-viewer/./src/utils/MobileUtils.ts?\n}");

/***/ }),

/***/ "./src/utils/Sounds.ts":
/*!*****************************!*\
  !*** ./src/utils/Sounds.ts ***!
  \*****************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _Events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Events */ \"./src/utils/Events.ts\");\n/* harmony import */ var _view_Controls__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../view/Controls */ \"./src/view/Controls.ts\");\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\r\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\r\n    return new (P || (P = Promise))(function (resolve, reject) {\r\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\r\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\r\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\r\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\r\n    });\r\n};\r\n\r\n\r\nclass Sounds extends _Events__WEBPACK_IMPORTED_MODULE_0__.EventHandler {\r\n    constructor() {\r\n        super();\r\n        this._timeouts = new Map();\r\n        this._container = null;\r\n        this._volume = 1.0;\r\n        this._timeout = null;\r\n        this._restraints = [\r\n            0.5, 0.5, 0.5, 0.5,\r\n            0.5, 0.5, 0.5, 0.5,\r\n            0.5, 1.0, 1.0, 1.0,\r\n            1.0, 1.0, 1.0, 1.0,\r\n            1.0, 1.0, 1.0, 1.0,\r\n            0.5, 0.5, 0.5, 0.5\r\n        ];\r\n        this._youtubes = [\r\n            { url: '7wedjXUereU', start: 3, length: 12 },\r\n            { url: 'AqYsUNFXOuM', start: 28, length: 12 },\r\n            { url: 'XQ8JjxoP_9Y', start: 0, length: 12 },\r\n            { url: 'j_0FwL91o7A', start: 7, length: 12 },\r\n            { url: 'WnhjDV5ZUL0', start: 8, length: 12, obscene: true },\r\n            { url: 'HnXVlPGxFH4', start: 84, length: 10, obscene: true }\r\n        ];\r\n        this.list = [];\r\n        this.initialize = () => __awaiter(this, void 0, void 0, function* () {\r\n            //  MotionDetector.addEventListener(Events.MOTION_DETECTION_STARTED, async () => {\r\n            //if (this._timeout) return console.log('[Sounds] Motion detect handler. Sound not played cuz of timeout');\r\n            //source = context.createBufferSource();\r\n            //audio = await buildAudio(this.list[Math.floor(Math.random() * this.list.length)]);\r\n            // if (!audio?.buffer) return console.log('[Sounds] Motion detect handler. Sound not played because of no audio buffer');\r\n            //this._timeout = setTimeout(() => this._timeout = clearTimeout(this._timeout), audio.buffer.duration * (Math.exp(Math.PI * Math.PI / Math.E + Math.PI * Math.PI / Math.E + Math.E / Math.PI)));\r\n            //const start: number = Math.random() * (audio.buffer.duration - Number(duration));  \r\n            // audio.start(0, 0, audio.buffer.duration);\r\n            //this.playYoutube();\r\n            //   });\r\n        });\r\n        this.prepareAudios = () => __awaiter(this, void 0, void 0, function* () {\r\n            //@ts-ignore\r\n            const context = new (window.AudioContext || window.webkitAudioContext)();\r\n            const getAudioList = (url) => {\r\n                return new Promise((resolve, reject) => {\r\n                    const request = new XMLHttpRequest();\r\n                    request.open(\"GET\", url, true);\r\n                    //  request.responseType = \"arraybuffer\";\r\n                    request.onload = () => resolve(request.response);\r\n                    request.onerror = (e) => reject(e);\r\n                    request.send();\r\n                });\r\n            };\r\n            let audios;\r\n            try {\r\n                audios = JSON.parse(yield getAudioList('./audios.json')).list;\r\n            }\r\n            catch (e) {\r\n                console.log('[Viewer] Sounds.initialize. error while handling config.');\r\n            }\r\n            console.log('[Viewer] Sounds.initialize. context here.');\r\n            const loadAudio = (url) => {\r\n                return new Promise((resolve, reject) => {\r\n                    const request = new XMLHttpRequest();\r\n                    request.open(\"GET\", url, true);\r\n                    request.responseType = \"arraybuffer\";\r\n                    request.onload = () => resolve(request.response);\r\n                    request.onerror = (e) => reject(e);\r\n                    request.send();\r\n                });\r\n            };\r\n            const buildAudio = (blob) => __awaiter(this, void 0, void 0, function* () {\r\n                source.buffer = yield context.decodeAudioData(blob.slice(0));\r\n                source.connect(context.destination);\r\n                return source;\r\n            });\r\n            audios.forEach((name) => __awaiter(this, void 0, void 0, function* () {\r\n                this.list.push(yield loadAudio(\"./images/\" + name + \".mp3\"));\r\n            }));\r\n            let source = null;\r\n            let audio = null;\r\n            let blob = yield loadAudio(\"./images/les-podervanskij-kazka-pro-repku_(mufm.me).mp3\");\r\n            /*     MotionDetector.addEventListener(Events.MOTION_DETECTION_STARTED, async () => {\r\n                     if (this._timeout) return console.log('[Sounds] Motion detect handler. Sound not played cuz of timeout');\r\n                     source = context.createBufferSource();\r\n                     audio = await buildAudio(this.list[Math.floor(Math.random() * this.list.length)]);\r\n                     if (!audio?.buffer) return console.log('[Sounds] Motion detect handler. Sound not played because of no audio buffer');\r\n                     this._timeout = setTimeout(() => this._timeout =\r\n                     //       ,     \r\n                         clearTimeout(this._timeout), audio.buffer.duration * (Math.exp(Math.PI * Math.PI / Math.E + Math.PI * Math.PI / Math.E + Math.E / Math.PI)));\r\n                     //const start: number = Math.random() * (audio.buffer.duration - Number(duration));\r\n                     audio.start(0, 0, audio.buffer.duration);\r\n                 });*/\r\n        });\r\n        this.playStream = (stream) => {\r\n            console.log('[Sounds] playStream try to remove node for remote stream.');\r\n            try {\r\n                this._container.removeChild(document.getElementById(\"remote-audio\"));\r\n            }\r\n            catch (e) {\r\n                console.log('[Sounds] playStream node doesnt exist. creating instance..');\r\n            }\r\n            const node = document.createElement(\"audio\");\r\n            node.id = \"remote-audio\";\r\n            node.autoplay = true;\r\n            document.getElementById(\"view-page\").appendChild(node);\r\n            // node.src = (URL || webkitURL).createObjectURL(stream);\r\n            node.srcObject = stream;\r\n        };\r\n        this.playYoutube = () => {\r\n            const domain = 'https://www.youtube.com/embed/';\r\n            const params = '?&autoplay=1&start=';\r\n            const container = document.getElementById('player_youtube');\r\n            const item = this._youtubes[Math.ceil(Math.random() * (this._youtubes.length - 1))];\r\n            if (this.youtube_timeout)\r\n                return console.log('[Sounds] playYoutube wont proceed cuz of timeout.');\r\n            try {\r\n                container.src = String(domain + item.url + params + item.start);\r\n                this.youtube_timeout = setTimeout(() => { container.src = ''; this.youtube_timeout = undefined; }, item.length * 1000);\r\n            }\r\n            catch (e) {\r\n                console.log('[Sounds] playYoutube failed with url : [' + item.url + ']');\r\n                this.playYoutube();\r\n            }\r\n        };\r\n        this.adjustVolume = (value) => {\r\n            this._volume = value;\r\n            _view_Controls__WEBPACK_IMPORTED_MODULE_1__[\"default\"].adjustVolume(value);\r\n        };\r\n        this._timeouts.set(_Events__WEBPACK_IMPORTED_MODULE_0__.MOTION_DETECTED, { instance: null, delay: 7777 });\r\n    }\r\n}\r\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (new Sounds());\r\n\n\n//# sourceURL=webpack://html-peer-viewer/./src/utils/Sounds.ts?\n}");

/***/ }),

/***/ "./src/utils/Utils.ts":
/*!****************************!*\
  !*** ./src/utils/Utils.ts ***!
  \****************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   addDataStamp: () => (/* binding */ addDataStamp),\n/* harmony export */   addSourceStamp: () => (/* binding */ addSourceStamp),\n/* harmony export */   addTimeStamp: () => (/* binding */ addTimeStamp),\n/* harmony export */   generateSortableFileName: () => (/* binding */ generateSortableFileName),\n/* harmony export */   getRgb: () => (/* binding */ getRgb),\n/* harmony export */   rbgToHsv: () => (/* binding */ rbgToHsv),\n/* harmony export */   rgbToHex: () => (/* binding */ rgbToHex),\n/* harmony export */   tryResizeWindow: () => (/* binding */ tryResizeWindow)\n/* harmony export */ });\nfunction getRgb(bitmap) {\r\n    let offset = 4;\r\n    let r = 0;\r\n    let g = 0;\r\n    let b = 0;\r\n    let j = 0;\r\n    for (let i = 0; i < bitmap.data.length - offset; i = i + offset) {\r\n        r += bitmap.data[i];\r\n        g += bitmap.data[i + 1];\r\n        b += bitmap.data[i + 2];\r\n        j++;\r\n    }\r\n    let R = r / j;\r\n    let G = g / j;\r\n    let B = b / j;\r\n    return { r: R, g: G, b: B };\r\n}\r\n;\r\nfunction rbgToHsv({ r, g, b }) {\r\n    r /= 255;\r\n    g /= 255;\r\n    b /= 255;\r\n    let maxc = Math.max(r, g, b);\r\n    let minc = Math.min(r, g, b);\r\n    let v = maxc;\r\n    if (minc === maxc) {\r\n        return { h: 0.0, s: 0.0, v: v };\r\n    }\r\n    let s = (maxc - minc) / maxc;\r\n    let rc = (maxc - r) / (maxc - minc);\r\n    let gc = (maxc - g) / (maxc - minc);\r\n    let bc = (maxc - b) / (maxc - minc);\r\n    let h;\r\n    if (r == maxc)\r\n        h = 0.0 + bc - gc;\r\n    else if (g == maxc)\r\n        h = 2.0 + rc - bc;\r\n    else\r\n        h = 4.0 + gc - rc;\r\n    h = (h / 6.0) % 1.0;\r\n    return { h: h * 360, s: s * 100, v: v * 100 };\r\n}\r\n;\r\nfunction rgbToHex({ r, g, b }) {\r\n    return \"#\" + (1 << 24 | r << 16 | g << 8 | b).toString(16).slice(1);\r\n}\r\nfunction getContrastingColor({ r, g, b }) {\r\n    //      \r\n    r = (255 - r);\r\n    g = (255 - g);\r\n    b = (255 - b);\r\n    return rgbToHex({ r, g, b });\r\n}\r\nfunction addTimeStamp(canvas, date = new Date()) {\r\n    const dateStr = '[time]    : ' + date.toISOString().split('T')[0] +\r\n        ' ' + date.toTimeString().split(' ')[0] +\r\n        '.' + String(date.getMilliseconds());\r\n    return drawChunks(canvas, dateStr, { x: 30, y: 30 });\r\n}\r\nfunction getAverageColor(imageData) {\r\n    const length = imageData.length;\r\n    let r = 0, g = 0, b = 0, count = 0;\r\n    for (let i = 0; i < length; i += 4) {\r\n        r += imageData[i]; // \r\n        g += imageData[i + 1]; // \r\n        b += imageData[i + 2]; // \r\n        count++;\r\n    }\r\n    //   \r\n    r = Math.round(r / count);\r\n    g = Math.round(g / count);\r\n    b = Math.round(b / count);\r\n    return { r, g, b };\r\n}\r\nfunction addSourceStamp(canvas, source) {\r\n    var _a, _b;\r\n    //@ts-ignore\r\n    source = ('[trigger] : ' + source + ' ' + (((_a = navigator === null || navigator === void 0 ? void 0 : navigator.userAgentData) === null || _a === void 0 ? void 0 : _a.platform) || 'iyc!') + ' ' + (((_b = navigator === null || navigator === void 0 ? void 0 : navigator.userAgentData) === null || _b === void 0 ? void 0 : _b.mobile) ? '??' : ''));\r\n    return drawChunks(canvas, source, { x: 30, y: 70 });\r\n}\r\nfunction drawChunks(canvas, source, delta) {\r\n    const context = canvas.getContext('2d', { alpha: true, desynchronized: false, colorSpace: 'srgb', willReadFrequently: false });\r\n    source.concat(' ').toUpperCase().split('').forEach((symbol, index) => {\r\n        var _a;\r\n        context.font = 'bold 36px Courier New';\r\n        context.fillStyle = getContrastingColor(getAverageColor((_a = context.getImageData(delta.x + index * 26, delta.y, 42, 42)) === null || _a === void 0 ? void 0 : _a.data));\r\n        context.fillText(symbol, delta.x + index * 26, delta.y);\r\n    });\r\n    return canvas;\r\n}\r\nfunction addDataStamp(canvas, data = null) {\r\n    if (!data)\r\n        return;\r\n    const source = '[viewdata] : h[' + data.h.toFixed(1) + '] s[' + data.s.toFixed(1) + '] v[' + data.v.toFixed(1) + ']';\r\n    return drawChunks(canvas, source, { x: 30, y: 110 });\r\n}\r\nfunction tryResizeWindow() {\r\n    var _a;\r\n    if (((_a = window.screen) === null || _a === void 0 ? void 0 : _a.availWidth) > 3000) {\r\n        // debugger;\r\n        window.resizeTo(window.screen.availWidth / 4, window.screen.availHeight / 4);\r\n    }\r\n}\r\nfunction generateSortableFileName() {\r\n    const now = new Date();\r\n    const year = now.getFullYear();\r\n    const month = String(now.getMonth() + 1).padStart(2, '0');\r\n    const day = String(now.getDate()).padStart(2, '0');\r\n    const hours = String(now.getHours()).padStart(2, '0');\r\n    const minutes = String(now.getMinutes()).padStart(2, '0');\r\n    const seconds = String(now.getSeconds()).padStart(2, '0');\r\n    return `${year}-${month}-${day}_${hours}-${minutes}-${seconds}`;\r\n}\r\n\n\n//# sourceURL=webpack://html-peer-viewer/./src/utils/Utils.ts?\n}");

/***/ }),

/***/ "./src/view/Controls.ts":
/*!******************************!*\
  !*** ./src/view/Controls.ts ***!
  \******************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Controls: () => (/* binding */ Controls),\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _record_Snaphots__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../record/Snaphots */ \"./src/record/Snaphots.ts\");\n/* harmony import */ var _network_StreamProvider__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../network/StreamProvider */ \"./src/network/StreamProvider.ts\");\n/* harmony import */ var _utils_Events__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/Events */ \"./src/utils/Events.ts\");\n/* harmony import */ var _network_RestService__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../network/RestService */ \"./src/network/RestService.ts\");\n/* harmony import */ var file_saver__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! file-saver */ \"./node_modules/file-saver/dist/FileSaver.min.js\");\n/* harmony import */ var file_saver__WEBPACK_IMPORTED_MODULE_4___default = /*#__PURE__*/__webpack_require__.n(file_saver__WEBPACK_IMPORTED_MODULE_4__);\n/* harmony import */ var _store_Model__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../store/Model */ \"./src/store/Model.ts\");\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\r\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\r\n    return new (P || (P = Promise))(function (resolve, reject) {\r\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\r\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\r\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\r\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\r\n    });\r\n};\r\n\r\n\r\n\r\n\r\n\r\n\r\nclass Controls {\r\n    constructor() {\r\n        this._watchButtons_0 = [];\r\n        this._imageButtons = [];\r\n        this._imageButtonsBlocked = false;\r\n        this._folders = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'];\r\n        this.initialize = () => __awaiter(this, void 0, void 0, function* () {\r\n            this._container = document.getElementById(\"controls\");\r\n            this._viewport = document.querySelector(\"video\");\r\n            this.createButtons();\r\n        });\r\n        this.createButtons = () => {\r\n            this.createTraceButton();\r\n            this.createVoiceButton();\r\n            this.createFullsButton();\r\n            this.createSnapsButton();\r\n            //this._watchToggle_0 = document.getElementById(\"watch-toggle-month\");\r\n            this.createWatchButton();\r\n            this.createWatchToggle();\r\n            this.createContextMenu();\r\n            this.createJonTravolta();\r\n            this.createSaveButtons();\r\n            this.createHudsControl();\r\n            this.createQualButtons();\r\n        };\r\n        this.createHudsControl = () => {\r\n            const streamersInfo = document.getElementById(\"sources-info\");\r\n            _utils_Events__WEBPACK_IMPORTED_MODULE_2__[\"default\"].addEventListener(_utils_Events__WEBPACK_IMPORTED_MODULE_2__.STREAMS_COUNT_CHANGED, (count) => {\r\n                streamersInfo.innerText = \"CAM1\" + count;\r\n            });\r\n        };\r\n        this.setVisible = (value) => {\r\n            this._container.style.setProperty('visibility', value ? 'visible' : 'hidden');\r\n        };\r\n        this.adjustVolume = (value) => {\r\n            this._voiceButton.style.opacity = String(value);\r\n        };\r\n        this.createTraceButton = () => {\r\n            this._traceButton = document.getElementById(\"trace-button\");\r\n            this._traceButton.onclick = () => {\r\n                _store_Model__WEBPACK_IMPORTED_MODULE_5__[\"default\"].matrixScreenEnabled = !_store_Model__WEBPACK_IMPORTED_MODULE_5__[\"default\"].matrixScreenEnabled;\r\n                if (this._traceButton.style.getPropertyValue('background-color')) {\r\n                    this._traceButton.style.removeProperty('background-color');\r\n                }\r\n                else {\r\n                    this._traceButton.style.setProperty('background-color', '#00ff0077');\r\n                }\r\n            };\r\n            this._chartButton = document.getElementById(\"chart-button\");\r\n            this._chartButton.onclick = () => {\r\n                _store_Model__WEBPACK_IMPORTED_MODULE_5__[\"default\"].colorCurvesEnabled = !_store_Model__WEBPACK_IMPORTED_MODULE_5__[\"default\"].colorCurvesEnabled;\r\n                if (this._chartButton.style.getPropertyValue('background-color')) {\r\n                    this._chartButton.style.removeProperty('background-color');\r\n                }\r\n                else {\r\n                    this._chartButton.style.setProperty('background-color', '#00ff0077');\r\n                }\r\n            };\r\n        };\r\n        this.createQualButtons = () => {\r\n            this._lowButton = document.getElementById(\"low-button\");\r\n            this._medButton = document.getElementById(\"med-button\");\r\n            this._higButton = document.getElementById(\"hig-button\");\r\n            this._higButton.style.setProperty('background-color', '#00ff0077');\r\n            const list = [this._lowButton, this._medButton, this._higButton];\r\n            const clickHandler = (target, quality) => {\r\n                list.forEach((button) => {\r\n                    if (button.style.getPropertyValue('background-color')) {\r\n                        button.style.removeProperty('background-color');\r\n                    }\r\n                });\r\n                if (target.style.getPropertyValue('background-color')) {\r\n                    target.style.removeProperty('background-color');\r\n                }\r\n                else {\r\n                    target.style.setProperty('background-color', '#00ff0077');\r\n                }\r\n                _network_StreamProvider__WEBPACK_IMPORTED_MODULE_1__[\"default\"].switchStreamQuality(quality);\r\n            };\r\n            this._lowButton.onclick = () => clickHandler(this._lowButton, 'low');\r\n            this._medButton.onclick = () => clickHandler(this._medButton, 'medium');\r\n            this._higButton.onclick = () => clickHandler(this._higButton, 'high');\r\n        };\r\n        this.createVoiceButton = () => {\r\n            this._voiceButton = document.getElementById(\"voice-button\");\r\n            this._voiceButton.onclick = () => {\r\n                if (this._voiceButton.style.getPropertyValue('background-color')) {\r\n                    //StreamProvider?.stopVoiceMessage();\r\n                    this._voiceButton.style.removeProperty('background-color');\r\n                }\r\n                else {\r\n                    //StreamProvider?.sendVoiceMessage(); \r\n                    this._voiceButton.style.setProperty('background-color', '#00ff0077');\r\n                }\r\n            };\r\n        };\r\n        this.createFullsButton = () => {\r\n            this._fullsButton = document.getElementById(\"fullscreen-button\");\r\n            this._fullsButton.onclick = () => {\r\n                console.log('[Controls] displayStream requesting fullscreen if avail');\r\n                if (document.body.requestFullscreen) {\r\n                    try {\r\n                        document.body.requestFullscreen();\r\n                    }\r\n                    catch (error) {\r\n                        console.log('[Controls] displayStream requesting fullscreen error');\r\n                    }\r\n                }\r\n            };\r\n            const _fullsButtonStream = document.getElementById(\"fullscreen-button-stream\");\r\n            const _viewport = document.getElementById(\"video-container\"); //document.querySelector(\"video\");\r\n            _fullsButtonStream && (_fullsButtonStream.onclick = () => {\r\n                try {\r\n                    _viewport.requestFullscreen();\r\n                }\r\n                catch (error) {\r\n                    console.log('[Controls] displayStream requesting fullscreen error');\r\n                }\r\n            });\r\n        };\r\n        this.createSnapsButton = () => {\r\n            this._snapsButton = document.getElementById(\"snaps-button\").parentElement;\r\n            this._snapsButton.onclick = () => _record_Snaphots__WEBPACK_IMPORTED_MODULE_0__[\"default\"].flushBuffer();\r\n        };\r\n        this.createWatchButton = () => {\r\n            this._watchButton = document.getElementById(\"watch-button\");\r\n            this._watchButton.onmouseenter = () => {\r\n                _network_RestService__WEBPACK_IMPORTED_MODULE_3__[\"default\"].getFilesList().then((response) => { var _a; return this._filesList = (_a = response.data) === null || _a === void 0 ? void 0 : _a.data; });\r\n                this._watchButton.firstElementChild.style.setProperty('visibility', 'visible');\r\n            };\r\n            this._watchButton.onmouseleave = () => this._watchButton.firstElementChild.style.setProperty('visibility', 'hidden');\r\n        };\r\n        this.createWatchToggle = () => {\r\n            this._watchToggle_1 = document.getElementById(\"watch-toggle-item\");\r\n            const arrow_0 = this._watchToggle_1.firstElementChild;\r\n            const onButtonMouseOver = (index) => {\r\n                var _a, _b;\r\n                this._watchToggle_1.replaceChildren(arrow_0);\r\n                arrow_0.style.setProperty('top', (2 + (index * 8.25)).toString() + '%');\r\n                if ((_b = (_a = this._filesList) === null || _a === void 0 ? void 0 : _a[index]) === null || _b === void 0 ? void 0 : _b.length) {\r\n                    this.showContextMenu(index);\r\n                }\r\n                else {\r\n                    this.createJonTravolta();\r\n                }\r\n            };\r\n            for (let i = 0; i < 12; i++) {\r\n                const button = document.getElementById(\"watch-toggle-month-\" + i);\r\n                button.onmouseenter = () => onButtonMouseOver(i);\r\n                this._watchButtons_0.push(button);\r\n            }\r\n        };\r\n        this.onDeleteButtonClick = (contextMenu) => {\r\n            const button = contextMenu.parentElement;\r\n            button.classList.toggle('button-months-deleting');\r\n            this._imageButtonsBlocked = true;\r\n            contextMenu.parentElement.removeChild(contextMenu);\r\n            const [month, name] = contextMenu.nonce.split('/');\r\n            _network_RestService__WEBPACK_IMPORTED_MODULE_3__[\"default\"].deleteSnapshot(month, name).then((_) => {\r\n                button.classList.remove('button-months-deleting');\r\n                this._imageButtonsBlocked = false;\r\n                this._watchToggle_1.removeChild(button);\r\n            });\r\n        };\r\n        this.onImageButtonClick = (button) => __awaiter(this, void 0, void 0, function* () {\r\n            if (button._state)\r\n                return;\r\n            const [month, name] = button.name.split('/');\r\n            this._imageButtonsBlocked = true;\r\n            button.classList.toggle('button-months-downloading');\r\n            const result = yield _network_RestService__WEBPACK_IMPORTED_MODULE_3__[\"default\"].getSnapshot(month, name);\r\n            button.classList.remove('button-months-downloading');\r\n            this._imageButtonsBlocked = false;\r\n            return file_saver__WEBPACK_IMPORTED_MODULE_4___default().saveAs(result, name);\r\n        });\r\n        this.createContextMenu = (index = undefined) => {\r\n            this._contextMenu = document.getElementById(\"context-menu\");\r\n            //@ts-ignore\r\n            this._contextMenu.firstElementChild.onclick = (event) => {\r\n                event.preventDefault();\r\n                event.stopPropagation();\r\n                this.onDeleteButtonClick(this._contextMenu);\r\n            };\r\n            //@ts-ignore\r\n            this._contextMenu.lastElementChild.onclick = (event) => {\r\n                event.preventDefault();\r\n                event.stopPropagation();\r\n                this.onImageButtonClick(this._contextMenu.parentElement).then((_) => {\r\n                    this.onDeleteButtonClick(this._contextMenu);\r\n                });\r\n            };\r\n        };\r\n        this.showContextMenu = (index) => {\r\n            this._imageButtons.length = 0;\r\n            this._filesList[index].forEach((fileName) => {\r\n                const imageButton = this._watchButtons_0[0].cloneNode(true);\r\n                if (!imageButton)\r\n                    return;\r\n                imageButton.textContent = fileName;\r\n                imageButton.style.setProperty('font-size', '24px');\r\n                imageButton.name = this._folders[index] + '/' + fileName;\r\n                imageButton.onclick = () => this.onImageButtonClick(imageButton);\r\n                imageButton.onmouseenter = () => {\r\n                    if (this._imageButtonsBlocked)\r\n                        return;\r\n                    this._imageButtons.forEach((button) => {\r\n                        if (button && button !== imageButton)\r\n                            button.style.removeProperty('background-color');\r\n                    });\r\n                };\r\n                imageButton.oncontextmenu = () => {\r\n                    if (this._imageButtonsBlocked)\r\n                        return;\r\n                    imageButton.appendChild(this._contextMenu);\r\n                    this._contextMenu.style.setProperty('visibility', 'visible');\r\n                    this._contextMenu.nonce = this._folders[index] + '/' + fileName;\r\n                    this._contextMenu.onmouseleave = () => {\r\n                        this._contextMenu.style.setProperty('visibility', 'hidden');\r\n                        imageButton.style.removeProperty('background-color');\r\n                    };\r\n                    imageButton.style.setProperty('background-color', '#ff0000');\r\n                    return false;\r\n                };\r\n                this._imageButtons.push(imageButton);\r\n                this._watchToggle_1.appendChild(imageButton);\r\n            });\r\n        };\r\n        this.createJonTravolta = () => {\r\n            const backgroundImage = document.createElement(\"div\");\r\n            backgroundImage.style.setProperty('background-image', 'url(./images/nothing_here.png');\r\n            backgroundImage.style.setProperty('width', '100%');\r\n            backgroundImage.style.setProperty('height', '100%');\r\n            backgroundImage.style.setProperty('background-repeat', 'no-repeat');\r\n            backgroundImage.style.setProperty('background-position', 'center');\r\n            backgroundImage.style.setProperty('opacity', '77%');\r\n            this._watchToggle_1.appendChild(backgroundImage);\r\n        };\r\n        this.createSaveButtons = () => {\r\n            const localSaveButton = document.getElementById(\"local-save-button\");\r\n            const remoteSaveButton = document.getElementById(\"remote-save-button\");\r\n            const onSaveButtonClick = (button) => {\r\n                if (button.style.getPropertyValue('background-color')) {\r\n                    button.style.removeProperty('background-color');\r\n                }\r\n                else {\r\n                    button.style.setProperty('background-color', '#00ff0077');\r\n                }\r\n            };\r\n            localSaveButton.onclick = () => onSaveButtonClick(localSaveButton);\r\n            remoteSaveButton.onclick = () => onSaveButtonClick(remoteSaveButton);\r\n        };\r\n    }\r\n    get localSaveEnabled() {\r\n        var _a;\r\n        return !!((_a = document.getElementById(\"local-save-button\")) === null || _a === void 0 ? void 0 : _a.style.getPropertyValue('background-color'));\r\n    }\r\n    get remoteSaveEnabled() {\r\n        var _a;\r\n        return !!((_a = document.getElementById(\"remote-save-button\")) === null || _a === void 0 ? void 0 : _a.style.getPropertyValue('background-color'));\r\n    }\r\n}\r\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (new Controls());\r\n\n\n//# sourceURL=webpack://html-peer-viewer/./src/view/Controls.ts?\n}");

/***/ }),

/***/ "./src/view/Matrix.ts":
/*!****************************!*\
  !*** ./src/view/Matrix.ts ***!
  \****************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _utils_Events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/Events */ \"./src/utils/Events.ts\");\n/* harmony import */ var _utils_Constants__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/Constants */ \"./src/utils/Constants.ts\");\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\r\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\r\n    return new (P || (P = Promise))(function (resolve, reject) {\r\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\r\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\r\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\r\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\r\n    });\r\n};\r\n\r\n\r\nclass Matrix {\r\n    constructor() {\r\n        this.initialize = () => __awaiter(this, void 0, void 0, function* () {\r\n            this._page = document.getElementById(\"view-page\");\r\n            this._container = document.createElement(\"div\");\r\n            this._container.id = \"container\";\r\n            this._container.width = \"100%\";\r\n            this._container.style.setProperty('z-index', '9999');\r\n            this._container.style.setProperty(\"position\", \"absolute\");\r\n            this._graphic = document.createElement(\"canvas\");\r\n            this._container.appendChild(this._graphic);\r\n            document.onmousemove = () => this.hide();\r\n            _utils_Events__WEBPACK_IMPORTED_MODULE_0__[\"default\"].addEventListener(_utils_Events__WEBPACK_IMPORTED_MODULE_0__.MATRIX_SCREEN_STATE_CHANGED, (value) => {\r\n                if (value)\r\n                    this.will();\r\n            });\r\n            return this;\r\n        });\r\n        this.show = () => {\r\n            /* let request = new XMLHttpRequest();\r\n             let url = \"https://api.openai.com/v1/responses\"; // Replace with your actual server endpoint\r\n     \r\n             request.open(\"POST\", url, true);\r\n             request.setRequestHeader(\"Content-Type\", \"application/json\");\r\n             request.setRequestHeader(\"Authorization\", \"Bearer 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\");\r\n            \r\n             let payload = `{\r\n             \"model\": \"gpt-5\",\r\n             \"input\": \"    '   '   , ,           ?\"\r\n             }`;\r\n            // res.output[1].content[0].text\r\n             request.onload =() => {\r\n                 if (request.status >= 200 && request.status < 300) {\r\n     \r\n                                   if (!this.exists()) {\r\n                 this._page.appendChild(this._container);\r\n                // this.matrixEffect(this._graphic);\r\n                 this.drawStuff(JSON.parse(request.response).output[1].content[0].text);\r\n             }\r\n            // debugger;\r\n           //  console.log(\"Response received:\", request.response.output.content[0]);\r\n             //           } else {\r\n               //       console.error(\"Request failed. Status:\", request.status, request.statusText);\r\n               }\r\n             };\r\n     \r\n             request.onerror = function() {\r\n                 console.error(\"A network error occurred during the request.\");\r\n             };\r\n     \r\n             request.send(payload);*/\r\n            if (!this.exists()) {\r\n                this._page.appendChild(this._container);\r\n                this.matrixEffect(this._graphic);\r\n            }\r\n        };\r\n        this.hide = () => {\r\n            if (this.exists()) {\r\n                this._graphic.getContext(\"2d\").clearRect(0, 0, window.innerWidth, window.innerHeight);\r\n                this._page.removeChild(this._container);\r\n                clearInterval(this._interval);\r\n                clearTimeout(this._timeout);\r\n                this.will();\r\n            }\r\n        };\r\n        this.will = () => {\r\n            clearTimeout(this._timeout);\r\n            return (this._timeout = setTimeout(() => this.show(), _utils_Constants__WEBPACK_IMPORTED_MODULE_1__.MATRIX_COOLDOWN_DELAY));\r\n        };\r\n        this.exists = () => {\r\n            return document.getElementById(\"view-page\") && document.getElementById(\"container\");\r\n        };\r\n        this.drawStuff = (stuff) => {\r\n            stuff = stuff.match(/.{1,77}/g) || [];\r\n            const canvas = this._graphic;\r\n            const context = canvas.getContext(\"2d\", { willReadFrequently: true });\r\n            const w = (canvas.width = window.innerWidth);\r\n            const h = (canvas.height = window.innerHeight);\r\n            context.fillStyle = \"rgba(0,0,0,.05)\";\r\n            context.fillRect(0, 0, w, h);\r\n            context.fillStyle = \"#ff0077ff\";\r\n            context.font = \"18px 'system-ui'\";\r\n            stuff.forEach((element, index) => {\r\n                context.fillText(element, 222, 222 + index * 22);\r\n            });\r\n        };\r\n    }\r\n    matrixEffect(canvas, font = 24) {\r\n        const context = canvas.getContext(\"2d\", { willReadFrequently: true });\r\n        const w = (canvas.width = window.innerWidth);\r\n        const h = (canvas.height = window.innerHeight);\r\n        const str = \"+0-1=2 3 4 5 6 7  ! ? .b    \" +\r\n            \" , :;      2      3 %$ 4  67 % \" +\r\n            \"6a bc defo#p-qrstu &v*  wxy3z           \" +\r\n            \"1871640532 1 udp 1677729535 188.212777 typ srflx raddr 0.0.0.0 rport 0 generation 0\" +\r\n            \"ufrag AfOL network-coe:832498458 1 udp 1677729535 4147.105 55549 typ srflx\" +\r\n            \" raddr 0.0.0.0 rport 0 generation 0 ufrag 4W3O ne      \t314      \" +\r\n            \"        ?  \t ?                \" +\r\n            \" a  igy    \t  \t     \t4TG\";\r\n        const matrix = str.split(\"\");\r\n        let cols = w / font;\r\n        let pool = [];\r\n        for (let i = 0; i < cols; i++)\r\n            pool[i] = 1;\r\n        const draw = () => {\r\n            context.fillStyle = \"rgba(0,0,0,.05)\";\r\n            context.fillRect(0, 0, w, h);\r\n            context.fillStyle = \"#00ff00\";\r\n            if (Math.random() > 0.9955) {\r\n                context.fillStyle = \"#f00\";\r\n            }\r\n            context.font = font + \"px system-ui\";\r\n            for (let i = 0; i < pool.length; i++) {\r\n                const txt = matrix[Math.floor(Math.random() * matrix.length)];\r\n                context.fillText(txt, i * font, pool[i] * font);\r\n                if (pool[i] * font > h && Math.random() > 0.95)\r\n                    pool[i] = 0;\r\n                pool[i]++;\r\n            }\r\n        };\r\n        this._interval = setInterval(draw, 77);\r\n    }\r\n}\r\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (new Matrix());\r\n\n\n//# sourceURL=webpack://html-peer-viewer/./src/view/Matrix.ts?\n}");

/***/ }),

/***/ "./src/view/Pincode.ts":
/*!*****************************!*\
  !*** ./src/view/Pincode.ts ***!
  \*****************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _utils_Constants__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/Constants */ \"./src/utils/Constants.ts\");\n/* harmony import */ var _utils_Events__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/Events */ \"./src/utils/Events.ts\");\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\r\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\r\n    return new (P || (P = Promise))(function (resolve, reject) {\r\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\r\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\r\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\r\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\r\n    });\r\n};\r\n\r\n\r\nclass Pincode extends _utils_Events__WEBPACK_IMPORTED_MODULE_1__.EventHandler {\r\n    constructor() {\r\n        super();\r\n        this._container = null;\r\n        this._inputs = [];\r\n        this.initialize = () => __awaiter(this, void 0, void 0, function* () {\r\n            const viewport = document.getElementById(\"entry-page\");\r\n            this._container = document.createElement(\"div\");\r\n            viewport.appendChild(this._container);\r\n            for (let i = 0; i < _utils_Constants__WEBPACK_IMPORTED_MODULE_0__.PINCODE_CHAR_LENGTH; i++) {\r\n                let _console = document.createElement(\"input\");\r\n                this._container.appendChild(_console);\r\n                _console.type = 'password';\r\n                _console.maxLength = 1;\r\n                _console.style.setProperty('position', 'absolute');\r\n                _console.style.setProperty('top', '45%');\r\n                _console.style.setProperty('left', 30 + (i * 12) + '%');\r\n                _console.style.setProperty('width', '60px');\r\n                _console.style.setProperty('background-color', 'black');\r\n                _console.style.setProperty('font-size', '48px');\r\n                _console.style.setProperty('text-align', 'center');\r\n                _console.style.setProperty('font-family', 'Courier New');\r\n                _console.style.setProperty('font-weight', 'bold');\r\n                _console.style.setProperty('color', 'green');\r\n                _console.style.setProperty('overflow', 'hidden');\r\n                this._inputs.push(_console);\r\n            }\r\n            this._inputs[0].focus();\r\n            document.onkeyup = (event) => {\r\n                if (this._inputs[this._inputs.length - 1].value) {\r\n                    const pin = this._inputs.map(({ value }) => value)\r\n                        .reduce((accumulator, currentValue) => accumulator + currentValue);\r\n                    this.dispatchEvent(_utils_Events__WEBPACK_IMPORTED_MODULE_1__.CONSOLE_EXECUTE_COMMAND, pin);\r\n                    document.onkeyup = () => { };\r\n                }\r\n                else {\r\n                    for (let i = 0; i < _utils_Constants__WEBPACK_IMPORTED_MODULE_0__.PINCODE_CHAR_LENGTH - 1; i++) {\r\n                        if (this._inputs[i].value) {\r\n                            this._inputs[i + 1].focus();\r\n                        }\r\n                    }\r\n                }\r\n            };\r\n        });\r\n        this.show = () => {\r\n            this._container.style.setProperty('display', 'inline');\r\n        };\r\n        this.hide = () => {\r\n            this._container.style.setProperty('display', 'none');\r\n        };\r\n    }\r\n}\r\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (new Pincode());\r\n\n\n//# sourceURL=webpack://html-peer-viewer/./src/view/Pincode.ts?\n}");

/***/ }),

/***/ "./src/view/View.ts":
/*!**************************!*\
  !*** ./src/view/View.ts ***!
  \**************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   View: () => (/* binding */ View),\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _utils_Events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/Events */ \"./src/utils/Events.ts\");\n/* harmony import */ var _Controls__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Controls */ \"./src/view/Controls.ts\");\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\r\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\r\n    return new (P || (P = Promise))(function (resolve, reject) {\r\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\r\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\r\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\r\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\r\n    });\r\n};\r\n\r\n\r\nclass View extends _utils_Events__WEBPACK_IMPORTED_MODULE_0__.EventHandler {\r\n    constructor() {\r\n        super();\r\n        this.initialize = () => __awaiter(this, void 0, void 0, function* () {\r\n            this.initializeView();\r\n        });\r\n        this.initializeView = () => __awaiter(this, void 0, void 0, function* () {\r\n            //@ts-ignore-line\r\n            //screen.lockOrientation?.(\"landscape\") || screen.lock?.(\"landscape\");\r\n            //document.querySelector(\"img\").src = \"./images/eye_frozen.png\";\r\n            document.querySelector(\"img\").onclick = () => {\r\n                document.getElementById(\"entry-page\").style.setProperty('visibility', 'hidden');\r\n                document.getElementById(\"view-page\").style.setProperty('visibility', 'visible');\r\n                document.getElementById(\"entry-page\").style.display = 'none';\r\n                document.getElementById(\"view-page\").style.display = 'flex';\r\n                _Controls__WEBPACK_IMPORTED_MODULE_1__[\"default\"].initialize();\r\n                this.dispatchEvent(_utils_Events__WEBPACK_IMPORTED_MODULE_0__.USER_PROCEEDED, null);\r\n            };\r\n        });\r\n        // TODO move this somewhere idk/////////////////////////////////////////////////////////////////\r\n        this.displayStream = (stream) => __awaiter(this, void 0, void 0, function* () {\r\n            document.getElementById(\"loader\").style.setProperty('visibility', 'hidden');\r\n            document.getElementById(\"loader\").style.display = 'none';\r\n            const wrapper = document.getElementById(\"video-container\");\r\n            wrapper.style.setProperty('display', 'block');\r\n            const viewport = document.querySelector(\"video\");\r\n            viewport.style.setProperty('visibility', 'visible');\r\n            viewport.style.display = 'flex';\r\n            viewport.onloadedmetadata = viewport.play;\r\n            console.log('[Viewer] displayStream setting viewport sinkId and assigning stream');\r\n            //  if (deviceId) {\r\n            //    (viewport as any).setSinkId(deviceId);\r\n            //   }\r\n            //  viewport.srcObject = stream;\r\n            //this.createDevicesInfoLabel(devices);\r\n        });\r\n        //private onStreamLost\r\n        this.handleMediaDevices = (deviceOptions = { labels: ['720', 'back'] }) => __awaiter(this, void 0, void 0, function* () {\r\n            console.log('[Viewer] handleMediaDevices. starting devices enumeration..');\r\n            let devices = yield navigator.mediaDevices.enumerateDevices();\r\n            console.log('[Viewer] handleMediaDevices got devices: ');\r\n            //devices?.forEach((device: any) => {\r\n            //  let button = document.createElement(\"button\");\r\n            //   button.type = 'radio';\r\n            //   button.style.width = '50%';\r\n            //    button.style.height = '5%';\r\n            //   button.textContent = device.deviceId + '* kind: [' + device.kind + ' ] label: [' + device.label + ']';\r\n            //   button.onclick = (event: any) => {\r\n            //     callback(event.currentTarget.textContent.split('*')[0]);\r\n            //    };\r\n            //     document.getElementById(\"view-page\").appendChild(button)\r\n            //alert(device.label + '-' + device.kind + '-' + device.deviceId);\r\n            //});\r\n            let deviceId;\r\n            if (deviceOptions.labels) {\r\n                deviceOptions.labels.some((label) => {\r\n                    try {\r\n                        deviceId = (devices.find((device) => device.label.includes(label))).deviceId;\r\n                    }\r\n                    catch (e) {\r\n                        console.log('      .device not found...');\r\n                    }\r\n                    if (deviceId) {\r\n                        return deviceId;\r\n                    }\r\n                });\r\n            }\r\n            /*if (!deviceId && deviceOptions.kind) {\r\n              try {\r\n                deviceId = (devices.slice().reverse().find((device) => device.kind === deviceOptions.kind));\r\n              } catch (e) {\r\n                console.log('      .device not found...');\r\n              }\r\n            }  */\r\n            console.log('[Viewer] handleMediaDevices found device: ' + (deviceId != undefined ? deviceId : 'no device found!'));\r\n            return deviceId;\r\n        });\r\n        this.createDevicesInfoLabel = (devices) => {\r\n            console.log('[Viewer] View.createDevicesInfoLabel. devices: ');\r\n            devices.forEach((device, index) => {\r\n                console.log('....deviceId: [' + device.deviceId + ']');\r\n                const _label = document.createElement(\"label\");\r\n                document.getElementById(\"view-page\").appendChild(_label);\r\n                _label.style.setProperty('position', 'absolute');\r\n                _label.style.setProperty('top', String(index * 5 + 45) + '%');\r\n                _label.style.setProperty('right', '3%');\r\n                _label.style.setProperty('font-size', '18px');\r\n                _label.style.setProperty('font-family', 'Courier New');\r\n                _label.style.setProperty('font-weight', 'bold');\r\n                _label.style.setProperty('color', '#00ff30');\r\n                _label.style.setProperty('visibility', 'visible');\r\n                _label.textContent = '[' + device.kind + '] ' + device.label;\r\n            });\r\n        };\r\n    }\r\n}\r\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (new View());\r\n\n\n//# sourceURL=webpack://html-peer-viewer/./src/view/View.ts?\n}");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			// no module.id needed
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/compat get default export */
/******/ 	(() => {
/******/ 		// getDefaultExport function for compatibility with non-harmony modules
/******/ 		__webpack_require__.n = (module) => {
/******/ 			var getter = module && module.__esModule ?
/******/ 				() => (module['default']) :
/******/ 				() => (module);
/******/ 			__webpack_require__.d(getter, { a: getter });
/******/ 			return getter;
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/define property getters */
/******/ 	(() => {
/******/ 		// define getter functions for harmony exports
/******/ 		__webpack_require__.d = (exports, definition) => {
/******/ 			for(var key in definition) {
/******/ 				if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
/******/ 				}
/******/ 			}
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/global */
/******/ 	(() => {
/******/ 		__webpack_require__.g = (function() {
/******/ 			if (typeof globalThis === 'object') return globalThis;
/******/ 			try {
/******/ 				return this || new Function('return this')();
/******/ 			} catch (e) {
/******/ 				if (typeof window === 'object') return window;
/******/ 			}
/******/ 		})();
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/hasOwnProperty shorthand */
/******/ 	(() => {
/******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	(() => {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = (exports) => {
/******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 			}
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
/******/ 		};
/******/ 	})();
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module can't be inlined because the eval devtool is used.
/******/ 	var __webpack_exports__ = __webpack_require__("./src/Entry.ts");
/******/ 	
/******/ })()
;